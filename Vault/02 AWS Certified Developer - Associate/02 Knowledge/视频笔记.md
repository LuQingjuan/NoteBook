#
  - [ ] 五一期间看完一遍AWS视频（34小时）
![[AWS账号#AWS账号|AWS账号]]
    * 20230423 [010/497 +10] 001 002 003 004 005 006 007 008 009 010
    * 20230424 [012/497 +02] 011 013
    * 20230425 [021/497 +09] 012 014 015 016 017 021 022 023 024
    * 20230426 [025/497 +04] 025 026 027 029
    * 20230427 [026/497 +01] 1_Quiz
    * 20230430 [027/497 +01] 030
    * 20230501 [029/497 +02] 031 032
    * 20230502 [031/497 +02] 033 034
    * 20230503 [035/497 +04] 035 036 040 041
    * 20230505 [038/497 +03] 042 2_Quiz 043
    * 20230506 [041/497 +03] 044 045 046

    * 20230500 [000/497 +00]
Pass：
* AWS CLI Setup：018 019 020
* SSH：037 038 039
Summary:
* IAM：028

TODO  047 048 049 050 051 052 053 054 055 056 057 058 059 060 061 062 063 064 065 066 067 068 069 070 071 072 073 074 075 076 077 078 079 080 081 082 083 084 085 086 087 088 089 090 091 092 093 094 095 096 097 098 099 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468

## 关系图
![[Relationship#Relationship|Relationship]]

## Section 1 - Course Introduction - AWS Certified Developer Associate [6 个讲座 • 11 分钟]
  - [X] 1 Course Introduction - AWS Certified Developer Associate [02:18]
    * 通过AWS，我们可以按需使用服务和服务器，容易扩展
  - [X] 2 PLEASE READ: Lectures you can skip if you took a course from me before [01:03]
    * 课程介绍
  - [X] 3 Create your AWS Account [01:48] Hands On
    * 注册AWS账号
  - [X] 4 AWS Account Activation Troubleshooting [02:05]
    * 注册AWS账号问题一览
  - [X] 5 Important Message [00:40]
    * 亲，五星好评哦！
  - [X] 6 About your instructor [02:45]
    * 联系方式
      * Linkedin（分享专业更新）
      * Instagram（分享别人的故事）
## Section 2 - Code & Slides Download [1 个讲座 • 1 分钟]
  - [X] 7 Code & Slides Download [00:15]
    * [代码]()
    * [文档]()
## Section 3 - Getting started with AWS [3 个讲座 • 14 分钟]
  - [X] 8 AWS Cloud Overview - Regions & AZ [08:08]
    * 如何选择接入点：
      * Compliance（符合当地政府规定）
      * Proximity（用户低延时）
      * Available services（服务可获得）
      * Pricing（定价）
    * 可获得区域
      * 每个地区都有许多可用区域，以保证出现异常的情况下，不影响正常使用
    * 服务点
      * 42个国家/地区的84个城市拥有200多个服务点
  - [X] 9 Tour of the AWS Console & Services in AWS [03:52] Hands On
    * 选择地区，越近越好（韩国首尔Seoul）
    * 不是每个区域都有全部的AWS服务。
      * 学习过程中遇到当前区域没有服务时，可以通过搜索aws global infrastructure，访问[全球服务查询网]([aws global infrastructure](https://aws.amazon.com/pt/about-aws/global-infrastructure/)点击 `AWS RegionalServices` [查看拥有服务的区域](https://aws.amazon.com/pt/about-aws/global-infrastructure/regional-product-services/?p=ngi&loc=4&refid=c3defc17-b9e8-4474-b125-209d35aff5a5)
  - [X] 10 About the UI changes in the course [01:50]
    * AWS网站在更新UI，如果学习过程中画面不一样，左上角可以进行 Old Version 和 New Version 的切换
## Section 4 - IAM & AWS CLI [18 个讲座 • 53 分钟]
  - [X] 11 IAM Introduction: Users, Groups, Policies [03:22]
    ![[IAM#IAM|IAM]]
  - [X] 12 IAM Users & Groups [06:55] Hands On
    * 创建monica用户，添加到admin组
      * 创建用户操作：
        * IAM → Users → Create user
        * 提供Management Console权力的权限 Provide user access to the AWS Management Console - optional
        * 考试的角度，选择 IAM user
        * 设置密码
        * → Next
      * 创建组操作：
        * → Create group
        * 设置组名 admin
        * 勾选 管理员访问 策略 AdministratorAccess
        * → Create user group
      * 用户添加到组操作：
        * 勾选 Add user to group
        * 勾选 admin 组
        * → Next
      * 设置 Tag
      * 账号发送给指定的人员
        * 发送email
        * 下载csv文件
    * 创建账号别名
      * Dashboard → （Account Alias）Create
  - [X] 13 IAM Policies [02:50]
    * Policies 策略
  - [X] 14 IAM Policies [06:09] Hands On
    * 操作：
      * IAM → Policies
    * 将用户从管理员组删除
    * 权限直接增加给用户
      * 添加权限并使用已经存在的策略或创建的策略或者直接向用户添加内部策略
      * 查看用户有几个策略
      * 策略如何运作
  - [X] 15 IAM MFA Overview [04:18]
    * 保护 用户及用户组不受危害
      * 密码策略（密码越强，账户越安全）
        * 设置最小长度
        * 要求特定字符类型（大小写，数字，特殊符号）
        * 允许不允许IAM用户更改自己的密码，设置每个一段时间后密码过期，必须更新密码
        * 防止历史上的重复密码
    * ![[MFA#MFA|MFA]]
  - [X] 16 IAM MFA [03:17] Hands On
    * 密码策略操作：
      * IAM → Account Settings → （Password policy）Edit
      * Custom → 修改策略
    * root用户设置MFA操作（仅看看就好，操作后，如果MFA丢了，账号就永远登不进去了）：
      * 右上角用户名 → Security credentials
  - [X] 17 AWS Access Keys, CLI and SDK [04:03]
    * 访问密钥（Access Key）
      * Access Key ID ~= username
      * Secret Access Key ~= password
    * 通过 Management Console（控制台） 访问 AWS
      * 密码 + MFA
    * 通过 Command Line Interface（CLI） 访问 AWS
      * 需要访问密钥（Access Key）
      * 在shell中使用命令和AWS交互
      * 通过CLI可以直接访问AWS服务的公共API
      * 通过脚本管理资源
      * ![[MFA#MFA|MFA]]
    * 通过 Software Developer Kit（SDK） 访问 AWS
      * 代码中调用 AWS 的 API 接口
      * 需要访问密钥（Access Key）
      * SDK 支持很多语言 JavaScript, Python, PIP，.NET, Ruby, Java, Go, Node.js, C++
      * 移动SDK（Android IOS） 传感器 物联网设备SDK
  - [ ] 18 AWS CLI Setup on Windows [01:45] Hands On
    * Pass
  - [ ] 19 AWS CLI Setup on Mac OS X [01:28] Hands On
    * Pass
  - [ ] 20 AWS CLI Setup on Linux [01:30] Hands On
    * Pass
  - [X] 21 AWS CLI [03:50] Hands On
    * 创建Access Key（访问密钥）操作：
      * IAM → Users → 选择用户
      * Security credentials → Create access key
      * 勾选 Command Line Interface（CLI）
        * 推荐AWS CloudShell或AWS CLI V2（这个有点复杂）
    * 配置 CLI configure操作：
  - [X] 22 AWS CloudShell [03:53] Hands On
    * 一个Shell终端，可以直接进行 CLI 操作
  - [X] 23 IAM Roles for AWS Services [01:39]
    * User VS Roles
      * User 是人使用（给User分配的权限，用户可以进行相应的操作）
      * Roles 是服务使用（给Role分配的权限，合适的Role就可以使用相关的服务）
    * 常见的Role
      * EC2 Instance Roles
      * Lambda Function Roles
      * Roles for CloudFormation
  - [X] 24 IAM Roles [02:04] Hands On
    * 操作：
      * IAM → Roles → Create roles
        * EC2（Allows EC2 instances to call AWS services on your behalf.）
        * Lambda（Allows Lambda functions to call AWS services on your behalf.）
  - [X] 25 IAM Security Tools [00:54]
    * IAM Credentials Report（account-level）
    * IAM Access Advisor（user-level）
      * 可以查看服务权限及上次访问这些服务的时间
      * 通过它，可以查看那些权限没有，减少用户可以获取的权限，以符合最小权限原则
  - [X] 26 IAM Security Tools [02:25] Hands On
    * 哪些用户值得你从安全角度来关注
      * IAM → Credential report →  Download credentials report
    * 上次还用某些服务的时间，最近的活动，通常出现在四个小时之内
      * IAM → Users → monica → Access Advisor 
      * 可以删除用户没有使用的服务 
  - [X] 27 IAM Best Practices [01:29]
    * 一般指南
      * 除非必要，一般不用root
      * AWS账户等于一个物理用户
      * 用户分配给组，用户就拥有了组的权限
      * 创建强密码策略
      * 也可以使用MFA增加账户安全性
      * 给AWS服务授权时，使用Role（两个简单的虚拟服务实例ＥC2、
      * 通过CLI/SDK，以命令行方式使用AWS时，必须生成访问密钥
      * 通过 IAM 的 Credentials Report 了解账户的安全性
      * 通过 IAM 的 Access Advisor 了解服务的使用情况
  - [ ] 28 IAM [01:05] Summary
    * 总结
      * Users: mapped to a physical user, has a password for AWS Console
      * Groups: contains users only 
      * Policies: JSON document that outlines permissions for users or groups
      * Roles: for EC2 instances or AWS services
      * Security: MFA + Password Policy
      * Access Keys: access AWS using the CLI or SDK
      * Audit: IAM Credential Reports & IAM Access Advisor

      这里是一个总结为IAM｡
      我们已经看到了IAM用户，他们应该被映射到公司内的实际物理用户｡
      此用户将拥有AWS控制台的密码｡
      现在，我们可以将这些用户分组到组中，
      因此仅限用户｡
      我们可以附加策略或共享概述用户或组权限的JSON文档｡
      我们还可以创建角色，
      这些角色将是身份，但这次可能是EC2实例或其他AWS服务｡
      我们假设，为了安全起见，
      我们可以启用多因素身份验证，以便MFA，
      并为我们的用户设置密码策略｡
      我们可以使用CLI通过命令行管理您的服务，
      或使用SDK通过编程语言管理您的AWS服务｡
      最后，我们可以使用CLI或SDK创建访问密钥来访问AWS｡
      最后，我们可以通过创建IAM凭据报告并使用IAM访问顾问服务来审计IAM使用情况｡
  - [X] 1_Quiz IAM & AWS CLI [10 问题] Quiy
    * 测试
## Section 5 - EC2 Fundamentals [14 个讲座 • 1 小时 22 分钟]
  - [X] 29 AWS Budget Setup [05:11]
    * 允许IAM账户查看账单操作
      * root账号登录
      * 右上角用户名 → Account
      * （IAM User and Role Access to Billing Information）Edit → Activate IAM Access → Update
    * IAM账户查看账单操作
     * IAM账号登录
     * 右上角用户名 → Billing Dashboard
    * 找到收费源，并确认在那个区域的服务收取了费用
      * Bills → Changes by Service
    * 查看免费的资源使用情况
      * Free Tier
    * 创建AWS预算，跟踪成本，在即将达到限制时收到警报
      * Budgets → Create a budget
  - [X] 30 EC2 Basics [05:08]
    * ![[EC2#EC2|EC2]]
  - [X] 31 Create an EC2 Instance with EC2 User Data to have a Website [13:48] Hands On
    * 通过 Console 创建 Linux EC2 Instance
      * EC2 → Instances → Launch Insatances
      * 添加名字 → Add additional tangs
      * 选择操作系统 Amazon Linux
      * 选择Instance type （t2 micro)免费的
        * CPU 内存 成本
      * 设置Key Pair(SSH 登陆示例时使用)
        * Create new key pair
          * Private key file format
            * .pem（其他）
            * .ppk（Windows版本低于10：Windows7 Windows8）
        * 自动下载pem文件
      * 网络设置（不做任何修改）
        * 会自动获取公共IP
        * 设置安全组，用于控制来往于我们实例的流量
          * 首先会自动创建一个安全组（launch-wizard-1），我们可以创建多个规则
          * 允许来自任何地方的 SSH 流量
          * 允许来自网络的http流量，用于启动web服务器
      * 配置存储默认数值
        * 进入Advanced 看一看，不做修改。
          * 终止时删除 Delete on termination
            * 一旦EC2实例停止，这个存储空间就被删除了
        * 返回Simple
      * 高级细节
        * User data
          * 在CE2 实例第一次启动时执行，且在EC2实例整个生命周期中只执行一次。
            * 下面的脚本用于更新一些东西，在机器上安装HTPD 服务器，编写一个html文件
              ```00 Inbox\code_v2023-02-23\ec2-fundamentals\ec2-user-data.sh
              #!/bin/bash
              # Use this for your user data (script from top to bottom)
              # install httpd (Linux 2 version)
              yum update -y
              yum install -y httpd
              systemctl start httpd
              systemctl enable httpd
              echo "<h1>Hello World from $(hostname -f)</h1>" > /var/www/html/index.html
              ```
      * Summary
        * 第一年750小时 t2 micro 免费
    * 启动
    * 查看
      * Instances → Instance state
        * Start instance
        * Stop instance
        * Reboot instance
        * Terminate instance
      * 重新启动 实例后 公共IP发生了变化，私有IP始终不变
  - [X] 32 EC2 Instance Types Basics [05:51]
    * ![[EC2#Instance|EC2]] 
  - [X] 33 Security Groups & Classic Ports Overview [07:26] Hands On
    * ![[EC2#Security|EC2]] 
  - [X] 34 Security Groups [04:45] Hands On
    * 查看实例的安全组信息
      * EC2 → Instances → 选中一个实例 → Security 
    * 查看详细的安全组信息
      * EC2 → Security Groups
        * 默认情况下有两个安全组：默认安全组 & 创建EC2实例时创建的起一个安全组(启动向导安全组)
      * → 选择安全组 → Inbound rules → 选择规则 → Edit Inbound rules
  - [X] 35 SSH Overview [02:47]
    * MAC Linux Windows>=10可以通过SSH 远程访问 EC2 实例
    * 所有的Windows系统都可以通过Putty
    * MAC Linux Windows 都可以在 Web 上通过 EC2 Instance Connect（但是只支持Amazon NX2系统的 EC2 实例）
  - [X] 36 How to SSH using Linux or Mac [07:05] Hands On
    * `> wsl`
    * `$ cd Vault/02\ AWS\ Certified\ Developer\ -\ Associate/Work/`
    * `$ sudo ssh -i EC2Tutorial.pem ec2-user@[Public IPv4 address]`
      * `-i EC2Tutorial.pem`：在 31 创建 EC2 的时候已经下载的`EC2Tutorial.pem`文件
      * `ec2-user`：Amazon Linux 操作系统默认的用户
    * 测试
      * `$ whoami`
      * `$ ping google.com`
    * 退出
      * `$ exit`
      * `$ logout`
  - [ ] 37 How to SSH using Windows [06:08] Hands On
    * pass
  - [ ] 38 How to SSH using Windows 10 [05:01] Hands On
    * pass
  - [ ] 39 SSH Troubleshooting [01:23] Hands On
    * pass
  - [X] 40 EC2 Instance Connect [03:15] Hands On
    * 通过 Web 实现 SSH 访问
      * EC2 → Instances → 选择EC2实例
      * 启动
      * Connect → EC2 Instance Connect → Connect
    * 此处不需要EC2Tutorial.pem密钥文件，因为会上传一个临时的SSH密钥
  - [X] 41 EC2 Instance Roles Demo [04:19] Hands On
    * 在 Amazon Linux EC2 实例中默认安装了AWS CLI
      * `$ aws --version`
      aws-cli/1.18.147 Python/2.7.18 Linux/5.10.177-158.645.amzn2.x86_64 botocore/1.18.6
      * `$ aws iam list-users`
      Unable to locate credentials. You can configure credentials by running "aws configure".
      执行`aws configure`需要手动输入密钥！！！很危险！！！
    * 为 EC2 实体增加 role：（已经创建了）
      * EC2 → Instances → 选择EC2实例 → Actions → Security → Modify IAM role
      * 选择DemoRoleForEC2 → Update IAM role
    * 再次执行`aws iam list-users` 不需要输入密钥了！
  - [X] 42 EC2 Instance Purchasing Options [09:48]
    * ![[EC2#采购选项|EC2]]
  - [X] 2_Quiz EC2 Fundamentals [11 问题] Quiz
    * 
 ## Section 6 - EC2 Instance Storage [13 个讲座 • 54 分钟]
  - [X] 43 EBS Overview [04:57]
    * ![[EBS#EBS|EBS]]
  - [X] 44 EBS [05:34] Hands On
    * 查看EBS Volume
      * EC2 → Instances → 选择EC2实例 → Storage → Block devices → 进入Volume → 选择Volume
      * or
      * EC2 → Volumes
    * 查看实例的AZ（Availability Zone）（因为EBS和AZ是绑定的）
      * EC2 → Instances → 选择EC2实例 → Networking → Availability zone
      * 是：ap-south-1a
    * 创建EBS Volume
      * EC2 → Volumes → Create Volume
        * 设置Size：2G
        * 设置AZ：ap-south-1a
    * EBS Volume附加给实例
      * → 选中EBS Volume → Actions → Attach volume
        * 设置EC2 实例
    * EC2 实例Terminate的时候Delete on termination **Yes**的EBS Volume会被删除
  - [X] 45 EBS Snapshots [02:08]
    * 在任意时间节点给EBS打快照，为EBS卷做备份｡将EBS卷从EC2实例中分离，
    * 跨可用性区域或区域复制这些EBS快照｡
      * 将EBS卷从一个AZ传输到另一个AZ的方式
      * 打EBS快照，拷贝快照，恢复快照
    * EBS快照功能
      * EBS Snapshot Archive（EBS快照归档）
        * 将快照移动到archive tier（归档层），成本最多可降低75%｡
        * 恢复归档需要24到72小时
      * EBS快照回收站
        * 如果你删除你的EBS快照，不是被永久删除，那么他们会在回收站｡
        * 意外删除后，可以从回收站中恢复｡
        * 回收站的保留时间可以设置为一天到一年｡
      * 快速快照恢复 FSR（Fast Snapshot Restore）
        * 强制快照进行完全初始化。
        * 这个功能非常有用，但需要花费大量资金。（越大，越贵，越开越贵）
  - [X] 46 EBS Snapshots [03:41] Hands On
    * 创建快照
      * EC2 → Volumes → 选择Volume → Actions → Create snapshot
    * 查看快照
      * EC2 → Snapshots
    * 拷贝快照（在另一个AZ备份可以应对突发情况）
      * EC2 → Snapshots → 选择Snapshot → Actions → Copy snapshot
    * 通过快照创建EBS Volume
      * EC2 → Snapshots → 选择Snapshot → Actions → Create volume from snapshot
    * 查看EBS Volume（借助快照，我们可以实现EBS Volume从一个AZ拷贝到另一个AZ）
      * EC2 → Volumes
    * EBS快照回收站规则设置
      * EC2 → Snapshots → Recycle Bin → Create retention rule
        * 设置Retention rule name：DemoRetentionRule
        * 设置Resource type：EBS Snapshots
        * 勾选Apply to all resources
    * 删除EBS快照
      * EC2 → Snapshots → 选择Snapshot → Actions → Delete snapshot
    * 恢复EBS快照
      * EC2 → Snapshots → Recycle Bin → Resources → 选择Snapshot → Revocer
  - [ ] 47 AMI Overview [02:45]
    * 
Instuctor：现在我们来讨论支持EC2实例的是AMI, AMI代表Amazon机器映像，
它们代表EC2实例的定制｡
因此，
您可以使用AWS创建的AMI，也可以将其自定义为您自己的AMI, AMI中包含哪些内容？
我们有自己的软件配置，
我们可以定义和设置操作系统，我们可以设置任何监控工具｡ 如果我们创建自己的AMI，
我们将获得更快的靴子时间和配置时间，因为我们希望安装到EC2实例上的所有软件都将通过AMI预打包｡
因此，我们必须构建自己的AMI，它们可以针对特定区域构建，
然后，
如果我们希望使用这些AMI并利用AWS全球基础架构，则可以跨区域复制它们｡
因此，我们可以从不同类型的AMI启动EC2实例｡
到目前为止，我们在本课程中所做的是使用公共AMI，这些AMI由AWS提供｡
Amazon Linux
2 AMI是AWS非常流行的AMI，
它是由AWS自己提供的，但我们可以创建自己的AMI，
因此您必须自己创建和维护它们｡
很明显，有一些工具可以实现自动化，但这是您作为云用户必须完成的任务，或者最后，您可以从AWS
Marketplace AMI启动EC2实例，这是由其他人创建的AMI，可能由其他人销售，
因此AWS上的供应商通常会创建自己的AMI或具有良好配置的软件等，然后他们将通过AMI市场进行销售，以便您购买，从而保存一些时间｡
即使你是一个用户，
你也可以在AWS市场上创建一个销售AMI的业务，这是一些企业所做的事情｡
EC2实例中的AMI进程是如何工作的？
我们将启动一个EC2实例并对其进行自定义｡
然后，我们将停止该实例以确保数据完整性正确，
然后，我们可以根据该实例构建AMI，这样还可以在后台创建EBS快照，
最后，我们可以从其他AMI启动实例，
这就是我们将在演示和下一讲中执行的操作｡
我们有US-EAST-1A，我们可以创建与US-EAST-1B相同的实例，
流程是在US-EAST-1A中启动该实例，
我们将对其进行自定义，然后从中创建AMI，这将是我们的自定义AMI｡
然后，
在US-EAST-1B中，我们将能够从该AMI启动，并将有效地创建EC2实例的拷贝｡
我希望你们很兴奋，我们下节课再见.
  - [ ] 48 AMI [04:59] Hands On
    * 
  - [ ] 49 EC2 Instance Store [02:47]
    * 
解说员：我们已经看到了一种将网络驱动器连接到EC2实例的方法，但它们的性能有限，我说这是有原因的，
因为它的性能确实很好，但有时您需要更高的性能，
这将是一个连接到EC2实例的硬件磁盘｡
因此，
EC2实例是一个虚拟机，但它显然连接到一个真实的硬件服务器｡
其中一些服务器确实有直接连接的磁盘空间，通过物理连接到服务器｡
因此，一种特殊类型的EC2实例可以利用称为EC2实例存储的东西，这是硬件的名称，
即连接到物理服务器的硬盘｡
因此，我们使用EC2实例存储来实现更好的I/O性能｡
我们还确保它们具有良好的吞吐量等特性，因此当您希望获得极高的磁盘性能时，
它们是理想的选择｡
但需要注意的是，如果停止或终止EC2实例（该实例具有实例存储），
则存储将丢失｡
因此，
它被称为临时存储，这意味着EC2实例存储现在可以用作持久的长期存储位置来存储数据｡
那么，什么是它的好用例呢？
如果您有一个缓冲区､ 缓存，您希望有临时数据或临时内容，
这将是一个很好的地方来做这些事情，但不适合长期存储｡
例如，对于长期存储，
EBS就是一个很好的使用案例｡
最后，如果EC2实例的在线服务器发生故障，那么您将面临巨大损失的风险，
因为连接到EC2实例的硬件也将发生故障｡
因此，如果您决定使用EC2实例存储，那么您的全部责任就是确保备份它，
并根据您的需要正确地复制它｡
所以我所说的更好的表现是什么意思，
这只是一个例子来说明它，不需要知道它｡
但是，如果您看一下实例大小I3，
就会发现有一个实例存储连接到这些类型的实例，如果您看一下读取IOPS和写入IOPS，它们对应于我们每秒可以执行的I/O操作数｡
然后，您可以看到，其中一些随机读取IOPS和写入IOPS可以达到3｡
300万或1.
400万，最有表现的一个｡
例如，
与类型为BP2的EBS卷相比，您可以达到32，
000 IOPS｡
所以这是很多｡
但同样，这只是从考试的角度来说明我的观点，
无论何时，
只要您看到EC2实例的高性能硬件连接卷，就可以考虑本地EC2实例存储｡
就这样了｡
我们下节课再见｡ 
  - [ ] 50 EBS Volume Types [05:32]
    * 
讲师：现在我们来讨论EBS容量｡
而且有不同的卷类型｡
今天，它们有六种不同的类型，
我们可以将它们分为几类｡
第一个是gp 2/gp 3，
这是一个通用SSD卷，
可针对各种工作负载平衡价格和性能｡
这也是我们在这门课上用到的东西｡
然后是io1和io2，它们是性能最高的SSD卷，
将用于任务关键型､ 低延迟和高吞吐量工作负载｡
然后，我们有st1卷及其低成本HDD卷，
专为频繁访问的吞吐量密集型工作负载而设计｡
我们有sc1卷，
它将是成本最低的HDD卷，并且将针对访问频率较低的工作负载而设计｡
现在，您如何定义EBS卷？
您可以考虑几个因素，
例如大小､ 吞吐量和IOPS, IOPS是指每秒的I/O操作数｡
显然，当有疑问时，
总是查阅文档｡
现在，对于EC2实例，只有gp2和gp3以及io1和io2可以用作引导卷｡
这意味着根操作系统将在哪里运行｡
现在，让我们更深入地了解一下gp2､ gp3､ io1､
io2和其他一些函数｡
但是gp2､ 通用和调配的IOPS将是您考试中最重要的部分｡
因此，gp2是一种低延迟､ 经济高效的存储，您可以将其用于系统启动卷､
虚拟桌面､ 开发和测试环境｡
大小可以在1 GB到16 TB之间变化｡
所以我们在gp2和gp3之间有差异｡
Gp3是较新一代的卷｡
因此，gp3为您提供了3，
000 IOPS的基准和每秒125 MB的吞吐量｡
然后，我们可以将IOPS提高到16，
000，将吞吐量分别提高到每秒1，
000 MB｡
所以他们没有联系｡
对于gp2，这是较旧的版本｡
它们是小型gp2卷，最多可突发3，000 IOPS｡
然后将卷的大小与IOPS联系起来｡
这意味着，如果您增加IOPS，如果您增加卷上的GB数，
那么您将获得三个以上的IOPS，
最高可达16，000 IOPS｡
这意味着，如果您有5，334 GB，那么您将有16，000
IOPS，并且已经达到最大值｡
从这张幻灯片上你还记得什么？
您还记得，在gp 2/gp 3中，这是为了实现经济高效的存储恢复能力｡
对于gp3，您可以独立设置IOPS和吞吐量，
而对于gp2，它们是相互关联的｡
现在，考试中将出现的其他类型的卷是调配的IOPS｡
如果您有需要持续IOPS性能的关键业务应用程序或需要超过16，
000 IOPS的应用程序，这将是一个非常好的使用情形｡
因此，一般来说，您会遇到这样一种使用情形：您有一个数据库工作负载，
例如，确实使用存储的东西，
它对存储性能和一致性非常敏感｡
在这种情况下，从gp2或gp3卷切换到io1或io2卷将是答案｡
如果我们考虑io1，
io2，io2是新一代｡
它们可以在4到16 TB之间｡
对于Nitro EC2实例，您将获得的最大IOPS为60，
000 IOPS｡
所以请记住，硝基实例给你...
Nitro可让您获得更高级别的IOPS｡
如果您没有Nitro EC2实例，
那么您将获得32，000 IOPS的最大值｡
使用io1和io2，
您可以独立于存储大小增加调配的IOPS，
就像gp3一样｡
我们为什么要用io2？
嗯，它有更多的耐用性和更多的每千兆字节的IOPS在相同的价格io1｡
所以今天使用io2是有意义的｡
还有io2 Block Express的预览版，
大小在4GB到64TB之间｡
而且这是一种性能更高的卷类型｡
这为您提供了亚毫秒级延迟，
并且您将获得最大256，000 IOPS，每GB
IOPS的比率为1，000/GB｡
最后，我们将在下一堂课中看到，
调配IOPS的EBS卷类型支持EBS多连接｡
现在让我们快速讨论一下st1和sc1｡
因此它们不能是启动卷｡
这只能用于以前类型的卷｡
您可以获得最大16 TB的大小｡
这里有两种体积｡
我们有吞吐量优化型硬盘，即st1，它非常适合大数据､
数据仓库存储和日志处理，
可提供每秒500 MB的最大吞吐量和500的最大IOPS｡
然后是冷硬盘，即sc1，它用于归档数据，
即不常访问的数据，当您需要尽可能降低成本时，
就应该使用它｡
这里的最大吞吐量是每秒250 MB，
最大IOPS也是250｡
现在，你不需要记住考试中的所有细节，
你只需要在很高的水平上理解所有这些卷的区别｡
因此，通用SSD与调配IOPS SSD（如果您需要数据库），
以及st1或sc1（如果您需要高吞吐量和最低成本）｡
所以你可以在这个链接里找到我所说的内容的摘要，
好吗？
这是我刚刚给你们拍的一张截图｡
所以不用再记细节了｡
但请记住，如果您还想获得超过32，000 IOPS的性能，
则需要使用带io1或io2的EC2 Nitro，这就是本课的主题｡
希望你们喜欢，
下次课再见.
  - [ ] 51 EBS Multi-Attach [01:45]
    * 
现在我们来讨论一下EBS卷的多连接功能｡
因此，正如名称所示，多连接功能允许您将相同的EBS卷连接到同一可用性区域中的多个EC2实例｡
这是什么意思呢？
这意味着，虽然我们有多个EC2实例，并且我们有一个启用了多连接功能的IO2卷，
但该卷可以一次连接到多个EC2实例，这仅适用于IO1和IO2系列的EBS卷｡
现在，每个实例都将拥有对高性能卷的完全读写权限，这意味着它们可以同时进行读写操作｡
因此，在集群Linux应用程序的情况下（例如，使用Teradata或您的应用程序必须管理并发写入操作），
您可以获得更高的应用程序可用性｡
因此，正如您所知，此多连接功能仅在指定的可用性区域内可用｡
当然，它不允许您将一个EBS卷从一个附加到另一个，因为多附加的另一个限制是，
一次最多可以附加16个EC2实例｡
这是你考试时必须知道的｡
所以要小心这个16号｡
最后，要使其正常工作，您必须使用一个支持集群的文件系统｡
所以它是一个不同于XFS或Xe4的文件系统｡
这只是一个小细节，如果你现在想使用这个功能，你知道，好的，这就是这节课的内容｡
我希望你们喜欢，我们下节课再见｡ 
  - [ ] 52 Amazon EFS [05:12]
    * 
大家好，欢迎来到Amazon
EFS -弹性文件系统讲座｡
EFS是一个托管NFS，它是一个网络文件系统｡
由于它是一个网络文件系统，
因此可以装载在许多C2实例上，这些EC2实例也可以位于不同的可用性区域中｡
这就是EFS的全部力量｡
因此，它具有高可用性､
可扩展性，但价格昂贵｡
它的成本大约是gp2
EBS卷的三倍，而且是按次付费｡
因此，您不必提前调配容量｡
让我解释一下｡
这样，您就有了EFS文件系统，
并在它周围设置了一个安全组｡
然后，您可以拥有EC2实例，例如，其中许多实例位于us-east-1a可用性区域，
或者EC2实例位于us-east-1b可用性区域或us-east-1c可用性区域｡
而且它们都可以通过EFS同时连接到同一个网络文件系统｡
EFS的使用案例包括内容管理､ Web服务､
数据共享和WordPress｡
它在内部使用NFS协议｡
为了控制对EFS的访问，您需要设置一个安全组｡
现在，EFS，非常重要的是要注意，它只兼容基于Linux的AMI，
而不兼容Windows｡
您可以使用KMS在EFS驱动器中启用静态加密，
KMS是Linux上的标准文件系统｡
所以使用POSIX系统，它有一个标准的文件API｡
EFS最酷的一点是，您不需要提前计划容量｡
该文件系统将自动扩展，并且您在EFS中使用的每GB数据都是按使用付费的｡
然后，我们有不同的性能和存储类别｡
EFS的第一个规模是，您可以获得数千个并发NFS客户端和10
GB以上的吞吐量，而且您可以自动扩展到PB级的网络文件系统，这非常好｡
您还可以在EFS网络文件系统创建时设置性能模式，
您有几个选项｡
第一个是“通用”，这是默认设置｡
它用于延迟敏感的用例，如web服务器､
cms等｡
但是，如果您想最大限度地提高吞吐量，您可以使用Max
I/O，这是一种高延迟的网络文件系统，但吞吐量更高，
而且高度并行｡
因此，如果您有大数据应用程序或媒体处理需求，
它将非常有用｡
现在是吞吐量模式，您有不同的选项｡
第一个是Bursting｡
所以你有一个TB意味着它是每秒15兆字节加上每秒100兆字节的突发｡
所以这就是你所得到的那种爆发｡
你不必记住这些数字，但只是让你有一个想法｡
资源调配是指您希望设置吞吐量而不考虑存储大小｡
上一个版本的吞吐量随着存储的增加而增长，
但通过调配，您可以让1 TB的存储达到每秒1
GB的速度，这很好，
因为您已经将吞吐量与存储解除了关联｡
最后，为了让事情变得简单一点，
您可以使用Elastic根据您的工作负载自动向上和向下扩展吞吐量｡
例如，根据您的工作负载，
读取速度可达每秒3 GB，
写入速度可达每秒1 GB｡
当您有不可预测的工作负载时，
这将是一个很好的选择｡
现在，对于存储类，同样有多个选项｡
因此，您可以设置存储层，
并且它的一项功能是在几天后将文件移动到不同的层｡
例如，标准层用于频繁访问的文件，
还有一个不频繁访问层EFS-IA，
如果您检索文件，它将为您提供检索文件的成本｡
但是，当您将这些文件存储在EFS-IA上时，
您将付出更低的代价｡
要启用EFS-IA，您必须使用生命周期策略｡
假设我们有一些EFS标准的常用文件，
但其中一个文件超过60天未被访问｡
然后，由于我们共同设置的生命周期策略，
文件将移动到不同层中的EFS-IA，
这将降低成本｡
现在，就可用性和耐用性而言，您有两种选择｡
您可以将EFS设置为Multi-AZ，
这非常适合生产使用情形，
因为如果可用性区域关闭，它不会影响EFS文件系统｡
但是，如果您希望开发具有一个区域EFS文件系统，
则可以这样做｡
因此，它非常适合开发，但它仅在一个AZ中使用，
默认情况下启用备份，而且它仍然与不常访问的存储层兼容｡
因此，它被称为EFS One Zone-IA，
如果您使用它，它将为您提供更优惠的折扣，
可节省约90%的成本｡
因此，该示例将询问您应该何时使用EFS，
以及应该在EFS网络文件系统上设置哪些选项，以确保验证并符合需求｡
好了，这堂课就到这里｡
我希望你们喜欢，我们下节课再见｡ 
  - [ ] 53 Amazon EFS [11:15] Hands On
    * 
  - [ ] 54 EFS vs EBS [02:05]
    * 
现在我们来讨论EBS卷和EFS文件系统的区别｡
EBS卷一次连接到一个实例，
但使用io1和io2类型卷的多连接功能的极端情况除外，
但这是针对非常特定的使用情形｡
EBS卷也锁定在AZ级别｡
这里有一个例子｡
我们在AZ1中有一个ec2，
并且有一个EBS卷连接到它，但它不能连接到AZ2中的ec2实例｡
现在，对于gp2类型的卷，如果磁盘站点增加，
IO也会增加，但对于io1，您可以单独增加IO｡
要跨AZ迁移EBS卷，我们需要创建快照，
以便将其放入EBS快照，
然后我们可以将快照恢复到另一个AZ｡
我们就是这样从一个方位移动到另一个方位的｡
现在，EBS卷备份将使用IO，因此您不应该在应用程序处理大量流量时运行它们，
因为这可能会影响性能｡
对于ec2实例，如果ec2实例被终止，
则默认情况下实例的根EBS卷将被终止，但是您可以禁用该行为｡
现在对于EFS来说，情况有点不同｡
这是一个网络文件系统，
目标是将其连接到跨可用性区域的数百个实例，
因此我们可以看到其中的区别｡
因此，对于一个EFS文件系统，我们可以在不同的AZ中拥有不同的装载目标，
然后多个实例可以一起共享该文件系统｡
所以这是非常有帮助的，例如，当你有WordPress的时候，
它只适用于Linux实例，因为它使用的是POXIS系统｡
EFS的价位高于EBS，但您可以利用EFS-IA功能来节省成本｡
因此，希望您现在了解EFS和EBS之间的区别，
对于即时存储，它物理连接到ec2实例，因此，如果您丢失ec2实例，也将丢失存储｡
好吧，就这样｡
我希望你们喜欢，我们下节课再见｡ 
  - [ ] 55 EBS & EFS - Section Cleanup [01:31] Hands On
    * 
  - [ ]  EC2 Data Management [9 问题] Quiz
    * 
 ## Section 7 - AWS Fundamentals: ELB + ASG [19 个讲座 • 1 小时 34 分钟]
  - [ ] 56 High Availability and Scalability [05:05]
    * 
讲师：这只是一个简短的讲座，只是简单介绍一下什么是可扩展性和高可用性｡
这是相当初学者的水平，所以如果你对这些概念感到非常自信，
请随意跳过这节课｡
现在，可伸缩性意味着您的应用程序系统可以通过适应来阻止更大的负载｡
因此，有两种可伸缩性｡
这将是垂直可伸缩性或水平可伸缩性，也称为弹性｡
因此，可伸缩性不同于高可用性｡
它们有联系但又不同｡
所以，
我想做的是深入探讨所有这些区别，我们将使用呼叫中心作为一个有趣的例子，真正把事情是如何工作的实践｡
那么，让我们来谈谈垂直可扩展性｡
垂直可伸缩性，这意味着您需要增加实例的大小｡
让我们以电话接线员为例｡
我们有一个初级操作员，我们刚刚聘请他｡
他很棒，但他每分钟只能接五个电话｡
现在，我们有一个高级操作员，他是更大的｡
他每分钟最多能接十个电话｡
所以，
我们基本上已经将初级操作员升级为高级操作员，他的速度更快，更好｡
这就是垂直可扩展性｡
如你所见，它上升了｡
例如，在EC2中，
我们的应用程序在t2上运行｡
我们想升级应用程序，
这意味着我们想在t2上运行它｡
那么，我们什么时候使用垂直可伸缩性？
当你有非分布式系统时，比如数据库，这是很常见的｡
对于数据库来说，
这是很常见的，例如，
在RDS或ElastiCache上，您可以通过升级底层实例类型来垂直扩展这些服务，尽管垂直扩展的程度通常有限制，这是一个硬件限制，但垂直可扩展性对于许多用例来说仍然是不错的｡
现在，我们来谈谈水平可扩展性｡
水平可伸缩性意味着您可以增加应用程序的实例/系统数量｡
让我们再来看看呼叫中心｡
我们有一个接线员，他超负荷了｡
我不想垂直扩展它，
我想雇佣第二个操作员，现在，我刚刚将我的能力增加了一倍｡
实际上，我会再雇一个接线员｡
你知道吗？
我会雇六个接线员｡
我已经横向扩展了呼叫中心｡
因此，当您具有水平扩展时，这意味着您具有分布式系统，
当您具有web应用程序或现代应用程序时，这是非常常见的，但请记住，
并非每个应用程序都可以是分布式系统｡
我认为，
借助Amazon EC2等云产品，横向扩展变得非常容易，因为我们只需右键单击网页，
突然之间，我们就有了一个新的EC2实例，我们可以横向扩展应用程序｡
现在，我们来谈谈高可用性｡
高可用性，
通常与水平扩展密切相关，但并非始终如此｡
高可用性，这意味着您至少在两个数据中心或AWS中的两个可用性区域中运行您的应用程序或系统｡
高可用性的目标是能够在数据中心丢失时幸存下来，因此，如果一个中心发生故障，
我们仍然可以继续运行｡
那么，让我们来谈谈我们的电话接线员｡
也许我会在纽约的第一栋楼里有三个电话接线员，
也许我会在美国另一边的第二栋楼里有三个电话接线员，在弗朗西斯科｡
现在，如果我在纽约的大楼失去了互联网连接或电话连接，那没关系，
他们不能工作，但我在弗朗西斯科的第二栋大楼仍然很好，
他们仍然可以接受电话｡
所以，在这种情况下，我的呼叫中心高度可用｡
现在，
高可用性也可以是被动的，例如，当我们有RDS
Multi AZ时，我们有一种被动的高可用性，但它也可以是主动的，
这是在我们有水平扩展的情况下，所以这是，
例如，我在纽约的两栋大楼里有我所有的电话｡
他们都在同一时间接电话｡
那么，对于EC2来说，这意味着什么呢？
垂直缩放，增加实例的大小，
它将向上或向下缩放｡
例如，现在AWS中最小的实例是t2｡
这是0｡
5 GB RAM､ 1个vCPU，最大的是A u-t12tb1｡
金属，其具有12. 3
TB的Ram和450个vCPU，这是一个相当大的实例，我相信随着时间的推移，这些东西会变得越来越大｡
所以，你可以从非常小的东西垂直扩展到非常大的东西｡
水平扩展，这意味着您可以增加拥有的实例数量，用AWS的术语来说，
这称为横向扩展或纵向扩展｡
Out，当您增加执行严修的数目时｡
在中，
当您减少执行严修数目时，这可用于其他扩充群组或负载平衡器｡
最后，
高可用性是指您在多个AZ上运行同一应用程序的同一实例，因此，这适用于启用了多AZ的自动扩展器组或启用了多AZ的负载平衡器｡
就这样了｡
快速浏览一下高可用性和可扩展性就可以了｡
当你看试题的时候，它们对你来说是必要的因为它们有时候会欺骗你，
所以要确保你对这些很有信心｡
你想想看，他们很容易｡
当你有这些问题的时候，请记住你脑海中的呼叫中心｡
好的，很好｡
我将在下节课上见到你｡ 
  - [ ] 57 Elastic Load Balancing (ELB) Overview [06:15]
    * 
现在我们来了解一下负载平衡｡
您可能会有一个问题，那就是什么是负载平衡？
负载平衡器是一台服务器或一组服务器，用于将接收到的流量转发到多个后端或下游EC2实例或服务器｡
例如，我们有三个EC2实例，它们将由一个弹性负载平衡器（一组后台服务器）作为前端｡
现在，如果有三个用户直接连接到弹性负载平衡器，会发生什么情况？
第一个将在一个后端EC2实例中发送其负载，
由于负载平衡良好，如果另一个用户连接到您的弹性负载平衡器，则会将其发送到另一个EC2实例｡
最后，
如果第三个用户连接到您的弹性负载平衡器，则该用户将再次进行负载平衡并感知到第三个EC2实例｡
因此，
我们的想法是，用户越多，EC2实例之间的负载就越平衡｡
但是，您的用户并不知道他们连接到了哪些后端实例｡
他们只知道他们必须连接到您的弹性负载平衡器，这只为他们提供了一个连接端点｡
现在，
为什么要使用负载平衡器将负载分散到多个下游实例上呢？正如我刚才所说，您将向应用程序公开一个访问点｡
您将无缝地处理下游实例的故障，
因为负载平衡器将具有一些运行状况检查机制，并且可以了解哪些实例不能向其发送流量｡
您可以对实例进行运行状况检查｡
您可以提供SSL终止｡
因此，
如果您的网站有HTTPS加密流量，您可以通过Cookie强制实现粘性､ 跨区域的高可用性，并将公共流量与云上的私有流量分开｡
我们将更深入地探讨这些概念｡
因此，弹性负载均衡器本身就是一个受管理的负载均衡器｡
AWS将管理它，我们将保证它将工作，无论什么｡
AWS将负责升级､ 维护和高可用性｡
它还将为您提供一些配置旋钮来调整负载平衡器的行为｡
这个想法是，
使用弹性负载平衡器是一个不用动脑筋，因为它将花费您比设置自己的负载平衡器更少｡
此外，
如果您必须管理自己的负载平衡器，从可扩展性角度来看，这将是一场噩梦｡
因此，负载平衡器还集成了许多AWS产品和服务｡
其理念是，它可以与EC2实例集成，
当然，我们稍后还会看到与扩展组､ Amazon
ECS､ Certificate Manager､ CloudWatch､ Route
53､ WAF Global Accelerator集成，而且很可能会随着时间的推移而集成更多组件｡
因此，
当涉及到AWS上的负载平衡时，负载平衡器是一个不用动脑筋的东西｡
现在我提到了健康检查｡
因此，
运行状况检查是弹性负载均衡器验证EC2实例是否正常工作的一种方式，因为如果它工作不正常，我们就不想向该实例发送任何流量｡
因此，它们对于负载平衡器至关重要，
它们是通过使用端口和路由来检查运行状况按钮来完成的｡
例如，
在本例中，我将协议设置为HDP，将端口设置为4567，
将端点设置为slash health，因为从应用程序的角度来看，此路由可能是检查应用程序运行状况的一种简单方法｡
如果EC2实例没有以okay响应（通常是HDP的200状态代码）进行响应，则该实例将被标记为不健康｡
并且弹性负载均衡器将不向该实例发送流量｡
好了，现在AWS上有四种托管负载平衡器｡
您可以使用传统的负载平衡器，称为老一代或V1，2009年推出，
称为CLB｡
现在，它与HTTP､ HTTPS､ TCP､
SSL或安全CP兼容｡
总的来说，AWS不希望您再使用该负载平衡器｡
因此，它将在控制台中显示为已弃用，
但仍可以使用｡
然后，我们有了新一代的负载平衡器｡
因此，
我们有2016年推出的应用负载平衡器，即所谓的ALB｡
而且这个支持HTTP､ HTTPS和web套接字协议｡
然后是2017年推出的网络负载均衡器，
支持TCP､ TLS､ 安全CP和UDP协议｡
最后是2020
GWLB的网关负载平衡器，它在网络层运行，因此有三个和IP协议｡
因此，总的来说，我们绝对建议您使用新一代的负载平衡器，
因为它们提供了更多的功能｡
而一些负载平衡器可以设置为内部的，所以私人和私人访问的网络或外部公共负载平衡器，例如，
为您的网站和公共应用程序｡
最后，您需要了解负载平衡器的安全性｡
因此，用户可以使用HTTP或HTTPS从任何地方访问您的负载平衡器｡
因此，
安全组规则将类似于下图，其中端口范围将为80或443｡
源代码是0｡ 0. 0.
0/0，意思是任何地方｡
因此，我们允许用户连接到我们的负载平衡器，但最酷的是，
EC2实例应该只允许直接来自负载平衡器的流量｡
因此，EC2实例的安全组规则看起来会有点不同｡
因此，
它将允许端口80上的HTTP流量，其来源将不是IP范围，而是安全组｡
因此，我们将把EC2实例的安全组链接到负载平衡器的安全组｡
实际上，
这将意味着EC2实例仅允许来自负载平衡器的流量，这是一种增强的安全机制｡
以上是对负载平衡器的概述｡
希望你喜欢｡
显然，
在这一节中，我们将围绕经典的应用负载平衡器和网络负载平衡器进行更多讨论，我们下节课再见｡
  - [ ] 58 Note: About the Classic Load Balancer (CLB) [00:12]
    * 
  - [ ] 59 Application Load Balancer (ALB) [05:49]
    * 
教师：现在，我们来了解一下第二种负载平衡器，
即应用负载平衡器｡
因此，它是一个仅限第七层的负载平衡器｡
这意味着HTTP｡
它还允许您跨计算机路由到多个HTTP应用程序｡
这些机器将被分成一个目标组｡
一旦我们开始动手，这将变得很有意义｡
它允许您对同一EC2实例上的多个应用程序进行负载平衡｡
我们将看到如何使用容器和ECS｡
它还支持HTTP/2和WebSockets｡
它还支持重定向｡
因此，如果您希望它自动将流量从HTTP重定向到HTTPS，
则可以在负载平衡器级别完成｡
它还支持路由路由｡
所以有基于不同目标群体的路由｡
例如，您可以根据URL的目的路径进行路由｡
举个例子吧｡ com/用户和示例｡ com/posts网站上｡
/users和/posts在你的URL中是不同的路径，不同的路径，
所以你可以把这两个东西重定向到不同的目标组｡
我们马上就知道这意味着什么｡
您也可以根据URL的主机名称进行路由｡
因此，如果您的负载平衡器使用一个访问｡
示例中｡ com或其它｡ 示例中｡
com上，
它可以被路由到不同的目标组，您也可以基于查询字符串和标题进行路由｡
所以举个例子｡
com/reserves和id=123&order=false中的一个或多个可能被路由到不同的目标组｡
ALB是应用程序负载平衡器的缩写，当您拥有微服务和基于容器的应用程序时，它们非常有用｡
在我们学习Docker和Amazon ECS之后，ALB将成为首选的负载平衡器，
因为它们具有端口映射功能，允许您重定向到ECS实例上的动态端口，
同样，有关此方面的更多信息，
请直接进入ECS部分｡
相比之下，
如果我们希望在传统负载平衡器的后面有多个应用程序，那么我们就必须有多个传统负载平衡器｡
实际上，我们需要为每个应用程序配置一个负载平衡器，而使用负载平衡器，
我们可以在多个应用程序之前配置一个应用程序负载平衡器｡
所以也许图表会有帮助｡
因此，我们有了外部应用负载平衡器｡
它面向公众，
在它的背后，我们有了第一个由EC2实例组成的目标群体｡
这一个是路由/用户的路由｡
我们还有一个由EC2实例组成的目标组，
这个目标组将是我们的搜索应用程序，它还将进行运行状况检查｡
它将通过/搜索路由的规则进行路由｡
正如你在这里看到的，我们有两个独立的微服务，
它们做不同的事情｡
第一个是用户应用程序｡
第二个是搜索应用程序｡
但它们位于同一个应用程序负载平衡器的后面，该平衡器知道如何根据URL中使用的路由智能地路由到这些目标组｡
那么，目标群体是什么？
第一个是它们可以是EC2实例，并且可以进行管理，
我们很快就会看到这一点｡
它们可由自动缩放组管理｡
它可能是ECS任务，我们将在ECS部分中看到这一点｡
它可能是Lambda函数，这是一个不太为人所知的函数｡
因此，
应用程序负载平衡器可以位于lambda函数之前，我们将在后面的章节中看到什么是Lambda函数，但它们是AWS中称为无服务器的一切的基础｡
最后，它可以是IP地址的前端，
并且必须是私有IP地址｡
因此，
ALB可以路由到多个目标组，并且运行状况检查将在目标组级别完成｡
让我们再举一个例子｡
我们有一个ALB，我们有两个目标群体｡
第一个基于AWS和EC2实例，第二个将在内部部署私有服务器，
也就是在我们自己的数据中心｡
所以对于目标群体来说，你可以存在｡
我们需要指定我们的服务器的私有IP到目标组，选择为他们进行注册｡
现在，
假设我们有一个应用程序，它通过ALB作为请求｡
我们想要的是通过移动的通信将第一个目标组发送给第一个目标组，通过台式机通信将第二个目标组发送给第二个目标组｡
为此，我们可以使用例如查询字符串或参数路由｡
因此，如果在客户端尝试使用的URL中有？
Platform=移动的，
我们可以在ALB重定向规则中写一条规则，即路由规则，来重定向到第一个目标组｡
如果有呢？
Platform=Desktop，
所以这是一个查询字符串或参数，然后我们可以说它重定向到目标组2｡
我不知道你会在哪里做这个，但这只是我提供给你的一个例子，好吗？
在我们开始实际操作之前，首先要了解的是，您的应用程序负载平衡器也有一个固定的主机名，
就像经典的主机名一样｡
应用程序服务器不能直接看到客户端的IP｡
客户端的真实IP将被插入到名为X-Forwarded-For的报头中｡
因此，
您还可以使用X-Forwarded-Ports获取端口，使用X-Forwarded-Proto获取正在使用的协议｡
这意味着我们的客户端IP，也就是12.1.56.78
直接与我们的负载平衡器对话，负载平衡器执行一种称为连接终止的操作｡
当负载平衡器与EC2实例通信时，它将使用负载平衡器IP，
这是EC2实例的私有IP｡
因此，
为了让EC2实例知道客户端IP，它必须查看HTTP请求中的这些额外报头，它们被称为X-Forwarded-Port和Proto｡
好吧，就这样｡
现在，让我们进行实际操作，创建我们的第一个应用程序负载平衡器｡
  - [ ] 60 Application Load Balancer (ALB) [08:34] Hands On - Part 1
    * 
  - [ ] 61 Application Load Balancer (ALB) [04:28]Hands On - Part 2
    * 
  - [ ] 62 Network Load Balancer (NLB) [03:35]
    * 
现在我们来讨论一下网络负载平衡器｡
它是第四层负载平衡器，
因此允许您处理TCP和UDP流量｡
好了，这是低层｡
第七层是HTTP，
第四层是TCP和UDP流量｡
因此，这些都适用于网络负载平衡器，因此，
当您在考试中看到UDP时，请考虑网络负载平衡器或甚至TCP｡
最重要的是，网络负载平衡器的性能非常非常高，
因此它每秒可以处理数百万个请求｡
与应用程序负载平衡器相比，
延迟时间更短｡
这意味着你得到了大约100毫秒，
而ALB是400毫秒｡
网络低平衡器的另一个特点是，每个可用性区域只有一个静态IP，
您可以为每个AZ分配一个弹性IP｡
因此，当您需要使用一组静态IP（可以是弹性IP）公开应用程序时，
这非常有用｡
因此，当考试你说，
“嘿，你的应用程序只能在一个，
两个，或三个不同的IP访问”｡
然后，您需要考虑将网络负载平衡器作为一个选项｡
因此，如果您看到极高的性能､ TCP､ UDP或静态IP，
请考虑使用网络负载平衡器｡
现在使用它不包括在AWS免费层中｡
让我们来看看它是如何工作的｡
因此，它的工作方式与应用程序负载平衡器非常相似｡
我们创建目标组，然后网络负载平衡器将重定向到这些目标组｡
因此我们可以使用例如TCP流量，或者例如在后端使用HTTP，
但仍在前端使用TCP｡
那么目标群体呢？
这才是重要的部位｡
因此，目标组可以是EC2实例｡
这意味着您的网络负载平衡器可以重定向到您的EC2实例，
并向其发送TCP或UDP流量，但您也可以注册IP地址，这些IP地址是硬编码的，必须是硬编码的，必须是私有IP｡
那你为什么要这么做？
当然，您可以发送您拥有的EC2实例的私有IP，
但也可以使用您自己数据中心中的服务器的私有IP｡
因此，它们都可以由同一个网络负载平衡器来处理｡
您也可以在应用程序负载平衡器之前使用网络负载平衡器｡
因此，在这种情况下，NLB位于ALB前面｡
那你为什么要这么做？
例如，借助网络负载平衡器，
您可以获得固定的IP地址，而借助应用负载平衡器，您可以获得处理HTTP类型流量的所有规则｡
因此，这是一个有效的组合｡
现在，您在考试中需要了解的最后一件事是，
网络负载平衡器目标组执行的运行状况检查支持三种不同的协议｡
它们支持TCP协议､ HTTP协议和HTTPS协议｡
因此，如果您的后端应用程序支持HTTP或HTTPS协议，
那么您完全可以在这些协议上定义一个健康检查｡
好了，网络负载平衡器到此结束｡
希望你喜欢｡
我们下节课再见｡ 
  - [ ] 63 Network Load Balancer (NLB) [04:36] Hands On
    * 
  - [ ] 64 Gateway Load Balancer (GWLB) [03:47]
    * 
现在我们来讨论一种最新的负载平衡器，称为网关负载平衡器｡
因此，
它可用于在AWS中部署､ 扩展和管理您的第三方网络､ 中立设备群｡
它马上会解释这意味着什么｡
因此，如果您希望网络的所有流量都通过防火墙或入侵检测和防御系统，
您可以使用网关负载平衡器｡
因此，IDP或深度数据包检测系统，或者您想要修改一些有效负载，
但在网络级别｡
好吧，我会的
让我们用一个图表把它变得非常简单｡
因此，
假设有用户，这些用户用于访问您的应用程序｡
现在我们知道，他们的用户可以使用负载平衡器和应用程序（或平衡器）直接访问我们的应用程序｡
然后，流量直接从用户进入ALB，再进入应用程序｡
但是，如果您希望在将所有网络流量发送到应用程序之前先对其进行检查，那么您实际上部署了一系列第三方虚拟设备，
例如EC2实例，您希望所有流量在到达应用程序之前都经过这些实例｡
因此，要做到这一点，
过去非常复杂，
但现在有了网关负载平衡器，它实际上非常简单｡
因此，
您将创建一个网关负载平衡器，并在后台执行此操作｡
必须在VPC中更新路由表｡
现在这是相当先进的，它更多的是在网络方面，
但请耐心等待｡
因此路由表被修改｡
现在，
所有用户的流量首先通过网关负载平衡器，然后网关负载平衡器将该流量分布到虚拟设备的目标组中｡
因此，
所有流量都会到达这些设备，然后这些设备会分析流量，执行任何必须执行的操作｡
例如，防火墙､
入侵者检测等等｡
然后，
如果他们对它满意，他们可以将它发送回网关负载平衡器｡
如果他们不满意，他们可以直接放弃流量｡
例如，对于防火墙，您可以丢弃流量，
但如果流量被接受，
则它会再次通过网关负载平衡器，然后网关负载平衡器会将流量转发到您的应用程序，并为您的应用程序转发｡
这是透明的｡
现在唯一发生的事情是所有流量都通过了网关负载平衡器｡
以及第三方巡逻设备，用于分析所有网络流量，并可能丢弃这些流量｡
这就是网关负载平衡器的功能，它可以分析网络流量等｡
那这是怎么做到的呢？
网关负载平衡器的运行级别比我们看到的所有负载平衡器都要低｡
这是第三层，是IP数据包的网络层｡
因此，网关负载平衡器有两个功能｡
第一个是透明网络网关，因为VPC中的所有流量都将通过一个入口和一个出口，它将成为网关负载平衡器，
然后成为负载平衡器，因为它将流量分布在一组虚拟设备和目标组之间｡
这基本上就是您所记得的网关负载平衡器｡
最后，
如果您在考试中看到，您希望在端口6081上使用热内夫协议｡ 同样，
如果您不使用负载平衡器，这将是立即完成的｡
希望这张图是有意义的｡
现在，
对于网关负载平衡器，哪些可以作为目的组呢？这是您得第三方设备.
它们可以是EC2实例（您按实例ID注册它们），也可以是IP地址｡
在这种情况下，它们必须是私有IP｡
例如，如果您在自己的网络和数据中心中运行这些虚拟设备，
则可以手动按IP注册它们｡
以上就是网关负载平衡器的全部内容｡
这是非常困难的做一个动手｡
所以我会跳过一个｡ 好吧，我会的
但你要知道，最重要的是要记住右手边的一张图，如果你理解这张图，
你就明白了，这是逃逸负载平衡器｡
我不认为任何深入的问题会被问到它只是在一个高层次，它的意思是什么，它是如何工作的｡
好吧，我会的
原来如此｡
我希望你们喜欢，下节课再见｡
  - [ ] 65 Elastic Load Balancer - Sticky Sessions [05:41]
    * 
教师：我们来谈谈粘性会话，
也称为弹性负载均衡器的会话关联｡
因此，可以实现所谓的粘性或粘性会话，
其思想是向负载均衡器发出两个请求的客户端将在后端具有相同的实例来响应请求｡
例如，您有一个带有两个EC2实例的ALB，
并且您有三个客户端｡
如果客户端发出一个请求，
并且它转到第一个EC2实例，
这意味着当它向负载均衡器发出第二个请求时，
它将转到同一个实例｡
这是一种不同的行为，
通常应用程序负载均衡器会将所有请求分散到所有EC2实例中｡
现在对于客户端2，如果它转到ALB并与第二个实例对话，
则所有请求都将转到那里｡
客户3也是如此｡
好吗？
因此，可以为经典负载平衡器､
应用程序负载平衡器和网络负载平衡器启用此功能｡ 至于其工作原理，
有一个cookie作为请求的一部分从客户端的两个负载平衡器发送｡
它具有粘性和到期日期，这意味着当cookie到期时，
客户端可能会被重定向到另一个EC2实例｡
这种情况的用例是确保用户连接到相同的后端实例，
以免丢失其会话数据｡
它可以获取一些重要信息，
例如用户的登录｡
但是如果你开启粘性，
可能会带来后端EC2实例负载不平衡的问题，
比如有的实例我有一个非常非常粘性的用户｡
好的｡
现在再深入一点，
关于饼干本身呢？
有两种类型的cookie可以用于粘性会话｡
第一种是基于应用程序的cookie，
第二种是基于持续时间的cookie｡
因此，对于基于应用程序的cookie，
它是由目标生成的自定义cookie，因此由您的应用程序本身生成｡
您还可以根据应用程序的需要包含任何自定义属性｡
必须为每个目标组单独指定cookie名称，
好吗？
并且您不能使用以下名称，例如AWSALB､
AWSALBAPP或AWSALBTG，因为它们已经保留供ALB本身使用｡
或者它可以是应用程序cookie，
并且这个时间将由负载均衡器本身生成｡
ALB使用的cookie名称将是AWSALBAPP｡
好吗？
第二种类型的cookie是基于持续时间的cookie，
它是由负载均衡器生成的cookie｡
名字是AWSALB代表ALB, AWSELB代表CLB｡
好吗？
这个想法是这个将有一个基于特定持续时间的到期日，
持续时间由负载均衡器本身生成｡
好吗？
而在此之前，有一个基于应用程序的cookie，
因此持续时间可以由应用程序本身指定｡
这就是它的工作原理，好吗？
您不需要确切地记住cookie的名称或您有自定义和应用程序的事实，
但您记得有基于应用程序的cookie和基于持续时间的cookie，它们有一个特定的名称，当我们谈论CloudFront时，这将被考虑在内｡
好吗？
如果我现在查看我的负载均衡器，
并在新选项卡中打开它，您可以看到它在负载均衡器中的三个实例之间运行｡
所以这是完美的｡
但现在我要启用粘滞会话｡
为此，我将转到目标组级别，打开我的目标组，
然后Action｡
我将可以编辑我的目标组的属性｡
在底部我有粘性或粘性会话｡
正如我们所看到的，
我们有两种类型的粘性｡
好吗？
我们有负载平衡器生成的cookie，
它是一种持续时间类型的粘性｡
所以我可以说在一秒到七天之间｡
或者，我可以使用基于应用程序的cookie，
同样是1秒到7天，但这一次我需要指定应用程序发送给负载均衡器的cookie名称｡
所以它可能是我的定制饼干｡
这就是负载均衡器用来执行粘性的东西｡
好吗？
粘性就是这样｡
正如我们所看到的，
如果我们只是有一个负载平衡器生成的cookie，
我们设置粘性持续时间等于一天，我将保存这个更改｡
现在让我们来看看｡
所以我也要打开调试器，这样我们就可以看看网络，
看看会发生什么｡
所以如果我们看一下网络，
然后我刷新这个页面，正如我们所看到的，
我刷新了多次｡
好吗？
您可以访问同一个实例｡
所以7-176是一个回来，
回来，回来，回来｡
现在将要发生的是，当你看到向负载均衡器发出的GET请求时，
我非常非常抱歉这里的字体大小，
我不认为我真的可以增加它｡
但是如果你去Cookie，正如你在这里看到的，
有一个响应cookie，好吗？
这意味着您的cookie将于明天到期｡
这里是路径，这里是cookie的值｡
然后在请求cookie中，
当浏览器向负载平衡器发出请求时，它会再次发送它在这里拥有的cookie｡
由于cookie被传递和发送，这就是粘性的工作方式｡
好吗？
我们来深入探讨一下粘性是如何工作的｡
但这就是这节课的内容，我希望你们喜欢｡
顺便说一下，要访问Web开发人员工具，请单击Web Developer，然后单击Web
Developer Tools｡
我用了一条捷径｡
在Chrome和Firefox上也是如此｡
然后你进入网络，
你可以访问你的信息围绕你的请求｡
好吗？
最后，只要回到你的目标群体，
然后你编辑属性本身，你可以禁用粘性回到正常的行为｡
我们应该可以走了｡
这就是今天的讲座，我希望你们喜欢｡
我们下节课再见｡ 
  - [ ] 66 Elastic Load Balancer - Cross Zone Load Balancing [05:53]
    * 
教练：现在我们来谈谈跨区域平衡｡
让我们举一个非常不平衡的情况的例子，
但它会说明这一点｡
因此，我们有两个可用性区域，第一个区域有一个负载平衡器，
其中包含两个EC2实例｡
而第二个也有一个负载平衡器｡
因此，负载平衡器实例显然具有八个EC2实例｡
负载平衡服务实例是同一个更通用的负载平衡器的一部分｡
因此，客户端正在访问这些负载平衡器｡
因此，通过跨区域负载平衡，每个负载平衡器实例将在所有可用性区域中的所有注册实例之间均匀分布｡
因此，客户端本身将50%的流量发送到第一个ALB实例，
并将50%的流量发送到另一个ALB实例｡
但是，每个ALB将跨所有10个EC2实例重定向流量，
而不管它们位于哪个可用性区域｡
这就是它被称为跨区域负载平衡的原因｡
如果你看一下第二个ALB的第一个，
对不起，它将发送它接收的流量的10%，
好吗？
因为我们有10个实例｡
所以他们每个人得到10%的流量｡
第一个ALB实例也是如此｡
它还将向所有这些实例发送10%的流量｡
因此，在本例中，通过跨区域平衡，
我们在所有EC2实例之间平均分配流量｡
然后也许是你想拥有或不想拥有的东西，谁知道呢，
但至少这种行为对你来说是可用的｡
第二个可用的行为是不进行跨区域平衡｡
因此，我们采用相同的示例，
但没有跨区域平衡｡
请求，抱歉，请求分布在弹性负载均衡器节点的实例中｡
在本例中，客户端将50%的流量发送到第一个AZ，
将50%的流量发送到第二个AZ｡
但第一个ALB实例将仅向其区域中的EC2实例发送流量｡
因此，这意味着在这个令人遗憾的能力区域中的每个EC2实例将获得总体流量的25%，
对吗？
所以一半一半｡
右侧的实例将再次将其接收的流量划分到在其AZ内注册的EC2实例中｡
所以AZ2
因此，我们可以看到，在没有交叉平衡的情况下，
流量包含在每个AZ中｡
但是，如果每个AZ中的EC2实例数量不平衡，
则特定AZ的某些EC2实例将比其他实例接收更多流量｡
这只是一个选择｡
答案没有对错之分｡
显然，这取决于用例｡
因此，对于应用平衡器，默认情况下将启用跨区域负载平衡，
但您可以在目标组级别禁用它，
并且如果您的数据跨可用性区域传输，将不会产生任何费用，
因为通常在AWS中，如果数据从一个AZ传输到另一个AZ，您将需要支付一些费用｡
但对于应用程序平衡器，
由于默认情况下启用了跨区域下行，
因此您不会对AZ间数据收取任何费用｡
现在，如果考虑网络负载平衡器和网关负载平衡器，
则默认情况下禁用跨区域负载平衡｡
如果启用它，您将需要支付一定的费用，
因为数据将从一个AZ传输到下一个AZ｡
最后，对于传统负载平衡器，
默认情况下它是禁用的，如果您启用它，
您将不会为AZ间的数据传输付费｡
好的，为了便于实际操作，我创建了一个工作负载平衡器､
一个应用程序平衡器和一个网关负载平衡器｡
我们先来看看网络负载平衡器｡
如果我向下滚动并单击属性，您可以看到跨区域低平衡已关闭，
但我可以编辑此选项并将其打开｡
如您所见，我将启用跨区域平衡，
这可能包括您的NLB的一些区域费用｡
因此，这是网关低平衡器的类似设置，因为它们在这方面具有类似的行为｡
同样，对于属性，跨区域负载平衡是关闭的，
但我可以对其进行编辑并将其打开｡
而这将意味着数据收费｡
现在，如果您看一下应用程序负载平衡器，
就会发现它有点不同｡
因此，如果转到属性，
您可以看到跨区域负载平衡在默认情况下处于打开状态｡
如果我编辑它，然后向下滚动，如你所见，我将在一秒钟内向你展示｡
如你所见，跨区域平衡一直都是开着的，
好吗？
这条信息你可以丢弃它，
因为我认为它是错误的｡
但无论如何，跨区域负载平衡始终为ALB打开｡
但是，如果您转到实际的目标组，也就是说，
如果我转到为此创建的目标组，然后转到目标组的属性，
我们实际上可以进行编辑｡
对于此处的跨区域负载平衡，我们可以从低平衡器属性继承设置（默认情况下处于打开状态），
也可以强制打开或关闭，然后针对特定目标组将其关闭｡
在演示经典负载平衡器时，
我这次不会包括它，因为经典负载平衡器将不再使用｡
它是上一代产品，
很快就要退役了｡
所以我认为你不需要知道它的考试｡
好吧，让我们看看｡
在本课中，请确保您是否希望按照步骤删除负载平衡器｡
我希望你们喜欢，我们下节课再见｡ 
  - [ ] 67 Elastic Load Balancer - SSL Certificates [06:04]
    * 
教师：好的，现在我们来讨论SSL和TLS证书｡
这是一个简化版的工作原理｡
这显然要复杂得多，但我想向你介绍一些概念，
以防你不知道｡
即使您知道SSL和TLS，也请观看本讲座｡
我将讨论SNI以及与负载平衡器的集成｡
所以请耐心等待｡
因此，SSL证书允许客户端和负载平衡器之间的流量在传输过程中进行加密｡
这称为动态加密｡
这意味着数据在通过网络时将被加密，
并且只能由发送方和接收方解密｡
SSL是指安全套接字层，用于加密传输连接｡
TLS是SSL的更新版本，
它指的是传输层安全｡
但问题是，现在，TLS证书是主要使用的一种，
但人们，包括我自己，我仍然将其称为SSL｡
所以我犯了个错误，
但我是故意的，好吗？
所以说TLS证书比SSL证书更好，
但出于多种原因，我还是说它是SSL，因为它更容易理解｡
公共SSL证书由证书颁发机构颁发，它们包括Comodo､
Symantec､ GoDaddy､
GlobalSign､ Digicert､ Letsencrypt等｡
使用这个附加到负载平衡器的公共SSL证书，
我们能够加密客户端和负载平衡器之间的连接｡
所以每当你去一个网站，
例如谷歌｡ com或任何其他网站，
你有一个锁或绿色锁，这意味着你的流量是加密的｡
如果流量没有加密，你会有一个红色的标志，
说，“嘿，流量没有加密｡
不要把你的信用卡详细资料｡
不要把你的登录信息，因为它不安全｡ SSL证书，它们有一个到期日期，
你可以设置，它们必须定期更新，以确保它们是真实的，
好吗？
那么，从负载平衡器的角度来看，它是如何工作的呢？
所以用户通过HTTPS连接，
它是S，因为它使用SSL证书，
而且是加密的｡
它是安全的，
它通过公共互联网连接到您的负载平衡器｡
在内部，您的负载平衡器会执行SSL证书终止｡
在后端，它可以使用HTTP与您的EC2实例通信，
因此不加密，但流量通过您的VPC，这是专用流量网络｡
这是安全的｡
因此，负载平衡器将加载一个X｡ 509证书，称为SSL或TLS服务器证书｡
您可以使用ACM（即AWS证书管理器）在AWS中管理这些SSL证书｡
所以我们不会在这节课上讨论ACM，
只是想了解一下它是什么｡
现在，如果您愿意，还可以将自己的证书上载到ACM｡
设置HTTPS侦听器时，
必须指定默认证书｡
然后，您可以添加一个可选的证书列表以支持多个域，
客户端可以使用称为SNI或服务器名称指示的东西来指定它们要访问的主机名｡
别担心，我将在下一张幻灯片中详细解释什么是SNI，
因为了解它的含义对您来说非常重要｡
这意味着，如果您希望支持所有版本的SSL和TLS（也称为传统客户端），
您还可以为HTTPS设置特定的安全策略｡
好吧，那我们来谈谈SNI吧，因为它太重要了｡
SNI解决了一个非常重要的问题，即如何将多个SSL证书加载到一个Web服务器上，
以便该Web服务器为多个网站提供服务？
还有一个较新的协议，现在要求客户端在初始SSL握手中指示目标服务器的主机名｡
所以客户端会说，“我想连接到这个网站｡
并且服务器将知道要加载什么证书｡
所以，这是一个更新的协议，这是新的东西｡
并非每个客户端都支持此功能｡
因此，只有当您使用应用负载平衡器和网络负载平衡器时，它才能正常工作，
因此，新一代产品或CloudFront｡
我们将在本课程的后面部分了解CloudFront是什么｡
当您使用传统负载平衡器时，
它不起作用，因为它是老一代的｡
因此，每当您在负载平衡器上看到多个SSL证书时，
请考虑ALB或NLB｡
作为一个图表，它看起来像什么？
我们这里有ALB，我们有两个目标群体｡
第一个是www. 真菌 第二个是Domain1｡
示例中｡ com的网站｡
因此，ALB将基于某些规则路由到这些目标组，
并且这些规则可以直接链接，在本例中链接到主机名｡
因此，ALB将具有两个SSL证书：网域1｡
示例中｡ com和www. 真菌 com，
其对应于相应的目标群体｡
现在，客户端连接到我们的ALB，
并说：“我想www｡ 真菌 com”，并且这是服务器名称指示的一部分｡
ALB说，“好吧，我知道你想要mycorp｡ com的网站｡
让我使用正确的SSL证书来填写该请求｡
因此，
它将采用正确的SSL证书，加密流量，然后通过路由，它将知道如何重定向到正确的目标组mycorp｡
com的网站｡
显然，如果您有另一个客户端连接到Domain1的ALB｡
示例中｡ com，
然后您将能够再次拉取正确的SSL证书，
并连接到正确的目标组｡
因此，使用SNI或服务器名称指示，
您可以为使用不同SSL证书的不同网站拥有多个目标组｡
好极了｡
最后，SSL证书支持什么？
因此，经典负载平衡器是可以的，您只能支持一个SSL证书｡
如果您希望多个主机名具有多个SSL证书，
最好的方法是使用多个经典负载平衡器｡
对于ALB, v2，
你需要，你可以支持多个监听器拥有多个SSL证书｡
这就是它的伟大之处，它使用SNI来使它工作｡
我们刚刚看到了它是什么｡
对于NLB或网络负载平衡器，
它同样支持具有多个SSL证书的多个侦听器，
并且它将再次使用SNI来使其工作｡
  - [ ] 68 Elastic Load Balancer - SSL Certificates [01:59] Hands On
    * 
  - [ ] 69 Elastic Load Balancer - Connection Draining [02:22]
    * 
教师：现在我们来讨论一个可能会在考试中出现的功能，称为“连接清空”｡
实际上，它有两个名字｡
如果您使用的是传统负载平衡器，则称为“连接耗尽”，但如果您使用的是应用程序平衡器或网络负载平衡器，
则称为“注销延迟”｡
这个概念背后的想法是，
在实例被注销或标记为不正常时，它将为您的实例给予一些时间来完成正在进行的请求或活动的请求｡
一旦连接被清空，
也就是说一旦实例被清空，ELB将停止向注销时被清空的EC2实例发送请求｡
让我们看一下图表，以便更好地理解｡
因此，我们有三个EC2实例，
其中一个实例将设置为清空模式｡
因此，已经连接到EC2实例的用户将有足够的时间（即耗尽期）来完成其现有连接和现有请求｡
然后一旦一切都完成了，那么所有的连接将被关闭｡
现在，如果新用户尝试连接到我们的ELB，
我们的ELB足够智能，
能够知道因为我们的EC2实例处于耗尽状态，所以它将只与其他EC2实例建立新连接，
例如，我的第二个EC2实例或我的第三个EC2实例｡
现在，您可以参数化这些“连接排出”参数｡
因此，您可以将其设置为1到3，600秒之间的任意值｡
默认情况下，它是300秒，
也就是5分钟，如果将值设置为零，则可以完全禁用它，
这意味着不会发生排水｡
现在，如果您将其设置为低值，
那么，
如果您的请求很短，这是很好的选择，例如，
如果有非常非常短的请求，比如说，不到一秒，那么，将draining
connection参数设置为30秒是一个好主意，因为这样可以非常快地清空EC2实例，然后使其脱机｡ 也许是要被替换或者类似的事情｡
如果您的请求可能很长，例如，
如果您有上传或长期请求，
那么您需要将其设置为相当高的值，但代价是EC2实例不会尽快消失，它必须等到连接耗尽期结束后才能消失｡
因此，这是您需要了解的有关此设置的高级信息｡
我希望你们喜欢它，我们下节课再见｡ 
  - [ ] 70 Auto Scaling Groups (ASG) Overview [04:42]
    * 
教师：现在我们来讨论一下什么是自动扩展组｡
因此，当我们部署一个网站或应用程序时，
负载会随着时间的推移而变化，
因为随着时间的推移，我们可能会有更多的用户访问我们的网站｡
我们已经看到，
在云中，在AWS中，我们可以使用EC2实例创建API调用快速创建和删除服务器｡
因此，
如果您希望自动执行此操作，我们可以创建一个自动扩展组｡
因此，ASG的目标是横向扩展，这意味着添加EC2实例，
您需要记住这一点，
横向扩展以匹配增加的负载，或横向扩展，这意味着删除EC2实例以匹配减少的负载｡
因此，ASG的规模将随着时间的推移而变化｡
总的来说，
我们还可以定义参数，以确保在ASG中随时运行最小和最大数量的EC2实例｡
ASG还有一个超级功能，
如果您将其与负载平衡器配对，则作为ASG一部分的任何EC2实例都将链接到负载平衡器｡
另一个超级功能是，如果一个实例被认为是不健康的，它将被终止，
并创建一个新的EC2实例来替换它｡
因此，自动扩展组是免费的，您只需为在其下创建的任何资源（如EC2实例）付费｡
让我们来看看ESG在AWS中的工作方式｡
因此，
我们设置了一个最小容量，即您希望ASG中至少有多少个实例｡
比如说，两个｡
然后设置所需容量，即ASG中需要的实例数，
例如四个，
然后设置最大容量，即ASG中最多需要多少个实例｡
这意味着，
如果您将所需容量移至更高的数字，但仍低于最大容量，则可以根据需要进行横向扩展｡
这意味着横向扩展意味着添加EC2实例，因此您的ASG可以越来越大｡
在本例中，最大容量为7｡
正如我所说的，ASG还可以与负载平衡器一起工作｡
因此，
如果我们在ASG中注册了四个实例，则ELB会立即将流量分发到所有这些实例，以便您的用户可以访问负载平衡的网站｡
但是ELB还能够使用运行状况检查来检查EC2实例的运行状况，并且可以将该运行状况检查传递给ASG｡
这意味着，
如果负载平衡器认为EC2实例不正常，ASG可以终止它们，这非常方便｡
此外，如果您进行横向扩展，
也就是说，如果您添加EC2实例，
那么ELB当然也会向它们发送流量并分散负载｡
因此，使用负载平衡器和自动扩展组确实是一个很好的组合｡
现在，
就创建ASG的属性而言，您需要创建一个启动模板｡
曾经有一种东西叫做启动配置，
但它已经过时了，但想法是一样的｡
启动模板包含有关如何在ASG中启动EC2实例的信息｡
因此，您可以获得有关AMI和实例类型､ EC2用户数据､
EBS卷､ 安全组､
SSH密钥对､ EC2实例的IAM角色､
网络和子网信息以及负载平衡器信息等信息｡
因此，所有这些参数看起来都很像我们在创建EC2实例时指定的参数｡
最重要的是，
您的ASG有一个最小大小､ 一个最大大小和一个初始容量，我们需要定义它们以及扩展策略｡
谈到扩展策略，让我们看看CloudWatch警报如何与自动扩展集成｡
当然，你们还不知道什么是CloudWatch，
但现在让我来简单介绍一下｡
因此，基于CloudWatch警报的ASG可以进行横向扩展和纵向扩展｡
例如，我们这里有一个ASG，
其中有三个EC2实例，
警报将被触发，因此我们将进行横向扩展活动｡
那么什么会触发警报呢？
它是一个可以返回的指标，
例如，平均CPU或任何您想要的自定义指标｡
例如，如果ASG的平均CPU整体过高，
则需要添加EC2实例，因此警报将被触发，并将触发自动扩展组中的扩展活动，
这就是它被称为自动扩展组的原因，因为与警报配合使用时，
在后台有一个自动扩展功能｡
因此，根据警报，我们可以创建横向扩展策略｡
这意味着增加实例的数量，或者我们可以在策略中创建规模来减少实例的数量｡
所有这些因素共同构成了ASG｡
我希望你们喜欢它，我们下节课再见｡ 
  - [ ] 71 Auto Scaling Groups [09:10] Hands On
    * 
  - [ ] 72 Auto Scaling Groups - Scaling Policies [05:00]
    * 
教师：现在，我们来讨论自动扩展组扩展策略｡
我们有两种不同的策略，首先是动态扩展策略｡
因此，
在动态缩放策略中，我们有三种，我们有目标跟踪缩放，这很容易｡
这是最简单､ 最容易设置的｡
例如，我希望跟踪所有EC2实例中自动扩展组的平均CPU利用率，
使其保持在40%左右｡
这是当你想有一个默认的基线，并希望确保你总是可用｡
简单和逐步缩放比较复杂｡
因此，
您可以设置自己的CloudWatch警报，当警报触发时，当ASG的CPU占用率超过70%时，您可以添加两个单位的容量｡
然后，您可以设置第二条规则，即，如果在ASG中CPU利用率整体低于30%，
则删除一个单元｡
但是你必须设置你的CloudWatch警报以及步骤，
你想一次添加多少个单元，你想一次删除多少个单元｡
最后是计划的操作，即根据已知的用户模式预测扩展｡
比如说，你说，嘿，
我知道下午5：00，因为当人们要完成工作并使用我的应用程序时，
您希望将ASG的最小容量自动增加到5：00开始｡
这是一个预定的操作，您可以提前了解扩展｡
还有一种新的缩放，叫做预测缩放｡
因此，借助预测性缩放，
您可以通过AWS中的自动缩放服务持续进行预测｡
它会查看负载，我们会提前安排扩展｡
因此，将对一段时间内的历史负载进行分析，
然后创建预测｡
然后根据预测，他们将提前计划扩展操作，这也是一种很酷的扩展方式｡
我认为这是未来，
因为这是机器学习的动力，这真的是一个自动缩放ASG的方法｡
因此，一些好的指标与规模是一个大问题｡
因此，
这实际上取决于您的应用程序在做什么以及它是如何工作的，但通常这里有几个｡
第一个是CPU利用率，因为每次您的实例接收到请求时，它们通常会进行某种计算，
因此会使用一些CPU｡
因此，如果您查看所有实例的平均CPU利用率，它会变得更高，
这意味着您的实例的利用率更高，因此这将是一个很好的扩展指标｡
另一个要衡量的指标，
它更像是特定于应用程序的，但它是每个目标的请求计数，这是基于您的测试｡
您知道，EC2实例的最佳运行请求为每次每个目标的每个请求1000个，
因此这可能是您希望进行扩展的目标｡
这里有一个例子｡
您有一个包含三个EC2实例的自动伸缩组，并且您的lb当前正在将实例请求分布到所有这些实例｡
因此，
现在每个目标的请求计数指标的值为3，因为每个EC2实例平均有3个未完成的请求｡
其次，如果您的应用程序是网络绑定的，
例如，有大量的上传和下载，
并且您知道网络将成为EC2实例的瓶颈，
那么您可能希望在平均网络上进行扩展，以确保在达到某个阈值时，您将基于该阈值进行扩展｡
或者您推送到CloudWatch的任何自定义指标，您可以设置自己的指标，这些指标将是特定于应用的，
并在此基础上设置您的扩展策略｡
现在，关于扩展策略，
您还需要了解的是扩展冷却时间｡
其思想是，在进行扩展活动之后，无论何时添加或删除实例，都将进入冷却期，
默认情况下为5分钟或300秒｡
在此冷却期间，ASG将不会启动或终止其他实例｡
这个推理背后的原因是，你让四个指标稳定下来，
好的，让你的新实例生效，看看新的指标会变成什么｡
因此，
当有一个缩放动作发生时，问题是，效果中是否有默认的冷却时间？
如果是，则忽略该操作｡
如果否，则继续执行启动或终止实例的缩放操作｡
因此，建议您使用现成的AMI来减少EC2实例的配置时间，以便它们更快地请求或服务请求｡
因此，如果您不花时间配置EC2实例，
那么它们可以立即生效｡
此外，
由于可以更快地激活，因此冷却时间可以缩短，您可以更动态地上下调整ASG｡
当然，
您需要确保为ASG启用详细监控之类的功能，以便每分钟访问一次较低级别的二级指标，并确保这些指标的更新速度足够快｡
这节课就讲到这里｡
我希望你们喜欢，下节课再见｡
  - [ ] 73 Auto Scaling Groups - Scaling Policies [09:15] Hands On
    * 
  - [ ] 74 [DVA-C02] Auto Scaling Groups - Instance Refresh [01:36]
    * 
教师：现在，我们来讨论自动缩放组的一个非常方便的功能，
即“实例刷新”｡
因此，我们的想法是，您要更新整个自动缩放组，
这要归功于您创建的新启动模板｡
因此，您需要重新创建所有EC2实例｡
为此，您可以使用名为“实例刷新”的“自动缩放”组的本机功能，
而不是终止实例并等待它返回｡
让我们举个例子｡
假设我们有一个Auto Scaling组，
并且EC2实例已使用旧的启动模板启动｡
我说旧是因为我们正在创建一个新的启动模板｡
例如，我们更新了EC2实例的底层AMI，
然后我们将进入名为Start
Instance Refresh的API调用｡
接下来，我们将设置一个最小正常百分比，
例如60%，这将告诉我们的自动缩放组随着时间的推移可以删除多少实例｡
然后，随着实例的终止，新的实例将使用新的启动模板｡
这就是为什么它被称为EC2实例刷新，
因为实例被终止，新的实例出现｡
随着时间的推移，所有具有旧启动模板的实例将被终止，
新的实例将出现｡
因此，最重要的是，为了确保您的EC2实例有足够的时间准备就绪并为流量提供服务，
您可以指定预热时间，也就是说，
在我们可以假定新EC2实例已准备就绪之前，
需要等待多长时间｡
好吗？ 这堂课就到这里｡
我希望你们喜欢，我们下节课再见｡ 
  - [ ]  High Availability & Scalability [20 问题] Quiz
    * 
 ## Section 8 - AWS Fundamentals: RDS + Aurora + ElastiCache [11 个讲座 • 1 小时 4 分钟]
  - [ ] 75 Amazon RDS Overview [03:46]
    * 
Stephane：那么，
让我们从AWS RDS的概述开始｡
RDS代表关系数据库服务，它的意思是它是一种使用SQL作为查询语言的数据库的托管数据库服务｡
因此SQL是一种结构化的数据库查询语言｡
它适应性很好，可以在很多引擎上运行｡
因此，它允许您在云中创建RDS服务的数据库，
这些数据库将由AWS管理，您将从中获得很多好处｡
那么，AWS管理哪些类型的数据库引擎？
第一个是PostgreSQL
然后是MySQL､ MariaDB､ Oracle､ Microsoft
SQL Server，最后是Aurora，我们有一个专门介绍Aurora的部分｡
所以现在你可以忘了它，好吗｡
但是前五个，PostgreSQL, MySQL，
MariaDB, Oracle和微软SQL服务器，
你必须记住它们｡
那么，为什么我们要使用RDS，
而不是在EC2实例上部署我们自己的数据库服务呢？因为这是可能的｡
RDS是一种托管服务，
因此AWS除了提供数据库之外，
还提供了许多服务｡
例如，数据库的供应是完全自动化的，
底层操作系统的修补也是如此｡
正在进行连续备份，
您可以恢复到特定的时间戳｡
它被称为时间点还原｡
您还可以使用监视面板来查看数据库的性能｡
你可以读到复制品，
在这门课里我们有一节专门讲复制品的课.
为了提高读取性能，您可以设置多AZ，
因此我们也有关于多AZ的章节，
这将有助于灾难恢复｡
您有用于升级的维护窗口，并且可以扩展公共功能，
包括通过增加实例类型实现的纵向扩展和通过添加读取副本实现的横向扩展｡
最后，存储由EBS提供支持｡
这是我们已经知道的，
即gp2卷或io1卷｡
但我们唯一缺少的是，
我们无法通过SSH访问实例，即RDS实例｡
因此，由于这是一个托管服务，
AWS为我们提供了一个服务，
我们无法访问底层EC2实例｡
但这并不太糟糕，因为如果我们想在EC2上部署自己的数据库引擎，
我们就必须自己设置所有这些东西｡
这里有一项功能可以在考试中提及，
它与RDS存储自动扩展有关｡
因此，当您创建RDS数据库时，需要说明您需要多少存储空间｡
例如，您想要20 GB的存储，但假设您经常使用数据库，
即将用完可用空间，那么启用RDS存储自动扩展功能后，RDS将检测到这一情况，
并自动为您扩展存储｡
因此，您不必执行任何类型的操作，
例如关闭数据库来增加存储｡
我们的想法是，您的应用程序会对RDS数据库执行大量的读写操作，
然后通过我们稍后将看到的某个阈值，
自动扩展存储｡
这是RDS的一个非常好的特性｡
因此，这一切都是为了使您避免手动扩展数据库存储的操作｡
为此，您需要设置一个最大存储阈值，
即您希望存储增长的最大限制，
因为您可能不希望它无限增长，
如果可用存储低于已分配存储的10%，
并且低存储已持续5分钟以上，自上次修改以来已过去6小时，您可以自动修改存储｡
如果是这种情况，
那么存储将自动增加时，你启用它｡
这对于具有不可预测工作负载的应用程序非常有用，
并且支持RDS的所有数据库引擎，
如MariaDB､ MySQL､ PostgreSQL､
SQL Server和Oracle｡
这节课就讲到这里｡
我希望你们喜欢它，我们下节课再见｡ 
  - [ ] 76 RDS Read Replicas vs Multi AZ [07:22]
    * 
Stephane：参加考试对于理解RDS
Read Replicas和Multi
AZ之间的区别以及准确理解这些用例非常重要｡
所以这堂课是专门用来理解读副本和多AZ的｡
让我们从读取副本开始｡
读副本顾名思义可以帮助您扩展读操作｡
我们来举个例子｡
在这里，我们有一个应用程序，
我们有一个RDS数据库实例，
我们的应用程序对我们的数据库实例执行读取和写入，但是我们想扩展读取，因为主数据库实例不能足够扩展｡
它收到了太多的请求｡
我们最多可以创建15个读取复制副本，
它们可以位于同一可用性区域､
跨可用性区域或跨区域｡
所以有三个不同的选择，
记住它们非常重要｡
假设我们有另一个RDS实例Read Replica和另一个RDS实例Read
Replica，将会发生的情况是，它们将是主RDS数据库实例和两个Read Replica之间的异步复制｡
异步，这意味着读取最终是一致的｡
这意味着，例如，
如果您的应用程序在有机会复制数据之前从读取副本中读取，
则您可能会获得所有数据｡
这就是为什么它被称为最终一致异步复制｡
这些副本，它们可以很好地读取扩展读取，
但它们也可以提升到自己的数据库｡
所以你可以选择其中一个副本，然后说，
好的，我希望它现在是它自己的数据库，并获得权限｡
所以你把它提升到自己的数据库｡
在那之后它就完全脱离了复制机制，但它仍然存在，
并有自己的生命周期｡
因此，如果您想使用Read Replicas，
屏幕顶部橙色的主应用程序必须更新连接字符串，
以利用RDS集群中所有Read
Replicas的列表｡
好的，很好｡
让我们来讨论一个经典的使用案例，
让您读取副本｡
因此，在本例中，我们有一个生产数据库，
它正在承担正常的负载｡
我们开始吧｡
我们的生产数据库正在对我们的主RDS数据库实例进行读写操作｡
新团队进来说，
我们想在你的数据上运行一些报告和分析｡
因此，如果您将该报告应用程序插入到主RDS数据库实例中，
那么它将使其过载，并可能降低生产应用程序的速度，
这是您不希望看到的｡
因此，作为解决方案架构师，您要做的是创建一个Read
Replica来运行新的工作负载｡
因此，您创建了一个读取复制副本｡
在主RDS DB数据库实例和读副本之间存在一些异步复制，
然后您的报告应用程序可以从读副本中读取并在那里运行分析｡
在这种情况下，生产应用程序完全不受影响，
这是完美的｡
所以请记住，如果你有一个读副本，
你需要确保它只用于SELECT类型的语句，
SELECT是一个SQL关键字｡
SELECT表示读取｡
因此，您不能使用关键字，如INSERT，
UPDATE或DELETE，这会改变数据库本身｡
好的，读取副本仅用于读取｡
那么，让我们来谈谈与RDS读取复制副本相关的网络成本｡
因此，在AWS中，您应该知道，当数据从一个可用性区域转移到另一个可用性区域时，
通常会有成本，但也有例外，这些例外通常用于托管服务｡
因此，对于RDS读取复制副本，这是一项托管服务｡
如果您的读取副本在同一区域内，好吗？
不同的地区，但相同的地区，你不支付这笔费用｡
这意味着，如果您在us-east-1a中有一个RDS
DB实例，然后在us-east-1b中有一个读副本，
并且存在异步复制，因为这是一个读副本，即使流量从一个AZ到不同的AZ，
复制流量也是免费的，因为RDS是一个托管服务，他们为您提供免费的流量｡
但是，如果您使用的是跨区域复制副本，
例如您位于一个区域us-east-1，
而转到另一个区域eu-west-1，
那么您的RDS DB实例和读取复制副本将具有跨区域复制，这将为您的网络带来复制费用｡
最后，让我们谈谈RDS Multi AZ，
Multi AZ主要用于灾难恢复｡
因此，我们有我们的应用程序，
它执行对可用性区域A中的主数据库实例的读取和写入，
我们认为您拥有的是对可用性区域B中的备用实例的同步复制，它们将同步复制主数据库中的每个更改｡
因此，这意味着当您的应用程序写入主服务器时，
该更改也需要复制到备用服务器才能被接受｡
所以我们得到的是一个DNS名称｡
因此，您的应用程序与一个DNS名称对话，
如果主服务器出现问题，将自动故障转移到备用数据库｡
多亏了这个DNS名称｡
因此，我们提高了可用性｡
这就是为什么它被称为多AZ，并且在我们丢失整个AZ或丢失网络或主数据库出现实例或存储故障时，
它们将进行故障切换｡
在这种情况下，备用数据库显然将成为新的主数据库｡
他不需要在你的应用程序中做任何手动干预，
只要它试图在某个时候自动保持连接到你的数据库，
它会故障转移到将被提升为主服务器的备用服务器，
你会很好，它不用于扩展｡
因此，正如您在这里看到的，
备用数据库只是用于备用｡
没有人能读到它｡
没有人可以写入它，它只是在这里作为故障转移，以防Master数据库发生任何事情｡
因此，快速的问题是，是否有可能将读取副本设置为用于灾难恢复的多AZ？
答案是肯定的，如果需要，您可以将读取副本设置为多AZ｡
这是一个常见的考试问题，好吗？
这就是Read Replicates和Multi
AZ的区别，但是你需要在考试中完全理解这一点，因为很多问题都会涉及到它｡
因此，考试中可能会出现的一个问题是，
如何使RDS数据库从单AZ变为多AZ？
所以你应该知道的是，
这是一个零停机操作｡
这意味着您不需要停止数据库以从单AZ转到多AZ｡
您需要做的唯一一件事就是单击数据库的修改并启用多AZ｡
这意味着您的RDS数据库实例将拥有一个主数据库，
拥有一个带有同步复制的备用数据库，除了修改该设置之外，
您无需做任何事情，数据库将不会停止｡
这是考试的题目，但我想告诉你们，
为了让考试顺利进行，幕后会发生什么.
因此，以下情况将在内部发生｡
RDS将自动为您的主数据库拍摄快照，
并且此快照将恢复到新的备用数据库中，
好吗？
然后，一旦备份数据库恢复，
将在两个数据库之间建立同步，因此备份数据库将赶上主RDS数据库，
这样您将处于多AZ设置中｡
这堂课就到这里｡
我希望你们喜欢，
我们下节课再见｡
  - [ ] 77 Amazon RDS [10:30] Hands On
    * 
  - [ ] 78 Amazon Aurora [06:29]
    * 
教师：我们来谈谈Amazon
Aurora，因为考试开始问你很多关于它的问题｡
现在，你们不需要深入了解它，但你们需要足够高层次的概述来理解它是如何工作的，
这就是我在这节课上要给你们讲的内容.
Aurora将成为AWS的专有技术｡
它不是开源的｡
但他们使它与Postgres和MySQL兼容｡
而且基本上Aurora数据库将具有兼容的驱动程序｡
这意味着，如果您像连接到Postgres或MySQL数据库一样连接，
那么它将工作｡
Aurora非常特别，
我不会深入了解其内部，但他们对其进行了云优化｡
通过进行大量优化和智能操作，
基本上他们在RDS上的性能比MySQL提高了5倍，
在RDS上的性能比Postgres提高了3倍｡
不仅如此，他们还在许多不同的方面获得了更多的性能改进｡
给我，我看｡
它真的很聪明，
但我不会详细介绍它｡
现在，Aurora存储会自动增长｡
我认为这是一个主要的特点，
这是相当可怕的｡
您的起始数据库容量为10
GB，但随着数据库中数据的增加，数据库容量会自动增加到128
TB｡
同样，这与如何设计它有关，
但最棒的是，现在作为一个数据库，
作为一个数据库或SysOps，
你不需要担心监视你的光盘｡
你只知道它会随着时间自动增长｡
对于读取复制副本，您最多也可以有15个复制副本｡
MySQL只有五个，而且复制速度比他们的方式快得多｡
所以总的来说，这是一场胜利｡
现在，如果您在Aurora中执行故障切换，
它将是即时的｡
因此，这将比从RDS上MySQL上的Multi-AZ进行故障转移快得多｡
由于默认情况下它是云原生的，
因此您可以获得高可用性｡
现在，虽然成本比RDS略高，
大约高20%，但它的效率要高得多，
在规模上，它对节省成本更有意义｡
那么，让我们来讨论一下非常重要的方面，
即高可用性和重新扩展｡
Aurora很特别，
因为只要您在3 AZ上写入任何内容，它就会存储您的数据的6个副本｡
所以奥罗拉是在它可用的时候制造的｡
因此，它只需要六个拷贝中的四个用于写入｡
这意味着如果一个AZ故障，你就没事了｡
这只意味着你有三个副本的六个需要阅读｡
同样，这意味着它的读取可用性很高｡
有一种自我修复过程，这是非常酷的，
如果一些数据损坏或坏了，那么它会在后端通过对等复制进行自我修复｡
而且很酷｡
而且，您不只是依赖于一个卷｡
您需要依赖数百个卷，这不是您需要管理的东西｡
它发生在后端，但这意味着你只是降低了这么多的风险｡
如果您从图表的角度来看，您有三个AZ，
还有一个共享存储卷，但它是一个逻辑卷｡
它还具有复制､ 自我修复和自动扩展功能，
这些功能非常多｡
因此，如果您要写入一些数据，可能是蓝色数据，
您会在三个不同的AZ中看到它的六个副本｡
然后，如果您写入一些橙色数据，
则在不同的AZ中再次写入六个副本｡
然后，随着写入的数据越来越多，
它基本上会在三个不同的AZ中再写入六个副本｡
最酷的是，它可以放在不同的卷上，
而且有条纹，效果非常非常好｡
现在，我们需要了解存储，
仅此而已，但实际上您并不与存储交互｡
这只是亚马逊的一个设计｡
我也想把它给你，这样你就能明白奥罗拉需要什么｡
现在Aurora就像是RDS的Multi-AZ｡
基本上，只有一个实例接受写入｡
所以奥罗拉有一个大师，我们将在那里进行写作｡
然后，如果主服务器无法正常工作，
故障转移平均将在不到30秒的时间内完成｡
因此，故障切换速度非常快｡
在主服务器上，您最多可以有15个读取副本，
所有副本都为读取服务｡
所以你可以有很多｡
这就是您扩展读取工作负载的方式｡
因此，在主服务器发生故障时，这些读取副本中的任何一个都可以成为主服务器｡
这与RDS的工作方式有很大不同，
但默认情况下，您只有一个主机｡
这些读取复制副本的最酷之处在于它支持跨区域复制｡
所以如果你看一下图右边的Aurora，
你应该记住｡
一个主服务器，多个根副本，
存储将被复制，自我修复，自动逐块扩展｡
现在让我们看看Aurora是如何作为一个集群的｡
所以这更多的是围绕着极光的工作原理｡
当您拥有客户端时，
您如何与所有这些实例进行交互？
如前所述，我们有一个共享存储卷，
它可以从10 GB自动扩展到128 GB｡
你的主设备是唯一能写入你的存储器的设备｡
由于主服务器可以更改和故障转移，因此Aurora为您提供的是所谓的写入器端点｡
因此，它是一个DNS名称，一个写入器端点，
并且始终指向主服务器｡
因此，即使主服务器发生故障转移，
您的客户端仍然会与编写器端点通信，
并自动重定向到正确的实例｡
现在，正如我之前所说的，
你也有很多阅读的复制品｡
我没有说的是，他们可以在这些读取副本的基础上进行自动扩展｡
因此，您可以拥有一个最多15个读取副本，
并且可以设置自动扩展，以便始终拥有正确数量的读取副本｡
现在，因为您有自动扩展功能，
所以您的应用程序要跟踪读取副本的位置可能会非常非常困难｡
网址是什么？
如何连接到它们？
所以为了考试，你一定要牢牢记住这一点｡
有一种叫做读取器端点的东西｡
读取器终结点与写入器终结点具有完全相同的功能｡
它有助于实现连接负载平衡，
并自动连接到所有读取副本｡
因此，每当客户端连接到读取器端点时，
它都会连接到其中一个读取副本，
并以这种方式完成负载平衡｡
请注意，负载平衡发生在连接级别，
而不是语句级别｡
这就是奥罗拉的工作原理
请记住写入器端点､ 读取器端点｡
记住自动缩放｡
记住自动扩展共享存储卷
记住这张图，因为一旦你得到它，
你就明白了极光是如何工作的｡
现在，如果我们深入了解这个功能，你会得到很多我已经告诉过你的东西｡
自动故障切换､ 备份和恢复､
隔离和安全性､ 行业合规性､ 通过自动扩展实现的按钮式扩展､
零停机的自动修补（后端操作很酷）､ 高级监控､
日常维护｡
所以所有这些事情都是为你处理的｡
您还可以获得一种称为回溯的功能，
它使您能够在任意时间点恢复数据｡
而且它实际上并不依赖于备份｡
它依赖于一些不同的东西｡
但你可以说，“我想回到昨天下午4点，
”然后你说，“哦，不，
实际上我想在昨天下午5点做｡
“而且它也会工作，
这是超级，超级整洁｡
奥罗拉就这样了｡
我们下节课再见｡
  - [ ] 79 Amazon Aurora [06:42] Hands On
    * 
  - [ ] 80 RDS & Aurora Security [02:32]
    * 
讲师：现在，我们来简单介绍一下RDS和Aurora
Security｡
因此，您可以加密RDS和Aurora数据库中的静态数据｡
这意味着数据在卷上是加密的｡
为此，您将使用KMS对主服务器和所有副本服务器进行加密｡
这是在首次启动数据库期间的启动时定义的｡
如果您没有加密master数据库（即主数据库），
则无法加密读取副本｡
此外，如果要加密现有的未加密数据库，
则必须从该未加密数据库中获取数据库快照，然后将该数据库快照还原为加密数据库｡
好吗？
因此，您必须执行快照和恢复操作｡
这是静态加密｡
然后，您可以进行飞行中加密｡
你的客户和数据库之间｡
因此，默认情况下，RDS和Aurora上的每个数据库都已准备好进行动态加密｡
因此，您的客户端必须使用AWS的TLS根证书｡
AWS网站上提供了这些信息｡
在数据库身份验证方面｡
因为这是RDS和Aurora，
所以您可以使用用户名和密码的经典组合｡
但是因为它写的是AWS，
所以您也可以使用IAM角色连接到数据库｡
这意味着，例如，如果您的EC2实例具有IAM角色，
则它们可以直接使用IAM角色而不是用户名和密码对您的数据库进行身份验证，
这可以帮助您管理AWS和IAM中的所有安全性｡
还可以使用安全组控制对数据库的网络访问｡
因此，您可以允许或阻止特定的端口､
特定的IP､ 特定的安全组｡
最后，RDS和Aurora当然没有SSH访问权限，
因为它们是托管服务，
除非您使用AWS的RDS自定义服务｡
如果您需要审核日志｡
因此，要了解一段时间内在RDS和Aurora上执行了哪些查询以及数据库上发生了什么，
您可以启用审核日志｡
然后他们会失去后一点时间｡
因此，如果您想长期保留这些日志，
您需要做的是将它们发送到AWS上的一个名为CloudWatch Logs服务的专用服务中｡
关于RDS和Aurora的安全性选项摘要的简短讲座到此结束｡
希望你喜欢｡
我们下节课再见｡
  - [ ] 81 [DVA-C02] RDS Proxy [04:32]
    * 
Stephane：现在，让我们来谈谈Amazon RDS Proxy｡
因此，我们知道我们可以在VPC内部署RDS数据库，
但现在我们还可以为RDS部署完全托管的数据库代理｡
因此，您可能会说：“好的，
我们可以直接访问RDS数据库｡
为什么我们需要一个代理来访问我们的数据库？ 如果您使用As an RDS Proxy，
这将允许您和您的应用程序共享与数据库建立的数据库连接｡
因此，不是让每个应用程序连接到RDS数据库实例，
而是连接到代理，代理将这些连接集中到RDS数据库实例的较少连接中｡
你为什么要这样做呢？
如果你有很多连接到RDS数据库实例，
这是很有意义的，它将通过减少数据库资源（例如CPU和RAM）的压力来提高数据库的效率，并最大限度地减少打开的连接和数据库的超时｡
所以从考试的角度来看，这是你需要注意的一件事｡
现在，正如我所说，RDS代理是完全无服务器的｡
它是自动扩展的，所以你不需要管理它的容量｡
而且很容易买到｡
它跨越了多个方位｡
因此，例如，在RDS数据库实例上发生故障转移时｡
例如，它从主实例转到备用实例，
然后由于RDS代理，它将减少故障转移时间高达66%｡
RDS和Aurora也是如此｡
因此，与其让所有应用程序连接到主RDS数据库实例，
然后自己处理feller，
它们只会连接到RDS代理，而RDS代理不知道任何故障转移｡
RDS代理本身将处理RDS数据库实例的故障转移，
从而缩短故障转移时间｡
所以从考试的角度你还需要寻找一些其他的东西｡
因此，RDS代理支持MySQL, PostgreSQL，
MariaDB, Microsoft SQL Server以及Aurora for MySQL和PostgreSQL｡
它不需要您在应用程序中进行任何代码更改｡
现在，您只需连接到RDS代理，而不是连接到RDS数据库实例或Aurora数据库，
就完成了｡
除此之外，使用RDS代理还有第三个优点｡
它用于对数据库强制执行IAM身份验证｡
因此，要确保人们只能使用IAM连接到您的RDS数据库实例｡
然后，这些凭证可以安全地存储在另一个名为AWS
Secrets Manager的服务中｡
因此，如果您需要找到一种方法来为您的数据库强制执行IAM身份验证，
请考虑RDS代理｡
最后，RDS代理永远不会公开访问｡
所以只能从你的VPC里访问｡
因此，您无法通过互联网连接到RDS代理，
这是增强的安全性｡
因此，我们还没有看到一个服务，
它肯定会得到RDS代理的帮助，
这就是所谓的Lambda函数｡
和Lambda函数，它们将执行代码片段｡
我们将在本课程的稍后部分介绍它们｡
好吧，你现在不需要知道它们，但是由于RDS代理功能，
我们现在必须解决它们｡
所以Lambda函数，
它们可以相乘，相乘很多很多次｡
它们出现和消失的速度非常非常快｡
因此，想象一下，你有100或1，000个Lambda函数像这样出现和消失，
并打开到RDS数据库实例的连接，
它们将是一个大问题，因为它会留下开放的连接和超时，这将是一个混乱｡
因此，您要做的是使用RDS代理为Lambda函数池连接，
然后Lambda函数将重载RDS代理，但它注定要重载｡
RDS代理将把这些连接汇集到RDS数据库实例的更少连接中，
从而解决您的问题，好吗？
这堂课就到这里｡ 希望你喜欢｡
别担心，我们会在进入Lambda课程后再回顾一下代理｡
但同样，RDS代理用于最小化和池化RDS数据库实例上的连接｡
它还用于最大限度地减少故障转移时间，
并将其减少多达66%｡
此外，它还用于对数据库实施IAM身份验证，
并将其凭据安全地存储在Secrets
Manager服务中｡
好吧，就这样｡ 希望你喜欢｡
我们下节课再见｡
  - [ ] 82 [DVA-C02] ElastiCache Overview [04:21]
    * 
讲师：我们来谈谈Amazon ElastiCache｡
因此，同样的方法，你得到RDS有管理的关系数据库，
ElastiCache将帮助你得到管理的Redis或Memcached，这是缓存技术｡
那么什么是缓存呢？
它们是内存中的数据库，
具有非常高的性能和低延迟｡
高速缓存将帮助您减少读取密集型工作负载的数据库负载｡
其思想是将常用查询缓存起来，
因此不会每次都查询数据库｡
只有您的缓存可以用于检索这些查询的结果｡
这还可以帮助您通过将应用程序的状态放入Amazon
ElastiCache来使应用程序无状态｡
由于RDS和AWS具有相同的优势，
因此它们将对操作系统进行相同的维护､ 修补､ 优化､
设置､ 配置､ 监控､
故障恢复和备份｡
现在，如果您使用Amazon
ElastiCache只是为了让您知道它将需要您为应用程序做一些繁重的应用程序代码更改｡
这不是一个只启用和关闭的东西，
你有一个缓存｡
您需要更改应用程序，以便在查询数据库之前或之后查询缓存｡
我们马上会看到策略｡
现在我们来讨论一下使用ElastiCache的架构｡
可能有很多，但我只是举个例子｡
假设我们有Amazon ElastiCache和RDS数据库以及您的应用程序｡
应用程序将查询ElastiCache，
以查看是否已进行查询｡
如果它已经被创建，并且存储在ElastiCache中，
则称为缓存命中｡
然后它直接从亚马逊ElastiCache得到答案｡
这样我们就省去了去数据库查询的时间｡
现在，如果缓存未命中，
我们需要从数据库中获取数据｡
所以我们要从数据库中读取｡
然后，对于将进行相同查询的其他应用程序或其他实例，
我们可以将数据写回到缓存中，
以便下次相同的查询将导致缓存命中｡
这样做的目的是帮助减轻RDS数据库的负载｡
而且，因为您要在缓存中存储数据，
所以必须有一个缓存失效策略来确保在缓存中只使用最新的数据｡
这就是使用缓存技术的全部困难｡
另一种架构是存储用户会话以使应用程序无状态｡
因此，我们的想法是，您的用户将登录到您的任何类型的应用程序，
然后应用程序将把会话数据写入Amazon ElastiCache｡
现在，如果您的用户被重定向到应用程序的另一个实例，
那么您的应用程序可以检索会话缓存，
会话直接来自Amazon ElastiCache，因此您的用户仍然处于登录状态，不需要再次登录｡
因此，现在的想法是，
通过将用户的会话数据写入Amazon
ElastiCache，
使应用程序无状态化｡
那么，如果我们比较Redis和Memcached，我们得到了什么？
对于Redis，我们有带自动故障转移的多AZ，
如果你想扩展读取并获得高可用性，
我们还有读取副本｡
这看起来很像RDS｡
我们使用AOF持久性实现了数据持久性，并且我们具有备份和恢复特性｡
所以，Redis的核心是数据的持久性｡
作为一个缓存，它支持集合和排序集合，
这些关键字也可以在考试中查找｡
所以在这里我想把Redis作为一个缓存来展示，
它可以被复制，具有高可用性和持久性｡
而Memcached则使用多节点进行数据分区｡
所以这叫做碎片化｡
没有高可用性，
也没有复制｡
它不是永久缓存｡
没有备份和恢复｡
这是一个多线程架构｡
因此，我们有多个实例在Memcached中工作，
并进行了一些分片｡
所以这里你需要记住的是Redis真正是为了高可用性，
备份，读取副本，这类东西｡
而Memcached是一个纯粹的缓存，它分布在你可以承受丢失的地方--你丢失了数据，
没有高可用性，也没有备份和恢复｡
这就是这两种技术之间的主要区别｡
原来如此｡
我希望你们喜欢，
我们下节课再见｡
  - [ ] 83 ElastiCache [04:34] Hands On
    * 
  - [ ] 84 ElastiCache Strategies [11:37]
    * 
好的，现在让我们更深入一步，讨论可以实现的不同缓存策略，
以及随之而来的注意事项｡
所以如果你想有一个阅读，我推荐这个链接｡
所有的信息都是从这个链接中得到的，
还有一点额外的好处，但我会在这节课上，给你们做一个总结.
那么，缓存数据安全吗？
一般来说是的，但有时您的数据可能会过期｡
所以你可能最终会有一致性｡
所以它并不适用于所有类型的数据集，好的.
对于某些数据，您需要确保只缓存它（如果可以缓存的话）｡
缓存对数据是否有效？
也是你需要问自己的另一个问题｡
比如说，
如果你的数据变化很慢，而且经常需要的键很少，那就很好了｡
但是对于一个反模式，例如，
如果你的数据变化非常非常快，并且你需要数据集中的所有键空间，那么缓存可能就不那么有效了｡
然后，您需要问自己，数据的结构是否适合缓存？
例如，
如果您有键值，或者如果您希望存储聚合结果，则缓存非常有用｡
但是在缓存数据之前，您需要确保数据是相应地结构化的，因为缓存是为了节省时间，
所以它是为了优化｡
而是更快地实现目标｡
因此，
您需要确保数据的结构符合您的查询要求，明白吗？
最后一个问题，
也是最重要的一个问题，哪种缓存设计模式最适合我们？
这就是我们现在要讨论的问题｡
第一种方法叫做“惰性加载”，但它可能会在考试时出现在“缓存备用”或“惰性填充”下｡
这三件事的意思是一样的｡
让我们来看看｡
我们有了应用程序｡
我们有Amazon ElastiCache和Amazon RDS，
并且有三个不同的组件｡
所以如果你的应用程序想要读取一些东西，首先，它会询问该高速缓存，
ElastiCache，
它可能是Redis或者Memcached，会说，是的，
我有一些东西，这叫做缓存命中｡
这是最伟大的案例｡
现在，如果没有缓存命中，则称为缓存未命中｡
因此，应用程序向ElastiCache发出请求｡
ElastiCache没有数据，因此我们得到一个Cache未命中｡
所以我们需要能够找到数据在哪里｡
因此，我们从数据库中读取数据，
在本例中为Amazon
RDS，然后应用程序就拥有了正确的数据｡
它要做的是将该数据写入该高速缓存，以确保请求相同数据的任何其他应用程序都将直接进入缓存命中｡
所以这个架构很棒，因为只有请求的数据才会被缓存，好吗？
如果没有从RDS请求的数据，则它不会在该高速缓存中结束｡
所以效率很高｡
万一您的缓存被擦除或出现节点故障，这并不是致命的｡
这会增加延迟，
因为案例需要预热，而预热意味着所有读取都必须转到RDS，然后进行缓存｡
这就是所谓的热身｡
但也有一些缺点｡
首先，如果我们得到一个缓存命中是伟大的｡
但是，如果出现缓存未命中，则意味着您的应用程序对ElastiCache执行了三次网络调用，
这是应用程序对RDS的缓存未命中，RDS从数据库读取数据，
最后再写入该高速缓存｡
因此，对于您的用户来说，当他们在阅读某些内容时，
他们会看到一些延迟，他们不习惯这种情况｡
因此，这三次往返可能是一个糟糕的用户体验｡
最后是陈旧数据｡
因此，如果您的数据在RDS中更新，
则它不一定会在ElastiCache中更新｡
因此，该高速缓存中可能会有过时的数据｡
这就是你需要问自己的问题，我的数据是否可以过时并最终保持一致？
这是第一种情况，考试要求你理解如何读取缓存或惰性加载类型的结构｡
所以我用Python，
我认为，这是一种容易阅读的语言，来看看｡
因此，
我们需要查看这段代码，并了解它确实是一个懒惰加载策略｡
让我们来看看，这很容易理解｡
def的意思是definition，它是一个函数定义，用来得到一个用户，
参数是用户ID.
所以我们在第17行称之为｡
我们希望用户等于get_user id 17，好的.
现在，用户如何获得他的get？
所以首先，你会记录等于缓存｡ 获取用户ID｡
因此，
在这里，我们将检查ElastiCache，看看该用户ID是否已缓存｡
如果缓存未命中，如果记录为“无”，则进入此循环，
否则，这将是缓存命中，
我们只返回记录｡
我们看到，
如果缓存命中，则直接进入响应｡
现在，
如果出现Cache未命中，则运行数据库查询以在数据库中查找该用户，因此我们执行db｡
查询，我们有一个SQL查询传递到RDS，并说，
好的，
我们得到了记录，然后我们用结果填充该高速缓存｡
所以我们要做缓存｡ 设置user_id, record，
以便下次有人进行缓存时使用｡
get它将是一个结果，它将是一个缓存命中｡
最后，
我们返回记录，这和我在图中展示的策略完全一样｡
从这段代码来看，它确实是，懒惰加载，
好｡
同样，
您不需要知道如何编写代码，而是需要阅读代码并理解代码的作用｡
这是非常小的考试，
但对于弹性缓存，这是必要的，好的.
第二种类型的策略称为直写｡
而Write Trough则是在更新数据库时添加或更新该高速缓存｡
让我们来看看｡
应用程序ElastiCache和RDS是相同的｡
当我们的应用程序与ElastiCache通信时，我们会得到一个缓存命中，这很好，当RDS发生写入时，
因此当我们的应用程序修改Amazon RDS数据库时，
它将写入该高速缓存｡
这就是为什么它被称为直写，因为我们通过ElastiCache写入RDS，好的｡
那么，我们从这个体系结构中得到了什么呢？
该高速缓存存里的数据永远不会过时，好吧.
每当Amazon
RDS发生变化时，缓存中就会自动发生变化｡
这一次，您将得到写性能损失与读性能损失｡
因此，在出现缓存未命中之前，我们总共必须执行三次网络调用，
这是一个读取损失｡
但现在，当我们写入数据库时，
会有写入损失｡
现在，每次写操作都需要两次调用，一次调用数据库，
另一次调用该高速缓存｡
从用户的角度来看，用户希望写入比读取花费更长的时间｡
例如，如果你在社交媒体上发布了一些东西，那么你希望这个帖子能持续一两秒钟｡
但如果你要做个侧写，你需要一瞬间的时间｡
在这里，用户知道对数据库的任何写入和更改都可能需要稍长的时间｡
所以从用户的角度来说可能会有更好的选择｡
那么，那些缺点呢？
嗯，
在Amazon RDS数据库更新或添加之前，数据会丢失｡
这意味着，在将数据写入RDS之前，您的ElastiCache或缓存通常不会拥有所需的所有数据，
因此可能会出现问题｡
因此，
您可以将直写策略与延迟加载相结合，例如，如果您的应用程序在ElastiCache中找不到数据，则它也会将延迟加载到RDS中｡
所以我们可以联合收割机这两种策略结合起来｡
这是一个缓存抖动｡
这意味着，
当我们在RDS中添加大量数据时，ElastiCache中也会有大量数据，但这些数据有可能永远不会被读取｡
所以如果你的缓存很小的话，这可能是个问题，好的.
同样地，我们将看一些伪代码｡
这一次，
我们有一个名为保存_user的函数，因为它之前是get_user，因为它是对该高速缓存的读取优化，但现在是对缓存的写入优化｡
它是保存_user，在这里，我们只看一下save_user函数，
我们要做得第一件事是保存到数据库.
所以我们做记录等于db｡
查询更新用户，然后使用值更新用户｡
然后我们把它推该高速缓存中｡
所以缓存｡ set
user_id, record，然后返回记录｡
这就是我们定义的直写策略和伪代码｡
您可以看到，将直写和惰性加载结合起来，
因为这是一个名为保存_user的函数，而另一个是名为get_user的函数，因此这两个函数可以一起使用｡
然后是缓存收回和生存时间（TTL）｡
因此，您的缓存大小有限｡
因此，可以使用一种称为“缓存逐出”的方法，
将数据从缓存中移除｡
因此，例如，
如果您该高速缓存中显式删除一个项，
或者缓存的内存已满，则可能会发生这种情况｡
然后，您的项目最近没有被使用，
因此将被逐出，这称为LRU，表示最近最少使用，
或者我们设置项目生存时间或TTL，也就是说，
嘿，您只能生存五分钟，在五分钟内，
我希望该高速缓存将您逐出｡
TTL对于任何类型的数据都非常有用，
比如排行榜､ 评论､ 活动流等｡
根据应用的不同，TTL的范围可以从几秒（这是一个非常短的TTL）到几小时或几天｡
但是，即使是对一些请求量非常大的数据使用几秒的TTL，
对于缓存来说也是非常有效的｡
因此，
TTL是一种很好的策略，可以在将数据保留在缓存中与将其逐出之间保持平衡，以便新数据出现并替换它｡
因此，如果由于某种原因导致回收次数过多（因为您的情况总是内存已满），
则应考虑通过扩大或缩小来更新缓存大小｡
因此，这意味着要扩大缓存｡
好吧，最后一句至理名言，因为缓存是很难的｡
因此，Lazy Loading and
Cache-Aside策略是一种非常容易实现的策略，并且可以在很多情况下作为基础，
特别是在提高读取性能方面｡
这是一件非常容易做到的事情，我建议你在许多应用程序中这样做｡
直写涉及的操作更多，它更像是一种优化，是在惰性加载之上的一种后续效果，
然后是一种缓存策略｡
因此，请确保直写不是您的首要任务｡
考虑一下它如何适用于您的用例，并在必要时实现它，
以改善您的缓存陈旧性｡
最后，TTL通常是个不错的主意，
除非你使用直写｡
而且您应该将它设置为一个适合您的应用程序的合理值｡
最后，也只有缓存数据才有意义｡
因此，它将是用户配置文件，博客，但可能不是定价数据｡
最后，也许不是某人的银行账户价值｡
最后，还有最后一个缓存｡
有句话是这样说的，“在计算机科学中有两件困难的事情：“缓存失效和命名｡
“这意味着缓存非常非常困难｡
这只是一个介绍，计算机科学的整个领域都是关于缓存的｡
但正如您所看到的，
对于考试，您需要了解不同的缓存策略､ 它们的伪代码及其含义｡
我希望这对你们有帮助，下节课再见.
  - [ ] 85 [DVA-C02] Amazon MemoryDB for Redis - Overview [01:18]
    * 
现在我们来谈谈亚马逊的MemoryDB for Redis｡
因此，它是一个与Redis兼容､
持久的内存数据库服务｡
所以Redis和MemoryDB for Redis的区别在于，
Redis的目的是作为一个具有一定持久性的缓存，
而MemoryDB实际上是一个拥有Redis兼容API的数据库｡
因此，它提供了超快的性能，每秒可处理超过1.6亿个请求，
因此性能非常高，而且它是内存中的数据，但它是具有Multi-AZ事务日志的持久数据存储｡
所以这是一种不同于Redis的功能｡
它可以无缝地从几十GB扩展到几百TB的存储空间，
Redis内存数据库的使用案例将是你的网络和移动应用程序､ 在线游戏､ 媒体流等等｡
想象一下你有很多微服务，
它们需要访问一个Redis兼容的内存数据库，
那么这是完美的｡
您可以在Redis上使用MemoryDB｡
您将获得超快的内存速度，
以及跨多个AZ存储的Multi-AZ事务日志，
并在需要时提供快速恢复和数据持久性｡
好吧，只是概述一下，
但对考试来说应该足够了｡
我希望你们喜欢，我们下节课再见｡
  - [ ]  RDS, Aurora，& ElastiCache [23 问题] Quiz
    * 
 ## Section 9 - Route 53 [20 个讲座 • 1 小时 30 分钟]
  - [ ] 86 What is a DNS? [06:24]
    * 
讲师：好的，在我们讨论53号公路之前，
我们必须先讨论一下什么是DNS？
所以，这是一个基本水平的讲座，但至少它会帮助你了解DNS是如何工作的｡
这是你每天都在幕后使用的东西，
但你并不确切地知道它｡
所以，让我们来看看｡
因此，DNS是一个域名系统，它所做的是将人类友好的主机名转换为目标服务器的IP地址｡
例如，当您在Web浏览器中键入www.
谷歌｡ com，
它最终会给你一个IP地址，这是你的网络浏览器将能够在幕后访问的IP地址，
并从谷歌获得一些数据回来｡
因此，DNS是互联网的主干｡
这是一种让你了解如何将这些URL､
这些主机名转换成IP的方法｡
因此，DNS有一个分层命名结构，其思想是在www.
谷歌｡ com为例，有｡ com，
但随后就有了例子｡ com，它更精确一些｡
然后，www. 例子｡ COM或API｡ 例子｡ com公司｡
所以，所有这些都将是你的域名的层次结构｡
接下来，我们需要定义一些关于DNS的术语｡
所以，有一个域名注册商｡
这是你要注册你的域名，它可以是亚马逊53号公路，
也可以是GoDaddy或任何其他域名注册商，你可以找到在线｡
然后你有DNS记录，他们有不同的类型，
我们将在这一节中详细看看他们｡
它可以是A､ AAAA､ CNAME､ NS等等｡
别担心，我们将在本节中详细介绍这些内容｡
包含所有DNS记录的区域文件｡
这就是如何将这些主机名与IP或地址进行匹配｡
名称服务器是实际解析DNS查询的服务器｡
我们也将在本节中了解它们｡
顶级域名是｡ com､ . 我们｡ 中的､ ｡ 政府，org等等等等｡
第二级域名是亚马逊｡ com和谷歌｡ com公司｡
所以你可以看到在一个点之间有两个单词｡
例如，如果我们看一下这个FQDN，
即完全限定的域名，我们有http：//api｡
www. 例子｡ com公司｡
好吗？
所以，最后一个点的结束被称为根，
它是所有域名的根｡
然后｡ com，
所以｡ com是您的TLD，因此这是您的顶级域｡
举个例子｡ com将成为您的二级域｡
然后我们有www. 例子｡ com公司｡
那是你的子域名｡
API｡ www. 例子｡ com是您的FQDN，
即完全限定的域名｡
HTTP将成为你的协议，所有这些东西一起将成为你的URL｡
现在，我们已经了解了一些术语，接下来让我们看看DNS是如何工作的｡
我们有一个Web服务器，例如，我们有一个IP，
它是公共IP，可以是EC2实例｡
且公共IP为9. 10. 11. 12，我们希望能够使用示例访问它｡
com域名｡
我们要注册这个例子｡ com域名在我们的DNS服务器之一｡
但是让我们看看电脑，你的网络浏览器，
是如何访问它并得到响应的｡
所以，你的网页浏览器会想要访问example. com公司｡
为此，它将询问其本地DNS服务器｡
“喂，你知道什么例子吗｡ com是什么？ 现在，这个本地DNS服务器通常由您的公司分配和管理，
或者由您的互联网服务提供商动态分配｡
如果本地DNS服务器以前从未见过此查询，
它将首先询问由ICANN组织I-C-A-N-N管理的根DNS服务器，然后会说，
“嘿，你知道示例是什么吗？ com？ 哪个是第一个被询问的服务器｡
根DNS服务器会说，“我从来没有见过它，
但我知道｡ com公司｡ 所以... com是NS，所以它是NS记录名称服务器，
并查看1234此公共IP｡
所以，这是对本地DNS说，
“嘿，我没有这个答案，但我让你更接近你的答案，
因为我知道｡
com域和.
com域名服务器具有此IP，1234｡ 本地DNS服务器说：“好的，很好｡
现在我将询问顶级域｡ 所以｡ com域服务器｡
“我要问我的问题的答案｡ 这是另一个由I-A-N-A､
IANA和示例管理的域｡ com，好的，会被再次询问这个DNS服务器｡
那么，你知道榜样吗？ com？
DNS服务器会说，
“嘿，我知道这个例子｡ com公司｡
我没有马上回答你的问题｡
我不知道是哪条记录，
但有一个服务器叫范例｡ com我知道的是5.1. 7. 8，
这是一个公共IP，你应该问你的问题的答案｡
因此，本地DNS服务器将转到我们的最终服务器，
即子级域DNS服务器，该服务器将由您的域名注册商管理｡
比如说，亚马逊53号公路等等｡
所以DNS服务器会说，
“嘿，你知道例子吗？ com？ 并且DNS服务器将具有例如条目｡ com公司｡
所以它会说，“嘿，是的，我当然知道这个例子｡
com公司｡ 结果证明这个例子｡ com，
我知道这是一个A记录，
它的结果是IP 9｡ 10. 11. 12.
因此，DNS服务器现在通过递归询问DNS服务器并找到最具体的一个来知道答案｡
然后它说，“好吧，嘿，是的｡
我会马上缓存这个答案，
因为我希望能够这样做，
例如，如果有人再次问我｡ 我想马上得到答案，给他们答案｡
因此，
它会将答案发送回您的浏览器，您的Web浏览器现在有了答案，
然后使用此IP地址就可以访问您的Web服务器｡
这就是DNS的工作原理｡
所以，你一直在幕后使用DNS所有一直你的生活.
例如，当您访问www. 谷歌｡ com您正在使用DNS或任何网站｡
现在我们来看看DNS查询是如何工作的｡
这只是一些背景知识，
因为现在我们将进入Route
53，学习如何自己管理DNS服务器｡
希望你们喜欢，
下次课再见.
  - [ ] 87 Route 53 Overview [06:18]
    * 
讲师：现在我们知道什么是DNS，
让我们来看看Amazon Route 53｡
因此，
这是一个高度可用､ 可扩展､ 完全托管和权威的DNS｡
什么是权威？
这意味着客户可以更新DNS记录，因此您可以完全控制此DNS｡
因此，我们的想法是，
您的客户希望访问您的EC2实例@example｡
但是现在您的EC2实例只有一个公共IP｡
因此，我们将把一些DNS记录写入到Amazon Route 53中的托管区域中，
例如，当客户端请求时｡
然后Route 53服务将能够说，“嘿，
你正在寻找这个IP54｡ 22. 33.
44”，
然后客户端将能够直接连接到我们的EC2实例｡
因此，Route
53也是一个域名注册商，因此它将能够在那里注册我们自己的域名，例如｡
我们将在动手实践中介绍这一点，以便我们能够开始使用此服务｡
因此，我们还可以检查Route
53中资源的运行状况，
我们将在本节中了解这一点｡
这是AWS中唯一一项将提供100%可用性SLA的服务｡
最后，为什么叫53号公路？
53是DNS服务使用的传统DNS端口的参考，因此得名｡
因此，
在Route 53中，您将定义一组DNS记录，这些记录定义您希望如何将流量路由到特定域｡
因此，每条记录都将包含大量信息，如域名或子域名，
如example｡
com的网站｡
记录类型，
我们将看到哪些类型的记录可供我们使用，例如，它可以是A或AAAA｡
然后是值，所以记录的值，例如，
12｡ 34. 56.
78路由策略，
即Route 53如何响应查询｡
TTL，即记录将在DNS解析器中缓存的时间量，也称为生存时间｡
此外，我们在Route
53中还支持许多不同的DNS报告类型｡
您必须知道的是A､
四个A､ CNAME和NS，我们将在实践中了解这些内容｡
你可以创造的高级记录，但我们不需要从考试的角度来知道，
都是我刚刚写在这里的｡
因此，让我们从考试的角度来了解我们需要了解的重要记录类型｡
A记录非常简单，
就是将主机名映射到IPv4 IP｡
这是当你有，例如，例子｡ com，其将被定向到1｡1. 3. 4.
好吧，太好了｡
然后我们有四个A｡
这与A的想法相同，但这次我们要将主机名与IPv6地址进行匹配｡
然后我们有一个CNAME，它用于将一个主机名映射到另一个主机名｡
那么目标主机名当然可以是A或四个A的记录｡
您不能在Route 53中为DNS名称空间或Zone Apex的顶级节点创建CNAMES，
我们将在以后的课程中看到这一点，以了解其工作原理｡
例如，您不能创建CNAME｡ com的CNAME记录，但您可以为www.
示例中｡ com的网站｡
我们会在以后的课上看到如何处理这个问题｡
最后，NS用于托管区域的名称服务器｡
它们是可以响应托管区域的DNS查询的服务器的DNS名称或IP地址，并且这将控制如何将流量路由到域｡
现在，让我们来了解一下什么是托管区域｡
因此，
托管区域是一个记录容器，它们将定义如何将流量路由到域及其子域｡
因此，我们有两种类型的托管区域，即公共托管区域和私有托管区域｡
因此，每当你购买一个公共域名，
例如mypublicdomain｡
com，这是一个公共域名，
因此我们可以创建一个公共托管区域，这些公共区域可以回答以下查询：“嘿，
域名application1的底层IP是什么？
我的公共域名 是否已过期？
“但我们也有私人托管专区｡
这些是您的域名，
它们不是公开的，它们是私有的，只有您在自己的虚拟私有云或VPC中才能解析此URL｡
例如，应用程序1｡ 公司｡ 内部的｡
如果您在一家私营公司工作，您可能已经看到了这一点，
他们有时会有您只能从公司网络内部访问的URL，这是因为这是一个私有URL，这是一个私有URL，
在后台有一个私有DNS记录｡
因此，对于任何托管区域，
你要创建一个AWS，你要支付每月50美分，所以这是不是免费使用53号公路｡
如果你要注册一个域名，就像我会在动手，
这将花费你至少12美元每年｡
所以你要知道，这部分不是免费的｡
为了便于理解，我们将介绍公共托管区域和私有托管区域｡
因此，公共托管区域可以回答，
可以回答来自公共客户端的查询｡
所以当你浏览网页时，
比如说，“嘿，给予我举个例子｡ com”，然后返回一个IP｡
在另一端，我们有一个私有托管区域｡
所以这是从你的VPC里面他们住｡
因此，它们允许您使用私有域名来标识私有资源｡
例如，我们有一个EC2实例，希望通过webapp标识它｡
示例中｡
内部，我们有另一个EC2实例，我们希望使用api标识它｡
示例中｡
内部，然后我们有一个数据库，我们希望与数据库标识｡ 示例中｡ 内部的｡
在这种情况下，我们将注册一个私有托管区域，
然后在第一个EC2实例请求api的情况下｡
示例中｡
internal，则专用托管区域有一个答案，即专用IP 10.1. 0. 10.
然后，EC2实例将连接到第二个EC2实例，
后者可能需要连接到数据库｡
所以它会说，“嘿，数据库是什么｡ 示例中｡ 内部的？
“而私有托管区域会说，“好吧，
这就是这个私有IP｡
“然后，
EC2实例可以直接连接到数据库｡
因此，公共托管区域和私有托管区域的工作方式完全相同，但只有公共托管区域允许来自互联网的任何人查询您的记录，
因此这是针对您的公共记录，而私有托管区域只能从您的私有资源（例如您的VPC）中查询｡
理论就讲到这里，现在我们进入下一节课，注册一个域，
然后创建一些记录｡
所以我们下节课再见｡
  - [ ] 88 Route 53 - Registering a domain [02:59]
    * 
  - [ ] 89 Route 53 - Creating our first records [03:56]
    * 
  - [ ] 90 Route 53 - EC2 Setup [05:40]
    * 
  - [ ] 91 Route 53 - TTL [05:28]
    * 
教师：好的，让我们来看看TTL｡
因此，记录TTL是一个生存时间｡
让我们以客户端访问我们的DNS路由53和web服务器为例｡
因此，我们为myapp发出DNS请求｡ 示例中｡
我们从DNS得到了一个答案，它说，
嘿，拜托，这是一个A记录｡
这是IP，
还有TTL，可能是300秒的TTL｡
因此TTL会说，嘿，客户端，
请在TTL期间缓存此结果｡
因此，在300秒内，客户端将缓存结果｡
这意味着，如果客户端再次请求或访问相同的主机名，将会发生的情况是客户端不会向DNS系统发出查询，
因为它已经知道答案，
因为答案已被缓存，并且我们仍在该高速缓存期内，因此缓存TTL｡
这背后的想法是，我们不想太频繁地查询DNS，
因为我们不希望记录发生太大变化，因此，使用它的响应，客户端可以访问我们的web服务器，
并执行HTTP请求和响应｡
所以我们有两个极端的例子｡
例如，
如果您将TTL设置为24小时，则Route
53上的通信量将大大减少，因为执行请求的客户端更少，因为结果将缓存24小时，而且客户端可能会有过期的记录｡
如果您想以某种方式更改记录，则需要等待24小时，
以确保所有客户端的缓存中都有新记录｡
如果您说设置一个较低的TTL，例如60秒，
则相反，
它将在您的DNS上处理更多的流量，因此您将花费更多的美元，因为您将按到达Route 53的请求数量计算价格｡
但是记录的过期时间会更短，因此您可以更快地更改记录，
并且更容易更改整个记录｡
因此，究竟什么是好TTL还是低TTL，完全取决于您自己｡
如果您计划更改一条记录，
其想法是，有时您会降低TTL，
比如说降低24小时，然后当您知道所有客户端都有一个较低的新TTL时，
您可以更改记录值，该值将为每个客户端更新，然后您可以增加TTL｡
这是一种策略｡
所以TTL对于每个记录都是强制性的，
除了别名记录，我们将在下节课中看到｡
让我们看看TTL在控制台中是如何工作的｡
现在，让我们来了解一下“生存时间”的工作原理｡
我们来创建一条新记录，将其命名为demo｡
斯蒂芬老师｡
它的值将是我们已知的EC2实例之一｡
那我们就选欧中一号吧｡
我将使用这个EC2实例并粘贴它的值｡
然后，对于TTL，我们将设置为两分钟｡
为此，我将双击“分钟”按钮｡
因此，TTL现在是120秒｡
所以让我来创造这张唱片｡
现在我的记录已经被创造出来了｡
因此，它是指向演示中特定IP的A记录｡
斯蒂芬老师｡ com的网站｡
现在，
我想告诉你，记录是工作的，但Firefox不是很好与我｡
所以如果我在Firefox中打开它就给予出现问题｡
所以这不是我能轻易解决的问题，
所以我会用右边的Google Chrome来给你们看｡
所以如果我做演示｡ 斯蒂芬老师｡
然后它会自动把我引导到我的eu-central-1实例｡
所以这意味着这个记录，这个A记录，
是完全正常的｡
我也可以确保这一点，
例如，如果我使用CloudShell｡
如果我清除这个并在demo上执行nslookup｡
斯蒂芬老师｡
如您所见，地址正确｡
如果我对它执行一个挖掘命令，我们就能得到答案｡
我们在这里展示了一个很酷的数字，答案部分是115｡
所以这里的想法，这是因为我做了一个DNS查询｡
然后，记录将缓存120秒｡
如果我在这里重新输入这个dig命令，你可以看到数字降到了98｡
这就意味着在98秒内，
实际上，我会得到相同的响应，因为，
无论如何，这都是缓存在我计算机上的内容｡
如果我的速度很快，我会转到此处的记录并对其进行编辑，因此，
我不想使用此IP，
而是要转到ap-southeast-1，因此我们将使用列表中的第一个IP并保存此IP｡
因此，即使该记录被更新，
如果我进入CloudShell，再次执行此dig命令，如您所见，
插入仍然与之前相同｡
这是因为还有66秒的时间会被缓存｡
如果我进入Chrome，我想我已经足够快了，我进入Chrome并刷新这个页面，
正如你所看到的，我仍然有来自eu-central-1的答案｡
这是因为，我的记录被缓存了两分钟｡
因此，当该高速缓存存到期时，只有在那时我的命令行界面或Chrome
web浏览器才会再次向53号公路询问此记录的值｡
然后，
我会再次得到答案，并将被重定向到这个新的IP｡
所以最好的检查方法就是等待｡
所以我再等一分钟，然后再打给你｡
好的，现在已经过了一分钟，如果我刷新我的web浏览器，
正如你现在看到的，
我会看到一个不同的Hello World，这次它来自ap-southeast-1b｡
如果我进入CloudShell并执行相同的dig命令，那么，如您所见，
会有一个新的TTL，
也就是120秒，这里会有一个新的IP，即IPO菜单服务器｡
这是一个很酷的TTL演示｡
我希望你们喜欢，下节课再见｡ 
  - [ ] 92 Route 53 CNAME vs Alias [07:00]
    * 
教师：现在，我们来了解一下CNAME和别名之间的区别｡
因此，
当您拥有AWS资源（例如负载平衡器或CloudFront）时，它将公开主机名｡
您需要的是将该主机名映射到您拥有的域｡
例如，您希望将此负载平衡器映射到myapp｡
mydomain中的值｡ com的网站｡
所以我们有两个选择｡
第一种方法是使用CNAME记录｡
我们已经看到了A记录，现在让我们看一下CNAME记录｡
因此，CNAME允许您将主机名指向任何其他主机名｡
例如，您可以说app｡ mydomain中的值｡
com都指向blabla｡ 什么都行｡ com的网站｡
这只在你有一个非根域名的情况下才起作用，所以如果你有东西的话｡
mydomain中的值｡ com的网站｡
它不仅适用于mydomain｡
我们将在实践中看到｡
另一方面，您有别名记录，这些记录特定于Route
53，但它们允许您将主机名指向特定的AWS资源｡
所以应用程序｡ mydomain中的值｡ com都指向blabla｡ 亚马逊人｡ com的网站｡
我们马上就能看到这些资源的位置｡
但这些别名记录对根域和非根域都有效｡
所以你可以拥有我的领域｡
作为别名指向别名资源，这非常非常好｡
这是考试中可能要测试的内容，我们将在实践中看到这一点｡
最重要的是，
别名是非常好的，因为它们是免费的，而且它们具有本机运行状况检查功能｡
好的，如果我们详细查看这些别名记录，
它们只映射到AWS中的资源｡
所以你会说，“好的，这是53号公路｡
我想举个例子｡
com作为类型为A的别名记录，该值是您所拥有的负载平衡器的DNS名称｡
这是对DNS功能的扩展｡
这是存在于所有DNS中的一个问题｡
如果基础ALB有IP更改，则别名记录将自动识别这些更改｡
所以它说与CNAME不同，别名记录可以用于顶级，对于顶级节点的DNS命名空间称为Zone
Apex，所以可以用别名记录为例｡
com的网站｡
现在，
别名记录始终是A或AAAA类型，这是针对资源的，因此是IPv4或IPv6｡
如果有别名记录，则不能设置TTL｡
它是由53号公路自动设置的｡
那么，别名记录的目标是什么？
嗯，可能是弹性负载平衡器｡
可能是云锋分销｡
有些你们会在这门课上看到，
有些你们不会在这门课上看到，但这很好.
只是让你了解一下他们的能力｡
ELB､ CloudFront分发､
API网关､ Elastic Beanstalk环境､
S3网站，
因此当这些桶作为网站､ VPC接口端点､ 全局加速器加速器和Route
53记录在同一托管区域中启用时，不是S3桶而是S3网站｡
有一点是不存在的，
那就是您不能为EC2 DNS名称设置别名｡
这是你需要记住的｡
因此，EC2 DNS名称不是您可以拥有的目标，
它可以是别名记录的目标，明白吗？
只是，也是为了让你知道｡
现在，让我们在控制台中查看一下CNAME和别名记录的工作方式｡
因此，
让我们继续创建一个记录，该记录的类型为CNAME｡
所以我把这个叫做myapp｡ 斯蒂芬老师｡ com的网站｡
现在的记录类型不是A，也不是AAAA｡ 这是CNAME｡
然后该值必须是域名｡
而且很容易，我已经有一个可用的域名｡
那是我的ALB
我现在要做的是复制ALB的名称并粘贴到这里｡
我的想法是，现在不是通过这个URL访问我的ALB，我想通过myapp访问ALB｡
斯蒂芬老师｡ com的网站｡
好的，我将创建此记录，现在是myapp｡
斯蒂芬老师｡ com已创建｡
如果我进入我的Chrome浏览器，在右边打开这个URL，
现在你会看到答案是Hello World，来自我的IP，
等等，
等等，等等，在AZ eu-central-1c｡
因此，此域名实际上由ALB覆盖，
ALB将流量定向到一个EC2实例，因此我收到了Hello World｡
这很好，但这不是AWS本地的，好吗？
这对许多域名来说都是可行的，但我们可以做得更好｡
因为我们要重定向到ALB，所以我们可以做的是创建别名记录｡
所以我可以创建一个记录，这次是我的别名｡
斯蒂芬老师｡
com，并且记录类型是A，因为我的ALB当前只有IPv4流量｡
以及它的值，所以我们必须说，我们必须在这里使用别名，
我们将流量路由到，
然后我们有一个选项列表，好吗？
因此，我们可以看到许多不同的选项，
但现在它将是应用程序和传统负载平衡器的别名｡
我们需要选择一个区域，所以它对我来说是在eu-central-1｡
然后，我们需要选择负载平衡器，因此我将在此处选择此负载平衡器｡
然后，
我们也可以自动评估目标运行状况，结果为“是”，因为这是别名记录｡
我们单击“Create this record”，现在这里有一个新记录，
名为myalias｡
斯蒂芬老师｡ com的网站｡
最酷的是这个记录是可以自由查询的，好吗？
所以我不打算付任何钱，因为这是一个别名记录｡
所以如果我点击我的别名｡ 斯蒂芬老师｡
它将执行一些DNS查询，现在，
我再次得到相同的响应｡
好吧，什么都没变，但它在起作用｡
好吧，那就太完美了｡
但是现在如果你考虑域顶点，如果你只想有stephanetheteacher｡
是否重定向到此页面？
我们要做的是创建一个记录，然后继续｡
所以我们这里什么都没有，好吗？
我们将有一个CNAME记录指向我的ALB的域名，它是从这里复制并粘贴到这里的｡
好的，我们想说，“嘿，斯蒂芬妮老师｡
com将是此值的CNAME｡ “现在，这是行不通的｡
让我们试试看｡
它在说，“嘿，糟糕的请求｡
不允许在此区域的顶点使用CNAME｡ “那么这个区里就是Stephanetheteacher了｡
这个区域的顶点是StephanetheTeacher｡
com，因此我们无法在顶点设置CNAME｡
因此，我们解决此问题的唯一方法是创建一个别名，
该记录的类型为A，该别名将再次指向eu-central-1区域中的ALB或CLB，负载平衡器将是之前的负载平衡器｡
现在，这将被接受，
因为这是一个别名记录，这是什么考试可能会考验你，好吗？
所以现在我们可以看到斯蒂芬老师｡
com是可访问的｡
所以如果我回到我的网页浏览器，打开一个新的标签，输入stephanetheteacher｡
com并按Enter键，在这里我从负载平衡器返回Hello World，因此一切都运行良好，
就是这样｡
我们已经展示了CNAME和别名记录在AWS中的工作方式｡
我希望你们喜欢，下节课再见｡
  - [ ] 93 Routing Policy - Simple [04:05]
    * 
教师：现在我们来讨论53号公路的路由策略｡
因此，路由策略帮助Route 53响应DNS查询，
我们不应对“路由”一词感到困惑｡
这与您有负载平衡器的情况不同，实际的负载平衡器会将流量路由到后端EC2实例｡
不，不，不，不，不，不，不
此路由是从DNS的角度进行的｡
因此DNS不响应，不路由任何流量｡
这样流量就不会通过DNS｡
例如，DNS只会响应DNS查询，
然后客户端将知道它们应该以哪种方式进行这些HTTP查询｡
因此，DNS只是帮助将主机名转换为客户端可以使用的实际端点｡
因此，Route 53将支持以下路由策略｡
有简单､ 加权､
故障转移､ 基于延迟､ 地理定位､ 多值答案和地理邻近性｡
我们将在这一节中对它们进行详细介绍｡
第一个是简单路由策略｡
我们的想法是，通过这个，我们以前实际上已经使用过了，
我们将把流量路由到一个典型的资源｡
这里有一个例子｡
客户会说，嘿，
我想去foo｡ 示例中｡
然后Routes53会说，嘿，
转到这个IP地址｡
而这是一张A级唱片｡
因此，我们可以在同一条记录中指定多个值｡
如果是这样，如果DNS返回多个值，
则客户端或客户端侧将选择随机值｡
在这个例子中，客户端再次请求foo｡
示例中｡
而AmazonRoute53将仅用嵌入到A记录中的三个IP地址来回复｡
然后，客户端将随机选择其中一个并将其应用于路由｡
因此，如果您在简单策略旁边启用了别名记录，
则只能将AWS资源指定为目标｡
最后，它之所以被称为简单，是因为它非常简单｡
因此，
您无法将此与运行状况检查联系起来，我们将在本节稍后部分了解运行状况检查及其工作原理｡
现在，让我们进入控制台，看看如何创建step
simple路由策略｡
我们来创建一条记录，记录名称将很简单｡
斯蒂芬老师｡ com的网站｡
这是一个A记录，
它的值是，例如，我在ap-seouthern-1中的实例｡
现在对于TTL，它将表示非常低的值，
例如20秒｡
路由策略将在这里｡
如您所见，
我们有不同的可能性，其中六种，还有一种在UI中的其他位置｡
因此，我们有一个TTL 20秒作为简单的写入策略，
让我们创建此记录｡
我们以前也这么做过｡
我们知道这是怎么回事｡
所以现在我们如果去简单｡ 斯蒂芬老师｡ com的网站｡
转到这个URL，
我们从我在ap-seoustern-1b的实例中得到Hello World，这太棒了｡
而如果我们做一个挖掘命令并看看，那么我们需要重新安装挖掘｡
所以sudo yum安装绑定实用程序｡
这是因为我在这里重新启动了我的机器｡
好的，我们要重做dig命令｡
所以我们在这上面执行dig命令｡
正如我们所看到的，我们有一个指向此IP的20秒TTL的A记录｡
但我们现在可以改变这个记录了｡
我们要编辑唱片｡
因此，我只需单击它并编辑记录｡
对于值，现在，我可以输入多个IP｡
例如，
我可以在ap-seast-1中插入一个，或者在us-east-1中插入一个｡
所以当我这样做并保存它时，会发生的是一旦TTL从之前过期，我们会得到两个记录｡
因此，让我们使用CloudShell来验证这一点｡
所以我要执行一个挖掘命令｡
正如你所看到的，现在我们在交叉点，我们有两个答案｡
我们在此IP中有一个，在此IP中有一个｡
所以这是客户端的选择｡
所以这意味着如果我去这个网站，
并刷新，我有一个机会在两个进入我们—东-1｡
但我没有｡
所以我回到了东南1b，
但让我暂停20秒，我会回来给你｡
我在提神｡
我从我们那里拿回了你好世界—东-1a｡
所以这起作用了｡
这绝对说明了简单记录是如何工作的｡
我希望你们喜欢，下节课再见｡
  - [ ] 94 Routing Policy - Weighted [05:02]
    * 
教师：现在我们来讨论加权路由策略｡
其思想是，
由于权重，您可以控制一定百分比的请求转到特定资源｡
简单地说，在图中，我们有Amazon
route 53，然后我们有三个EC2实例，
它们被分配了不同的权重，
分别是70､ 20和10｡
在我的例子中，这些权重加起来是100，但在真实的生活中你不必这么做，
好吗？
但这意味着，
来自Amazon的70%的DNS响应将重定向到第一个EC2实例，然后20%重定向到第二个，10%重定向到第三个｡
所以我们在权重中要做的就是给每个记录分配一个相对权重｡
然后流量百分比将被发送到每条记录，就像记录的权重除以所有记录的所有权重之和，就像所有权重的百分比一样，
好吗？
权重不需要加起来等于100，它们只是表示与DNS名称中的所有其他记录相比，
我们要向该实例发送多少内容｡
因此，要实现这一点，
DNS记录必须具有相同的名称和类型，您可以将它们与运行状况检查关联起来，虽然我们还没有看到运行状况检查，但我们很快就会看到它们｡
现在，加权路由策略的使用情形非常明显，例如，
可能跨不同区域执行负载平衡，
或者通过向新应用程序版本发送少量流量来测试新应用程序版本，等等｡
然后，如果你发送到一个权重为零的排序，那么你将停止发送流量到一个特定的资源，
所以你可以随着时间的推移转移权重｡
如果所有资源记录的权重都为零，则返回的所有记录的权重都相等｡
让我们在控制台中看看它是如何工作的｡
让我们创建一个新记录，这个记录叫做加权记录｡
史蒂芬妮塔彻 com的网站｡
这是一个A记录，路由策略将被加权｡
首先对于第一个值，让我们输入ap-southeast-1的值，这次我给它赋值的权重是10，
好吗？
所以它的重量非常非常小｡
对于TTL，我会将其设置为非常低的值，3秒，
以便向您展示加权的影响｡
但很明显，这不是你在真实的生活中会使用的TTL｡
因此，正如我们所看到的，我们可以将运行状况检查与它关联起来，
但现在我们不会｡
我们有一个可以设置的记录ID｡
这是为了在加权记录集内标识该特定记录｡
在这个例子中，我从东南方向得到这个例子，
我只写东南方向｡
好的，然后我们可以再加一条记录｡
同样，我们将使用相同的权重｡
史蒂芬妮老师 好吗？
路由策略将被加权｡
它的值是来自us-east-1的值｡
我将复制此IP地址并粘贴到此处｡
这次的重量是70.
因此，
我们将70%的流量发送到us-east-1，然后记录ID为“US East”｡
太好了，还是TTL，三秒｡
最后一条记录我们要加，
同样是加权的，它的值是eu-central-1，在这里｡
我将把它作为加权记录发送｡
我将发送20个砝码，
记录ID将是EU OK｡
和TTL三秒｡
现在，让我们继续创建这些记录｡
正如我们所看到的，我们现在在这个表中有三条记录，
好吗？
这就是为什么它不同于，例如，一个简单的记录有两个值，
这里，我们有三个记录，每个记录有一个值作为答案，
但是我们有10，20和70的权重｡
如果我现在转到这个URL，如果我转到加权｡
斯蒂芬老师｡
然后按Enter键，
我得到了来自us-east-1a的第一个响应，这是有道理的，因为这是70%的流量应该流向这个地区的地方｡
但是，
如果我刷新，我需要刷新可能每三秒，
在某些时候，我应该得到一个来自另一个地区的响应｡
而这仅仅是基于权重，所以这是加权资源背后的（模糊不清）｡
如您所见，这一个变化不大，
我们来执行一个dig命令，以显示它的输出，即dig加权｡
斯蒂芬老师｡ com的网站｡
这里我们得到的TTL值是3，答案是，我想还是来自us-east-1的那个，
但是让我们试着再发出一个，看看我们会不会更幸运｡
所以70的重量绝对是一个很大的重量｡
好的，但是我们可以看到，我们刚刚得到了一个答案，这个是不同的IP，
3｡ 70.
14，这对应于20的权重｡
正如我们所看到的，加权做的正是它应该做的，
它将大多数查询重定向到一个有最大权重的查询，但有时，你会得到其他的答案，
好吗？
如此等等｡
所以这是你可以在你的网页浏览器中练习的东西，就像我们看到的那样，
很酷｡
我刚被编辑进了中央1c｡
这节课就讲到这里，希望它能向你们展示加权记录的力量｡
我希望你们喜欢，下节课再见｡
  - [ ] 95 Routing Policy - Latency [04:39]
    * 
教师：我们来讨论一种非常容易理解的路由策略，即基于延迟的路由策略｡
好吧，我会的
现在，我们来讨论一下基于延迟的路由策略｡
我们的想法是，您希望重定向延迟最低的资源｡
因此，最接近我们，这是超级有用的，
当延迟是你的网站或应用程序的主要关注点｡
现在，延迟将根据用户连接到最近的､
已确定的AWS区域以获取该记录的速度进行测量｡
例如，
如果用户在德国，而您在美国的资源具有最低的延迟，那么这就是您将被重定向到的位置｡
这可以和健康检查结合起来，我们会在下一节课看到.
那么让我们看一下世界地图来了解它｡
假设我们在世界的两个不同地方部署应用程序，
一个在美国东部1，另一个在亚太东南部1｡
然后，
用户遍布世界各地，延迟将由Route 53进行评估｡
因此，距离ALB最近且延迟最低的用户us-east-1将被重定向到ALB｡
而其他用户将被重定向到ap-southern-1｡
现在，让我们在控制台中将其付诸实践｡
所以让我们创建新记录｡
记录的名称将是“延迟”｡
斯蒂芬老师｡ com的网站｡
第一个值将是ap-southern-1中的值｡
所以我可以把值粘贴到这里｡
然后，路由策略将是“延迟”｡
因此，当我们执行此操作时，因为我们只是在此处输入了一个IP地址，
所以我们需要指定记录的区域｡
所以这一个将对应于ap-seouthern-1，它在新加坡｡
好吧，我会的
原因是Alias不够智能，至少在这个阶段，无法获取此IP并知道它来自我在新加坡的EC2实例，
因为这实际上可能是世界上的任何IP｡
因此，我们需要指定该IP对应的地区，即亚太地区､ 新加坡｡
然后，我们可以关联运行状况检查和记录ID｡
所以我把这个叫做ap-southern-1
这只是我给予它起的名字｡
现在，我们可以添加另一条记录｡
同样，
记录名称将为“Latency”，此名称的值将为us-east-1｡
这里有一个值，它将被加权.
否，延迟｡ 不好意思，当然｡
然后是美东一号｡
同样，我将它作为一个us-east-1为我的记录ID｡
最后一条记录是欧洲中央一号｡
所以我就复制了这个IP｡
记录名称是this，值是here，路由策略是Latency，
区域是eu-central-1，名称也是如此｡
好吧，我会的
如我们所见，我们有三个记录正在创建，已成功创建，
这就是它｡
现在让我们来尝试一下｡
所以现在我在欧洲｡
所以如果我打开这个，我希望它会转到我在欧洲的实例｡
我转到这个URL，从eu-central-1c的这个IP得到一个响应，Hello
World｡
如果我使用CloudShell来测试它，我们在上面执行一个dig命令｡
正如我们所看到的，我们得到的错误代码只有一个值｡
好吧，我会的
因此，只有一个值的IP地址与此相同｡
这是我在eu-central-1c中的实例｡
如果我继续刷新，因为我的延迟没有变成中央1，我会得到，
总是相同的答案｡
好吧，我会的
但是，我们如何测试延迟记录是否有效呢？
好吧，我可以用VPN｡
比如说加拿大｡
在加拿大，我的潜伏期最接近美国｡
S的｡
因此，如果我现在刷新这个页面，
我会从U. S的｡
当我确实改变了我的位置，
由于VPN，它清除了我的DNS缓存的所有TTL，在我的笔记本电脑本地｡
这就是为什么通过自动刷新它，我能够得到us-east-1a的最新值｡
但是，如果我使用dig，因为它没有改变，好吧，
我的CloudShell仍然在欧洲，好吧｡
如果我使用dig命令，并使用与这里完全相同的命令，我仍然会得到与前面完全相同的值，
好吧，
因为，这台计算机就在这里，这台CloudShell位于eu-central-1｡
所以这仍然是最接近欧盟中央一号的位置｡
我们怎么测试AP东南部的那个？
我们去香港吧｡
好吧，我会的 所以我现在离新加坡很近了｡
我会刷新这个｡
答案是，你好，世界，从ap-东南-1b｡
因此，延迟记录是有效的，它们真的非常好，
在网上非常常用｡
我希望你们喜欢，下节课再见｡
  - [ ] 96 Route 53 Health Checks [04:54]
    * 
教师：那么，让我们来谈谈53号公路的健康检查｡
健康检查是一种检查公共资源健康状况的方法，当然我们也可以对私有资源进行健康检查，
这节课我们会讲到｡
例如，我们在不同的区域有两个负载平衡器，它们是公共负载平衡器，
好吗？
在后台，我们的应用程序在这两个平台上运行｡
因此，
我们需要一个多区域设置，因为我们需要在区域级别实现高可用性等｡
然后，我们将使用Route 53创建DNS记录｡
这就是用户访问我们的URL的时间，例如mydomain｡
com上，然后它们被重定向到例如它们拥有的最近的负载平衡器｡
这就是延迟类型记录的情况｡
但我们希望确保，如果一个地区出现故障，
我们不会将用户发送到该地区，这是显而易见的，对吗？
为此，我们将从53号公路创建运行状况检查｡
因此，
我们将在us-east-1中的实例上创建运行状况检查，并在eu-west-1中的实例上创建运行状况检查｡
有了这两项健康检查，我们就能把它们和53号公路的记录联系起来.
我们这样做的原因是为了实现自动化的DNS故障转移｡
因此，我们有三种可能的健康检查｡
我刚才向大家展示的是监控端点（公共端点）的运行状况检查｡
因此，它可以是应用程序､
服务器或其他AWS资源｡
它可以是监控其他运行状况检查的运行状况检查（也称为计算运行状况检查），也可以是监控CloudWatch警报的运行状况检查，
这将为您提供更多控制，
并有助于私有资源，我们将在本讲座中看到这一点｡
最后，
这些运行状况检查有自己的指标，您也可以在CloudWatch指标中查看它们｡
现在，让我们看看运行状况检查如何与特定端点配合使用｡
因此，
如果我们对eu-west-1和ALB进行运行状况检查，那么AWS的运行状况检查人员将来自世界各地｡
因此，这不仅仅是一个运行状况检查器｡
这是来自世界各地的15个健康检查员｡
它们都会将请求发送到我们的公共端点，发送到我们设置的任何路由｡
然后，如果它返回200个OK代码或我们定义的代码，
则认为该资源是健康的｡
因此，大约有15个全局运行状况检查器将检查端点的运行状况，
然后您可以设置一个阈值来判断运行状况是否正常｡
您可以设置一个间隔，因此我们有两个选项｡
它可以是30秒的定期健康检查或每10秒，
这是一个更高的成本，这就是所谓的快速健康检查｡
它支持许多协议，如HTTP､ HTTPS和TCP｡
规则是，
如果超过18%的健康检查员说端点是健康的，那么53号公路将认为它是健康的，否则它被认为是不健康的｡
您还可以选择要用于运行状况检查的位置｡
现在，
仅当您从负载平衡器返回状态2xx或3xx状态代码，并且运行状况检查具有冷却功能时，运行状况检查才会通过｡
因此，如果它是基于文本的响应，那么健康检查器可以检查响应的前5，120个字节，
以在响应本身中查找一些特定的文本｡
最后，从网络角度来看非常重要的一点是，
如果您希望运行状况检查器正常工作，那么很明显，它必须能够访问您的应用程序平衡器或您拥有的任何端点｡
因此，
您必须允许来自Route 53健康检查器的IP地址范围的传入请求｡
您可以在屏幕右下角的URL中找到此地址范围｡
第二种类型的运行状况检查是计算运行状况检查｡
因此，这是将多个运行状况检查的结果联合收割机到单个运行状况检查中｡
如果您看一下Route 53，其中有三个EC2实例，
我们可以创建三个运行状况检查｡
它们都将是儿童健康检查，并且它们都可以逐个监视每个EC2实例｡
然后，我们可以定义父级运行状况检查，
该检查将在所有这些子级运行状况检查上定义｡
因此，
联合收割机所有这些运行状况检查的条件可以是OR､ AND或NOT｡
您最多可以监视256个子级运行状况检查，并且可以指定父级需要通过多少个运行状况检查｡
例如，
如果您希望进行父级健康检查，以便在不导致所有健康检查失败的情况下对您的网站执行维护，则可以使用此用例｡
那么，我们如何监控私人资源的健康状况呢？
因此，如果您想要监控某些私有内容，
这将是困难的，
因为虽然所有Route 53运行状况检查程序都位于公共web上，但它们位于VPC之外，因此无法访问私有端点｡
因此，如果是私有VPC或内部资源，
因此，
我们可以这样做，虽然，
是创建一个CloudWatch指标，并分配一个CloudWatch警报｡
然后，您可以将CloudWatch警报分配到运行状况检查器中｡
我们的想法是，使用CloudWatch指标监控私有子网中EC2实例的运行状况｡
然后，
如果违反了指标，我们将在其上创建CloudWatch警报｡
当警报进入警报状态时，运行状况检查程序将自动处于不正常状态，
因此将创建我们想要的内容，即对私有资源进行运行状况检查，这是最常见的使用情形｡
这节课就讲到这里｡
我希望你们喜欢它，我们下节课再见｡ 
  - [ ] 97 Route 53 - Health Checks [04:39] Hands On
    * 
  - [ ] 98 Routing Policy - Failover [04:12]
    * 
导师：好的，现在我们来谈谈路由策略，
这一条是针对故障转移的｡
我们的想法是，
我们在中间有路由53，我们有EC2实例，
其中一个将是我们的主EC2实例，第二个将是辅助EC2实例，即灾难恢复EC2实例｡
在本例中，我们要将主记录与运行状况检查关联起来，这是强制性的｡
如果运行状况检查结果不正常，则路由53将自动故障切换到第二个EC2实例，并开始将结果发回｡
当然，
如果我们需要，辅助EC2也可以与运行状况检查关联｡
但只能有一个主要和一个次要｡
现在，
当客户端发出DNS请求时，它将自动获取被认为运行正常的资源｡
所以如果我们的主要是健康的，那么53号公路将回答一个主要的记录｡
但是，如果运行状况检查不正常，我们将自动获得第二条记录的响应，
这确实有助于我们执行（模糊的）故障转移｡
好了，
让我们开始动手练习，看看我们如何练习｡
好的，现在让我们利用这些运行状况检查并创建故障切换记录｡
因此，在我的托管区域中，我将创建一个记录，这个记录将称为故障转移｡
斯蒂芬老师｡
com，
它是A记录，第一个值是我的EU-central-1实例，
也就是离我最近的那个，路由策略是故障转移｡
TTL会将其设置为非常低的值，
例如60秒｡
故障转移记录类型有两个选项｡
它可能是主要的或次要的，只有这两个｡
所以这是我的主要记录，我会将它与健康检查联系起来，我必须这样做｡
因此，它将与名为EU-central-1的运行状况检查关联，
并且记录ID将为E｡
也就是说，
此记录应该是我的主记录，但它将与运行状况检查相关联，这意味着您可以故障切换到第二个记录｡
我们来添加一条新记录，并将记录名称保留为failover｡
斯蒂芬老师｡
它的值将是我在US-east-1中的实例｡
好的，我们仍然需要执行故障切换，TTL为60秒，
故障切换记录类型将为次要｡
现在，我们可以选择将您的健康检查与它关联，好的，
美国东部1号，但您不必这样做｡
记录ID将是US｡
现在，
让我们创建此记录，请注意，它已成功创建｡
让我们回到健康检查｡
目前，这两项与我的记录相关联的健康检查是健康的｡
如果我进入URL，那么如果我进入故障切换｡
斯蒂芬老师｡
现在，我从EU-central-1c得到了一个答案，那太好了｡
但我要做的是触发一个失败｡
让我们进入EU-central-1区域，
我将在这里找到我的实例，并找到安全组，然后再次停止一些安全组角色｡
让我们刷新此页面｡
它确实存在，那太完美了｡
对于入站规则，我将对其进行编辑，
它将删除端口A上的规则｡
因此，这将使我的实例完全无法从健康检查器访问｡
我现在要做的就是等待运行状况检查变为不正常状态，然后我们就可以测试故障切换了｡
我们来刷新一下，
现在我们可以看到，我的EU-central-1运行状况检查被认为是不正常的，
我们可以查看“监视”选项卡，看看它何时出现不正常的情况，这非常酷｡
健康检查器是阳性的，
然后它变成了零，然后我们可以看到有多少百分比的健康检查器报告健康，再次，这下降到零｡
这意味着，由于我们设置与此运行状况检查关联的故障切换的方式，
此运行状况检查现在处于不正常状态｡
那么下次刷新时，
我不应该在欧盟中部-1c，我应该在美国东部-1｡
所以，
让我们刷新这个（模糊的）页面，是的，答案是我们在美国东部1｡
因此，故障转移确实在后台无缝运行｡
在修复时，
您只需返回安全组，编辑入站规则，
然后重新添加HTTP规则，然后运行状况检查将自动再次通过，因此我们将故障切换回主位置｡
这节课就讲到这里，
希望你们喜欢，下节课再见｡
  - [ ] 99 Routing Policy - Geolocation [04:15]
    * 
现在我们来讨论一下路由策略—地理定位，它与基于延迟的路由策略有很大不同｡
因此，这是基于用户的实际位置｡
所以，举个例子，
你可以说，如果一个用户来自一个特定的大陆，或者一个国家，或者更准确地说，
在美国｡ S的｡
状态，
并且，首先将选择最精确的位置，然后将其路由到此IP｡
因此，您应该创建一个默认记录，以防在位置上没有匹配项，
并且此记录的使用情形将用于网站本地化､
限制内容分发､ 执行负载平衡等｡
并且这些类型的记录可以与运行状况检查相关联｡
因此，我们的想法是，如果我们有一个欧洲地图，有多个国家，
我们可以定义一个德国的地理位置记录，看看德国用户应该去这个IP，
其中包含我的德语版本的应用程序｡
如果我去法国，那么就去这个IP，
它包含了我的应用程序的法语版本｡
但是对于其他任何地方，请转到这里的默认IP，
其中可能包含我的应用程序的英语版本｡
这就是地理定位的使用方法
现在，让我们在控制台中练习｡
好的，那么，让我们继续，创建我们的第一个地理记录｡
我将创建一条记录，并将其设为geo，
记录类型为A，
其值为，我们先将其链接到ap-seouthern-1｡
我们在这里要做的是，路由策略将是地理定位｡
我们说，好的，
所有亚洲，
所以，任何位于亚洲的用户，都应该转到我的ap-southeast-1 EC2实例｡
如果需要，
我们可以将运行状况检查与它关联，我们需要给予一个记录ID，现在开始｡
现在，让我们再添加两条记录｡
所以我要做的是，
我会说这是，对于us-east-1｡
我想发送来自的任何用户，我们可以再次说地理定位｡
比如说，
一个国家，我们可以说，美国｡
最后，我们可以说，这是记录ID, U｡ S的｡ 所以，你们可以看到，
我指定了一个国家，这里指定了整个大陆，这并不重要｡
最后，
我们再添加一条记录，这是记录名称，其值为eu-central-1｡
这是我的默认位置，
地理位置是默认位置，这意味着任何与亚洲或美国不匹配的内容都将转到我的默认位置，这一个将被称为“默认欧盟”｡
现在，它正在创建这些记录，
它们已经成功创建｡
所以，我现在能做的就是测试它，对吧？
所以，目前，我不在美国｡ S的｡ ，而我又不在亚洲｡
如果我打开这个URL，我将得到eu-central-1区域，
这很好，这意味着这是默认记录，是纯记录，工作正常｡
现在，
让我们改变地理位置，为此，我将使用我的VPN，
现在让我们转到亚洲的一个国家，所以让我们转到印度｡
所以，我现在连接到印度｡
当我现在刷新这个页面时，
我希望从我的ap-seouthern-1实例中得到一个Hello World｡
如您所见，这是一个很长的负载，
我知道发生了什么，
这是一个超时，因此，每当您在AWS中看到超时时，通常您必须考虑安全组｡
因此，如果我转到我的安全组，
是的，
我在正确的区域中，即在新加坡区域中，查看入站规则，并编辑它们｡
如果您还记得，我已经删除了使运行状况检查失败的HTTP规则，
因此，我们需要重新添加该HTTP规则，现在我们将其重新添加，
屏幕上的编辑效果很好｡
HTTP规则已添加回来，现在，如果我返回此页面，
我们可以看到，
现在，我们从ap-southeast-1b获得Hello World，
因此，Asia功能正常工作｡
现在，如果我去美国的一个国家｡ S的｡ 如果我去美国，总的来说，我在美国｡
S的｡
然后刷新，我将从us-east-1a获得Hello World，这样就完美了｡
而且，如果我去的地方就在U｡ S的｡ 但在美国没有｡ S的｡ ，比如说，如果我去墨西哥｡
然后刷新，如您所见，我得到了eu-central-1c，因为这是我的默认记录，
并且，在地理位置Route
53记录中没有将Mexico指定为规则｡
好吧，就是这样，这是完美的工作｡
我希望你们喜欢这节课，下节课再见｡
  - [ ] 100 Routing Policy - Geoproximity [03:21]
    * 
教师：现在，
我们来讨论另一项功能，即地理邻近路由｡
这可能会有点混乱，但我会在下一张幻灯片中用图表来解释，
以使其清晰｡
因此，这允许您根据用户和资源的地理位置将流量路由到您的资源｡
因此，这个想法是，通过这个策略，
你可以使用一个称为偏差的数字，将更多的流量转移到基于特定位置的资源上｡
在下一张幻灯片的图表中，我们将向您展示这一点｡
因此，要更改地理位置的大小，您需要指定一个偏差值｡
如果您希望更多流量流向特定资源，则可以通过增加偏差值来扩展该值｡
如果你想让更少的流量流向你的资源，你可以缩小它，你可以把偏差值减少到一个负数｡
因此，资源可以是来自AWS的资源，在这种情况下，
您指定它们所在的区域，列表将自动计算正确的路由｡
或者，如果没有，则使用AWS资源，
例如您的内部部署数据中心｡
然后，您只需要指定纬度和经度，这样AWS就知道它们现在的位置｡
然后它选择功能，你需要使用先进的53号公路交通流，
以便能够利用偏见｡
所以这个图应该会让一切都更简单｡
而对我来说，这是你应该记住的｡
因此，让我们以us-west-1中的一个资源和us-east-1中的一个资源为例｡
并且在两个区域中偏置都被设置为零｡
这意味着，
如果美国各地的用户都在尝试访问这些资源，则会有一条线将美国一分为二，这条线左侧的用户将访问us-west-1，而这条线的用户权限将访问us-east-1｡
现在，这很简单，这是当没有偏见的时候，好吗？
而这看起来像是基于用户位置去到最近的资源区域｡
但由于存在偏差，我们可以使用相同的设置，
但使用不同的方式将用户路由到不同的区域｡
让我们举个例子｡
我们有美国西部1号和美国东部1号，美国西部1号的偏差设置为0，
但美国东部1号的正偏差为50｡
我们已经看到，这种偏向会使更多的用户和更多的流量流向该资源｡
为什么？
好吧，因为现在的偏见该报就报，
先划清界限再说｡
由于us-east-1的偏置较高，这两种资源将稍微偏左一点｡
也就是说，这条线左边的用户可以转到us-west-1，
但右边的用户或这条线将转到us-east-1｡
那我们该怎么办呢？
例如，您可以在世界各地设置资源，并说您需要将更多流量转移到特定区域｡
您要做的是使用地理邻近路由策略来增加该特定区域中的偏差｡
因此，
有更多的用户被拖动，更多的用户有流量被吸引到该地区｡
因此，您在参加考试时需要记住的是，当您需要通过增加偏差将流量从一个区域转移到另一个区域时，
地理邻近路由非常有用｡
好吗？
希望这些图能帮助您更好地理解地理邻近路由策略｡
我希望你们喜欢这节课，下节课再见｡
  - [ ] 101 Routing Policy - Traffic Flow & Geoproximity [07:32] Hands On
    * 
  - [ ] 102 Routing Policy - IP-based [01:45]
    * 
教师：现在我们来讨论另一种路由策略，
称为基于IP的路由，
它非常直观，因为您将根据客户端IP地址定义路由｡
在Route 53中，您将定义一个CIDR列表，
它们是客户端的IP范围，
并且您将根据CIDR指定流量应发送到的位置｡
因此，使用情形将是优化性能，
因为您提前知道了IP，
或者降低网络成本，
因为您知道了IP的来源｡
因此，一个例子是，如果您知道您有一个特定的互联网提供商，
并且他们正在使用IP地址的特定CIDR，则可以通过此策略将它们路由到特定端点｡
让我们举个例子｡
在Route 53中，我将使用两个不同的CIDR块定义两个位置｡
正如您所看到的，一个以203开头，
另一个以200和定义的IP范围开头｡
现在我们要将这些位置链接到特定记录｡
举个例子｡ com我们将有一个位置｡
所以第一个CIDR块要发送的值为1｡
1. 3. 4，
第二个位置，CIDR块号2，将其发送到5｡
1. 7. 8.
这是两个EC2实例的公网IP｡
现在，如您所料，如果用户使用的特定IP是位置1
CIDR块的一部分，则他们将被定向到IP
1的第一个EC2实例｡
1. 3. 4，
并且具有属于位置2的第二IP地址的用户B将被重定向并且将具有对IP 5的EC2实例的DNS查询响应｡
1. 7. 8.
这就是基于IP的路由｡
很简单，希望你喜欢｡
我们下节课再见｡ 
  - [ ] 103 Routing Policy - Multi Value [03:42]
    * 
教师：我们来讨论最后一个路由策略，
即多值路由策略，当您希望将流量路由到多个资源时，将使用该策略｡
因此，路由53将返回多个值或资源｡
现在，您可以将它们与运行状况检查相关联，因此，
通过多值策略返回的资源将是与运行状况良好的运行状况检查相关联的资源｡
因此，对于每个多值查询，
最多将返回八个正常记录｡
虽然它看起来像ELB，但它不能代替ELB｡
其思想是客户端负载平衡｡
让我们看一个例子｡
我们将为示例设置多个A记录｡
我们将它们与运行状况检查相关联｡
因此，
当我们的客户端执行多值查询时，它将收到最多八条记录，然后客户端将选择其中一条｡
但至少通过将此功能与运行状况检查相结合，我们知道返回的八条记录中有一条（或最多八条）将是健康的｡
因此，客户端可以非常安全地查询它们｡
这将是不同的，例如，当您有一个简单的路由，
其中有多个值，
因为如您所知，简单的路由策略不允许健康检查，因此有可能在简单的路由策略的查询返回的资源之一将是不健康的｡
这就是为什么多值作为记录类型功能更强大的原因｡
因此，让我们在UI中查看一下如何测试它们｡
让我们来练习多值记录｡
让我们创建一个多记录，多点等等等等｡
然后它的值将与us-east-1相关联｡
我将在此处添加此值，然后路由策略将为“多值”｡
运行状况检查将是us-east-1｡
而记录将是美国｡
TTL为60秒｡
让我们添加另一条记录｡
因此，
multi，我们将再次路由到另一个区域，该区域为ap-southeast-1｡
所以答案是多值答案｡
运行状况检查是ap-southern-1｡
而记录ID将是亚洲｡
然后记录TTL是一分钟｡
最后，
最后一个，再一次，一个记录名称｡
该值将链接到这里的eu-central-1｡
TTL为一分钟｡
而路由策略是多值答案｡
而对于运行状况检查，我们将使用来自eu-Central-1的一个｡
记录ID为EU｡
好的，我们来创建这些记录｡
并且记录已成功创建｡
现在让我们来测试一下｡
因此，我们将在这里使用CloudShell｡
现在，让我们重新连接到CloudShell｡
而我想做的是测试这张唱片｡
所以我会把记录拷贝到这里，然后我会清空我的屏幕｡
所以如果我在这上面做一个挖掘测试，我会得到三个答案｡
因此，
这三个IP被返回，原因是，这三个运行状况检查完全正常｡
所以如你所见，他们都很健康｡
但是如果我拿其中一个，比如，
我去掉了eu-central-1，
所以我会把这个变成不健康的，我会通过编辑来欺骗它，然后做一个反转健康状态｡
所以这会让健康的人变得不健康，反之亦然.
这只是一个快速的方法，我创建一个不健康的健康检查｡
所以让我暂停一下｡
好吧，现在我的欧盟中央一号健康检查结果是不健康｡
所以如果我在这里重新发出一个dig命令，我应该只会看到两个值，是的，
作为结果｡
所以多值答案起作用了，而且效果非常好｡
为了恢复此状态，请编辑此运行状况检查，
然后取消选中此“Invert health check status”（反转运行状况检查状态），
就可以开始了｡
好了，这节课就讲到这里.
希望你喜欢｡
我们下节课再见｡
  - [ ] 104 3rd Party Domains & Route 53 [02:24]
    * 
Stephane：所以我们需要区分域名注册服务商和DNS服务｡
因此，
实际上您可以向任何类型的域名注册商购买域名，并且您需要支付年费｡
到目前为止，我们在本课程中使用的方法是通过Route 53控制台使用Amazon
Registrar，但您也可以使用任何域名注册机构｡
例如，你可以使用GoDaddy，
你可以只使用Google Domains，等等｡
通常，每当您向域名注册机构注册一个域时，他们也会为您提供DNS服务来管理您的DNS记录｡
因此，当我们创建一个时，当在Amazon注册一个带有主机名的DNS名称时，我们有一个Route
53托管区域来管理我们的DNS记录｡
但是，当您在亚马逊注册服务商处注册了您的域名后，
您也可以选择不使用AWS Route 53作为您的DNS记录｡
反之亦然，您可以在GoDaddy注册您的域名｡
所以您要购买这个例子
com，但您将使用Amazon Route
53来管理您的DNS记录｡
这是一个完全可以接受的组合｡
那我们该怎么做呢？
在GoDaddy上，您将注册您的域，然后您将有名称服务器选项，
您可以指定自定义名称服务器｡
那我们放什么进去呢？
首先，
我们将转到Amazon Route 53，然后为我们想要的任何域创建一个公共托管区域｡
然后在托管区域详细信息中，我们将在右侧找到名称服务器｡
因此，这四个名称服务器是我们将不得不在GoDaddy网站上更改的｡
因此，这时GoDaddy回答了一个问题，“嘿，
我应该使用哪个名称服务器？
“名称服务器将指向Amazon Route
53名称服务器，
因此我们可以使用Amazon Route
53来管理从该控制台剥离的所有EDNS记录｡
因此，总结一下，
如果您在第三方注册商处购买域名，您仍然可以使用Route 53作为您的DNS服务提供商｡
为此，
您将在Route 53中创建一个公共托管区域，然后在您购买域名的第三方网站上更新NS或名称服务器的记录｡
然后将它们指向Routes 53名称服务器｡
因此，
正如您所知，域名注册服务商看起来像DNS服务，
但与DNS服务不同，尽管每个域名注册服务商通常都附带一些DNS功能｡
这节课就讲到这里｡
希望你喜欢｡
我们下节课再见｡ 
  - [ ] 105 Route 53 - Section Cleanup [01:21]
    * 
  - [ ]  Route 53 [7 问题] Quiz
    * 
 ## Section 10 - VPC Fundamentals [6 个讲座 • 25 分钟]
  - [ ] 106 VPC Fundamentals - Section Introduction [01:23]
    * 
欢迎学习有关VPC的这一部分，
这只是对VPC的概述，VPC代表虚拟私有云｡
让我们来看看这一部分的内容｡
因此，如果您通过了认证解决方案架构师助理或认证SysOps管理员助理考试，
就应该深入了解VPC｡
但这是AWS认证开发人员级别，因此您不需要深入了解，
但您应该在较高级别上了解它，因为在VPC考试中可能会出现一到两个，甚至三个问题｡
所以我想确保我能在这一节给予你们上一堂关于VPC的速成课｡
因此，您应该了解VPC､
子网､ 互联网网关和NAT网关､ 安全组､ 网络ACL和NACL､
VPC流日志､ VPC对等､ VPC端点､ 站点到站点VPN和直接连接｡
所以只有这个｡
我会给予你们一个概述｡
正如我所说的，在考试和本课程后面的部分中，它的问题不会超过一两个，
任何时候我们回到VPC时，我都会强调它｡
因此，如果您没有立即记住本节中的所有内容，请不要担心｡
一旦VPC在本课程中再次发挥作用，我将提醒您一些概念，
好吗？
因此，
如果您已经完成了SysOps管理员或认证解决方案架构师助理VPC部分，您可以跳过这一部分，不用担心｡
或者你可以再看一遍，因为如果你知道这些概念的话，
修改一下是很好的｡
好吧，我会的
好了，介绍到此为止｡
我们下节课再见｡ 
  - [ ] 107 VPC, Subnets, IGW and NAT [05:23]
    * 
[讲师]好的，首先我们来了解一下VPC和子网｡
因此，
VPC是一个虚拟私有云，这意味着它是AWS云中的一个私有网络，允许您在其中部署资源｡
VPC是一种区域资源｡
因此，如果您有两个AWS区域，
它们将有两个不同的VPC｡
所以VPC是这样表示的｡
在你的VPC里面，这只是一个逻辑结构｡
您有子网，子网允许您在VPC内对网络进行分区，
子网在可用性分区级别定义｡
所以我们有一个AZ，在这个例子中有一个AC｡
我们可以有多个子网｡
我将创建的第一个子网是公共子网｡
如您所见，公共子网是一个可从互联网访问的子网｡
这就是子网，可以访问万维网，也可以被访问｡
从万维网，好的，
那么我们有另一种子网，叫做私有子网，
私有子网是一个不能从互联网访问的子网｡
我们将在下一张幻灯片中了解如何定义它｡
为了定义对Internet的访问以及子网之间的访问，我们将使用路由器表｡
因此，
在VPC中，您将定义一组写入表，这些表将定义网络如何在所有不同子网之间流动｡
请记住，这一部分的内容都是高层次的，
因此我们不会进行任何动手操作，但请尝试记住这些概念，您很快就会明白这些概念是否有意义｡
因此，
我们在公共子网中有一个易于实现的实例，并且该实例可以访问Internet｡
我们在私有子网中有一个situ实例｡
然后一个人无法访问互联网或互联网无法访问它｡
原因是，我们希望它更安全，更私密｡
好的，如果我们看一下更大的VPC图表，
我们就有了云基础架构｡
我们有一个区域，在这个区域内我们有一个VPC｡
并且VPC具有一组IP范围｡
所以叫苹果酒场｡
这只是您的VPC中允许的IP范围｡
在本例中，我们有两个AZ｡
因此，
在第一个AZ中，我将有一个公共子网和一个专用子网｡
我们可以在每个子网中启动EC2实例｡
而在AZ中有两个，一个公用子网和一个专用子网｡
这就是VPC在高水平上的样子｡
这在为您创建的VPC中非常常见｡
在AWS上使用云时｡
您只有公用子网｡
您没有专用子网｡
我们每个AZ都有一个公共子网，您在为您创建的每个区域都有一个VPC｡
它被称为默认VPC｡
好吧，下一个在你的网络｡
我们讨论了公用子网和专用子网，但我们将更深入地进行讨论｡
然后讨论互联网网关和Nat网关｡
因此，
如果我们返回到同一张图，假设我们有一个易于执行的实例，位于公共子网中｡
是什么使子网真正公开？
它如何访问互联网？
为此，我们使用了互联网网关｡
我们的互联网网关将帮助我们子网中的VPC实例连接到互联网｡
这是您的互联网网关，它位于您的VPC中｡
因此，公共子网将有一个路由到互联网网关｡
因此，您的公共子网（例如，
该公共子网中的EC2实例）具有到Internet网关的路由｡
你的互联网网关知道如何与互联网的，这就是什么使一个子网成为公共子网｡
因此，公共子网将有一个路由直接路由到一个互联网网关｡
现在让我们再举一个例子｡
我们在专用子网中有EC2实例，我们希望它也能够访问互联网，
例如获取软件更新，但我们不希望它可以从互联网访问，
不希望互联网能够访问我们专用子网上的网站｡
例如，
为此我们使用了NAT网关或NAT实例，它们的作用相同｡
它们为您的专用子网提供网络｡
但NAT网关由AWS管理，因此您不必担心配置和扩展它们｡
而NAT实例是自我管理的｡
而且它们都允许您的私有子网中的实例在保持私有的同时访问Internet｡
那么它是如何工作的呢？我们将部署一个NAT网关，或者在这种情况下，
部署在我们的公共子网中｡
然后，我们将创建一条从专用子网到NAT实例或网关的路由｡
然后它有一个到互联网网关的路由，因为它在公共子网中，因此你的私有子网可以通过坚果一路访问互联网｡
这就是Nat网关的全部意义｡
这是一个典型的基础设施｡
在AWS和NAT网关中，NAT实例将在本课程稍后的部分发挥作用，当我们讨论lambda函数时，请记住，
这是一个非常简单的图，
请随时在本课程稍后的部分再次回顾这一部分，可能会有更大的意义，但我仍然想向您介绍一些概念｡
下一节课我们会讨论更多的UBC概念｡
  - [ ] 108 NACL, SG, VPC Flow Logs [04:39]
    * 
讲师：现在我们已经了解了在VPC中定义网络的所有方面，
让我们来谈谈网络安全｡
下面我们来讨论网络ACL和安全组的概念｡
所以我们回到了VPC｡
它有1个公共子网和1个EC2实例｡
我们可以创建NACL或网络ACL｡
它是控制进出子网的流量的防火墙｡
这可以有允许和拒绝规则｡
因此，我们可以允许流量或拒绝流量｡
很明显｡
您可以在子网级别附加这些NACL，
并且规则仅包括IP地址｡
所以你说，嘿，来自这个IP地址的所有流量都是允许的，
或者来自这些IP地址的所有流量都被拒绝，等等｡
所以NACL就在这里，它是我们公共子网的第一个防御机制，
它在子网级别｡
因此，正如我们所看到的，
进出互联网的流量将首先通过网络ACL｡
但是它还没有到达我们的EC2实例｡
接下来是安全组，我们已经在本课程中看到过｡
因此，安全组是一个防火墙，它控制来往于一个ENI弹性网络接口或EC2实例的流量｡
在这种情况下，正如我们所看到的，
安全组只能有允许规则，它们可以引用IP地址或其他安全组｡
这是我们在这门课上已经看到的｡
因此，我们将安全组附加到EC2实例，
现在流量可以一直流到我们的EC2实例｡
我们有第二种防御机制｡
在本课程中，我们已经深入了解了安全组，但还没有真正触及NACL｡
为什么？ 因为当你有一个默认的VPC时，
默认的NACL允许所有东西进入，也允许所有东西离开｡
这就是为什么我们在本课程中不必更改网络ACL，
而且我们也不会进行任何实际操作｡
但要知道，在互联网流量到达您的EC2实例之前，
它必须通过充当防火墙的网络ACL｡
因此，它们与网络SCL和安全组非常不同｡
这里有一个表格来总结它｡
你不需要记住｡
这更多的是解决方案架构师助理或认证的Sysap的助理｡
但其理念是，安全组附着到实例或弹性网卡，
而网络ACL位于子网级别｡
安全组只有允许规则，而网络ACL只有允许和拒绝规则｡
是有状态的，因此这意味着无论任何角色，
返回流量的任何流量都将自动被允许｡
而在这里，对于网络ACL，
您需要允许流量进出｡
在这里你可以看到剩下的，
但这与认证无关｡
好吧，如果你好奇的话｡
现在，所有这些流量都流经我们的VPC，
通过网络ACL和安全组，我们很好奇，
我们是否可以获得有关所有这些流量的信息？
我们能从中得到一个日志吗？
这称为VPC流日志｡
这将捕获有关进入接口的所有IP流量的信息｡
包括VPC流量日志､ 子网流量日志､ 弹性网卡流量日志或弹性网络接口流量日志｡
因此，无论何时您有网络通过您的VPC，
它都将记录在流日志中｡
因此，这有助于您监视和排除连接问题｡
例如，如果你想知道为什么你的子网不能访问互联网，
或者为什么一个子网可以或不能与另一个子网或互联网通信，等等｡
因此，每当您遇到网络问题并需要进行故障排除时，
您都需要查看VPC流日志，因为它们会为您提供一切信息｡
关于允许和拒绝流量的所有信息｡
它还将从AWS管理的任何内容中捕获网络信息｡
因此，弹性负载均衡器，您的ElastiCache, RDS, Aurora所有这些都会出现在您的VPC流量日志中｡
因此，如果出现连接问题，您可以立即查看VPC流日志数据可以发送到Amazon
S3，它可以发送到CloudWatch Logs和Kinesis
Data Firehose，因此您可以将其发送到AWS中的许多地方｡
这堂课就到这里｡
希望你喜欢｡
我们已经看到了NACL､
安全组和VPC流日志，我们下次讲座再见｡
  - [ ] 109 VPC Peering, Endpoints, VPN, DX [05:50]
    * 
教师：好的，现在我们来讨论一下如何在VPC和其他结构之间建立连接｡
第一件事就是VPC对等｡
假设您有两个虚拟专用云，它们位于两个不同的帐户或两个不同的区域，您希望将它们连接在一起，
就像它们是同一网络的一部分一样｡
因此，
我们希望连接到VPC，专用于AWS的V网络｡
这将使它们的行为就像它们在同一个网络中一样｡
因此，
我们有VPC A和VPC
B，如果您想让它们彼此通信，我们需要建立从A到B的VPC对等连接，非常简单｡
为了确保这些VPC可以连接，您需要确保为每个VPC定义的IP范围不重叠｡
因为为了能够将网络寻址到另一个VPC，您需要与IP地址通信，因此如果网络范围明显重叠，
则网络不知道该去哪里｡
因此，要连接到VPC，
您需要确保其运行的IP地址范围不同且不重叠｡
并且VPC对等连接是不可传递的，因此必须为每个需要相互通信的VPC建立对等连接｡
我的意思是，如果我们通过a和C之间的VPC对等连接来连接VPC
C, B和C就不能相互通信，VPC对等中就没有传递性｡
这意味着，如果我想在VPC B和VPC之间建立连接，
那么我需要在B和C之间创建它自己的VPC对等连接｡
这就是VPC对等的意义所在，因此，随着您添加越来越多的VPC，
您需要添加越来越多的对等连接｡
好吧，这是第一条｡
第二，
VPC端点，这在本次考试中非常重要｡
因此，端点允许您使用专用网络而不是公共Internet网络连接到AWS服务｡
您可能不知道的是，所有AWS服务都是公共的，
因此，无论何时，例如，您的EC2实例使用VAWS服务时，
它们都会公开与AWS通信，
但有时您的EC2实例未连接到公共子网，因此您希望它们私下访问您的AWS服务，这就是VPC端点｡
因此，这为您访问AWS服务提供了增强的安全性和更低的延迟｡
让我们举一个例子，我们有一个私有子网和其中的一个EC2实例，他希望访问Amazon
S3和DynamoDB，
这两个实例位于VPC之外，进入公共领域｡
然后，
我们可以创建一个VPC端点网关，这仅适用于S3和DynamoDB｡
在本课程中，我们将了解端点网关以及S3和DynamoDB的功能｡
您是EC2实例，
与该VPC端点进行通信，并且可以私下访问S3和DynamoDB，您可以看到流量不通过Internet｡
然后，对于VPC Endpoint接口，
这是服务的其余部分，它仅在您的VPC中使用，
因此这意味着我们可以在您的专用子网中创建VPC Endpoint接口，并通过该发票接口（带有ENI）以专用方式访问CloudWatch｡
因此，VPC端点在您需要从VPC内部以私有方式访问AWS服务时非常有用，
这是您需要记住的｡
其他考试需要知道网关和接口之间的区别，
我不认为认证开发人员考试需要知道这一点，但要知道，
任何时候考试都要求你私下连接到AWS服务，那么VPC端点将是一种方式｡
好的，
那么现在，我们如何在您的内部部署数据中心（例如，您的办公楼）之间建立连接｡
和您的云VPC｡
第一种方式称为站点到站点VPN，将内部部署的VPN设备连接到AWS，连接将自动加密，
并通过公共互联网传输｡
因此，
在本示例中，我们在您的内部部署数据中心和VPC之间建立了一个VPN虚拟专用网络，该网络通过公共互联网连接｡
这是非常容易设置非常快，你可以设置在几分钟内，
你去，你有一个私人连接或加密连接对不起，
通过公共互联网到您的VPC.
另一个选项是直接连接｡
它实现了相同的目的，即在内部部署数据中心和VPC之间建立连接，
但这次是物理连接｡
这意味着连接将是私有的，不会通过公共互联网，
将是安全和快速的｡
它通过专用网络，
因为它是到VPC的专用线路，所以至少需要一个月才能建立，因为需要做一些工作才能与AWS建立专用连接｡
因此，这称为直接连接，
这是专用路由｡
因此，我们可以看到，
VPN和Direct Connect实现了相同的目的，但方式和时间线不同｡
请注意，如果您使用站点到站点VPN或直接连接，这两种方式都无法访问我们之前讨论过的VPC端点，
VPC端点仅用于在您的VPC中私下访问AWS服务，而不是通过连接您的内部部署数据中心｡
这是你在参加考试时应该注意的｡
好了，关于VPC的连接，就像VPN和直连等外部VPC对等VPC端点而言，我希望这对大家有所帮助，
我们下一堂课再见｡
  - [ ] 110 VPC Cheat Sheet & Closing Comments [02:34]
    * 
这是一个很重的部分，
没有任何实际操作，所以可能会让人感到困惑，但我真的不想用实际操作来打扰您，因为这不是为认证开发人员准备的｡
你们只需要记住这一节中的几个概念，所以我将在一张幻灯片中总结所有内容｡
相信我，
你会准备好所有的VPC问题进入考试，好吗？
所以别太紧张｡
第一种是VPC，即虚拟私有云｡
在本课程中，我们在创建EC2实例时一直使用默认VPC｡
对于我们正在使用的AWS区域，将有一个默认的VPC｡
子网绑定到特定的可用性区域｡
这是我们启动EC2实例的地方｡
它们表示VPC的网络分区｡
互联网网关是用来访问我们的公共子网中的实例到互联网的，好吗？
它们是在VPC级别定义的｡
NAT网关和NAT实例这次将通过EC2实例和私有子网为私有子网给予Internet访问｡
NACL或网络ACL是用于入站和出站的无状态子网规则防火墙，
而安全组（我们以前见过）是有状态的，它们在EC2实例级别或ENI上运行，并且可以引用其他安全组｡
对于VPC Peering，这允许我们将两个VPC连接在一起，
只要它们不重叠，这不是一个可传递的VPC Peering，
因此，
如果你想让它们彼此连接，你需要在所有VPC之间建立VPC Peering连接｡
VPC
Endpoints将为您提供对VPC中AWS服务的私有访问，我们将在以后的课程中了解一些服务｡
VPC流日志将为您给予网络流量日志，以确保您可以调试是否有访问被拒绝，
或者流量是否在您的VPC中被锁定或允许｡
最后，让我们建立从本地数据中心到AWS的连接，您有站点到站点VPN，它将通过公共互联网建立VPN连接，
如果您希望直接专用连接到AWS，则有Direct
Connect｡
因此，如果您没有完全理解该部分的内容，请不要强调，
您可以稍后再回过头来｡
正如我在课程中所说的，我将重点介绍我们需要的所有特定VPC功能｡
如果你想的话，最后再回来，但不要太紧张｡
我真的，真的很认真｡
我只想给予你们提供更多的信息，
以确保我们能达成共识，我们继续学习这门课.
相信我，它会得到更多的发展非常非常快｡
好吧，就这样｡
我们下节课再见｡ 
  - [ ] 111 Three Tier Architecture [05:16]
    * 
教师：那么，我为什么要谈论所有的VPC的东西？
好吧，
我们来看看典型的三层解决方案体系结构，因为现在它应该更有意义了｡
因此，
我们的用户希望访问我们的web应用程序，因此，
我们必须将其设计为使用弹性负载平衡器，该平衡器将分布在多个可用性区域中｡
由于该弹性负载平衡器将可公开访问，因此需要将其部署在公共子网中｡
所以这就是我们到目前为止这样做的原因｡
要访问您的弹性负载平衡器，您需要执行DNS查询以了解它的位置，因此我们将使用Route
53，然后我们的用户将直接与我们的弹性负载平衡器对话｡
现在，我们的弹性负载平衡器会将该流量分布到EC2实例上，
因此它们将位于自动扩展组中，但这次，
由于该自动扩展组不需要可从互联网公开访问，只需从ELB访问，
因此我们将其部署在专用子网中｡
因此，我们将有三个AZ，分别是1､
2和3，每个AZ中都有EC2实例，
ELB将能够使用路由表将流量从公共子网发送到专用子网｡
因此，
正如我们所看到的，我们已将架构的计算端隔离在专用子网中，因此安全性大大提高｡
然后，我们需要在某个地方保存数据集｡
因此，
我们将有第二个专用子网，一个更深一层，有时也称为数据子网｡
因此，在这个数据子网中，
这是我们典型的三层解决方案架构中的第三层｡
然后我们将有Amazon
RDS，这是我们的数据库，它将有助于读写数据｡
因此，我们的EC2实例将连接到RDS，但我们的数据子网中还可以有另一个东西，
即ElastiCache，它将有助于缓存RDS中的数据，
或者在内存中存储和检索web应用程序的EC2实例的会话数据｡
这是典型的三层解决方案体系结构，在考试的情景问题中经常出现｡
这就是我之所以要介绍VPC的原因，因为我希望您在了解典型的三层解决方案体系结构之前先了解子网的概念｡
好的，那么，
您可能会在考试中看到EC2上的另一个LAMP堆栈｡
LAMP代表Linux，这将是我们用于EC2实例的操作系统｡
Apache，这是将在EC2的Linux上运行的web服务器｡
我们有MySQL，
这是一个数据库，所以我们可以在RDS上使用MySQL｡
最后，PHP是应用程序逻辑，它将理解如何呈现网页，
并将在EC2上运行｡
这就是LAMP堆栈｡
然后在LAMP栈上，你可以随时添加Redis或Elasticache的Memcached，以包括缓存技术｡
如果我们需要它来本地存储数据､ 本地缓存数据，或者存储应用程序数据或软件，
我们可以使用连接到EC2实例的EBS驱动器｡
这就是AWS架构的另一个想法｡
最后，
如果你使用过Wordpress，你可能知道它是如何工作的，如果你没有，
它是一个博客工具，所以有一种方法可以在AWS上部署Wordpress，所以让我们来看看｡
我们使用与以前完全相同的体系结构，
因此这里有两个层，即负载平衡器层和应用程序层｡
因此，
他们需要能够共享用户发送的图像，因此用户通过负载平衡器将图像发送到我们的EC2实例｡
因此，EC2实例需要能够与所有其他EC2实例共享这些映像，为此，EFS是一个完美的用例，它是一个网络文件系统，
一个网络驱动器，将在每个AZ中创建弹性网络接口，
因此，
您的EC2实例可以将映像存储在EFS上，所有其他EC2实例都可以访问这些映像｡
这是一个非常简化的图表架构，
用于AWS上的Wordpress，我没有表示数据库等｡
因此，
在AWS的网站上，有一个完整的Wordpress架构，
令人惊讶的是，到现在为止，你应该几乎完全理解｡
所以，在你自己的时间里看看这个图表，它很酷｡
您应该能够了解所有内容，因此我们有NAT网关､ Internet网关､ 自动扫描组､
不同子网､
Aurora､ EFS､ 定位技术等｡
您目前唯一不应该了解的是CloudFront和S3，但不用担心，
这很快就会出现｡
因此，这里的整个目的是向您展示，
到目前为止，
您已经了解了很多关于AWS解决方案架构的知识，这对您作为开发人员的考试非常有帮助，好吗？
这节课就讲到这里，希望你们喜欢｡
请花点时间来看看这个架构，我们下节课再见｡
  - [ ]  VPC [8 问题] Quiz
    * 
 ## Section 11 - Amazon S3 Introduction [13 个讲座 • 47 分钟]
  - [ ] 112 S3 Overview [05:06]
    * 
讲师：欢迎学习Amazon S3的这一部分｡
这一部分非常重要，
因为Amazon S3是AWS的主要构建模块之一，
它的宣传方式是可以无限扩展存储｡
因此，事实上，很多网络都依赖于Amazon
S3｡
例如，许多网站使用Amazon S3作为主干，
许多AWS服务也将使用Amazon S3进行集成｡
因此，在本节中，我们将逐步了解Amazon
S3的主要功能｡
因此，Amazon S3有如此多的用例，
因为其核心是S存储｡
假设S3用于备份和存储｡
它可以用于您的文件，
也可以用于您的光盘等｡
用于灾难恢复｡
例如，您要将数据移动到另一个区域｡
如果某个区域出现故障，
则您的数据将备份到其他位置｡
这是为了存档｡
因此，您可以在Amazon S3中归档文件，
并在稍后阶段以非常非常便宜的价格检索它｡
适用于混合云存储｡
因此，如果您有内部存储，但您不会将其扩展到云中，
您可以使用Amazon S3｡
承载应用程序，承载媒体，如视频文件､
图像等｡
建立一个数据湖，存储大量数据，
执行大数据分析，提供软件更新，托管静态网站，
等等｡
两个使用案例是，纳斯达克将七年的数据存储到S3冰川共享服务中，
这就像亚马逊S3的存档服务｡
Sysco对其数据进行分析，并从Amazon
S3获得业务见解｡
因此，Amazon S3将文件存储到存储桶中｡
和存储桶可以被视为顶级目录｡
实际上，这些S3存储桶中的文件称为对象｡
这些存储区是在您的帐户中创建的，必须具有全局唯一的名称｡
这意味着名称必须是唯一的，
在所有地区，你有它在您的帐户，
但也有所有帐户存在的AWS｡
因此，这是AWS中唯一必须全球唯一的东西｡
并且在区域级别定义存储桶｡
因此，即使存储桶的名称在所有区域和所有客户中是唯一的，
也必须在特定AWS区域中定义存储桶｡
因此，three看起来像是一个全局服务，
但bucket实际上是在一个区域中创建的，
这是初学者的常见错误｡
因此，S3存储桶有一个命名约定｡
你不记得了，但知道了也不错｡
因此存储桶名称不能包含大写字母和下划线｡
它们的长度必须介于3到63个字符之间｡
它们不能是IP｡
它们必须以小写数字或小写字母开头｡
还有一些前缀限制｡
所以只要你使用字母､ 数字和连字符，你就可以开始了｡
好了，现在我们来谈谈物体｡
这些对象是文件，
它们有一个密钥｡
Amazon S3对象键是文件的完整路径｡
如果你看我的桶，这是顶级目录｡
那么我的文件在TXT的键就是我的文件点TXT｡
但是如果你想把它嵌套在我们称之为文件夹的地方，
那么键就是完整路径｡
所以我的文件夹一个斜杠另一个文件夹斜杠我的文件点TXT｡
因此，键由前缀和对象名组成｡
例如，我们可以将路径从之前分解为前缀，即my folder
one和another folder，以及对象名，
即my file. TXT｡
因此，Amazon S3本身没有目录的概念，尽管当您查看控制台（UI）时，
您会有不同的想法，您实际上会创建目录｡
但亚马逊S3中的任何东西和一切实际上都是一把钥匙｡
键是一个非常长的名字，
包含斜杠，键是由前缀和对象名组成的｡
好吧，那么这些物体，它们是什么？
嗯，他们的价值观是身体的内容｡
所以你可以上传一个文件，
你可以上传任何你想上传到亚马逊历史记录｡
因此，最大对象大小为5 TB｡
这是5，000 GB｡
如果你上传一个非常大的文件，
如果这个文件大于5GB，
那么你必须使用多部分上传将文件分成几个部分｡
因此，如果你有一个5 TB的文件，
那么你必须上传至少1，000个5 GB的部分｡
现在，对象还可以具有元数据，
即它们的键和值对的列表，并且可以由系统设置或由用户设置以指示关于文件的一些元素，
即一些元数据｡
例如，它们的标记，它们的Unicode键和值对（最多10个），
它们对于安全性和生命周期非常有用，
如果您启用了版本控制，有时对象会有版本ID｡
以上就是对Amazon S3的介绍｡
我相信你一定很好奇它是如何工作的，
所以让我们进入控制台开始吧｡
  - [ ] 113 S3 [05:55] Hands On
    * 
  - [ ] 114 S3 Security: Bucket Policy [05:03]
讲师：现在我们来谈谈Amazon S3-安全性｡
第一部分是基于用户的｡
因此，作为用户，您可以拥有IAM策略，
您和此IAM策略将授权特定IAM用户应允许哪些API调用｡
您也可以使用基于资源的安全性｡
所以这是新的｡
我们可以使用所谓的S3 Bucket策略，
您可以直接从S3控制台分配桶范围的规则｡
这将允许，例如，一个特定的用户进入或允许另一个帐户的用户，
这被称为跨帐户访问您的S3桶｡
这也是我们将S3 Bucket公开的方式，
稍后我将向您展示｡
接下来，您会看到对象访问控制列表（ACL），
它们是更细粒度的安全性，并且可以禁用｡
如果您需要进入存储桶级别，
则可以使用存储桶ACL，这是一种不太常见的ACL，
也可以禁用｡
现在在Amazon S3 Bucket上实现安全性的最常用方法是使用Bucket策略｡
那么，在什么情况下IAM主体可以访问S3对象呢？
如果IAM权限允许，或者如果资源策略允许，
并且操作中没有显式拒绝，
则IAM主体可以访问指定API调用上的S3对象｡
我们稍后将看一下这些使用情形｡
最后，在Amazon S3上实现安全性的另一种方法是使用加密密钥对对象进行加密｡
那么，S3 Bucket策略实际上是什么样子的呢？
因为这是我们S3-Security的重点｡
它们是基于JSON的策略，看起来像这样｡
这是JSON文档，非常容易阅读｡
首先，您有一个资源块，
该资源会告诉策略此策略应用于哪些存储桶和对象｡
在这里我们可以看到，这适用于示例Bucket中的每个对象，
这就是星号的作用｡
接下来我们有效果｡
那么，允许或拒绝，我们允许或拒绝什么呢？
我们拒绝行动.
因此，我们有一组API，我们可以允许或拒绝，
在本例中，我们允许的操作是GetObject｡
所以这就允许任何人感谢原则，原则提出帐户或用户应用策略，
所以原则是明星｡
所以，在这里我们允许任何带星号的人来GetObject，所以要从我的例子Bucket中检索一个带星号的对象，
那就意味着它里面的任何对象｡
因此，这个S3 Bucket，在我的Buckets中的所有对象上设置公共读取｡
因此，我们可以使用S3 Bucket策略来授予对Bucket的公共访问权限（如右侧所示），
或者强制在上载时对对象进行加密，
或者向另一个帐户授予访问权限｡
那么让我们来看看现在的情况｡
这是公共访问的存储桶策略｡
我们有一个用户，他在万维网上，是一个网站访问者，
他想访问我们S3 Bucket中的文件｡
因此，我们将附加一个允许公共访问的S3
Bucket策略｡
这就是您在上一张幻灯片中看到的｡
一旦将此Bucket策略附加到S3 Bucket，
我们就可以访问其中的任何对象｡
这就是我们将在实践中看到的｡
但另一种方法是，
如果您的帐户中有一个用户，
即IAM用户，并且该用户希望访问Amazon
S3，那么我们可以通过策略为该用户分配IAM权限｡
因此，由于策略允许访问S3 Bucket，
因此用户现在就可以访问我们的S3
Bucket｡
如果我们有一个EC2实例，并希望从EC2实例授予对S3
Buckets的访问权限，那么我们已经看到IAM用户是不合适的｡
我们需要改用IAM角色｡
因此，我们创建一个具有正确IAM权限的EC2实例角色，
该EC2实例将能够访问Amazon S3 Buckets｡
更高级的是，
如果我们希望允许跨帐户访问，则必须使用Bucket策略｡
因此，我们在另一个AWS帐户中有一个IAM用户，
我们创建了一个S3 Bucket策略，
该策略允许该特定IAM用户进行跨帐户访问，因此IAM用户将能够对我们的S3
Bucket进行API调用｡
您需要了解的其他安全设置是“阻止公共访问”的“存储桶”设置｡
这就是我们在创建Buckets时设置的内容，
这些设置是AWS发明的，
作为防止公司数据泄露的额外安全层｡
因此，即使您将设置一个S3 Bucket策略，
使其成为公共的，如果启用了这些设置，
Bucket将永远不会成为公共的｡
所以这是为了防止数据泄露｡
因此，如果您知道您的Bucket永远不应该是公共的，
那么请将这些设置保留为打开状态，
这样您就有了这种级别的安全性，
可以防止设置错误的S3 Bucket策略的人｡
如果您知道您的S3
Bucket都不应该是公共的，那么您可以在帐户级别进行设置｡
好了，S3安全部门就到这里了
现在让我们进去动手练习吧｡
    * 
  - [ ] 115 S3 Security: Bucket Policy [03:32] Hands On
    * 
  - [ ] 116 S3 Website Overview [01:07]
    * 
演讲者：现在我们来谈谈如何使用Amazon
S3来创建美学网站｡
因此，S3可以托管静态网站，
并在互联网上访问这些网站，网站URL将取决于您创建此网站的AWS区域，
或者是此网站，或者是此网站｡
它们看起来非常非常相似｡
但唯一的区别是，这里有一个破折号，
这里有一个点｡
你记不记得都没关系，但你要知道，
就是这个.
因此，我们有一个额外的桶，
它将包含文件，可能是HTML文件，可能是图像，
然后我们将使其与托管网站兼容｡
这就是相应URL的外观，然后用户将访问我们的S3桶｡
但是，如果我们没有在S3桶上启用公共读取，
这将不起作用｡
这就是为什么在第一节课，
我们学习了S3桶策略.
因此，如果在启用S3存储桶进行读取后出现403禁止错误，
则意味着存储桶不是公共的｡
因此，您必须附加一个允许其为公共的S3存储桶策略｡
这节课就讲到这里，
现在我们开始动手练习｡
  - [ ] 117 S3 Website [01:58] Hands On
    * 
  - [ ] 118 S3 Versioning [01:13]
    * 
教师：现在我们来讨论Amazon
S3中的版本控制｡
因为我们已经了解了如何创建一个网站，
但如果能够以安全的方式更新它，那就太好了｡
因此，您可以在Amazon S3中对文件进行版本控制，
这是您必须在存储桶级别启用的设置｡
我们有一个存储桶，它支持版本控制｡
因此，每当用户上传一个文件时，
它都会在选定的键处创建该文件的一个版本｡
然后我们是否应该重新上传相同的密钥，
是否应该覆盖那个文件，然后它会创建一个版本2，然后是版本3，
依此类推｡
因此，最好的做法是对存储桶进行版本控制｡
为什么？
首先，它可以防止意外删除｡
因此，例如，如果您删除了一个文件版本，
实际上您只需添加一个删除标记，
因此您可以恢复以前存在的版本｡
您还可以轻松地回滚到以前的版本｡
所以，如果你想回到两天前发生的事情，
你可以把一个文件回滚｡
所以，有一些注意事项你需要注意｡
首先，在启用版本化之前未进行版本化的任何文件的版本都将为空｡
此外，如果您暂停版本控制，它不会删除以前的版本，
因此，这是一个安全的操作｡
好的，现在让我们进入控制台，
看看如何使用版本控制｡
  - [ ] 119 S3 Versioning [04:17] Hands On
    * 
  - [ ] 120 S3 Replication [01:25]
    * 
讲师：现在我们来谈谈Amazon
S3复制，它有两种形式｡
因此，CRR用于跨区域复制，
而SRR用于同区域复制｡
我们的想法是，我们在一个区域中有一个S3
Bucket，在另一个区域中有一个目标S3
Bucket，我们希望在这两个Bucket之间设置异步复制｡
因此，要执行此操作，首先必须在源存储桶和目标存储桶中启用版本控制｡
如果我们执行CRR，即跨区域复制，则两个区域必须不同｡
如果我们进行SRR，则两个区域相同｡
现在，您可以在不同的AWS帐户中使用这些存储桶，
并异步进行复制｡
因此，复制机制是在后台进行的｡
要使复制正常工作，
您必须为S3服务授予适当的IAM权限，
以便它具有从指定的存储桶进行读写的权限｡
因此，复制的使用情形是多种多样的｡
第一个原因是，如果您使用跨区域复制，
这可能有助于实现合规性，
或降低数据访问延迟（因为数据位于另一个区域），
或跨帐户复制数据｡
对于SRR或相同区域复制，这对于跨多个S3
Bucket聚合日志或在生产帐户和测试帐户之间执行实时复制非常有用，
因此，您拥有自己的测试环境｡
好了，这就是关于复制的｡
我会在下一节课上和你们一起练习｡ 
  - [ ] 121 S3 Replication Notes [00:57]
    * 
教师：嘿，下面是关于Amazon
S3复制的几点说明｡
因此，如您所见，在启用复制后，
将只复制新对象｡
如果要复制现有对象，
则需要使用S3批复制功能｡
因此，这将复制现有对象和复制失败的对象，
如果您有删除操作，您可以将这些删除标记从源存储桶复制到目标存储桶｡
这是一个可选设置，但如果您有一个版本ID为的删除，
则不会复制它们，因此如果这是一个永久删除，因为您希望避免从一个存储桶到另一个存储桶发生恶意删除｡
最后，没有复制链｡
这意味着如果桶1已经复制到桶2，
然后，桶2已经复制到桶3，
那么桶1的对象不会复制到桶3，
就是这样｡
我希望你们喜欢它，我们下节课再见｡ 
  - [ ] 122 S3 Replication [06:29] Hands On
    * 
  - [ ] 123 S3 Storage Classes Overview [06:12]
    * 
讲师：好的，
我们来讨论一下Amazon S 3的不同存储类｡
第一个是亚马逊S三个标准—通用｡
然后我们有亚马逊S的三个罕见的访问｡
然后我们有亚马逊S三个一个区域罕见的访问｡
然后是Glacier即时检索，Glacier灵活检索，Glacier深度归档，最后是Amazon
S得三个智能分层.
我们会在这节课中深入学习这些课程，但你们必须在考试前了解它们.
然后，当您在Amazon S3中创建对象时，
您可以选择其类，也可以手动修改其存储类，
或者，
正如我们将看到的，您可以使用Amazon S3生命周期配置在所有这些存储类之间自动移动对象｡
因此，
首先，在我们开始上课之前，让我们定义一下持久性和可用性的概念｡
所以耐久性代表了一个对象会被亚马逊S三丢失多少次｡
所以亚马逊S三有一个非常高的耐用性｡
叫做11个9｡
所以是99点然后是9乘以9%｡
而这意味着，
平均来说，如果你在亚马逊S三上存储了1000万个对象，你可以预期每一万年会丢失一个对象｡
所以它相当耐用｡
而且耐用性对于亚马逊S三中的所有存储类来说都是一样的｡
可用性表示服务的可用性｡
这取决于存储类｡
例如，S三Standard有一个99｡ 99%的可用性｡
这意味着一年大约有53分钟的时间，这项服务将无法使用｡
这意味着在处理服务时会出现一些错误｡
因此，
在开发应用程序时，您需要考虑到这一点｡
好吧，我会的
所以S3标准有99. 99可用性｡
它将用于频繁访问的数据｡
这是您默认使用的存储类型，它具有低延迟和高吞吐量｡
它可以承受AWS端的两个并发设施故障，其用例将是大数据分析､
移动的和游戏应用程序以及内容分发｡
接下来，我们有S三个不频繁访问｡
顾名思义，
这些数据访问频率较低，但需要在需要时快速访问｡
它的成本会比S3标准低，
但你会有一个检索成本｡
所以S三标准IA是99｡ 9%的可用性，所以可用性稍低｡
它的使用情形将是灾难恢复和备份｡
和亚马逊S三个一个区域—不频繁访问，一个区域-IA｡
ESC有很高的耐用性，好吧，只在一个AZ内，
如果AZ被破坏，数据就会丢失｡
耐用性更低｡
所以是99｡ 5%的可用性｡
因此，
S three One
Zone-IA的使用情形是存储备份的辅助副本，这些备份可能是内部数据，也可能是您可以重新创建的数据｡
接下来是冰川储藏课程｡
Glacier是一种低成本的对象存储，用于归档和备份｡
定价是您将支付存储费用和检索费用｡
在Glacier中的三个存储类中，
有Amazon S三个Glacier即时检索｡
这使您可以在几毫秒内完成检索，
这对于每季度访问一次的数据来说是非常好的，而且最短存储持续时间为90天｡
这是备份，但您需要在几毫秒内访问它｡
然后我们有冰川灵活检索｡
它曾经被称为亚马逊S三冰川，
但后来他们重新命名的东西，因为他们增加了更多的层次｡
因此，亚马逊冰川灵活检索有三个灵活性｡
所以你加快了速度，在1到5分钟内就可以得到数据｡
您可以使用标准备份，在3到5个小时内恢复数据，也可以使用批量备份，
在5到12个小时内恢复数据｡
最短贮存期也为90天｡
在这里，实例意味着您可以即时检索数据，
而灵活性意味着您愿意等待长达12小时的时间来检索数据｡
然后我们有冰川深度存档，这是为了长期存储｡
所以我们也有两层检索｡
我们有12小时的标准和48小时的散装｡
因此，您可能需要等待很长时间才能检索数据，但它将为给予提供最低的成本，
而且最短存储期限为180天｡
如您所知，存储类别很多，最后一种称为“S3智能分层”，
它允许您根据使用模式在多余的层之间移动对象｡
为此，您将每月支付少量的监控费用和自动分层费用｡
而且在three智能分层中没有检索费用.
因此，有一个频繁访问层，它是自动默认层｡
然后，
我们为未访问的对象设置了“不频繁访问”层，例如，30天｡
然后是归档即时访问层，对于超过90天未访问的对象也是自动的｡
然后是可选的归档访问层｡
您可以将其配置为90天到700多天｡
此外，深度归档访问层也是可选的，
您可以为在180天到700多天内未访问的对象配置该层｡
好吧，我会的
因此，three智能分层让您可以在three为您移动对象时轻松地坐下来｡
因此，如果您比较所有存储类别，您不需要记住这些数字，
但它只是为了让您了解它们是什么｡
所以你在任何地方都能得到11个9的耐久度｡
然后，随着可用性下降，当然，
您拥有的分区就越少｡
它只显示最短存储时间图表等｡
因此，请花些时间自己看一下这张图｡
你应该理解它，但你不应该肯定地记住它｡
如果我们看一些定价，
例如美国东部地区的定价，那么这就是所有存储类别的定价｡
再说一次，你不应该记得所有的事情｡
不过，
你最好在自己的时间看一下，以确保你理解｡
因为如果你知道类名是什么，那么你就应该能够理解这些类｡
好吗？
这就是讲座的内容｡
希望你喜欢｡
我们下节课再见｡ 
  - [ ] 124 S3 Storage Classes [03:37] Hands On
    * 
  - [ ]  Amazon S3 [8 问题] Quiz
    * 
 ## Section 12 - AWS CLI, SDK, IAM Roles & Policies [9 个讲座 • 36 分钟]
  - [ ] 125 AWS CLI Dry Run [04:56]
    * 
教师：好的，有时我们只是想确保我们拥有权限，但由于某种原因，
我们无法真正查看IAM策略｡
我们实际上并不想运行该命令｡
我们只是想确保我们有权限｡
而一些AWS CLI命令（如EC2命令），如果成功执行，
则开销会非常大｡
因为，假设我们想创建一个EC2实例，并且我们实际上创建了它，
我们只是想尝试它是否工作｡
因此，
这些命令（但不是所有命令）可能包含minus minus模拟运行选项｡
这个选项就是模拟API调用｡
如果您没有权限，则会收到拒绝异常，
然后您就知道了｡
但如果您有权限，则不会运行该命令｡
那么，让我们来练习一下｡
因此，假设我们希望查看具有IAM角色的EC2实例是否可以创建其他EC2实例｡
这会是一个有趣的测试，对不对？
但我们实际上并不想创建另一个EC2实例，我们只想确保它可以创建EC2实例｡
那么让我们来看看，看看命令｡
因此，它被称为AWS EC2运行实例｡
如您所见，我直接从EC2实例运行此命令｡
我将确保运行help，因为我希望获得有关此命令的帮助｡
这个命令相当长，你可以阅读整个文档，
也可以在线获得｡
不过，
我会让你觉得非常简单：我们将需要一些参数，并且还将添加模拟运行参数以测试该命令｡
让我们来做一次预演，这是我要说明的第一件事，因为我想确保无论我接下来做什么，
它都是一次预演｡
现在，我们必须指定一个image-id｡
映像id基本上就是AMI ID，
为此，我们只需转到EC2实例，
单击已在运行的AMI
ID，然后从此处获取AMI ID即可｡
我们要把这整件事都复制下来，然后贴上去｡
就在这里｡
接下来我们要做的是指定实例类型｡
对于实例类型，我将选择t2｡ 微型的
现在，看起来没问题，这足以运行此命令，
因此我只需单击Enter｡
我们会得到“发生错误（未授权操作）"｡
所以我们无权执行此操作｡
这是因为我们设置了模拟运行命令，
因此，基本上，使用此模拟运行，您可以测试您是否具有执行某项操作的授权｡
现在，让我们做一些有趣的事情，并给予我们自己运行实例的权限｡
我将返回IAM，并附加之前由我们管理的策略，让我查找它｡
就在这里，我把它接上｡
我将编辑此策略，我将转到“策略”，在这里单击它，
然后编辑此策略｡
使用可视化编辑器，我将添加其他权限，我将选择一个服务，
将是EC2｡
我们向下滚动，EC2就在这里｡
现在，我们需要指定权限｡
所以如果我们回到这个命令，我们可以看到它试图运行的东西叫做RunInstances.
现在我们转到Write，因为这是一个写入操作，如果向下滚动，
我们可以看到RunInstances就在这里｡
让我们回到这整个菜单滚动｡
现在，
我们有了Write实例，其中一个已选中，您可以看到，
我只选择了一个需要执行的操作，我没有对EC2实例授予过高的权限，明白吗？
为角色提供运行所需的最低权限是关键｡
现在，对于资源，它说“您选择了需要图像资源类型的操作“，
等等｡
“为了使它非常简单，我只会说“所有资源”，
它会有一个星星就在这里｡
现在，
我可以查看策略，正如您现在所看到的，我的EC2对所有资源都具有有限的写访问权限｡
保存变更｡
我们还可以查看JSON文档｡
现在我们可以看到，我们在EC2上获得了一个Allow：运行所有资源实例
因此，我的策略已经应用，现在如果我从EC2机器返回EC2控制台，
并尝试运行此命令，这次我会收到一个名为“DryRunOperation”的错误｡
它说，“请求本来会成功，
“但设置了DryRun标志”｡
那太完美了!
从这个DryRun操作中，我们确保了我们有执行RunInstance操作的权限，但实际上它没有成功，
因为我设置了dry-run标志｡
所以我们得到了这个DryRunOperation异常｡
这很好，这是我们测试API调用的方式，对于某些API调用，
模拟运行标记很重要｡
正如您所看到的，如果它们被拒绝，
我们将得到“UnAuthorizedOperation”，如果它们被允许，
我们将得到“DryRunOperation”｡
但是在任何情况下都没有运行这个新实例，所以这是有帮助的｡
这节课就讲到这里了，下节课我们会试着去理解这个错误信息到底是什么意思｡
所以下节课再见｡ 
  - [ ] 126 AWS CLI STS Decode [04:34]
    * 
教师：所以当你运行API调用时，它们失败了，就像我们在上一节课中所做的那样，
我们会得到一个很长的错误消息，这并不意味着什么，
我们希望能够解码它｡
这也是考试中很常见的问题，你需要STS命令行｡
所以你必须运行这个sts decode-authorization-message来解码消息｡
没有更好的方法来实践这个概念，所以让我们来看看它是如何工作的｡
您还记得，当我们进行EC2运行实例模拟运行时，我们得到了这样一条消息：您无权执行此操作，
然后它将这条完整的消息作为授权失败消息提供给我们｡
现在我们要解码它｡
因此，我将在Google中输入AWS sts解码—授权—消息｡
点击它，基本上它说我们可以解码关于请求的授权状态的附加信息｡
因此，
使用它的方法是运行decode-authorization-message，然后我们传递一个名为encoded-message的标志，以及消息的值｡
现在让我们来看看它是如何工作的｡
我们会做aws sts解码—授权—消息｡
我得确保我做对了｡
我们已经传递了编码的消息和值｡
所以，编码消息，我们将传递整个消息，
从这里，从vb一直到1k｡
我将粘贴它并按回车键｡
现在我们得到了，很明显，也许你预测到了，
访问被拒绝｡
这是因为我们的IAM使用角色无权执行此操作STS｡
因此，基本上任何时候运行AWS API调用时，
都必须对自己进行授权｡
因此，我们可以直接从我们的计算机运行此命令，它将工作，
但只是为了好玩和练习，我将授权我的EC2实例运行此命令｡
让我们来看看｡
我们将返回IAM管理控制台，编辑策略｡
我们将添加一个附加权限｡
对于服务，
我们将选择STS，然后我们将基本上授权读或写操作｡
它实际上是一个写操作｡
我们将授权一个解码授权信息
我们不需要选择资源，也不需要指定条件｡
我们将查看策略，
现在我们具有STS权限，我们保存更改｡
完成此操作后，
我们的EC2实例应该在这里有一个语句allow，表示允许您解码授权消息｡
听起来差不多｡
现在让我们来给予｡
我将在这里运行完全相同的命令，如您所见，
我们将得到一条解码后的消息｡
我得承认，这条信息现在并没有多大帮助｡
但是，如果您正在运行一个API调用，其中包含一些非常有趣的信息，
那么您可以从sts解码消息中获取这些信息｡
你总是可以使用来回显这个，
所以让我们回显这个看看它是如何工作的｡
我们会回显，现在我们得到了一个稍微好一点的格式｡
我喜欢做的是将这个JSON文件复制到我的VS代码下｡
所以我在这里粘贴它，我说它是一个JSON文档，所以我们得到了稍微好一点的格式｡
然后使用一个快速操作，我基本上可以重新格式化，
格式化文件，格式化选择，
这给了我一个更好的JSON文档｡
所以我们现在可以看到，我们没有被允许，
我们没有得到明确的否认｡
如果它被允许或拒绝，我们会得到一个匹配的语句，
这基本上可以帮助我们深入分析为什么会出现错误，或者如果我们得到失败，它们也会出现在这里｡
然后，它为我们提供了一系列有关所进行的API调用的上下文，
如API调用的ID和ARN，例如，
在这里，我们可以看到IAM角色MyFirstEC2Role从该实例ID运行，
非常好｡
然后，
我们尝试在此资源上运行RunInstances API调用，结果发现所有这些参数都已指定｡
正如你所看到的，这里发生了很多事情｡
但是，我想让你们明白的是，从这个非常神秘的长消息中，
让我再给你们看一遍，从这个非常神秘的长消息中，
使用sts解码授权消息，
我们能够解密它，从中获得有价值的信息｡
这就是你应该知道的考试｡
您必须运行sts解码授权消息API｡
所以我希望这是有希望的，我会在下一节课看到你们｡
  - [ ] 127 AWS EC2 Instance Metadata [04:53]
    * 
教师：还有一个概念叫做EC2实例元数据，它非常强大，我认为它是开发人员最不了解的特性之一，
所以它非常好｡
当你发现它的时候，
你会说，哇，这真是太棒了，让我们来看看这个｡
它基本上允许EC2实例了解自己，因此它们不必为此使用IAM角色｡
这就说得通了，对吧？
您的EC2实例应该能够知道它们是谁以及它的URL，
您应该记住这一点，即169｡
1.   169.
254/最新/梅塔，这非常非常重要｡
这IP 169｡ 254. 169.
254基本上是AWS的一个内部IP，
它不能在您的计算机上工作，
它只能在您的EC2实例上工作，使用它，
您可以从元数据中检索IAM角色名称，但不能检索IAM策略，对吗？
测试IAM策略的唯一方法是使用策略模拟器或模拟运行选项｡
但是，我们无法使用此URL检索IAM策略的内容｡
请记住，元数据是关于EC2实例的信息，我们稍后将看到，
其中作为用户数据，将启动EC2实例的脚本，
好吗？
它们是非常非常不同的概念，我们将能够访问两者｡
因此，
让我们练习一下，看看我们可以使用此EC2实例元数据做些什么｡
现在我在EC2实例中，我首先要做的是curl, curl是查询URL，
我将对169执行curl｡
1.   169.
254，我们得到的是一堆数字和日期｡
这基本上就是你正在使用的API
curl的版本，我所说的是，现在我们真的不关心API
curl的版本，我们只使用斜杠，最新的｡
现在，当我运行slash latest时，我们就在这里，slash
latest，您要确保始终添加最后一个斜杠，我们会得到两个不同的字段，动态字段和元数据字段，
实际上，在这里，
您可能看不到它，这是第三个字段，对不起｡
它是用户数据，
因此您可以从中看到，您可以检索元数据和用户数据｡
我们现在对用户数据不感兴趣，我们感兴趣的是元数据｡
那么，让我们继续添加元数据｡
永远不要忘记在最后加上斜线｡
从这里，我们得到了一堆不同的选择｡
我们会得到AMI ID､ 启动索引､
主机名､ IAM等等｡
任何时候它以斜杠结尾，这意味着它还有更多的内容，例如，
IAM，
有一个斜杠，它还有更多的内容，
当它不是以斜杠结尾时，这意味着它是一个值｡
如果我们看实例ID，
我们会做curl, instance，
ID，我们得到的是我的实例ID，很棒吧？
我们可以用本地IPV 4做同样的事情｡
本地IPV 4，
我们将获取EC2实例的本地IPV
4，因此您注意到，我们尚未获得通过IM角色获取此信息的授权，此信息是免费的｡
任何没有IM角色的EC2实例都可以请求所有这些信息，学习如何浏览这些信息对您来说非常重要，
这在您进行自动化时非常有用｡
例如，
如果我输入主机名，我会得到主机名，如果我输入IAM，
我们马上就会看到，我们会看到更多的值｡
例如，
信息，有一个叫做安全凭据的东西，我将给予你一点关于它是如何工作的内幕｡
基本上，
当您附加EC2实例角色并键入安全凭据时，您将获得角色名称，这就是我的第一个EC2角色｡
我的第一个EC2角色是一个访问密钥｡
一个秘密访问密钥和一个令牌，因此在后台，
当您将IAM角色附加到EC2实例时，
它执行API目标的方式是查询整个URL，从而获得访问密钥ID､ 秘密访问密钥和令牌｡
而事实证明，这是一张短命的凭证｡
如你所见，
这里有一个有效期，通常是一个小时左右｡
因此，
我们的想法是，EC2实例通过附加到它的IAM角色获取临时凭据｡
这基本上就是IAM角色在EC2实例上的工作方式，我知道没有多少人会告诉您这方面的信息，但我只是想激发您的好奇心，
并向您展示完整的URL｡
但是，你应该记住的是，使用这个元数据，而不是用户数据，
元数据和这个URL就在这里，169｡
1.   等等｡
你可以从EC2实例中得到很多信息，
我希望这对你有帮助，我们下节课再见｡
  - [ ] 128 AWS CLI Profiles [03:07]
    * 
因此，我经常会遇到这样一个问题：您如何管理多个AWS帐户？
例如，现在我们在我的AWS目录中｡
如果转到config，我们会看到默认部分，如果转到credentials，
也会看到默认部分，其中包含AWS访问密钥id和秘密访问权限｡
那我们怎么办｡
因为这链接到我以前的一个AWS帐户｡
但是，如果我有多个AWS帐户，该如何操作？
为此，我们使用了一种叫做配置文件的东西，所以配置文件是非常特殊的使用｡
基本上，我们要做的就是为一个新的配置文件定义一个名称，配置它，
然后我们就可以在任何命令行中使用它｡
因此，我们的做法是键入AWS configure｡
这是之前的内容，如您所见，它提示我输入访问密钥id，就在这里｡
如果我输入了，它会提示我输入这个秘密访问密钥，就在这里，
我按回车键就可以了.
它会改变，配置文件，它的作用是，
我们选择我们想要的配置文件｡
因此，我们必须为配置文件命名｡
我会称之为我的其他AWS帐户，但你可以命名为任何你想要的｡
通常是短一点的｡
如您所见，AWS访问密钥id现在为None，它以前是一个id，
现在为None，这意味着这是一个全新的帐户｡
所以我可以快速生成一些东西｡
所以我会随机复制一些东西，
对于我的访问密钥id，我会复制这个和我的秘密访问密钥｡
同样，这也是你在一个真实的AWS账户上基本上可以获得的东西，就像我们以前做的那样｡
但现在我只是在粘贴一些虚拟数据｡
我们走吧｡
我按回车键，输入地区名称｡
我想在美国做些事情｡ S的｡
西部2区谁知道呢｡ 默认的输出格式我按回车键开始了.
我们已配置了其他配置文件｡
那么现在有什么变化呢？
如果我们现在转到凭据文件，我们可以看到有一个新的括号｡
因此，以前只有默认帐户，但现在有我的其他帐户，其中包含一组新的凭据｡
同样，如果我们转到config，我们现在可以看到配置文件的配置｡
我在这里的其他aws帐户是我们要使用的区域｡
这是一件很酷的事情，因为现在我们可以在不同的帐户之间切换｡
现在，如果您执行AWS s3 ls，它将针对默认配置文件执行｡
好的，我会的
因为我们就是这样配置的｡
但是如果你想对另一个配置文件执行这个函数，比如说我刚刚配置的另一个aws帐户，
我们必须添加—-profile和我们拥有的配置文件的名称｡
所以这只是一个小把戏你应该知道｡
但基本上对于任何命令，
只要您可以事先使用aws configure命令行配置该配置文件，您就可以使用—-profile以及您想要的配置文件名称｡
就是这样，这不是你应该在考试中知道的东西，但这是你作为一个开发人员应该知道的东西，
我想给予你真实的的提示｡
因此，如果您开始拥有多个AWS帐户，请确保使用配置文件，
并将命令行设置为使用—-profile命令行参数来定位正确的AWS帐户｡
  - [ ] 129 AWS CLI with MFA [05:14]
    * 
考试中可能会出现的一个问题是如何将多因素身份验证与CLI或SDK配合使用｡
因此，如果要将其与CLI一起使用，则必须创建一个临时会话，
因此必须使用的API是STS
GetSession Token｡
所以你要记住｡
GetSession
Token是您要调用的API，用于获取多因素身份验证设备的凭据｡
我们将立即执行CLI，
即STS GetSession
Token，然后传递mfa设备的序列号｡
来自我们的mfa设备的令牌代码和我们想要的凭据的持续时间｡
这将返回一个结果，该结果显示了一个新的访问密钥id､ 秘密访问密钥､
会话令牌，我们都可以在API调用AWS时使用它们｡
现在我们来看看实际操作，它会变得更加清晰｡
首先，让我们转到IAM，顺便说一句，
这是一个非常复杂的mfa实践，如果你不想做，
你可以不做｡
这只是为了演示API调用，即STS
GetSession令牌｡
因此，我将转到我的用户，找到Stephane，然后在安全凭据下，
我需要分配一个mfa设备｡
我将对此进行管理，并分配一个虚拟mfa设备，单击“继续”，
我将使用Auty，因此我将使用Authy应用程序来扫描此二维码｡
我现在要显示二维码，
然后添加帐户，扫描它，然后扫描我的帐户｡
太好了，搞定了｡
然后我再次输入我的两个mfa代码，我从这里得到，
所以第一个是902495｡
我得到的第二个代码是865515，然后我点击分配MFA，我的设备已经成功注册｡
因此，这里重要的是获取此Assign MFA设备｡
这里的arn表示下一个命令需要做什么｡
接下来，我将进入控制台和CLI，并键入aws
sts get-session-token，
然后我需要查看帮助，因为我忘记了参数的名称，
因此它是序列号和令牌代码｡
所以——序列号，然后我粘贴我刚从控制台得到的—--token-code，我在这里输入直接从身份验证器或authy应用程序获得的代码，
然后按回车键，我得到的是凭据｡
现在，
这些凭据是临时的，它们通过多因素身份验证获得｡
我有一个AccessKeyId，一个SecretAccessKey，
一个会话令牌，
所有这些都在这里，还有一个过期日期，从现在起一个小时后.
正如我们所看到的，这是临时凭据，我不介意将其显示给您，
因为它在某些时候将无效｡
好了，
现在我要向大家展示如何使用这些凭据，我刚刚重新生成了一些凭据，以便进行实际操作，我将把这些凭据复制到另一个屏幕上的文本文件中｡
我们走吧｡
现在我要使用这些凭据｡
所以我能做的就是做aws配置—-profile mfa｡
因此，
我将配置一个名为mfa的新配置文件，它与我刚刚获得的这些凭据相对应｡
因此，我的AWS访问密钥ID是我刚从输出中获得的ID，
因此我将其粘贴在此处｡
然后是我的秘密访问密钥，再一次我需要从我得到的东西中复制它｡
很好，我的默认区域名称很好，输出格式也很好｡
接下来我要做的是在aws/credentials中打开文件，因此您需要使用您最喜欢的工具打开它｡
例如，
我将使用VS代码来执行此操作，因此我打开了文件，需要添加会话令牌｡
为此，
我键入aws_session_token =，然后复制之前获得的整个令牌，
因此这可能是一个非常长的令牌，然后单击“保存｡
现在这意味着，
每当我使用此配置文件执行API调用时，它将使用我的临时凭据｡
如果我回到这里，现在运行aws s3 ls，
然后我运行profile mfa，那么这将使用我的profile mfa对Amazon
s3发出一个API调用，你们可以看到很多额外的桶，
因为我现在正在重新录制这节课，所以你们会看到比现在更多的桶，但不用担心｡
这很酷，因为我现在使用的是mfa设备，在这里使用了会话令牌，所以这是临时凭据，
这节课到此为止｡
如果您不能跟着我沿着学习，也没关系，这非常复杂，
但您必须记住的一点是，我们用来生成这些临时会话令牌的API称为STS
GetSession Token，它为我们提供了访问密钥､
密钥和临时会话令牌｡
就是这样，
我希望这对你们有帮助，下节课再见.
  - [ ] 130 AWS SDK Overview [01:40]
    * 
讲师：现在，我们来讨论AWS SDK概述｡
那么什么是SDK？
那么，
如果您希望直接从应用程序代码在AWS上执行操作，而不使用我们迄今为止一直在使用的CLI，该怎么办？
为此，我们使用了一个SDK，这是一个软件开发工具包，有一堆不同语言的AWS官方SDK，
例如Java｡
NET､ 节点｡
js, PHP, Python, Go, Ruby和C++，好吗？
也许这个名单会随着时间的推移而变长｡
因此，我们在使用CLI时一直使用Python SDK，
因为CLI实际上是用Python编写的，
它使用Boto3 SDK｡
好的，
当我们针对AWS服务（例如DynamoDB或Amazon S3）发出API调用时，我们使用SDK｡
正如我所说的，有趣的是，CLI使用Python SDK Boto3｡
因此，考试希望您知道何时应该使用SDK｡
因此，我们将在本课程中介绍Lambda函数时了解SDK，
并了解SDK如何在实际代码中工作｡
所以在此期间，我们可以开始了｡
很高兴知道，
如果您没有指定区域，也没有配置默认区域，
那么您的SDK将默认选择us-east-1来发出API调用，这也是开发人员考试中可以测试的内容，好吗？
以上就是SDK的概要信息｡
别担心，
我们会练习一下的，
但最好先介绍一下，我们下节课再见｡
  - [ ] 131 Exponential Backoff & Service Limit Increase [03:48]
    * 
讲师：好的，现在我们来谈谈AWS限制，
也称为配额｡
因此，有两种类型的限制｡
您有API速率限制，
即您可以连续调用AWS API的次数｡
例如，用于Amazon EC2的DescribeInstances
API限制为每秒100次调用｡
Amazon S3上的GetObject限制为每秒每个前缀5，500个GET｡
因此，
当我们检查时，我们将进入间歇性错误，因为我们将被抑制｡
因此，我们应该使用指数退避策略，
我将在下一张幻灯片中介绍这一点｡
如果我们因为频繁使用应用程序而不断遇到这些错误，
并且不断超出这些限制，那么我们应该请求增加API节流限制，以确保我们能够例如每秒发出100个以上的DescribeInstances调用，
也许我们需要300个，好吗？
所以我们会要求AWS提供这个｡
这是API速率限制，
另一种限制是服务配额，也就是服务限制，即我们可以运行的资源数量｡
例如，对于您的按需标准实例，我们最多可以运行1，
152个虚拟CPU，
如果您希望在您的帐户中运行更多的vCPU，则只需打开票证即可请求增加服务限制｡
您还可以通过使用此服务配额API请求增加服务配额，
也可以通过编程方式完成此操作，明白吗？
因此，我们为您的资源提供了API速率限制和服务配额｡
我说什么来着？
如果出现间歇性错误，则应使用指数回退｡
那么，我们何时使用指数回退？
好吧，当我们得到一个ThrottlingException｡
这是一个考试题，
只要您看到由于执行了太多API调用而出现ThrottlingException，通常答案就是执行指数回退｡
因此，
如果您正在使用AWS SDK，则此重试机制已包含在SDK行为中｡
但是，如果您使用的是AWs API，
那么您将负责实施指数备份｡
因此，
考试中的一个问题可能会问你，在指数回退时，应该重试哪些类型的错误？
如果您正在解释､ 实现您自己的SDK､
您自己的自定义HTTP调用，那么只有在收到错误代码以500开头的服务器错误时，您才必须实现重试｡
所以503或其他什么，5XX，因为这些服务器错误和限制错误是可以重试的错误，
但是您不应该对4XX客户端错误实施重试或指数回退，好吗？
400个错误，因为这意味着你的客户端发送了错误的东西，所以如果你继续重试，
你会继续收到同样的错误｡
那么，指数回退是如何工作的呢？
好吧，我们尝试第一个请求，
比如说一秒钟，然后我们将把时间加倍，直到下一个请求｡
所以两秒可能是因为我们在下一次重试时加倍了所以我们要再次加倍.
四秒后我们再翻倍｡
对于下一次重试，
我们将设置为8秒，然后对于下一次重试，我们将设置为16秒｡
因此，使用指数回退的想法是，我们重试的次数越多，
等待的时间就越长，
因此，如果许多客户端同时执行此操作，
其结果是服务器上的负载将越来越少，从而使服务器能够提供尽可能多的答案｡
这就是指数回退的整个概念｡
原来如此｡
我希望你们喜欢这节课，下节课再见｡
  - [ ] 132 AWS Credentials Provider & Chain [04:39]
    * 
教师：现在我们来谈谈AWS中的证书提供链的理论讲座｡
这是考试中的一个问题，所以你知道这一点很好｡
因此，当您使用CLI时，它将按以下顺序查找凭据｡
因此它将查找命令行选项｡
因此，如果您在命令行选项中指定了区域､
输出､
配置文件或指定了额外密钥ID､ 秘密访问密钥和会话令牌，则此选项的优先级高于任何选项｡
然后它查找的第二个地方是环境变量｡
因此，
如果您设置了这些环境变量之一，但尚未设置命令行选项，则此选项将优先｡
然后，当我们运行AWS配置时，它将查看CLI凭据文件，
然后它将查看CLI配置文件｡
配置方式相同｡
然后，它将查看容器凭据｡
因此，
如果您有一个ECS任务，它将查看容器凭据｡
我们还没有看到ETS是什么，但很快就会看到｡
最后，如果我们使用的是EC2实例配置文件，
那么他将查看实例配置文件凭据｡
正如我们所看到的，最优先的是命令行选项，
然后是环境变量｡
优先级最低的是EC2配置文件凭据或ECS容器凭据｡
因此，
我们的想法是，有一个优先级，
这将是重要的一个场景的问题，它将解释给你很快｡
因此，如果我们看一下SDK，例如Java SDK，
就会有类似的想法｡
因此，将采用的第一个属性将是Java系统属性｡
然后，我们将拥有非常重要的环境变量，如访问权限､
密钥ID和秘密访问密钥｡
而且它们的优先级高于除Java系统属性之外的任何其他属性｡
然后，
我们有默认凭据配置文件､ Amazon ECS容器凭据和实例配置文件凭据｡
因此，我们在这里要记住的是，
环境变量仍然比EC2实例配置文件凭据具有更高的优先级｡
那我为什么要跟你说这些
好吧，
这是一个场景，这是你必须记住的事情｡
因此，假设您在EC2实例上部署一个应用程序，
并使用IAM用户的环境变量调用Amazon
S3 API｡
这是非常糟糕的做法，但说，你已经做到了｡
因此，您一直使用其权限的这些IAM用户具有S3
FullAccess权限｡
这意味着它可以在Amazon S3中的每一个桶上做任何它想做的事情｡
因此，
尽管部署了应用程序，但它只使用一个Amazon S3存储桶｡
因此，
根据最佳实践，因为您已经观看了本课程，
所以您将定义IAM角色和EC2实例配置文件，您将在EC2实例上创建和分配IAM角色和EC2实例配置文件｡
而且，
此角色被分配了最低权限，仅可访问应用程序正在使用的一个S3存储桶｡
您已经完成了我在本课程中介绍的所有操作，您正在执行最低权限操作｡
您正在创建EC2实例配置文件，然后发生了一些事情，
对吗？
你煽动了它｡
然后，即使实例配置文件被分配给EC2实例，
它仍然可以访问所有S3存储桶｡
问题是，为什么？
所以从我所说的，你能猜出答案吗？
答案是，凭据链仍然为您之前设置的环境变量指定优先级｡
因此，
要删除它们，唯一的方法就是取消设置这些环境变量｡
然后，通过查看凭据更改优先级，它将在最后利用EC2实例配置文件和由此产生的权限｡
这是一个常见的情景问题，希望你能理解｡
因此，
凭据最佳实践是，永远不要将凭据存储在代码中｡
这是非常糟糕的做法｡
最佳做法是从凭据链继承凭据｡
因此，这意味着如果您在AWS中工作，则应尽可能多地使用IAM角色｡
这意味着您必须为EC2实例使用ECS实例角色，或为ECS任务使用ECS角色，或者如我们将看到的，
为Lambda函数使用Lambda角色｡
你懂的｡
在AWS中，尽可能多地使用IAM角色｡
如果您在AWS之外工作，请使用环境变量或命名配置文件，
就像我们在配置CLI时所做的那样｡
但是，永远不要将凭据直接存储在代码中｡
这是可怕的做法｡
原来如此｡
希望这对你有帮助｡
我们下节课再见｡ 
  - [ ] 133 [DVA-C02] AWS Signature v4 Signing (Sigv4) [03:23]
    * 
讲师：现在，让我们更深入地了解我们实际上如何向AWS发出API请求｡
因此，当您调用AWS HTTP
API（所有服务的API）时，
您将签署请求，
这样AWS就可以知道您是谁，并且您有权执行请求｡
为了签署你的请求，
你需要使用你的AWS凭据，比如你的访问密钥和秘密密钥｡
通过签名，AWS知道你是谁，然后你就可以走了｡
现在这个过程非常复杂，对于Amazon
S3的一些请求，您不需要签名｡
例如，如果您正在读取公共对象｡
但是对于大多数API调用，您必须对HTTP请求进行签名｡
现在，我们还没有看到签署HTTP请求的过程，
因为我们一直在使用SDK或AWS
CLI，因此默认情况下，所有请求都将由CLI或SDK自动签署｡
因此，将要发生的事情以及您需要记住的是，
当您收到API请求时，您需要做的是对其进行签名｡
当你签署它的时候，
你使用SigV4来签署它｡
现在这个过程很复杂｡
一共有四个步骤，你不需要知道如何用SigV4签名，
因为那会很复杂｡
但您需要知道的是，您可以通过两种方式将计算出的签名传输到AWS｡
因此，第一种方法是在任何HTTP请求的授权头中发送签名｡
所以你计算它，然后发送它｡
这就是CLI所做的，
默认情况下将包括在内，如下所示｡
第二个选项是使用查询字符串｡
所以查询字符串是直接在URL中包含签名的字符串，
正如您在这里看到的｡
签名将位于查询字符串的指定键中，
称为X-Amz-Signature｡
这是两种传输SigV4的方式，
现在我将进入控制台，
向大家展示第二种方式，
以便大家真正了解签名｡
所以在这里，我在亚马逊S3，这是我的咖啡｡ jpg文件｡
我将要做的是，我将要点击这里打开它｡
如你所见，它显示在我的浏览器中｡
而这个文件在我的浏览器中正确显示的原因是因为签名｡
让我将URL复制到文本编辑器中并显示给您｡
如你所见，我有了自己的网址，我把它分解成几个步骤，
让你看看｡
这是安全令牌｡
这里我们有AWS
S4的算法，因此SigV4｡
我们有日期，我们有有效期｡
所以当这个网址将要过期的时候，这是很好的，
当你看到这个视频的时候，它已经过期了｡
您还拥有AMZ证书｡
那么我的帐户ID是什么等等｡
然后是AMZ签名，它代表SigV4的签名部分｡
正如你所看到的，这是一个由我的网络浏览器创建的URL，
可以访问我在Amazon S3中的文件｡
这堂课就到这里｡
简单地说，希望您记住SigV 4用于将请求签名到AWS中，
签名可以使用Authorization中的HTTP标头发送，
也可以使用带有X-Amz-Signature密钥的查询字符串选项发送｡
好吧，就这样｡
我们下节课再见｡ 
  - [ ]  AWS IAM, CLI，& SDK [13 问题] Quiz
    * 
 ## Section 13 - Advanced Amazon S3 [7 个讲座 • 24 分钟]
  - [ ] 134 S3 Lifecycle Rules (with S3 Analytics) [04:20]
    * 
教师：现在我们来讨论一下如何在不同的存储类之间移动对象，
以便进行转换，这是一个示意图，
说明了如何实现这一点｡
如您所见，
您可以从标准IA到智能分层，
再到单区IA，然后如您所见，您可以从单区IA转到灵活检索或深度归档｡
所有的排列方式都在这张图中显示出来了｡
因此，事实上，如果您知道您的对象将很少被访问，
那么就将它们移到Standard IA｡
如果您知道要归档对象，请将它们移到Glacier
of tiers或Deep
Archive层｡
当然，移动这些对象可以手动完成，
但我们可以使用生命周期规则自动执行此操作｡
所以这些生命周期规则是由多种因素组成的｡
第一件事是一个转换操作，用于配置对象以转换到另一个存储类｡
例如，您说在创建后60天后移动到标准IA类，
或者在六个月后移动到Glacier进行归档｡
您还可以设置到期操作｡
因此，配置要删除的对象，使其在一段时间后过期｡
例如，您的访问日志文件，
您希望在365天后将其删除｡
例如，如果启用了版本控制，
则可以使用到期操作删除文件的旧版本｡
或者我们可以用它来删除不完整的多部分上传，
例如，多部分上传已经超过两周了，
因为，嗯，现在应该已经完全上传了｡
也可以为某个前缀指定规则｡
因此它们可以应用于整个存储桶或存储桶中的特定路径｡
也可以为特定对象标记指定它｡
因此，如果您只想为部门财务制定规则，
也可以｡
这里有一些场景｡
例如，您在EC2上有一个应用程序，
它在将个人资料照片上传到Amazon
S3后创建图像和缩略图｡
但是这些缩略图，它们可以很容易地从原始照片重新创建，
它们只需要保存60天｡
但是源图像，他们应该能够立即检索这60天，
之后用户可以等待长达6个小时｡
那么你会如何设计呢？
这是一道考试题要问你的问题｡
因此，S3源图像可以位于Standard类中，
并具有生命周期配置，以便在60天后将其转换为Glacier和缩略图图像，例如，
这就是您使用前缀区分源图像和缩略图的方式｡
缩略图可以放在One-Zone
IA上，因为它们很少被访问，
可以轻松地重新创建，而且您可以通过生命周期配置使它们在60天后过期或删除｡
另一种情况是，您公司的一项规则规定，
您应该能够在30天内立即恢复已删除的S3对象，
尽管这种情况可能很少发生｡
在此时间之后（最长365天），
删除的对象应可在48小时内恢复｡
为此，我们可以启用S3版本控制，以便保留和拥有对象版本，
这样被删除的对象实际上被删除标记隐藏，然后可以恢复｡
然后，您将创建一个规则，将对象的非当前版本转换为Standard
IA｡
这意味着不是顶级版本的版本，
然后将这些非当前版本过渡到Glacier
Deep Archive以供存档｡
最后，我们如何确定将对象从一个类转换到另一个类的最佳天数？
好吧，你可以做到这一点感谢亚马逊S3分析.
它将为您提供标准和标准IA的建议｡
它不适用于One-Zone IA或Glacier｡
因此，S3存储桶将在其上运行S3分析｡
这将创建一个CSV报告，它将为您提供一些建议和一些统计数据｡
报告将每天更新，然后可能需要24到48小时才能开始看到从中产生的数据分析｡
因此，这是很好的第一步，这个CSV报告将有意义的生命周期规则放在一起，
或者改进它们｡
好了，这堂课就到这里｡
我希望你们喜欢，我们下节课再见｡ 
  - [ ] 135 S3 Lifecycle Rules [02:24] Hands On
    * 
  - [ ] 136 S3 Event Notifications [02:28]
    * 
导师：现在我们来谈谈S3事件通知｡
这个想法是你的事件将发生在亚马逊S3｡
什么是事件？
事件是指创建对象，
删除对象，恢复对象或发生复制等事件.
您可以筛选这些事件｡
所以你可以说我只想考虑以JPEG结尾的对象｡
例如，
事件通知的用例可以是自动对Amazon S3中发生的某些事件做出反应｡
例如，
您希望为上传到Amazon S3的所有图像生成缩略图｡
因此，您将创建事件通知，
然后将其发送到几个目的地｡
它可以是一个SNS主题，
它可以是一个SQSQ，和一个Lambda函数｡
如果你现在还不知道这一点，也不用担心｡
我们将在接下来的课程中学习这些特性｡
因此，您可以根据需要创建任意数量的S3事件，
并将它们发送到任何目标｡
因此，
我们的想法是，这些事件通常在几秒钟内发送到这些目的地，但有时可能需要一分钟或更长的时间｡
这是三个主要的目的地尚未记住｡
但是现在有了第四个，
这是S3事件通知的一个新特性，它与Amazon EventBridge集成｡
因此，您的事件将进入您的Amazon
S3桶，所有事件最终都将进入Amazon EventBridge，无论发生什么情况｡
所有的人，好吗？
然后从EventBridge（您还不知道，但您可以设置规则），通过这些规则，
您可以将这些事件发送到超过18个不同的AWS服务作为目的地｡
因此，它确实增强了S3事件通知的能力｡
在本课程的稍后部分，我们将再次看到EventBridge｡
但是，使用EventBridge，
您可以获得比以前更多的高级筛选选项｡
因此，您可以按元数据､ 对象大小和名称进行筛选｡
您可以一次发送到多个目的地｡
例如，您可以设置为步进函数，
您可以查看数据流或消防水管，甚至可以直接从Amazon EventBridge获得功能｡
因此，
您可以归档事件､ 重放事件，并获得更可靠的交付｡
好的，在本课程中，
我们对新服务还有很多不了解的地方，但让我们集中讨论Amazon S3事件通知｡
这个想法是你可以对Amazon S3中发生的事件做出反应｡
感谢发送到SQS, SNS，
Lambda或亚马逊EventBridge｡
好吧，就这样｡
我们下节课再见｡ 
  - [ ] 137 S3 Event Notifications [05:42] Hands On
    * 
  - [ ] 138 S3 Performance [04:54]
    * 
因此，我们必须讨论一下S3基准性能｡
因此，默认情况下，Amazon S3会自动扩展到非常非常高的请求数量，
并且具有非常非常低的S3，从S3中获取第一个字节的时间为100到200毫秒｡
所以，这是相当快的｡
就每秒可以获得的请求数量而言，桶中每个前缀每秒可以获得3，
500个PUT/COPY/POST/DELETE请求，或者每个前缀每秒可以获得5，
500个GET/HEAD请求｡
你可以在网站上找到，
我想这不是很清楚，
所以我会向你解释每秒每个前缀是什么意思｡
但这在viral中意味着，
它的性能非常非常高，而且，对存储桶中的前缀数量没有限制｡
因此，让我们以四个名为file的对象为例，
分析该对象的前缀｡
第一个在你的桶里，在文件夹1，
子文件夹1斜线文件｡
在本例中，前缀将是bucket和file之间的任意值｡
在本例中，它是文件夹1，子文件夹1｡
这意味着对于这个前缀中的文件，每秒可以得到3，500个Put和5，500个Get.
现在，如果我们有另一个文件夹1和子文件夹2，前缀是bucket和file之间的任何东西，
所以斜杠folder 1斜杠sub 2，所以我们也得到了3，500个Put和5，500个Get，以此类推｡
如果我有一个和两个，我们就有不同的前缀，所以现在很容易理解什么是前缀，
也很容易理解一个桶中每个前缀每秒3，500个Put和5，500个Get的规则｡
因此，这意味着如果您将读取均匀地分布在上面的所有四个前缀上，
那么对于Head和Gets，您可以达到每秒22，000个请求｡
现在，我们来讨论一下S3性能，
以及如何优化它？
第一个是多部分上传｡
因此，建议对超过100 MB的文件使用多部分上载，
并且必须对超过5 GB的文件使用多部分上载｡
多部分上传所做的是，
它使上传并行化，这将帮助我们加快传输速度，
以最大限度地利用带宽｡
所以，作为一个图表，它总是更有意义｡
我们有一个字节文件，我们希望将该文件上传到Amazon
S3｡
我们将它分成几个部分，因此较小的文件块和每个文件将并行上传到Amazon
S3｡
在亚马逊S3中，一旦所有的部分都上传完毕，
它就可以很聪明地把它们放在一起，
放回大文件中｡
好吧，非常重要｡
现在，我们有了S3传输加速，
它用于上传和下载，通过将文件传输到AWS边缘位置来提高传输速度，
AWS边缘位置将数据转发到目标区域中的S3存储桶｡
因此，边缘位置不仅仅是区域｡
现在大约有200多个边缘位置，而且还在增长，
让我在图表中展示一下这意味着什么？
S3传输加速与多部分上传兼容｡
所以，让我们来看看｡
我们在美国有一个文件，我们想将其上传到澳大利亚的S3
bucket｡
因此，我们将通过美国的一个边缘位置上传该文件，
这将非常非常快，然后我们将使用公共互联网｡
然后，从该边缘位置到澳大利亚的Amazon
S3存储桶，边缘位置将通过快速的专用AWS网络传输数据｡
这就是所谓的传输加速，
因为我们最小化了我们通过的公共互联网的数量，
最大化了我们通过的私人AWS网络的数量｡
因此，传输加速是加快传输速度的一个很好的方法｡
好了，现在去拿文件吧？
用最有效的方式读取文件怎么样？
我们有一个叫做S3字节范围获取的东西，
所以它通过为你的文件获取特定的字节范围来瘫痪获取｡
因此，如果您无法获取特定的字节范围，
则可以重试较小的字节范围，
并且在失败时具有更好的恢复能力｡
所以，这次可以用它来加快下载速度｡
让我们试试S3中的一个文件，它非常非常大，
就是这个文件｡
也许您希望请求第一部分，
即文件的前几个字节，然后请求第二部分，
最后请求结束部分｡
所以，我们请求所有这些部分作为特定的字节范围获取，
这就是为什么它被称为字节范围，因为我们只请求文件的特定范围｡
而且所有这些请求都可以并行提出｡
所以，我们的想法是，我们可以并行化获取，
并加快下载｡
第二种使用情形是只检索文件的一部分｡
例如，如果您知道S3中文件的前50个字节是标头，
并提供了有关文件的一些信息，
那么您只需使用前50个字节向字节范围请求发出标头请求，您将很快获得该信息｡
好了，S3的性能就到这里｡
我们已经了解了如何加快上传和下载｡
我们已经看到了基准性能和KMS限制｡
所以，你们一定要知道这些要考的内容，
我们下节课再见｡
  - [ ] 139 S3 Select & Glacier Select [01:17]
    * 
讲师：现在我们来谈谈S3 Select和Glacier
Select｡
其思想是，您知道要从S3检索文件，
但在检索后要对其进行筛选，
因此检索的数据太多｡
如果您可以使用SQL来执行服务器端筛选，
会怎么样？
因此，这意味着您将使用简单的SQL语句按行或按列进行筛选，
以减少网络传输，并降低客户端实际浏览数据和筛选数据所需的CPU成本｡
因此，在S3 Select之前，
您要做的是检索所有数据，然后在应用程序端对数据进行筛选，
以找到所需的数据｡
这意味着有大量数据进入，
而使用的数据却很少｡
但是如果您使用S3 Select，
您实际上会让Amazon S3为您过滤文件，您只检索您需要的数据｡
因此，亚马逊声称使用S3选择的速度快了400%，
价格便宜了80%｡
把它放在另一个图表中，我们将得到一个带有Amazon
S3 Select的CSV，好的｡
Amazon S3将找到CSV文件，
并在服务器端对其进行过滤，也就是在自己的服务上，
然后将过滤后的数据集发送给我们，
这样数据集就小得多，也便宜得多｡
对于简单的过滤，请考虑S3选择，它也适用于Glacier，
因此Glacier选择｡
就这样了｡ 我们下节课再见｡ 
  - [ ] 140 [DVA-C02] S3 Object Tags & Metadata [02:33]
    * 
Stephane：那么让我们讨论一下用户定义的对象元数据和S3对象标记｡
所以当你创建一个对象，当你上传一个对象，
你也可以分配元数据｡
元数据只是附加到对象的键值对的一个花哨的名称｡
因此，如果您上传用户定义的元数据，
则名称必须以x-amz-meta开头-因为存在AWS生成的元数据｡
所以元数据可以在检索对象的同时被检索，
它给你关于对象本身的信息｡
例如，对于S3对象，前两个参数是Content-Length和Content-Type，
值为7｡ 5千字节和html｡
由AWS提供｡
而x-amz-元原点：巴黎只是你出于某种原因给自己下的定义｡
接下来是S3对象标记｡
这是比较常见的，
因为这是你在AWS中看到的标签｡
Amazon S3中的对象有键值对｡
我们使用标记而不是元数据的原因是标记实际上可以用于细粒度的权限｡
例如，仅允许访问AWS中具有特定标记的特定对象｡
或者用于分析目的｡
例如，如果您使用S3 Analytics这样的解决方案，
您可以按标签对您的发现进行分组｡
例如，对于这个S3对象，
我们可以使用Project：蓝色，
PHI，个人健康信息，正确｡
只是一些信息，你可能想为你的对象提供｡
所以我希望你们记住的最重要的一点是元数据和标签在Amazon
S3上是不可搜索的｡
不能按元数据过滤，也不能按标签过滤｡
这是不可能的｡
那么，我们首先为什么要这样做？我们如何在S3存储桶中搜索对象？
如果您确实希望搜索S3 bucket，则必须在数据库中构建一个外部索引，
例如DynamoDB，但它可以是您想要的任何索引｡
稍后我们会看到DB｡
但是您将把所有元数据和所有这些标记放入DynamoDB中的一个可搜索索引中，
然后在DynamoDB上执行搜索｡
搜索结果将被提取为Amazon
S3上的对象｡
因此，这是一个常见的考试问题，
也是您需要了解的有关此体系结构的知识｡
好了，这堂课就到这里｡
希望你喜欢｡
我们下节课再见｡ 
  - [ ]  Amazon S3 Advanced [7 问题] Quiz
    * 
 ## Section 14 - Amazon S3 Security [13 个讲座 • 48 分钟]
  - [ ] 141 S3 Encryption [07:31]
    * 
讲师：现在我们来讨论Amazon
S3中的对象加密｡
因此，您可以使用以下四种方法之一来加密S3桶中的对象｡
第一个是服务器端加密，SSE，你有多种风格｡
因此，您有SSE-S3，这是使用Amazon
S3管理的密钥的服务器端加密，并且默认情况下为您的存储桶和对象启用｡
然后我们有SSE-KMS，我们用KMS密钥来管理加密密钥｡
然后我们让SSE-C使用客户提供的密钥，
所以这次我们提供自己的加密密钥｡
别担心，我们将在下一张幻灯片中详细介绍所有这些内容，
因此这只是一个概述｡
然后我们有客户端加密，当我们想要加密客户端的所有内容，
然后将其上传到Amazon S3｡
所以在考试中，了解哪些是针对哪些情况很重要，
所以让我们深入了解所有这些并了解它们的特殊性｡
第一个是Amazon S3，用于SSE-S3加密｡
因此，在这种情况下，加密使用的是由AWS处理､
管理和拥有的密钥｡
您永远无法访问此密钥｡
该对象将由AWS在服务器端加密，
加密的安全类型为AES-256｡
因此，您必须将头设置为“x-amz-server-side-encryption”：“AES
256”请求Amazon S3使用SSE-S3机制为您加密对象｡
现在，默认情况下为新存储桶和新对象启用SSE-S3｡
那么这是怎么回事呢？
我们有Amazon S3，我们有我们的用户｡
用户，你，你要上传一个具有正确标题的文件，
然后它将成为Amazon
S3下的对象｡
Amazon S3会将它与S3拥有的密钥配对，因为我们使用的是SSE-S3机制｡
然后，我们将通过混合密钥和对象来执行加密，
这将是存储在S3存储桶中的内容｡
这就是简单的SSE-S3｡
然后是SSE-KMS｡
因此，这次您不需要依赖AWS和S3服务拥有的密钥，
而是希望使用KMS服务（密钥管理服务）自己管理自己的密钥｡
因此，使用KMS的优点是您可以对该密钥进行用户控制，
因此您可以在KMS中自己创建密钥，
并且可以使用CloudTrail编辑密钥使用情况｡
因此，任何时候有人在KMS中使用密钥，这将被记录在一个名为CloudTrail的服务中，
该服务记录AWS中发生的一切｡
因此，我们必须有一个名为“x-amz-server-side-encryption”的头：“aws：kms”，
然后对象将被加密服务器端｡
因此，任何SSE，当然，是服务器端｡
那么这是怎么回事呢？
同样，我们上传对象，这次使用不同的头，
在头中我们实际上指定了我们想要使用的KMS密钥｡
然后对象出现在Amazon
S3中，这次要使用的KMS密钥来自AWS
KMS｡
所以这两件事将被混合在一起，
然后你会得到加密，
这是文件将最终在S3桶｡
因此，现在要从S3存储桶中读取该文件，
不仅需要访问对象本身，还需要访问用于加密该对象的底层KMS密钥｡
所以这是另一个安全级别｡
所以SSE-KMS有一些限制，
因为现在您从Amazon
S3上载和下载文件时，需要利用KMS密钥｡
KMS密钥有自己的API，例如GenerateDataKey，
当您解密时，您将使用Decrypt API，
因此，您将对KMS服务进行API调用｡
这些API调用中的每一个都将计入每秒API调用的KMS配额，
因此根据区域，您每秒有5，000到30，000个请求，尽管可以使用服务配额控制台增加这些请求｡
因此，如果您有一个非常非常高吞吐量的S3存储桶，并且所有内容都使用KMS密钥加密，
您可能会进入线程链接类型的用例｡
所以这是考试可能会考验你的东西｡
接下来是SSE-C类型的加密｡
因此，这一次密钥是在AWS之外管理的，但它仍然是服务器端加密，
因为我们将密钥发送到AWS｡
但是Amazon S3永远不会存储您提供的加密密钥｡
它们用过之后，就被丢弃了｡
因此，在这种情况下，由于我们将密钥传输到Amazon
S3，因此必须使用HTTPS，并且必须将密钥作为HTTP头的一部分传递给每个请求｡
那么这是怎么回事呢？
用户将上传文件和密钥，但用户在AWS之外管理密钥｡
然后，Amazon S3将使用客户端提供的密钥和对象执行一些加密，
然后将加密的文件放入S3存储桶中｡
当然，要读取该文件，
用户必须再次提供用于加密该文件的密钥｡
最后，我们有客户端加密｡
因此，如果我们利用一些客户端库（如客户端加密库），
这将更容易实现｡
客户端加密的想法是，
客户端必须在将数据发送到Amazon
S3之前自己加密数据｡
此外，您还可以从Amazon S3检索数据，
然后在Amazon S3之外的客户端上对数据进行解密｡
因此，客户端完全管理密钥和加密周期｡
那么这是怎么回事呢？
我们有一个文件，我们有一个客户端的密钥，
它在AWS之外｡
客户端本身将提供并执行加密，
因此现在我们有一个加密文件，该文件可以发送到Amazon
S3进行上传｡
我们已经了解了对象的所有加密级别，现在让我们来讨论传输中的加密｡
因此，传输中的加密也称为SSL或TLS，
基本上您的Amazon S3存储桶有两个端点，未加密的HTTP端点和在传输中加密的HTTPS端点｡
因此，每当您访问一个网站时，
您看到那个绿色的锁或锁，
通常这意味着它在飞行中使用加密，
这意味着您和目标服务器之间的连接是安全的，
完全加密的｡
因此，当您使用Amazon
S3时，完全建议使用HTTPS来进行安全的数据传输，当然，
如果您使用SSE-C类型的机制，则必须使用HTTPS协议｡
现在，这在现实生活中并不需要担心，
因为大多数客户端默认使用HTTPS端点｡
现在，您将如何在传输中强制加密？
为此，我们可以使用桶策略｡
因此，您将存储桶策略附加到S3存储桶，
并附加以下语句，即如果条件为“aws：SecureTransport”，
则拒绝任何GetObject操作：“假的”｡
因此，无论何时使用HTTPS, SecureTransport都将为true，
而无论何时您不使用加密，加密连接时，SecureTransport都将为false，
因此，任何试图在您的bucket上使用HTTP的用户都将被阻止，但使用HTTPS的用户可能会被允许｡
好了，这就是加密的内容，
希望你们喜欢，我们下节课再见｡
  - [ ] 142 S3 Encryption [04:39] Hands On
    * 
  - [ ] 143 S3 Default Encryption [01:23]
    * 
讲师：我们来简短地讲一下默认加密与存储桶策略｡
因此，默认情况下，
现在所有存储桶都具有默认加密SSE-S3｡
所以它会自动应用到新对象的新桶中｡
但是您可以将其更改为不同的默认加密，
例如SSE-KMS｡
尽管如此，您也可以通过使用bucket策略来拒绝任何API调用以放置没有正确加密头的S3对象，
从而强制进行加密｡
例如，SSC-KMS或SSE-C｡
这是一种桶策略，例如，这个策略说，
嘿，如果你做了一个PUT对象，
但是你没有AWS KMS的加密头，
那么拒绝这个请求｡
或者，嘿，如果你上传这个，
但是没有客户端算法，所以没有SSE-C，那么拒绝这个对象｡
这只是一个示例，
但至少您可以看到，存储桶策略还可以强制在存储桶中进行加密｡
顺便说一句，存储桶策略总是在默认加密设置之前进行评估｡
就是这样，请记住，SSC-S3的默认加密是默认启用的，
但您可以更改它，并且可以抢先应用存储桶策略，以强制对您想要的加密进行加密｡
好吧，就这样｡
我希望你们喜欢，我们下节课再见｡ 
  - [ ] 144 S3 CORS [04:19]
    * 
现在我们来谈谈CORS｡
CORS是跨源资源共享｡
而这是你在考试时需要知道的一个问题｡
现在，我将深入探讨它是如何工作的，
这将使回答这个问题变得非常容易｡
因此，源是一个方案､ 一个协议､ 一个主机､
一个域和一个端口｡
例如，如果您查看https：//www. 示例中｡ 对于HTTPS，隐含的端口是443，
协议是HTTPS本身，域当然是www. com｡
示例中｡ 现在，
CORS是一个基于Web浏览器的安全机制，允许或拒绝访问主源时对其他源的请求｡
那么，让我们来看看同源是什么意思｡
因此，如果我们有相同的方案､ 相同的主机和相同的端口，
则它是相同的源｡
例如，我们有这两个URL，
它们共享相同的来源｡
但是，我们可以有不同的起源｡
例如，www. 示例中｡ com和其他网站｡ 示例中｡ 因此，如果我们的Web浏览器正在访问一个网站，
并且作为请求方案的一部分，应该向另一个网站发出请求，那么这些请求将不会被满足，
除非另一个源允许使用CORS报头的请求｡
它们被称为“访问控制允许来源”标头｡
让我们通过一个示意图来了解它的工作原理以及如何利用它们｡
我们有一个Web服务器，它是您的源，它是https：//www｡
示例中｡ com和网络浏览器｡
第二个网络服务器，也就是交叉源，好吗？
所以，www. 其他｡ 现在，Web浏览器将向第一个源Web服务器发出HTTPS请求｡
作为结果的一部分，HTML文件检索到的索引会说，
嘿，你还必须得到一些图像，例如，从另一个Web服务器｡
因此，Web浏览器具有内置的安全性，
并且首先将向跨源进行飞行前请求｡
所以，它会说，嘿，我想得到www的选项｡
其他｡ 顺便说一下，
我的请求来源是https：//www｡
示例中｡ com的网站｡
然后，如果考虑并配置Web服务器使用跨源资源共享，
则它会说，是的，我确实允许此源，如示例所示｡
com源代码，用于get､ put和delete方法｡
这就是我们所说的CORS标头｡
而且，如果Web浏览器对该CORS头满意，
则Web浏览器将向其他服务器发出请求，以检索这些文件并进行这些调用｡
那么，它如何应用于Amazon S3呢？
如果客户端在我们的S3桶上发出跨源请求，
我们需要启用正确的CORS头｡
这是一个非常流行的考试题，
一个快速的方法是允许一个特定的原点，
或者允许 *，这意味着所有的原点｡
那么，让我们来看看｡
我们有一个Web浏览器和一个S3 bucket，
其中启用了一个静态网站｡
这就是我的桶HTML｡
我们将资产和图像存储在另一个称为my-buckets-assets的S3存储桶中｡
同样，我们为它启用了一个静态网站｡
因此，Web浏览器转到第一个S3桶，
然后说，嘿，我想获取索引，
即HTML文件，这里的URL当然是静态网站URL｡
所以，我们拿回了索引｡ HTML和索引内｡
html中有一个图像，
并且该图像存在于另一个网站上｡
因此，我们得到了图像/咖啡，
这是Web浏览器在做它的事情，
但这次它说，嘿，目标主机是这个其他网站，但起源是这个第一个网站｡
如果S3存储桶未配置为具有正确的CORS标头，
它将拒绝该请求，否则，
如果它允许该请求，则它将具有正确的标头，并说，好的，您可以执行该请求，
并且您可以获得映像｡
请记住，CORS是一种Web浏览器安全机制，
允许您在请求来自其他来源时从一个S3存储桶中检索图像､ 资产或文件｡
就这样了｡
希望大家喜欢，我们将在下一堂课中进行一些实践，
向大家展示CORS的工作原理｡
  - [ ] 145 S3 CORS [07:23] Hands On
    * 
  - [ ] 146 S3 MFA Delete [01:24]
    * 
教师：现在，我们来讨论一项名为MFA
Delete的安全功能｡
MFA代表多因素身份验证，这是一种强制用户在设备上生成代码的方法｡
例如，它可以是具有Google身份验证器应用程序或其他应用程序的移动电话，
或者是另一个应用程序，或者是诸如MFA硬件设备之类的硬件｡
这会给你一个代码，
在执行重要操作之前，必须将该代码插入到Amazon
S3中｡
那么什么时候需要MFA呢？
当你想永久删除一个对象版本时，
这是必需的｡
因此，这绝对可以防止永久删除，
或者如果您希望挂起存储桶上的版本控制，
也可以使用此功能｡
这两个选项都具有相当大的破坏性，
因此MFA将被恢复｡
但如果您要启用版本控制或列出已删除的版本，
则不需要MFA，
因为这些操作并不危险｡
因此，要使用MFA删除，您必须首先在存储桶上启用版本控制，
因为这当然与版本控制相关，并且只有存储桶所有者（即root帐户）才能启用或禁用MFA删除，
您将在下一个操作中看到｡
这是相当复杂的，因为使用root帐户并不是一件需要经常做的事情，
但在下一节课中，你会看到如何做｡
请记住，MFA删除是一种额外的保护，
可防止永久删除特定对象版本｡
就这样，我们下节课再见.
  - [ ] 147 S3 MFA Delete [06:25] Hands On
    * 
  - [ ] 148 S3 Access Logs [01:16]
    * 
现在，我们来讨论一下S3访问日志｡
因此，出于审计目的，
您可能希望记录对S3存储桶的所有访问｡
因此，这意味着从任何帐户向S3存储桶发出的任何请求，
无论是否被授权或拒绝，都将作为文件记录到另一个S3存储桶中｡
然后可以使用诸如AmazonAthena之类的数据分析工具来分析这些数据｡
现在，目标日志记录存储桶也必须位于同一AWS区域中｡
那这是怎么做到的呢？
您将向S3存储桶发出请求，
然后启用访问日志｡
所有请求都被记录到日志记录存储桶中｡
现在，有一个特定格式的日志，
你可以在这个URL找到它，
找到日志格式｡
现在，有了访问日志，就有了一点警告｡
永远不要将您的日志记录存储桶设置为与您正在监视的存储桶相同，
因为否则，它将创建日志记录循环，并且它将是无限的，您的存储桶将以指数级的方式增长｡
那是什么意思呢？
虽然你确实放了对象，
但应用程序桶和日志记录桶是一样的｡
所以会有一个记录循环，
你会再记录一次，再记录一次，
再记录一次，你会付出很多钱｡
所以不要在家里尝试这个｡
好了，S3的访问日志到此为止.
我希望你们喜欢，
下节课再见｡
  - [ ] 149 S3 Access Logs [02:49] Hands On
    * 
  - [ ] 150 S3 Pre-signed URLs [01:50]
    * 
教师：现在，我们来讨论Amazon
S3预签名URL｡
因此，它们是您可以使用S3控制台､ CLI或SDK生成的URL，
并且该URL具有过期时间｡
因此，如果使用控制台，最长可达12小时;如果使用CLI，
最长可达168小时｡
因此，当您生成一个预签名的URL时，
将获得该URL的用户将继承生成GET或PUT的URL的用户的权限｡
那么，使用情形是什么？
假设您有一个S3 bucket，它是私有的，
并且您希望允许AWS之外的某个人访问一个文件｡
你不会想把文件公之于众的｡
你不想以任何破坏安全的方式制作文件，
对吧？
因此，作为bucket的所有者或用户，
您将从该文件中生成一个预签名的URL, S3 Bucket将为您提供一个URL｡
该URL将被预先签名，
这意味着它将延续您的凭据，
就访问该文件的授权而言｡
然后将此URL发送给目标用户，您希望授予该用户在有限时间内访问该文件的权限｡
然后，对不起，该用户将使用URL访问S3
Buckets上的文件｡
然后，您将从S3存储桶中取回一个文件，
例如，用户可以下载该文件｡
因此，在临时访问一个特定文件以进行下载甚至上传时，
预签名URL是一种非常常见的用例｡
例如，只允许登录的用户下载S3 bucket的高级视频，
或者通过动态生成URL允许不断变化的用户列表下载文件，或者临时允许用户将文件上传到S3
bucket中的精确位置，同时保持S3 bucket的私有性｡
这节课就讲到这里，
下节课我们会亲自动手｡
  - [ ] 151 S3 Pre-signed URLs [01:48] Hands On
    * 
  - [ ] 152 S3 Access Points [03:34]
    * 
教师：现在我们来讨论S3接入点｡
让我们以一个具有大量数据的S3存储桶为例｡
我们有财务数据，有销售数据，
还有不同的用户或组想要访问他们的数据｡
我们可以创建一个非常复杂的S3存储桶策略，
并使其随时间增长｡
用户越多，您拥有的数据越多，
这可能变得越难以管理｡
那么解决办法是什么呢？
我们可以创建所谓的S3接入点｡
例如，我们可以创建一个连接到财务数据的财务访问点｡
它是如何与财务数据连接的？
我们将定义一个访问点策略，
此策略看起来就像S3存储桶策略，将授予对finance前缀的读写访问权限｡
然后我们可以定义一个销售访问点｡
同样，由于接入点策略，它将连接到销售数据，
该接入点附加了另一个策略，它将授予对销售前缀的读写访问权限｡
如您所见，我现在有两个策略，
如果我希望有一个分析访问点，我们可以创建它，
使其指向财务和销售，但只能进行只读访问｡
因此，我们将在分析访问点上创建自己的只读策略｡
您可以看到，我们已将安全管理从S3存储桶策略推广到接入点，
每个接入点都有自己的安全性｡
因此，有了适当的IAM权限，我们的用户就可以访问财务访问点，
并且只能连接到bucket的财务部分｡
销售用户只能访问销售，分析组可以同时访问财务和销售｡
因此，通过使用接入点，我们定义了访问S3存储桶的不同方式｡
结果就是我们有了一个非常简单的方法来管理安全性｡
我们有附加到每个接入点的策略，而且我们在Amazon
S3上有一个非常简单的桶策略｡
因此，我们可以真正扩展对S3存储桶的访问｡
总结一下接入点，简化S3存储桶的安全管理，
每个接入点都有自己的DNS名称｡
你就是这样连接到接入点的｡
您可以选择将其连接到互联网作为源或VPC的私人流量｡
然后再附加一个与存储桶策略非常相似的接入点策略｡
这使您能够大规模管理安全性｡
关于S3接入点的VPC起源，我们可以将它们定义为私有可访问的｡
例如，VPC访问中的EC2实例表示，
在不通过Internet的情况下，我们的S3桶通过VPC访问点，通过VPC源｡
为此，要访问此VPC原点，我们必须创建所谓的VPC端点来访问访问点｡
因此，它是我们的VPC中的某个东西，
它将允许我们通过我们的VPC原点私下连接到接入点｡
然后，VPC端点有一个策略，
该策略必须允许访问目标存储桶和接入点｡
因此，VPC端点策略将允许EC2实例同时连接到VPC､
Amazon S3上的接入点和S3存储桶｡
在本例中，我们使用VPC端点来实现安全性｡
我们还提供了接入点策略的安全性和S3存储桶级别的安全性｡
好吧｡ 这就是接入点｡
我希望你们喜欢，我们下节课再见｡ 
  - [ ] 153 S3 Object Lambda [03:10]
    * 
EFS三个接入点还有另一个用例，称为S3
Object Lambda｡
因此，我们的想法是，您有一个S3桶，
但您希望在颜色应用程序检索对象之前对其进行修改｡
例如，我们可以使用S3
Object Lambda来代替复制bucket，
使每个对象具有不同的版本｡
为此，我们需要刚才看到的S3接入点｡
那么这是怎么回事呢？
假设我们有云，其中有一个S3存储桶｡
因此，电子商务应用程序可能拥有此S3存储桶中的数据，
因此它们能够直接访问S3存储桶，
并从中放入和取出原始对象｡
但是，分析应用程序可能只想访问编校的对象｡
这意味着某些数据已从对象中删除｡
因此，我们可以做的不是为此创建新的S3桶，
而是在S3桶之上创建S3接入点，并将其连接到Lambda函数｡
现在，我们还没有深入了解Lambda，
但是Lambda函数允许您非常轻松地在云中运行一些代码｡
这个Lambda函数将在检索对象时对其进行编辑｡
在这个Lambda函数之上，
我们将创建一个S3对象Lambda访问点｡
这就是分析应用程序访问S3存储桶的方式｡
总结一下，分析应用程序访问我们的S3
Object Lambda访问点，这将调用我们的Lambda函数｡
我们的Lambda函数将从S3桶中检索数据，
并运行一些代码来编辑数据｡
因此，分析应用程序从与电子商务应用程序完全相同的S3桶中获取编校对象｡
现在，营销应用程序可能希望访问一个丰富的对象，
并且他们有一个客户忠诚度数据库来增强数据｡
因此，不必再创建一个新的S3存储桶并使用所有丰富的数据创建所有对象｡
我们能做的是，再次使用Lambda函数｡
又是一段代码｡
而这一个将通过从客户忠诚度数据库中查找来丰富数据｡
因此我们也可以在它上面创建一个对象Lambda访问点｡
因此，我们的营销应用程序可以访问这个访问点，
这个S3对象Lambda访问点获得，
再次丰富的对象｡
如您所见，我们只需要一个S3桶，
但我们可以创建访问点和对象Lambda来根据需要修改数据｡
因此，它的用例是编辑，例如，PII数据｡
个人身份信息，用于分析或非生产环境，
或者将数据从XML转换为JSON，
或者执行任何类型的转换｡
例如，动态调整图像大小和对图像添加水印，
但水印是请求对象的用户所特有的｡
这是S3对象Lambda的一种很酷的用法｡
希望你们喜欢，
我们下节课再见｡
  - [ ]  Amazon S3 Security [9 问题] Quiz
    * 
 ## Section 15 - CloudFront [12 个讲座 • 47 分钟]
  - [ ] 154 CloudFront - Overview [05:11]
    * 
讲师：现在我们来谈谈CloudFront｡
CloudFront是一个内容交付网络，或CDN，所以任何时候你在考试中看到CDN，
都可以考虑CloudFront｡
它通过在不同的边缘位置缓存网站的内容来提高读取性能｡
由于您的内容在世界各地进行缓存，因此您在世界各地的用户将有更低的延迟，
这将改善用户体验｡
CloudFront由全球216个存在点组成，
这些存在点对应于全球的AWS边缘位置｡
AWS不断增加位置，
以进一步改善各地的用户体验｡
最重要的是，通过在全球分发内容，我们可以获得DDoS保护｡
DDoS是一种全球所有服务器同时受到攻击的攻击，
我们稍后将在本课程中了解这一点，
其理念是，CloudFront因为您的应用遍布全球，所以您可以抵御这些攻击，也可以使用Shield和Web应用防火墙，
我们将在安全部分中了解这一点｡
因此，如果我们想查看世界地图，
这些就是地图，我们可以在边缓存中看到一些边位置｡
假设我们在澳大利亚创建了一个S3存储桶和一个S3存储桶上的网站，
但我们有一个可能在美国的用户，那么该用户将使用CloudFront从美国的边缘位置请求内容，
CloudFront将能够从澳大利亚获取内容｡
现在，如果美国的另一个用户将请求相同的内容，
那么它将直接从边缘提供服务，
而不会一直到澳大利亚提供该内容｡
同样，如果用户在中国，
那么它将与中国的存在点通话，
然后重定向到S3桶，然后内容将在边缘缓存｡
CloudFront有几种类型原点｡
例如，您有S3 bucket，
用于分发文件并使用CloudFront在边缘缓存它们｡
为了保证只有CloudFront可以访问您的S3桶，
您可以使用称为源访问控制（OAC）的东西，
它将取代旧的源访问身份（OAI）｡
CloudFront还可以用作将数据发送到S3桶中的一种方式｡
因此，将数据上传到文件到S3，
这称为入口｡
您也可以在任何自定义源HTTP后端之前使用CloudFront｡
这可能是一个应用程序负载平衡器，
也可能是一个EC2实例，
以及S3网站，
但首先您必须将bucket启用为静态S3网站，或者您想要的任何HTTP后端｡
那么，从更高的层面来看，CloudFront是如何工作的呢？
我们在世界各地都有优势，好吗？
然后它将连接到你的起源｡
那么，它是S3桶还是HTTP服务器呢？
当客户端连接并向边缘位置发出HTTP请求时，
边缘位置将查看缓存中是否有该请求｡
如果缓存中没有，
则它将转到源位置以获取请求结果｡
一旦检索到结果，它就会将其缓存到本地缓存中，
这样，如果另一个客户端从同一个边缘位置请求相同的内容，
则边缘位置不需要转到源位置｡
如果我们将S3作为原点，
那么如果我们看一下云，
S3桶是某个区域的原点，然后在世界各地都有边缘位置，
例如，在洛杉矶｡
访问洛杉矶边缘位置的用户将通过边缘位置直接获得内容服务，
但首先边缘位置将通过专用网络从源S3存储桶获得内容｡
并且将使用源访问控制并通过修改S3桶上的S3桶策略来保护S3桶｡
这与我们在圣保罗的用户相同，
例如，在巴西｡
同样，这将是另一个边缘位置，
它将为靠近巴西的用户提供服务，
然后它将是边缘位置和S3桶之间的专用连接，
依此类推｡
因此，使用CloudFront和边缘位置，
我们可以看到，一个区域中S3桶的内容可以通过边缘位置或存在点分布到世界各地｡
因此，一个常见的问题是，
CloudFront与S3复制之类的产品之间有什么区别？
如果你有CloudFront，
你使用的是Global
Edge网络，所以这大约是216个存在点，
文件将缓存在每个边缘位置，
可能一天｡
所以，如果你有静态内容，
必须能够在世界各地提供，
这是惊人的｡
S3跨区域复制是不同的，它必须为您希望发生复制的每个区域设置，
因此这并不适用于世界上的每个区域｡
然后，文件将以接近实时的方式更新，
因此不会发生缓存｡
它仅用于只读，因此，
如果您的动态内容需要随时更改，
并且在少数地区以低延迟提供，
这将非常有用｡
因此，它们的用途非常不同，
CloudFront是一个CDN，
用于缓存世界各地的内容，而S3跨区域复制则是将整个存储桶复制到另一个区域｡
所以希望这对CloudFront有意义｡
在下一讲中，我们将进行一次演示，
了解如何在云中为S3存储桶设置CloudFront分发｡
我们下节课再见｡ 
  - [ ] 155 CloudFront [05:06] Hands On
    * 
  - [ ] 156 [DVA-C02] CloudFront - Caching & Caching Policies [06:46]
    * 
讲师：那么，让我们花点时间来了解CloudFront中缓存的工作原理｡
因此缓存位于每个CloudFront边位置｡
所以缓存的数量和边的位置一样多｡
缓存中的每个对象都将由一个缓存键标识｡
我们将在下一张幻灯片中看到什么是缓存键｡
但想法是，通过CloudFront边缘位置提出的请求｡
边位置首先检查对象是否已被缓存｡
如果它在缓存中，
根据生存时间判断它是否过期｡
如果没有，如果它不在缓存中，
那么请求将被转发，
我们将看到它是如何转发到源的｡
然后将来自源的响应缓存到边缘位置｡
以便将来请求返回缓存结果｡
因此，您希望通过最小化对源的请求来最大化缓存命中率｡
这意味着您希望在边缘位置缓存尽可能多的内容｡
我们还将看到，
根据TTL，您可以不等待项目过期｡
如果要从缓存中删除它，
可以创建一个失效｡
那么什么是CloudFront缓存密钥，
我们在哪些内容上进行缓存？
缓存键是缓存中每个对象的唯一标识符｡
默认情况下，如果您不执行任何操作，
它将由主机名和URL的资源部分组成｡
在这个例子中，有一个mywebsite｡
com公司｡
这就是主机名｡
然后是GET/内容/故事/示例故事｡
html.
这是URL的资源部分｡
这意味着，
如果缓存未命中，任何发出类似请求的人，首先，
我们将从源位置获取对象，然后将根据这两个键缓存对象，
即主机名和URL的资源部分｡
然后，具有相同主机名和相同资源部分的类似请求将命中缓存并获得缓存命中｡
但有时候你希望你的缓存密钥更复杂一点，
因为有时候，你的内容会根据用户或设备或语言或用户来自的位置等而变化｡
所以我们要做的是增强缓存键并添加更多信息｡
因此，我们希望在其中添加HTTP头､
Cookie或查询字符串｡
要定义如何创建缓存键，
我们必须定义所谓的CloudFront缓存策略｡
所以这个缓存策略可以是基于HTTP头的缓存｡
因此，您可以不选择其中任何一个，
也可以选择白名单来指定您要包括的内容｡
你有饼干｡
因此，您可以不选择其中任何一个，
选择白名单或您想要包括的列表，
或者全部或全部接受｡
我们有查询字符串｡
同样，您希望不包括任何一个､
白名单､ 所有例外还是全部？
这基本上是要配置如何创建缓存密钥｡
在缓存策略中，
您还可以控制TTL｡
所以从零秒到一年的缓存｡
然后，您还可以使用称为缓存控制标头或过期标头的特定标头来控制该设置｡
因此，您可以创建自己的缓存策略，
也可以使用AWS预定义的托管策略｡
我希望你们记住的非常重要的一点是，
所有包含在缓存键中的HTTP头､
cookie和查询字符串都将自动包含并转发到原始请求｡
以HTTP头为例，
假设我们有一个请求，语言为fr-fr，这意味着我们请求法语的博客｡
这是怎么回事？
如果我们定义了一个无HTTP头缓存策略，
那么没有任何头会被缓存，
也不会被转发，除非，我会在这节课剩下的时间里告诉你们会发生什么｡
因此默认情况下，
不会转发标头｡
但这会给您带来最佳的缓存性能，
因为其中没有任何标头｡
如果要将特定标头列入白名单，
这可能意味着有必要，因为您希望将语言作为缓存键，然后指定要包含在缓存键中的标头，例如语言标头｡
然后这个标题，语言也会被转发到你的源，
这样源就可以实际响应请求，
给你正确语言的博客｡
这是一个非常类似的查询字符串机制｡
所以查询字符串就是URL中问号之后的内容｡
例如，边框等于红色，
大小等于大｡
在这里，我们需要一个猫的形象｡
但很明显，它会被原产地定制一点｡
同样，如果你没有，
那么没有查询字符串会被用于缓存键，它们不会被转发到你的源｡
白名单，您可以指定要包括哪些查询字符串｡
包含所有--除了指定不需要的查询字符串，
其余的都通过，所有的都包含缓存键中的所有查询字符串，
所有的查询字符串都将被转发｡
但当然，如果您有很多，
这会给您带来最差的缓存性能｡
我们已经看到，
当我们定义缓存策略时，我们可以将查询字符串､ cookie和头作为白名单｡
例如，选择（模糊）想要的，
他们将被转发到原点｡
但是如果你想在原始请求中包含一些东西呢？
但您不希望将它们包含在缓存关键字中｡
在这种情况下，
您可以定义所谓的原始请求策略｡
所以这个想法是，
你可以包含额外的HTTP头或cookie或查询字符串，
但它们将被转发到源，但它们不会在缓存键中使用｡
因此，作为源请求策略的一部分，
您还可以向源添加自定义HTTP头或CloudFront
HTTP头，即使它们不存在于查看器请求中｡
例如，如果您想传递一个API密钥或一个机密标头｡
因此，您可以创建自己的策略，
也可以使用预定义的托管策略｡
因此，在这一点上，
您可能会感到困惑，缓存键和原始请求策略之间的真正区别是什么？
好吧，让我尽我所能总结一下｡
因此，请求将带有一些查询字符串､
一些cookie和一些头，然后我们将根据缓存策略进行缓存｡
例如，我们希望在这里缓存主机名､
资源和一个名为authorization的头｡
但是，你的本源可能需要比这三样东西更多的东西来真正起作用，
并真正恰当地服务于请求｡
因此，您可能希望将用户代理､
会话ID和ref查询字符串作为请求的一部分添加到源｡
因此，在本例中，
发送到源的请求将得到增强，
但缓存将不会根据我们转发到源请求策略的内容发生｡
它只会基于缓存策略｡
所以我希望你们能看到这两者之间的协同作用，
这应该足以回答考试中的问题｡
好吧，就这样｡
我希望你们喜欢，
我们下节课再见｡
  - [ ] 157 [DVA-C02] CloudFront - Cache Invalidations [02:40]
    * 
讲师：现在，我们来讨论CloudFront中的缓存失效｡
当然，CloudFront有一个后端来源｡
如果您碰巧更新了后端来源，CloudFront边缘位置将不知道这一点，
并且只有在缓存的TTL过期后才能从您的后端来源获得刷新的内容，
即您想要的更新｡
但这对您来说可能是一种不受欢迎的行为，
因为您希望尽快提供新内容｡
因此，您可以强制执行整个或部分缓存刷新｡
因此，你消除了所有的TTL发生，目前在您的缓存.
对此，您也要执行所谓的CloudFront失效｡
因此，您需要传入一些文件路径｡
因此，您可以使所有带星号的文件无效，
也可以使特殊路径无效，
例如/images/*｡
好吧，那是怎么回事？
假设我们有一个CloudFront分布，
有两个边缘位置｡
每个边位置都有自己的缓存，
其中包含索引｡ html和图像直接从你的源，
这是一个S3桶｡
例如，这些文件的TTL确实设置为一天｡
因此，这意味着在一天之内，
边缘位置将为缓存重新获取这些文件｡
现在，您作为用户和管理员，
将更新S3存储桶中的文件｡
您将添加或更改一些图像｡
同时，更改索引｡ html文件｡
并且您希望这些更新尽快反映给CloudFront中的用户｡
因此，你能做的就是让两条路径无效｡
首先是/索引｡ html以使特定文件无效｡
然后，您将使/images/* 无效，
以从缓存中移除边缘位置的所有图像｡
然后，CloudFront将通知边缘位置使缓存中的这些文件无效，
然后将它们从缓存中删除｡
现在，下一次用户要请求，例如，
索引｡ CloudFront将把请求转发到一个特定的边缘位置，
该位置将意识到该文件已不在其缓存中｡
因此，边位置将对原点发出请求，
并获得更新的索引｡ html.
因此，您已经看到了缓存失效的价值｡
就这样了｡
我希望你们喜欢，我们下节课再见｡ 
  - [ ] 158 [DVA-C02] CloudFront - Cache Behaviors [02:52]
    * 
教师：现在我们来讨论缓存行为｡
其思想是，您可能希望为不同的URL路径模式使用不同的来源和缓存｡
例如，您希望基于源Web服务器为所有JPEG图像设置一个特定的缓存行为｡
或者，您可能希望根据内容类型或路径模式对不同的源或源组进行布线｡
例如，你说，嘿，对于/images/*，
只需转到S3，对于/api/*，转到我的原点，
对于/*，然后转到我的默认原点｡
它也称为默认缓存行为｡
在这个CloudFront示例中，
我们有两个缓存行为｡
第一个是/api/*，
它将我们发送到应用程序负载平衡器源｡
然后是/*，它是默认的缓存行为，
始终是/*｡
例如，您可以重定向到S3存储桶作为源｡
因此，基于他们将从CloudFront获得的资源，
用户可以被重定向到第一缓存行为或第二缓存行为｡
现在，当您添加其他缓存行为时，
默认缓存行为（始终为/*）也始终是最后处理的｡
因此，我们将查看是否存在更具体的匹配，
如果没有，则返回到默认缓存行为｡
例如，这方面的一个用例是如何将访问控制在S3存储桶中，
因为我们希望确保用户通过登录页面正确登录｡
因此，我们的做法是为/login定义一个缓存行为，
这样点击/login页面的用户将被重定向到我们的EC2实例｡
EC2实例的作用是生成CloudFront签名的Cookie｡
因此，这些签名的Cookie被发送回用户，
然后用户将使用签名的Cookie访问我们的默认缓存行为，即任何其他URL，
然后/login，然后访问我们的S3存储桶文件｡
如果用户尝试访问默认缓存行为而没有先登录，
我们可以做的是，我们可以设置缓存行为，
只有在签名的Cookie存在时才接受请求｡
因此，我们可以重定向到/login页面，
然后就可以开始了｡
这是一个非常好的用例｡
使用不同缓存行为的另一个方法是最大化缓存命中｡
例如，静态请求可能进入Amazon S3｡
在这里，我们没有任何带有头或会话的缓存策略｡
我们仅根据命中的资源来最大化缓存命中｡
对于动态缓存，例如，对于使用负载平衡器和EC2的REST
HTTP服务器，您可能希望根据正确的标头和cookie进行缓存，这些标头和cookie基于您之前定义的缓存策略｡
希望这是有道理的｡
我希望你们喜欢，我们下节课再见｡
  - [ ] 159 [DVA-C02] CloudFront - Caching & Caching Invalidations [04:37] Hands On
    * 
  - [ ] 160 CloudFront - ALB as an Origin [01:35]
    * 
教师：如您所知，CloudFront可以访问任何自定义HTTP后端｡
因此，这还包括EC2实例或应用负载平衡器｡
假设我们在EC2实例上开发了一个HTTP后端，
因此我们希望用户通过CloudFront访问它｡
我们怎么办？
它们将访问CloudFront的边缘位置，
这些边缘位置将向我们的EC2实例发出请求｡
因此，EC2实例必须是公共的，否则边缘位置将无法访问我们的EC2实例，
因为CloudFront中没有私有VPC连接｡
因此，我们还必须有一个安全组，
允许列出CloudFront边缘位置的所有公共IP，
以确保安全性兼容并有效｡
您可以在此URL中找到这些CloudFront
IP的列表｡
这就是我们的第一个模式｡
第二种模式是使用应用程序负载平衡器｡
同样，它必须是公共的，
而后端EC2实例可以是私有的，
因为在应用负载平衡器和EC2实例之间存在私有VPC连接｡
我们只需要确保EC2实例安全组允许负载平衡器的安全组｡
因此，用户将访问边缘位置，然后必须在ALB的安全组中允许边缘位置的公共IP，
以确保可以建立连接｡
好了，这节课就讲到这里.
我希望你们喜欢，我们下节课再见｡ 
  - [ ] 161 CloudFront - Geo Restriction [00:58]
    * 
讲师：这是一个关于CloudFront的地理限制的简短讲座｡
因此，您可以根据访问您的发行版的国家/地区来限制可以访问您的发行版的用户｡
因此，您可以设置允许列表来定义已批准国家a地区的列表，
也可以设置阻止列表来设置已禁止国家a地区的列表｡
现在，通过使用第三方地理IP数据库将用户的IP与其所属的国家/地区进行匹配来确定国家/地区｡
因此，使用地理限制的用例是通过版权法来控制对内容的访问｡
因此，如果我们查看CloudFront中的地理限制，
您可以编辑它们，并可以设置允许列表或阻止列表，
然后例如说，只有来自美国和印度的人才允许在我的分发中使用，
否则就不允许，然后保存更改｡
这节课就讲到这里｡
我希望你们喜欢，我们下节课再见｡ 
  - [ ] 162 CloudFront Signed URL / Cookies [03:39]
    * 
解说员：假设您有一个CloudFront发行版，
您希望将其私有化，并让全世界的用户都可以访问付费共享内容｡
但是您希望能够看到和知道谁可以访问您的CloudFront分发上的内容｡
为此，您可以使用CloudFront签名的URL或签名的Cookie，
而不必在本幻灯片的最后说明SAML和Cookie的区别｡
因此，首先，当我们创建URL和Cookie时，
您需要附加一个策略，
并需要告知URL或Cookie何时过期｡
哪些IP范围可以访问此数据？
因此，如果您知道客户端的目标IP，
那么您绝对应该使用它｡
和受信任的签名者，
因此哪些地址帐户可以为您的用户创建签名的URL｡
然后您可以问我，
“这个URL的有效期应该是多长？ 如果你要分享一个内容，
例如电影或音乐，你可以把它做得很短，
几分钟｡
但如果内容是用户的私有内容，
他们将在很长一段时间内访问，您可以使该URL或签名的Cookie持续多年｡
那么，URL和cookie之间有什么不同呢？
签名的URL提供对单个文件的访问｡
因此，每个文件都有一个URL｡
因此，如果您有100个文件要显示，您将获得100个URL｡
如果你有一个签名的cookie，那么你可以访问多个文件，
cookie可以被重复使用｡
因此，这次您有一个签名的cookie用于许多文件｡
因此，根据上下文选择您需要的任何内容｡
现在，签名的URL如何作为图工作？
因此，我们有我们的CloudFront分布，
并有一堆的位置｡
例如，我们之前看到，我们可以通过OAC源访问控制访问Amazon
S3存储桶，以实现最高的安全性｡
因此，这意味着除了CloudFront之外，其他任何设备都无法访问S3桶中的对象｡
但我们仍然希望能够让人们通过CloudFront访问他们的对象｡
我们有客户端，客户端将对应用程序进行授权和身份验证，
我们必须对该应用程序进行编码｡
我们的应用程序将使用AWS SDK直接从CloudFront生成签名的URL｡
它会将签名的URL返回给客户端，
然后客户端将能够使用该签名的URL直接从CloudFront获取数据､
文件､ 对象或任何您需要的东西｡
这对签名的URL有效，但显然也对签名的cookie有效｡
但您可能会问自己，我应该使用CloudFront签名的URL还是S3预签名的URL？
而且它们有不同的目的｡
所以CloudFront签名的URL是允许访问的一个路径，
不管来源｡
因此，签名URL不仅适用于作为源的S3，
还适用于HTTP，以及任何您想要的后端｡
这是一个帐户范围的密钥对，因此只有root用户可以管理它｡
您可以按IP､ 路径､ 日期和过期日期进行筛选｡
您还可以利用CloudFront的所有缓存功能｡
因此，如果您看一下图表，
我们会让客户端使用已签名的URL访问您的CloudFront分发，
然后CloudFront分发与您的源进行通信｡
在本例中，我放置了一个EC2实例｡
好吧，我们有个主意｡
现在对于S3预签名URL，它以预签名URL的人的身份发出请求｡
如果我用我自己的IAM原则签署了这个URL，并且我用我的IAM密钥签署了这个URL，
那么拥有这个URL的人就拥有和我一样的权利｡
它的寿命有限｡
因此，现在客户端可以使用预先签名的URL直接访问您的S3桶｡
所以，如果你想让人们访问你的CloudFront发行版，
它就在S3的前面｡
您必须使用签名的URL，因为您无法正常访问S3存储桶，
因为存在一个存储桶策略，将其限制为OAI｡
但是如果您的用户直接使用S3，并且您希望在不使用CloudFront的情况下直接分发一千个S3，
那么预签名URL将是一个很好的用例｡
好了，这是这次理论课的内容｡
我们下节课再见｡ 
  - [ ] 163 CloudFront Signed URL - Key Groups [04:44] Hands On
    * 
  - [ ] 164 CloudFront Advanced Concepts [07:07]
    * 
解说员：让我们来了解一下考试中可能出现的CloudFront的一些高级选项｡
那么，我们来谈谈定价和价格分类｡
我们知道，CloudFront的边缘位置遍布全球，但由于它们遍布全球，
因此每个边缘位置的数据输出成本会有所不同｡
这是一张表｡
因此，
正如您所看到的，基于边缘位置所在的大陆或地理区域，您将有不同的定价｡
所以如果你看这张表，（喃喃自语）数字｡
但如果你看看墨西哥､ 美国和加拿大，第一个10
TB的成本是0美元｡ 08｡
但如果你在印度接受同样的教育，费用将是0美元的两倍｡
传输的数据每千兆字节17个，依此类推｡
而且从CloudFront传输出来的数据越多，成本就越低｡
因此，如果你从CloudFront传输超过5 PB的数据，
你只需要支付0美元｡ 02离开美国｡
因此，从左到右，成本较高，
这就导致了价格分类｡
因此，
您可以做出选择，减少全球用于汽车CloudFront分发的边缘位置的数量，从而降低成本｡
有三种价格等级可供选择｡
有价格类所有这是给你所有地区，显然是最好的性能｡
但这会让你多花一点钱，
因为正如你所看到的，例如，在印度的边缘位置比在美国接受教育的成本要高｡
您可以选择价格等级200，它提供了最多的区域，但排除了最昂贵的区域，
而选择印刷机等级100，只获得最便宜的区域｡
下表总结了这一点｡
现在这张桌子看起来并不有趣｡
所以我做了一个小图表，这是一个世界，
我们在世界各地有很多边缘位置｡
现在，
价格级别100将为我们给予美洲､ 北美和欧洲｡
然后，价格类200将添加这些区域中的一些，
并且价格类all将使整个世界可用于边缘位置｡
现在我们来讨论一下云锋中的多个起源，然后是起源群｡
例如，
您可能希望根据内容类型或传递给CloudFront的路径，重定向和路由到不同类型的源｡
例如，
您有一个图像路径､ 一个API路径和一个其他所有内容的路径｡
在这种情况下，
您可以在CloudFront中设置不同的缓存行为，并确定路径｡
例如，如果您有这个/API/*
路径，
您可以说，您需要从作为应用程序负载平衡器的源获得响应｡
但是，如果请求了其他内容，则可能其他内容都是稳定的内容，
那么您应该从S3桶中获取该内容｡
因此，正如我们所看到的，我们已经根据Amazon
CloudFront中的路径定义了多个源｡
现在，您还可以设置原始组，
这是一个不同的用例｡
这是为了提高高可用性，并在一个源发生故障时执行故障切换｡
因此，一个原点组由一个主要原点和一个次要原点组成｡
如果主源发生故障，CloudFront将尝试故障切换到第二个源｡
我们举个例子，假设我们有CloudFront，
并且有一个由两个EC2实例组成的源组｡
第一个将是我们的主要起源，第二个将是我们的次要起源｡
因此，Amazon
CloudFront将向第一个EC2实例发送请求｡
如果EC2实例返回错误，
则Amazon平台将在源B上重试相同的请求，希望此请求将以OK状态代码响应｡
因此，发生了故障切换｡
你也可以用这个与亚马逊是免费的｡
因此，在本例中，如果我们将S3和CloudFront与源组一起使用，
我们就可以实现区域级的高可用性和灾难恢复｡
让我们来看看｡
我们有一个由两个S3桶组成的源组｡
第一个是主要的起源，第二个是次要的起源｡
如果这些S3存储桶位于不同的区域，则我们可以在这些存储桶之间设置复制｡
所以原点A的所有内容都会被复制到原点B｡
现在，如果Amazon CloudFront发送一个请求，
而我们从第一个S3存储桶收到一个错误，因为可能存在区域级别的中断，
那么CloudFront将尝试在另一个区域中的另一个S3存储桶上发送相同的请求，
由于复制的原因，该区域的所有数据都与第一个存储桶相同｡
因此，这一个应该有希望回复一个ok状态｡
因此，它为您提供了一个出色的体系结构，可实现Amazon
CloudFront和S3存储桶的区域级灾难恢复｡
最后，我们来谈谈字段级加密｡
因此，这是为了通过应用程序堆栈保护敏感信息｡
除了使用HTTPS在飞行中使用加密之外，这还增加了额外的安全级别｡
因此，其思想是，无论何时用户发送敏感信息，
边缘位置都将对其进行加密，
并且只有在有人能够访问私钥的情况下，才能对这些信息进行解密｡
因此，这将使用非对称加密｡
那么它是如何工作的呢？
在向Amazon CloudFront发出的POST请求中，
它们将是一组我们希望加密的字段（最多10个字段），
例如，信用卡｡
并且它们将指定用于加密它们的公钥｡
让我们看一个例子｡
我们有一个客户端通过HTTPS连接到边缘位置，该位置将再次使用HTTP将其转发到CloudFront服务｡
然后，它将通过应用程序负载平衡器使用HTTPS一路到达源，
应用程序负载平衡器将使用HTTPS将所有数据转发到您的web服务器｡
因此，航班中的所有内容都是加密的，但我们希望指定字段级加密｡
例如，我们的用户向我们发送了一些信用卡信息，这是橙子的信息｡
我们指定要对信用卡信息进行字段级加密｡
并且因此边缘位置将使用公钥来加密该字段｡
因此，现在从边缘位置传递到Amazon CloudFront再传递到源位置的数据将使用公钥对信用卡信息进行加密｡
因此，信息将一直传递到web服务器｡
然后，
web服务器将能够访问私钥，我们将能够使用私钥解密该加密字段，从而解密并获得信用卡号｡
正如我们在沿着堆栈中所看到的，CloudFront位置和应用程序负载平衡器都没有机会减少该字段｡
只有web服务器需要您具有一些自定义应用程序逻辑来解密该字段｡
这节课就讲到这里｡
希望你喜欢｡
我们下节课再见｡ 
  - [ ] 165 [DVA-C02] CloudFront - Real Time Logs [01:29]
    * 
讲师：这是一个关于CloudFront中实时日志的简短讲座｡
因此，您可以将CloudFront接收到的所有请求实时发送到Kinesis数据流｡
例如，这样做的目的是基于内容交付性能来监视､
分析和采取措施｡
我们先来概述一下，用户将向CloudFront发出大量请求，
如果启用实时日志，所有这些请求都将记录到Kinesis数据流中｡
然后，例如，您可以使用Lambda函数来处理来自Kinesis数据流的这些记录｡
如果您需要进行近乎实时的处理，您将执行完全相同的第一部分，
因为CloudFront只能发送到Kinesis
Data Stream，但之后您将使用Kinesis Data Firehose批量处理这些记录，并可能将它们发送到Amazon
S3或Open Search，或您想到的任何目的地｡
因此，这也允许您选择采样率，即您希望在Kinesis数据流中接收的请求的百分比｡
因为如果您有一个非常高流量类型的API或端点，
您可能不希望在那里有所有的请求，
只是一个样本｡
此外，您还可以指定您希望在Kinesis数据流中访问哪些字段和哪些缓存行为或路径模式｡
例如，你说，“嘿，我只想有（模糊的）斜线图像类型的缓存行为，
因为我只想看到对这个路径的请求｡
好了，这堂课就到这里｡
我希望你们喜欢，我们下节课再见｡ 
  - [ ]  CloudFront [9 问题] Quiz
    * 
 ## Section 16 - ECS, ECR & Fargate - Docker in AWS [16 个讲座 • 1 小时 19 分钟]
  - [ ] 166 Docker Introduction [05:10]
    * 
大家好，欢迎来到集装箱部分，我们将讨论Docker､
ECS和EKS｡
那么Docker是什么？
Docker是一个用于部署应用程序的软件开发平台｡
它的理念是一种容器技术｡
因此，应用程序将被打包到容器中，
这些容器是标准化的｡
因此它们可以在任何操作系统上运行｡
这意味着，
您的应用程序一旦被容器化，无论在何处运行，都将以相同的方式运行｡
它可能是任何机器｡
您没有任何兼容性问题｡
这种行为是可预测的，这意味着你有更少的工作要做｡
它更易于维护和部署，并且可以与任何类型的语言､
任何操作系统和任何技术一起工作｡
因此Docker的用例是一个微服务架构｡
所以这是一个很好的关键词｡
将应用程序从内部部署迁移到云｡
任何时候你想经营集装箱，真的｡
那么Docker是如何在操作系统上工作的呢？
我们有一个服务器，在我们的例子中，它可能是EC2实例，
但也可以是任何类型的服务器，您将运行Docker代理｡
然后，您可以从那里启动Docker容器｡
因此，您的第一个Docker容器可能包含Java应用程序｡
你的第二个Docker容器可能包含一个节点JS应用程序和Docker容器，它们可以运行多次｡
因此，您可以拥有同一Java应用程序的多个Docker容器，或者同一节点JS应用程序的多个Docker容器｡
您也可以在Docker中运行数据库，例如My
SQL等｡
所以Docker是非常多才多艺的｡
从服务器的角度来看，所有这些都是Docker容器｡
那么，您将Docker图像存储在哪里呢？
你把它们存储在一个叫做Docker Repository的东西里｡
好吧，我们有很多选择｡
第一个是Docker Hub，
它是一个公共存储库，您可以找到许多技术或操作系统（如Ubuntu､ MySQL等）的基础映像｡
很受欢迎的｡
此外，对于更多的私有集成，
您可以使用Amazon ECR､ Amazon
Elastic
Container Registry，
您可以在其中运行您的私有映像，但ECR上还有一个公共存储库选项，称为Amazon ECR公共库｡
现在，Docker与虚拟机有何不同？
Docker是一种虚拟化技术，但不完全是，
如果我这么说，纯粹主义者会试图攻击我，
所以资源与主机共享｡
这意味着您可以在一台服务器上共享多个容器｡
因此，如果您看一下虚拟机的体系结构，您会看到基础架构､
主机操作系统､ 虚拟机管理程序､
应用程序和来宾操作系统｡
这就是EC2的工作原理，例如，当您得到一台EC2机器时，
它实际上是一台在虚拟机管理程序上运行的虚拟机｡
因此，
Amazon可以为许多不同类型的客户提供许多EC2实例，所有这些EC2实例和所有这些虚拟机都将是独立的｡
它们不会共享资源，而且会相互隔离，但对于Docker容器，
您仍然拥有基础架构和主机操作系统（这次可能是EC2实例），然后拥有Docker守护程序，
在此基础上，
您可以拥有许多容器，这些容器可以是运行在Docker守护程序之上的轻量级容器｡
这使得这些容器能够真正地共处在一起｡
他们实际上可以共享网络，共享一些数据等等｡
因此，
它不如虚拟机安全，但它允许您在单个服务器上运行更多容器｡
这就是为什么我们非常喜欢Docker容器｡
那么，您如何开始使用Docker？
首先，
您必须编写一个Docker文件，该文件定义Docker容器的外观｡
因此，
我们有一个基本Docker映像，我们添加一些文件，然后我们将构建它｡
而这将成为一个码头工人的形象｡
您可以将Docker映像存储在Docker存储库中，这称为“推送”，您可以将其推送到Docker集线器（一个公共存储库）或Amazon的ECR（Amazon版本的Docker存储库）｡
然后你可以从这些存储库中取回这些图像，然后你可以运行它们｡
当你运行一个Docker映像时，它就变成了一个Docker容器，
它运行你从Docker构建中构建的代码｡
这就是Docker的整个过程｡
那么，如何在AWS上进行Docker容器管理呢？
第一个叫做亚马逊ECS｡
这是亚马逊弹性容器服务｡
这是亚马逊自己的Docker管理平台｡
我们将深入了解一下｡
然后我们有Amazon EKS，
它是Amazon Elastic Kubernetes
Service，它是Amazon的Kubernetes托管版本，
是一个开源项目｡
我们很快就看一下｡
我们有AWS Fargate，这是亚马逊自己的无服务器容器平台｡
Fargate同时与ECS和EKS合作，我们将在本节中深入探讨Fargate｡
然后，我们使用Amazon ECR来存储容器图像，
正如我之前所展示的｡
我们大致了解了如何使用Docker，
什么是Docker，以及如何在AWS中使用Docker｡
现在，让我们深入了解一下Amazon ECS和其他内容｡ 
  - [ ] 167 Amazon ECS [06:43]
    * 
好吧，我会的
现在我们来谈谈Amazon X，我们将对它的各个方面进行概述｡
我首先要谈的是易于启动的类型｡
因此，X代表弹性容器服务，当您在AWS上启动Docker容器时，
您将在x集群上启动所谓的x任务｡
而一个x集群是由容易发射的东西组成的，嗯，这些东西都是容易发射的实例｡
在这种情况下，如果您使用易于启动类型的X集群，则必须自行配置和维护基础架构｡
因此，这意味着Amazon x x集群将由多个easy two实例组成｡
这些实例有点特殊，因为它们都必须运行X代理，然后该代理将每个EC2实例注册到Amazon
X服务和指定的x集群中｡
现在，一旦您准备好了，那么当您启动x个测试时，它将启动或停止容器｡
这意味着，每当你有一个新的Docker容器将被放置在相应的每个等｡
实例，正如您在这里看到的，您可以启动或停止X任务，它将被自动替换｡
因此，这是我们提前配置的两个实例，其中一个是易于启动的类型，另一个是将Docker容器放置在Amazon上｡
现在还有第二种启动类型，称为目标启动类型，您再次在AWS上启动Docker容器，
但这次您不配置基础设施｡
因此没有易于管理的实例｡
这一切都是无服务器的，因为我们不管理服务器，但当然后面还有服务器｡
因此，在目标类型中，如果我们有一个X集群，我们只需创建任务定义来定义我们的任务，然后它将根据我们需要的CPU和RAM数量为我们运行这些任务｡
因此，无论何时，只要我们想要运行一个新的Docker容器，就这么简单，它将在我们不知道它在哪里运行的情况下运行，
也没有一个简单的实例在我们的帐户后端创建，它才能工作｡
所以这有点神奇｡
然后要扩展，嗯，你只需要简单地增加任务的数量｡
您不需要管理更多的EC2实例，考试会告诉您使用“忘记”，因为目标是无服务器的，
而且它比易于启动的类型更容易管理｡
好吧，我会的
所以我们看到了两种大型的救护车｡
现在，让我们来讨论一下这些任务的角色｡
因此，让我们举一个易于启动类型的例子，其中我们有一个在汽车上运行X代理的实例｡
因此，在本例中，我们可以创建一个易于实例化的配置文件，当然，
该配置文件仅在您使用易于启动的类型且仅由X代理使用时才有效，然后X代理将使用E两个实例配置文件对X服务进行API调用以进行注册｡
该实例将对云监视日志进行API调用，以发送容器日志，并将使用对ACR的API调用从ACR中提取Docker映像，
还将引用Secret Manager或SM参数存储中的敏感数据｡
然后我们的X个任务将得到X个任务角色｡
所以这是有效的，既容易启动，键入和忘记｡
这里我有两个任务，我们可以为每个任务创建一个特定的角色｡
所以我的第一个任务会有一个容易的任务，而第一个任务a会有一个角色，第二个任务B会有任务B的角色｡
为什么我们有不同的角色？
因为每个角色都允许您链接到不同的X服务｡
因此，例如，EC两个任务a角色允许您运行任务a，一些API调用针对Amazon
S3，而任务B角色允许您再次运行｡
API调用Dynamo DB，并在X服务的任务定义中定义任务角色｡
因此，请记住易于实例､ 配置文件角色和易于任务角色之间的区别｡
下一个负载平衡器集成｡
在本例中，我处于易于启动的类型，但当然也可以是运行多个任务的类型｡
所有这些都在一个集群中，我们希望将这些任务公开为HTTP或https端点｡
因此，我们可以在它的前面运行一个应用平衡器，然后用户将进入ALB，
并在后端直接进入任务｡
因此，在这种情况下，ALB是受支持的，并且将支持大多数使用情形，这是一个不错的选择｡
仅当您具有非常高的吞吐量或高性能使用情形时，建议使用网络负载平衡器;或者，
正如您在本课程后面部分所了解到的，如果您将网络负载平衡器与专用链路一起使用，或者如果您希望使用旧一代弹性平衡器，
则可以使用网络负载平衡器｡
但我们绝对不推荐这样做，因为您无法获得任何高级功能，也无法将弹性负载平衡器链接到目标，
而如果您使用应用程序平衡器，则它当然可以与目标一起工作｡
那么，Amazon上的数据持久性如何呢？
是的，我知道
为此，您需要数据卷，数据卷有不同的种类，但其中一种值得注意，那就是EFS｡
假设你有一个X星系团｡
在本例中，我表示了SC two实例以及我的X集群的目标启动类型｡
我们希望将一个文件系统挂载到X任务上以共享一些数据｡
在这种情况下，我们使用Amazon FS文件系统，因为它是一个网络文件系统，
将与EC2和Target启动类型兼容，并且它允许我们将文件系统直接挂载到X测试上｡
然后，在任何链接到该Amazon FS文件系统的系统中运行的测试将共享相同的数据，因此，
如果他们愿意，可以通过文件系统相互通信｡
因此，最终的组合是以无服务器的方式使用忘记启动X任务，并使用Amazon FS实现文件系统持久性，
因为FS也是无服务器的｡
我们不管理任何服务器｡
它是按需购买，只是提前调配，您可以随时使用｡
因此，使用FS和X的用例是将持久性多个作为容器的共享存储｡
而且你应该注意的是，亚马逊是三不能作为文件系统挂载在你的x任务上｡
好吧，就这样｡
我希望你们喜欢，下次课我们再见面练习｡ 
  - [ ] 168 IMPORTANT: ECS UI CHANGES [00:10]
    * 
  - [ ] 169 Creating ECS Cluster [04:45] Hands On
    * 
  - [ ] 170 Creating ECS Service [10:06] Hands On
    * 
  - [ ] 171 Amazon ECS - Auto Scaling [03:21]
    * 
讲师：现在我们来谈谈ECS服务自动缩放｡
因此，
正如我们所看到的，我们可以手动增加服务中ECS任务的数量｡
但我们也可以自动增加或减少任务的数量｡
为此，我们可以利用名为AWS应用程序自动缩放的服务｡
我们有三个指标，我们可以衡量使用该服务｡
我们可以根据ECS服务的CPU利用率进行缩放｡
我们可以根据内存利用率（即ECS服务的RAM）进行缩放｡
或者，每个目标的ALB请求计数，
这是来自ALB的度量｡
所以你只需要记住这些指标｡
然后，您可以设置不同类型的自动缩放｡
您可以设定“目的追踪”，以追踪上述三个测量结果的特定目的｡
或步进缩放｡
或者，如果您希望根据可预测的变化提前扩展ECS服务，
则可以选择计划扩展｡
请记住，如果您处于EC2启动类型，
则在任务级别扩展您的服务（ECS服务）并不等于扩展EC2实例集群｡
因此，
这就是为什么当你没有必要的EC2自动伸缩时，当你在后端没有EC2实例时，使用Fargate可以使服务自动伸缩更容易设置，因为一切都是无服务器的｡
所以我才喜欢法盖特｡
考试促使你经常使用Fargate｡
那么，
对于EC2启动类型，如果我们正在使用它，我们如何在后端实际扩展EC2实例呢？
所以我们有多种方法｡
我们可以使用自动缩放组缩放｡
因此，我们根据CPU利用率等因素来扩展ASG｡
然后，我们可以随着时间的推移添加EC2实例，
如果CPU激增｡
或者，我们可以使用称为ECS Cluster
Capacity Provider的更新､ 更高级的功能，
我们在之前的实践中已经看到过该功能｡
对于这一点，容量提供商非常聪明｡
一旦您缺乏启动新任务的能力，它就会自动扩展您的ASG｡
因此，容量提供商与自动扩展组配对｡
如果缺少RAM或CPU，则会创建EC2实例｡
所以第二个选择是更聪明的做事方式｡
因此，如果您必须在自动扩展组扩展和ECS群集容量提供程序之间进行选择，请将ECS群集容量提供程序用于您的EC2发布类型｡
那么，让我们来看看服务｡
因此，我们有一个服务A，它有两个任务｡
还有CPU使用率｡
它将由AWS应用程序自动缩放功能自动缩放｡
但是，假设我们拥有更多用户，因此您的CPU使用率确实上升，
那么再次在ECS服务级别监控CPU使用率的CloudWatch指标将触发CloudWatch警报，这将在ECS服务的自动扩展中触发扩展活动｡
您的ECS服务所需的容量将增加，并将创建一个新任务｡
此外，
如果此服务在EC2启动类型上运行，则ECS容量提供程序可以帮助您扩展由EC2实例支持的ECS集群｡
  - [ ] 172 Amazon ECS - Rolling Updates [02:33]
    * 
教师：现在，我们来讨论如何更新ECS服务｡
为此，我们将滚动更新｡
因此，
当您将ECS服务从v1更新到v2时，您可以控制一次启动和停止的任务数量以及顺序｡
因此，
当您更新ECS时，当您选择新的任务定义编号并希望更新ECS服务时，您将有两个设置：最小正常百分比和最大正常百分比｡
所以默认情况下它们是1和200，但让我们看看它们是什么意思｡
例如，您的ECS服务正在运行九个任务，这表示实际运行容量为100%｡
然后如果你设置一个小于100的最小健康百分比，
这会说，“嘿，你可以终止右手边的所有任务，
只要我们有足够的任务，超过最小健康百分比｡
“在最大百分比中，显示了您可以创建多少个版本2的新任务，
以基本上滚动更新您的服务｡
这就是这两个设置如何影响您的更新｡
因此，您将继续创建新任务，然后终止所有任务，
依此类推｡
All以确保所有任务都将被终止，然后更新到较新的版本｡
让我们讨论两种情况｡
例如，
最小值为50%，最大值为100%，我们从四个任务开始｡
在本例中，我们将丢失四个要终止的任务，
因此我们将以50%的容量运行｡
然后会创建两个新任务，好吗？
现在，我们的容量已恢复到100%｡
然后，两个旧任务将被终止，
我们将恢复50%的容量｡
将创建两个新任务，我们的容量又回到了100｡
而且我们已经做了滚动更新｡
在本例中，我们一直在终止任务，因为我们将最小值设置为50%，
将最大值设置为100%｡
如果我们的最低完成率为100%，最高完成率为150%，那么我们从四个任务开始｡
我们无法确定任务，因为最小值为100%｡
因此，
我们可以创建两个新任务，这将使我们的能力达到150%｡
然后，
因为我们高于最低100%，我们可以终止两个旧任务，我们回到100%｡
然后，
我们将创建两个新任务，最后，终止两个旧任务｡
这将执行我们的ECS服务的滚动更新｡
所以你们应该知道，如果你们在考试前读了课程，
这可能只发生在一个问题上｡
好吧，就这样｡
我们下节课再见｡ 
  - [ ] 173 Amazon ECS - Solutions Architectures [02:31]
    * 
讲师：现在，
我们来讨论一下您在使用Amazon ECS时可能遇到的几个解决方案架构｡
因此，第一个是由EventBridge调用的ECS任务｡
例如，假设我们有一个Amazon ECS集群，
它由fargates和S3存储桶提供支持｡
我们的用户将把对象上传到S3存储桶中｡
例如，这些S3桶可以与Amazon
EventBridge集成，
以便将所有事件发送给它｡
Amazon EventBridge可以有一个规则来运行ECS任务｡
现在将创建ECS任务｡
他们将具有与其关联的ECS任务角色｡
从任务本身来看，它可以做的是获取对象，处理对象，
然后将结果发送到Amazon DynamoDB｡
这要归功于我们有一个与之关联的ECS任务角色｡
在这里，
我们所做的就是创建一个无服务器架构来处理图像，或者使用Docker容器处理来自S3桶的对象｡
这就是使用Amazon EventBridge､ ECS查找fargate模式，
以及与Amazon S3和Amazon
DynamoDB对话的ECS任务角色｡
另一个再次使用EventBridge的体系结构是使用EventBridge调度｡
因此，我们有一个由fargates和Amazon EventBridge支持的Amazon
ECS集群｡
我们安排一个规则每小时触发一次｡
现在这个规则将为我们在fargates运行ECS任务｡
这意味着每个人每小时都会在我们的fargate集群中创建一个新任务｡
任务可以做任何我们想做的事｡
例如，我们可以创建一个访问Amazon
S3的ECS任务角色，因此我们的任务､ Docker容器和程序可以每隔一小时对Amazon
S3中的一些文件进行一些批处理｡
同样，所有架构都是完全无服务器的｡
我们的最后一个示例是使用ECS-SQS队列｡
因此，我们可以在ECS上有一个服务，
它有两个ECS任务，消息被发送到SQS队列中，
服务本身轮询SQS队列中的消息并处理它们｡
我们可以在此服务的基础上启用ECS服务自动缩放｡
这意味着，例如，
SQS队列中的消息越多，ECS服务中的任务就越多，这要归功于自动缩放｡
好了，这就是ECS上的一些架构｡
我希望这是有意义的｡
我们下节课再见｡ 
  - [ ] 174 Amazon ECS Task Definitions - Deep Dive [09:02]
    * 
现在，让我们深入讨论Amazon X任务定义｡
因此您在JSON表单中定义它们｡
但是通过控制台，有一个UI可以帮助您创建JSON，测试定义告诉服务如何在X上运行一个或多个Docker容器，
并且测试定义中有一些关键信息，例如映像名称､ 容器和主机的端口绑定｡
如果你在EC2 上，你的容器所需的内存和CPU，环境变量，
网络信息，附加到任务定义的I am角色和登录配置，比如云监视｡
所以还有更多的信息｡
但这些都是最重要的，考试将在其中的几个方面对你进行测试｡
所以我会在这节课上深入探讨其中的一些｡
让我们举个例子｡
我们有一个易于实例化的，并且因为它在X集群中注册，所以它必须运行X代理｡
接下来，我们将通过X任务定义运行Docker容器，例如，Apache HTTP服务器，
并且我们必须将该服务器公开到Internet｡
因此，我们将在其上定义一个容器端口，这意味着在容器上，端口80是公开HTTP服务器的端口｡
但我们还有主机端口，因为我们位于EC2 上｡
如果我们在目标上，这将是不相关的，但我们在EC2 上，因此我们需要将此集装箱港口映射到主机港口，
例如，可以是T，但也可以是88｡
所以它们不一定是一样的｡
由于主机端口，Internet或外部网络通信能够访问端口88上的EC2实例，
该主机端口将定向到容器端口80，然后我们将访问HTTP服务器｡
OC，并且您应该知道您可以为每个测试定义定义多个容器｡
每个任务定义最多可以定义十个容器｡
让我们先深入了解一下集装箱码头｡
因此，如果您有负载平衡并且使用易于启动类型，那么您将获得所谓的动态主机端口映射｡
如果您只定义容器端口和任务定义，让我来解释一下｡
例如，我们正在运行一个X任务，所有这些任务都将容器端口设置为80，
但将主机端口设置为0，即不设置｡
接下来的情况是，此图中仅显示主机端口｡
但主机端口将是随机的｡
它将是动态的｡
因此，EC2实例中的每个x任务都可以从主机（EC2实例）上的不同端口访问｡
因此，如果您要定义一个应用程序负载平衡器，那么您可能会说，
ALB很难连接到X测试，因为端口正在更改｡
但是，当ALB链接到一个ex服务时，由于动态主机端口映射特性，它知道如何找到正确的端口｡
所以alb自动地感谢X服务节点自动地连接到不同的端口到不同的实例上｡
所以这个设置可以工作，但是它不适用于经典的负载平衡器，因为它是老一代的｡
因此，这种逻辑只适用于ALB｡
因此，从安全角度来看，EC2实例安全组必须允许来自ALB安全组的任何端口，
因为我们事先不知道主机端口映射是什么｡
这就是EC2发射类型｡
但是现在，当我们有了目标发射类型时会发生什么？
好的，这次每个x任务都将获得一个唯一的私有IP｡
因为这里没有主机，所以我们只需要定义容器端口｡
如果你看一下你的集群，比如说，有四个任务，每个任务都将通过E和A的弹性网络接口获得自己的私有IP，
然后AENA将获得相同的容器端口｡
这就是你将得到的目标设置｡
因此，当您有一个ALB时，要连接到目标任务，只需连接到端口80上同一端口上的所有ALB｡
这里有X，即需要允许ALB安全组端口80的任何安全组，然后ALB安全组只需要允许两个端口80，
或者如果您从Web启用了sstl，则允许四个或三个端口｡
接下来，考试将询问您关于注册X的问题，您应该知道，“我是”角色是根据任务定义分配的｡
因此，您有一个任务定义，然后分配一个X任务角色｡
例如，这将允许您的测试定义中的X任务访问AmazonS3服务｡
因此，当您从这个任务定义创建X服务时，每个X任务将自动承担并继承这个简单任务角色｡
但是您应该知道，角色是在任务定义级别定义的，而不是在服务级别｡
因此，服务中的所有任务都可以访问Amazon｡
如果你定义了另一个任务定义，你可以在上面添加另一个角色｡
例如，这个角色可以访问Dynamo｡
DB如果您要创建另一个服务，那么该服务将承担另一个角色，您就可以开始了｡
因此，考试将询问您在何处定义X任务的IM角色？
答案就在你的任务定义上｡
接下来，您有环境变量，因此您的测试定义可以有环境标签，并且它们可以来自多个地方｡
您可以对它们进行硬编码｡
例如，可以直接从任务定义中设置它们｡
例如，这是当你有一个固定的非机密URL｡
但是，如果您有敏感变量，如API密钥或共享配置，或者数据库密码，
那么您可以使用相同的参数存储或机密管理器来存储这些值，并从任务定义中引用它们｡
在启动X任务时，这些值将在运行时被获取和解析，并作为环境变量注入到x任务中｡
最后，还有最后一个选项，您可以直接从Amazon S3存储桶加载X环境变量，
这称为批量环境变量通过文件加载｡
接下来，我们讨论如何在这些任务之间共享数据？
正如我所说的，一个X任务可以包含一个容器，但是您也可以在同一个任务定义中定义多个容器｡
你会这么做是因为有时候你的边容器也叫边车可以帮助你记录，
跟踪等等｡
这是一种常见的模式，但有时候，例如，对于日志记录和指标等，
这些容器需要一起共享一些文件，因此我们必须将数据卷装载到两个S､ 两个容器上，
对不起，然后它们才能共享数据｡
因此，这种数据卷绑定对EC2和目标任务都有效｡
假设我们有一个X任务，并且有应用程序容器｡
它可以是一个，也可以是多个，然后是一些边车容器，例如矩阵和日志容器，
您将创建一个绑定装载，它将创建一个共享存储，您必须在任务之间定义该存储｡
例如，您可以说它是slash var和slash logs，因此您的应用程序容器将能够写入此共享存储，
并且您的指标和日志容器可以从这些共享存储读取｡
这就是垃圾箱的全部设计理念｡
因此，如果您使用SC进行测试，那么绑定挂载本身就是EC2实例存储，因此该挂载的数据与EC2实例的生命周期相关联｡
或者对于忘记任务，则使用临时存储，并且使用临时存储将数据绑定到容器生命周期｡
因此，每当你的目标测试消失时，你的存储也会消失｡
现在，您可以获得20 GB到200 GB得共享存储空间.
因此，它为不同的使用情形提供了大量空间｡
所以他们之间｡
因此，基本用例（尤其是从考试的角度来看）是在多个容器之间共享数据｡
或者当您有一个边车容器时，边车用于将指标或日志发送到其他目的地，并且需要从共享存储中读取这些指标或日志｡
好了，Amazon X的任务定义就到这里了｡
深潜｡
我希望你们喜欢，我们下节课再见｡ 
  - [ ] 175 Amazon ECS Task Definitions [03:36] Hands On
    * 
  - [ ] 176 Amazon ECS - Task Placements [05:55]
    * 
所以考试需要知道的一个新概念是ECS任务布置的概念｡
因此，
当您创建EC2类型的任务时，ECS必须根据目标EC2实例上的可用内存､ CPU和端口来确定将任务放置在何处｡
例如，这是由三个EC2实例组成的ECS集群，
一些任务以某种方式放置在每个实例上｡
如果ECS服务有一个新的容器（即它希望放置在EC2实例上的新任务），则需要确定将其放置在何处｡
这是一个大问号｡
因此，类似地，
每当服务扩展时，
我的意思是，我们删除ECS任务，ECS服务需要确定终止哪个ECS任务｡
好吧，我会的
因此，为了帮助您实现这一点，您可以定义所谓的任务放置策略和任务放置约束｡
这将指导在何处添加新容器或从何处删除容器｡
这只适用于在EC2实例上启动ECS的情况，不适用于Fargate，
因为对于Fargate, AWS会为您计算出从何处启动容器，而您不管理任何后端实例｡
好吧，我会的
因此，这仅对EC2上的ECS有效｡
好吧，我会的
现在我们来谈谈任务布置过程｡
好吧，我会的
所以首先要注意的是，任务安排策略是一种最大的努力｡
如果你想有约束，我们很快就会看到这一点｡
好吧，我会的
因此，当ECS放置任务时，
它将使用以下过程来选择放置任务的位置｡
第一个是它将识别满足任务定义中的CPU､ 内存和端口要求的实例｡
因此，首先要弄清楚它可以把任务放在哪里｡
然后它会看一下任务安排的限制，我们会在这节课上看到｡
最后，它将尝试识别出最符合任务放置策略的实例｡
然后，它将选择该实例作为任务放置位置，并将任务放置在那里｡
现在我们来谈谈这些任务布置策略是什么｡
你需要知道的第一个考试出现的是所谓的binpack｡
而binpack将根据最少的可用CPU或内存量来放置任务｡
这是为了帮助您最大限度地减少正在使用的实例数｡
因此，这将为您节省成本｡
所以如果你想定义一个binpack放置策略，这就是它的JSON｡
所以它在这里｡
它说binpack上的字段内存，所以RAM｡
这意味着，如果我们有一个EC2实例，
它将尝试用容器填充该EC2实例｡
然后，
当它无法在一个EC2实例上放置更多容器时，它将在另一个EC2实例上放置EC2容器｡
如您所见，我们在一个EC2实例上放置了尽可能多的容器，
然后再移动到另一个实例｡
这就是为什么它被称为binpack，因为它把所有的容器包装在一起｡
这是最能节省成本的策略，因为它将最大限度地减少使用中的EC2实例数量，
并尝试最大限度地提高一次一个EC2实例的利用率｡
好吗？
接下来的任务投放策略为随机｡
所以这里很简单，它随机地放置任务｡
因此，如果我们看一下JSON中的放置策略，
就会发现它非常简单｡
假设我们有两个EC2实例，并且正在添加任务，
那么它们将被随机放置｡
没有任何逻辑，只是随机的，非常非常简单｡
这不是最佳策略，但确实非常有效｡
好吧，我会的
需要注意的最后一个布局版本称为扩展｡
假设我们有三个EC2实例，它们位于三个不同的可用性区域中｡
然后，如果我们进行分摊，
则任务将基于指定值进行分摊｡
例如，该值可以是实例ID或ECS可用性区域等｡
在这个例子中，我会让它变得非常简单易懂｡
我们选择在ECS可用性区域上展开的放置策略｡
这意味着任务将平均分配到AZ｡
因此，
我的第一个任务可能是AZ-A，然后是AZ-B，然后是AZ-C｡
所以它们就像你在每个AZ上看到的那样分散开然后一切又会重新开始｡
因此，
通过将任务分散到EC2实例上，我们基本上最大化了ECS服务的高可用性｡
所以，这些任务布置策略可以混合在一起｡
因此，
我们可以在可用性区域上进行分布，然后在实例ID上进行分布，或者我们可以在可用性区域上进行分布，然后在内存上进行装箱｡
所以你可以混搭｡
但是考试应该只考基础知识｡
所以要理解装箱扩散和随机扩散的区别｡
然后，我们有ECS任务放置约束，
以限制任务的放置方式｡
因此，第一个实例称为distinctInstance，我们通过ECS服务看到每个任务都应放置在不同的容器实例上｡
因此，您永远不会在同一个实例上有两个任务｡
这是由这个JSON定义的，称为放置约束distinctInstance｡
然后还有第二个任务约束，称为memberOf，我们希望将任务放在满足表达式的实例上，该表达式可以在集群查询语言中定义，
这是非常高级的｡
我给你们举一个具体的例子，这就足够了.
例如，我们在这里做了一个位置约束，我们想说实例类型必须是t2类型｡
所以我们在这里所说的是，所有这些任务都应该只放在t2实例上｡
所以这就是你可以和memberOf一起使用的约束｡
因此，我们有distinctInstance，
它非常容易理解，还有memberOf，它使用更复杂的集群查询语言，强制您的任务仅在EC2实例上作为示例｡
好吧，我会的
这节课到此为止｡
希望你喜欢｡
我们下节课再见｡ 
  - [ ] 177 Amazon ECR [01:38]
    * 
解说员：好的，让我们来简单介绍一下Amazon
ECR｡
Amazon ECR是Elastic Container Registry的缩写，
用于存储和管理AWS上的Docker映像｡
到目前为止，我们一直在使用在线存储库，
如Docker hub，但我们也可以在Amazon
ECR上存储我们自己的图像｡
实际上，ECR有两种选择｡
我们可以只为您的帐户或您自己的帐户（带有s）私下存储图像，或者您可以使用公共存储库并发布到Amazon ECR公共图库｡
现在ECR与亚马逊ECS完全集成，这太棒了｡
而您的图像则在Amazon S3的后台存储｡
因此，您的ECR存储库可能包含不同的Docker映像，然后是ECS群集｡
例如，ECS集群上的EC2实例可能需要拉取这些映像｡
为此，我们将为EC2实例签署一个IAM角色，
此IAM角色将允许我们的实例提取Docker映像｡
因此，对ECR的所有访问都受到IAM的保护｡
这包括，
如果您在ECR上出现权限错误，请查看您的策略，然后在您的EC2实例拉取容器后，它们将在您的EC2实例上启动｡
这就是ECS和ECR如何协同工作｡
现在，Amazon
ECR非常棒，因为除了作为存储库之外，它还支持图像漏洞扫描､ 版本控制､
图像标记和图像生命周期｡
因此，总的来说，任何时候你看到存储Docker图像认为ECR，
这应该是你在考试｡
好吧，我会的
希望你喜欢｡
我们下节课再见｡
  - [ ] 178 Amazon ECR [05:43] Hands On
    * 
  - [ ] 179 [DVA-C02] AWS CoPilot - Overview [01:23]
    * 
讲师：现在我们来谈谈AWS Copilot｡
Copilot不是一项服务，
它是一个命令行界面工具，将用于构建､
发布和操作生产就绪的容器化应用程序｡
我们的想法是，我们希望消除在AppRunner､
ECS和Fargate上运行应用程序的困难，
只需使用CLI工具部署到这些环境中｡
因此，它可以帮助您专注于构建应用程序，
而不是设置基础架构，并且基础架构的所有复杂性（如ECS､ VPC､
ELB､ ECR等）都由Copilot为您完成｡
最重要的是，如果你想把它和CodePipeline集成起来，
你可以这样做，这样你就可以只使用一个命令来自动部署容器｡
您还可以使用Copilot部署到多个环境｡
您将获得应用程序的故障排除､
日志和健康状态｡
使用CLI或YAML文件以微服务方式描述应用程序的体系结构｡
然后，您将使用Copilot CLI来容器化应用程序并部署它们｡
然后，您将获得一个体系结构良好的基础架构设置，
它将具有适当的规模并可自动扩展｡
您可以获得部署管道，
并且可以获得有效的操作和故障排除｡
总之，您可以部署到Amazon
ECS或AWS Fargate或AWS App Runner｡
好了，这堂课就到这里｡
我希望你们喜欢，
我们下节课再见｡
  - [ ] 180 [DVA-C02] AWS CoPilot [12:29] Hands On
    * 
  - [ ] 181 Amazon EKS [03:58]
    * 
教师：那么，让我们来谈谈在AWS上运行容器的另一种方法，
这就是使用Amazon EKS｡
因此，Amazon EKS代表亚马逊弹性Kubernetes服务｡
因此，正如名称所示，这是一种在AWS上启动和管理Kubernetes集群的方法｡
那么，什么是Kubernetes？
这是你在屏幕右上角看到的蓝色标志｡
Kubernetes是一个开源系统，
用于自动部署､ 扩展和管理容器化的应用程序（通常是Docker）｡
因此，它是ECS的替代方案，ECS的目标与ECS类似，
都是运行容器，但API却截然不同｡
其理念是ECS绝对不是开源的｡
而Kubernetes是开源的，
被许多不同的云提供商使用，这给了你某种标准化｡
因此，EKS支持两种启动模式，同样是EC2启动模式（如果您希望部署像EC2实例这样的工作者模式），
或者Fargate模式（如果您希望在EKS集群中部署无服务器容器）｡
因此，使用EKS的用例是：您的公司已经在内部使用Kubernetes，
或者已经在另一个云中使用Kubernetes，
或者他们只是想使用Kubernetes
API，并且他们想使用AWS来管理Kubernetes集群，那么他们将使用Amazon EKS｡
因此，从考试的角度来看，Kubernetes是云不可知论者，
它可以用于任何云，如Azure､ Google
Cloud等｡
这意味着，如果您尝试在云或容器之间迁移，
使用Amazon EKS可能是一个简单得多的解决方案｡
从图表上看，这就是它的样子｡
因此，我们有一个VPC，3个AZ分为公共子网和专用子网｡
因此，您可以创建EKS工作节点，
例如EC2实例，其中每个节点都将运行EKS
Pod｡
它们与ECS任务非常相似，但从命名的角度来看，
任何时候你看到pod，它都与Amazon
Kubernetes有关，好吗？
我们有EKS Pod，它们在EKS节点上运行，因此这些节点可以由自动缩放组管理｡
现在，与ECS非常类似，如果您希望公开EKS服务和Kubernetes服务，
我们可以设置一个专用负载平衡器，或一个公共负载平衡器来与Web通信｡
因此，让我们总结一下Amazon
EKS中存在的不同节点类型｡
您可以使用管理节点组，
AWS将创建和管理节点，因此您可以使用EC2实例｡
这些节点是自动缩放组的一部分，
由EKS服务本身管理｡
您还可以支持按需和现场实例｡
您还可以根据需要选择自我管理节点，
也就是说，如果您希望进行更多自定义和控制，
也可以这样做｡
因此，在这种情况下，您需要自己创建节点，
然后将它们注册到EKS集群，然后将自己的节点作为ASG的一部分进行管理｡
您仍然可以为此使用预构建的Amazon EKS Optimized
AMI，这可以节省一些时间，
或者您也可以构建自己的AMI，这会更加复杂｡
这也支持On-Demand和Spot实例｡
最后，如果你不想看到任何节点，那么Amazon
EKS，就像我告诉你的，支持Fargate模式，
在这种模式下，不需要维护，
也不需要管理任何节点，你可以在Amazon EKS上运行容器｡
现在，您可以将数据卷附加到Amazon EKS集群｡
为此，您需要在EKS群集上指定StorageClass清单，
这将利用所谓的容器存储接口（CSI兼容驱动程序）｡
所以考试时要注意的关键词｡
您可以支持Amazon EBS，
也可以支持Amazon EFS，这是唯一一种可以与Fargate配合使用的存储类｡
您拥有适用于Lustre的Amazon
FSx和适用于NetApp ONTAP的Amazon FSx｡
这就是亚马逊EKS｡
我希望你们喜欢它，我们下节课再见｡ 
  - [ ]  Containers on AWS [15 问题] Quiz
    * 
 ## Section 17 - AWS Elastic Beanstalk [15 个讲座 • 1 小时 11 分钟]
  - [ ] 182 AWS Elastic Beanstalk - Section Introduction [00:39]
    * 
现在，
我们知道了所有的基础知识，也知道了如何通过编程方式访问AWS｡
我们开始以正确的方式部署应用程序如何？
您可能已经注意到，在过去的部分中有大量的手动工作正在进行，但在本部分中，
我们将学习弹性豆茎｡
Elastic Beanstalk将允许我们以一种安全的方式轻松地部署我们的应用程序｡
这实际上是最难的考试部分之一，
我想现在就做，因为我认为你会因为马上知道它而获得强大的力量｡
那么，让我们开始吧，学习如何以正确的方式部署应用｡
  - [ ] 183 Elastic Beanstalk Overview (High level) [05:15]
    * 
教练：好了，现在我们来谈谈弹性豆茎｡
到目前为止，在本课程中，
我们部署应用程序时使用的是相同的体系结构｡
因此，我们有一个负载平衡器，
它接收来自用户的所有请求，然后我们有一个具有多个可用性区域的自动扫描组｡
在每个AZ中，将部署一些EC2实例｡
在后端，我们可能有一些数据子网｡
因此，我们有一个RDS数据库来执行读取和写入操作，可能还会有一些读取应用程序等等｡
如果是通信层，我们需要查看缓存层的弹性缓存｡
因此，如果我们要部署的应用程序太多，而且它们遵循相同的体系结构，
那么每次重新创建它可能会很痛苦｡
因此，作为一名开发人员，管理基础设施和部署代码是非常复杂的｡
我们不希望配置所有数据库的负载平衡，
等等｡
当然，我们希望一切都能扩展｡
因此，正如我们所看到的，大多数Web应用程序将具有相同的架构，
其中包含一个负载平衡器和一个自动扫描组｡
作为一个开发人员，我所要做的就是让我的代码运行，
好吗？
我不想担心其他的事｡
同样，如果我使用不同的编程语言进行开发，并且拥有不同的应用程序和环境，
我可能希望使用单一的方法来部署应用程序｡
这就是豆茎发挥作用的地方｡
因此，Beanstalk提供了一个以开发人员为中心的视图来部署AWS上的应用程序｡
我们的想法是，从一个单一的接口，
它将重用所有的组件，我们已经见过，
如EC2，ASG, ELB, RDS｡
但它将是一个托管服务，将为您部署所有这些东西｡
因此，它将处理容量调配｡
它将处理配置､ 负载平衡器､
扩展､ 应用程序健康监视､ 实例配置等｡
作为一个开发人员，你唯一的责任就是代码本身，
好吗？
您仍然可以完全控制每个组件的配置，
但至少可以将其捆绑为Beanstalk中的一个单一接口｡
这个想法是，Beanstalk也有一个非常酷的更新应用程序的方式｡
因此，Beanstalk服务本身是免费的，
但您将为Beanstalk或ASG或ELB等利用的底层实例付费｡
因此，Beanstalk的组件由一个应用程序组成，
该应用程序是Beanstalk组件（如环境､
版本和配置）的集合｡
应用程序的版本本身就是应用程序代码的迭代｡
所以你可以有版本一，版本二，版本三，
等等｡
然后是运行特定应用程序版本的资源集合环境｡
因此，您一次只能拥有一个应用程序版本｡
在我们可以看到的环境中，我们将看到，
我们实际上可以将环境中的应用程序版本从版本1更新到版本2｡
我们有层次｡
因此，我们可以在豆茎中有两个不同的层｡
这里是Web服务器环境，
这里是工作环境｡
我们很快就能看到｡
我们还可以在Beanstalk中创建多个环境，
如开发､ 测试和生产｡
不管你想要什么样的环境｡
所以这个过程就是创建一个应用程序｡
然后，我们上传一个版本，
然后启动一个环境，最后管理一个环境生命周期｡
如果您想迭代，我们可以通过上传新版本来更新版本，
然后在我们的环境中再次部署该新版本，以更新我们的应用程序堆栈｡
因此，Beanstalk支持许多编程语言，
如Go Java SE､ Java with Tomcat､ . NET内核在Linux上的应用｡ NET核心在Windows服务器上，
节点. PHP, Python, Ruby，
Packer Builder，单个Docker容器，
多个Docker容器，预配置的Docker｡
如果您的编程语言不在这里，
您可以创建自己的自定义平台，这是高级的｡
所以这个想法是，在Beanstalk上，你应该能够部署几乎任何东西｡
最后，服务器层和工作者层是什么意思？
虽然Web层看起来是这样的，但这是传统的体系结构，
我们知道在哪里可以找到负载答案｡
然后，它将流量发送到一个自动扩展组，
该组具有多个EC2实例，
这些实例将成为您的Web服务器｡
这是豆茎的第一个架构｡
Beanstalk的第二个体系结构将围绕一个工作环境｡
所以这次没有客户端直接访问您的EC2实例｡
我们将使用SQS队列，
这是一个消息队列，消息将被发送到SQS队列中｡
EC2实例将成为工作者，因为它们将从SQS队列中提取消息以进行处理｡
在本例中，工作环境将根据SQS消息的数量进行扩展｡
因此，消息越多，EC2实例就越多｡
最酷的是，您可以通过让Web环境将一些消息推送到工作环境的SQS队列中，
将Web环境和工作环境放在一起｡
最后，您需要了解Beanstalk的两种部署模式｡
第一个是单个实例，
非常适合于开发目的｡
在本例中，您将拥有一个EC2实例，
该实例将具有Elastic IP，您还可以启动RDS数据库等｡
但这一切都是基于一个实例与弹性IP｡
这非常适合于开发目的，但如果您希望扩展真正的Elastic
Beanstalk模式，则需要使用低平衡器来实现高可用性，
这非常适合生产环境，在这种情况下，您可以使用负载平衡器在多个EC2实例之间分配负载，这些实例是为自动扩展组和多个可用性区域管理的｡
最后，您可能有一个RDS数据库，它也是多AZ的，
有一个主数据库和一个备用数据库｡
好吧，就这样｡
我希望你们喜欢，我们下节课再见｡ 
  - [ ] 184 Beanstalk First Environment [05:35]
    * 
讲师：那么让我们继续练习使用Beanstalk服务｡
在此之前，请确保您没有运行EC2实例｡
请确保您的负载平衡器已关闭（如果有）｡
请确保您没有任何可用的“自动缩放”组｡
好的，
让我们创建一个Beanstalk应用程序，应用程序名称为my-first-webapp-beanstalk｡
然后向下滚动，我们可以添加应用程序标记，
但我现在不会这样做｡
我们需要选择一个平台，为此我们将选择Node｡
js，但是正如你所看到的，你有很多不同的选项可供我们使用｡
我们选择“节点”｡ js，
对于平台分支，我将使用最新版本的Node｡ js，
所以16，如果你看到一个不同的版本，
这是很好的，不用担心，只要选择最新的版本｡
对于平台版本，请选择最新或推荐的版本｡
然后，
您将转到示例应用程序，因为我们必须将一些代码部署到Elastic Beanstalk上｡
还有一个来自Node的简单应用程序｡
js已经由AWS为我们创建了，所以这是完美的｡
我们将使用此示例应用程序，只需单击“Create Application”｡
好的，
现在正在创建我的应用程序环境，我将暂停视频，直到完成｡
所以这花了一点时间，大约五分钟，
但现在我的应用程序已经启动并运行了｡
如果我点击这个网址，我就可以访问“祝贺你”｡
这是我的节点｡ js
16简单的web应用程序运行在弹性豆茎上，这是惊人的｡
如你所见，健康状况良好，我们也很好｡
所以我能做的就是给你们看几个选择｡
我想看的是“事件”选项卡｡
这些事件向你展示了当它被创建时发生了什么｡
因此，如果我转到最底部，
创建环境开始，然后有一个用于存储一些数据的Amazon S3存储桶，这是我的应用程序存储的位置｡
如果我在这里进入S3服务，然后过滤我刚刚得到的桶名称｡
我们从这里开始筛选存储桶名称｡
正如你所看到的，是的，我可以看到这个桶是创建的｡
那就完美了｡
接下来，
我们来看一下正在创建的目标组，因为在此设置中，我们默认使用AWS的快速创建功能招募了一个负载平衡器｡
安全组､ 更多内容和一个自动扩展组，
因此我们无法猜测体系结构｡
因此，有一个自动扩展组､
一个策略和负载平衡器等｡
让我们真实的验证一下｡
因此，
如果我们分别进入两个管理控制台并刷新“Auto Scaling”（自动扩展）页面，我们会发现找不到自动扩展组｡
如果我们进入负载平衡器页面，我们将找到负载平衡器｡
如果您进入Instances页面，我们会发现由我的ASG创建的一个实例链接到我的负载平衡器｡
所以这是伟大的｡
所有这些都是由豆茎非常迅速地创建的，
只要说我们想要哪个平台，好吗？
回到Elastic
Beanstalk，我将进入Myfirstwebappbeanstalk-env，这样我们就可以很快地看到这个URL｡
所以我们有了健康，如果一切都好就好了｡
Running版本是示例应用程序，我们将在某个时候继续并上传一个新版本｡
平台为节点｡ js，我们可以开始了｡
我们可以看一下事件，就像我之前说的｡
我们很快就会花很多时间来进行配置，所以我现在不会单击它｡
Logs为您提供了应用程序的所有日志，您可以请求日志的最后100行，如果需要，
您可以单击此处的下载按钮下载这些日志｡
健康给你一个非常有趣的观点｡
现在我们有一个实例，它不是很有趣，但它为您提供了Beanstalk环境中所有实例的视图以及许多指标，
因此您可以查看例如某个实例是否非常不正常或行为不正确｡
健康为您提供一个健康仪表板，这来自CloudWatch.
警报会在您定义警报时提供警报｡
管理更新是您更新环境的方式｡
我们之前看到的事件，以及标记环境的标记｡
我们已经在这里看到了关于Beanstalk环境的所有内容，现在我们可以再上一层了｡
因此，如果您单击“Environments”（环境），
我们可以看到，在我的应用程序中，我们只有一个环境，
但我们可以继续创建多个环境｡
因此，
如果我们希望在同一个应用程序中同时拥有开发环境和生产环境，我们可以这样做｡
对于一个特定的环境，
我也可以加载安全配置，交换URL，我们将看到如何做到这一点｡
我们可以克隆此环境，
或重新启动应用程序服务器，或重建环境，或干脆将其完全终止｡
如果您向上一级转到左侧应用程序中的Beanstalk（如我们所见），我们的应用程序名称就在这里，名为my-first-webapp-beanstalk，
其中包含一个环境｡
如果我单击此应用程序名称，左手将显示应用程序版本，其中一个应用程序版本已上传到我们的Beanstalk环境，
称为示例应用程序｡
这是由AWS提供的，
但我们可以上传更多的应用程序版本，并将其应用到不同的环境中｡
最后，我们可以看看安全的配置，如果我们有的话｡
这是对Beanstalk的一个非常广泛的概述，
我们将在后面做更多有趣的事情，但我们已经看到了除了配置之外的大多数选项｡
我们已经看到，环境确实是在祝贺声中部署的｡
我们已经看到了Beanstalk设置后部署的基础架构，所以我们非常高兴｡
就这样了，希望你喜欢｡
我们下节课再见｡ 
  - [ ] 185 Beanstalk Second Environment [09:15]
    * 
教师：好的，让我们继续学习豆茎｡
我们有一个环境，但在我的应用程序中，
我现在要创建第二个环境｡
我将单击“创建新环境”｡
这里有一个新的对话框，
即，您要创建web服务器环境还是工作环境？
这是一个与以前不同的选项，因为我们已经在这里创建了一个环境，
因此第二个环境可以是web服务器或工作环境｡
现在，我们只关注web服务器环境，因此我将单击web服务器环境，
稍后讨论什么是工作环境｡
好的，接下来，环境名称｡
之前它被称为-env，但现在我们可以将其命名为更重要的名称｡
所以我们会说-prod｡
在此之前，假设这是我的开发环境｡
现在这是我的生产环境｡
就域而言，
我们可以选择所需的值，例如myappinprodbystephane，希望我们可以检查可用性，
是的，它是可用的｡
所以这是伟大的｡
我们可以给予一个描述，例如，我在prod中的Beanstalk应用程序｡
这很好，我将向下滚动，
我们可以选择托管平台｡
所以我们要选择节点｡ js，
剩下的12个应该不起作用，所以让我们回到节点｡
JS10，并采取5｡ 0. 0推荐，这是伟大的｡
在这里，我们选择应用程序代码，
因此要么是简单的应用程序，
要么是上传我们自己的代码或现有的应用程序，但我们无法选择它，因为我们没有上传示例应用程序，所以它还不存在｡
因此，我们将尽量保持简单，但这一次，
我们将配置更多选项，而不是在创建环境上进行创建｡
现在，让我们来看看可以在Beanstalk中配置的所有选项｡
正如你所看到的，
有很多这样的东西，我们会尽量让它变得非常非常简单｡
所以最上面的部分是，配置MyFirstWebappBeanstalk-prod｡
而且我们有不同的预设｡
我们有一个符合免费层条件的实例，这是我们用来创建第一个环境的实例｡
现在，我们有了不同的选择，我们可以使用单实例（使用现货实例）､
高可用性､ 高可用性（使用现货和按需实例）或自定义配置｡
为此，
我将选择高可用性，并将其作为一个预设，然后看看它会带来什么｡
但是，
我们非常欢迎您通过单击“自定义配置”来自定义所有内容，然后在此处更改所有内容｡
让我们从高可用性开始，
我将向下滚动，看看我们可以做些什么｡
我首先要向大家展示的是软件｡
因此，如果我单击软件的“编辑”，我们可以看到配置，
我们有x光片，
但我们还没有看到它是什么，S3日志源，因此，如果你想在历史中存储应用程序的日志，
如果你想在服务CloudWatch日志中保存日志，则将日志流传输到CloudWatch日志，
因此我们还没有看到服务是什么，但您可以预期它会将应用程序日志存储在CloudWatch中｡
所以现在，我们不能在这里拍摄任何东西｡
所以我要回到这里，
我要保存它，好吗？
那么对于这个实例，我们也可以在这里看一下｡
因此，我们可以指定根卷､ 所需的卷类型，
以及大小和安全组｡
我将单击“保存，因为我不想编辑任何内容｡
对于容量，更重要的是，
这是它真正有趣的地方｡
我们有一个自动扩展组，这是一个负载平衡环境，与单实例环境不同，
因此我们可以在这里配置安全组，
哦，自动扩展组｡
因此，最小实例数为1，最大实例数为4，
那么我们的自动缩放组需要什么组成？
还是我们只需要按需实例？
或者，我们是否还需要spot实例和按需实例，
所以我将其简化为按需实例，我将向下滚动，
这些将是按需和spot组合的设置，然后实例类型将保持为t2micro，用于启动这些ec2实例的AMI
ID，
易于使用的数量为任意1､ 任意2､
任意3，或者保持不变，还有位置，
所以我们选择欧—西2a，2b和2，好的｡
现在将触发扩展，那么我们是否希望在扩展自动扩展组上进行自动扩展，以及您想要的指标，
例如网络输出或CPU利用率或您想要的任何指标？
统计数据､ 平均值､
单位和一些阈值｡
因此，我们单击“保存｡
这里，我们已经完成了加载和自动扩展配置｡
接下来是负载平衡器｡
因此，我们有一个ESG，但也有一个负载平衡器｡
在这里，如果我们单击“编辑”，我们可以看到我们有一个应用程序负载平衡器，
它是使用HTTP和HTTPS的新一代产品，这是一个web应用程序，
所以这很有意义｡
但是，
如果您愿意，我们可以使用传统负载平衡器;如果您希望为应用程序提供超高性能和静态IP地址，我们也可以使用网络负载平衡器｡
我们将其保留为ALB，在这里，我们可以通过添加侦听器等来修改应用负载平衡器配置，
以及进程和规则，
最后，对于负载平衡器，日志文件和访问文件可以存储在Amazon S3中｡
好的，我们保存此配置｡
到目前为止，
我们可以看到，使用这四个设置，我们能够配置Elastic
Beanstalk环境的底层组件，我们将使用负载平衡器和自动扩展组｡
滚动更新和部署将在以后的课程中介绍，因此我将跳过它｡
安全性定义了Beanstalk的服务角色，以及用于ec2实例的密钥对｡
监控就是围绕着监控，所以我就先不过去了｡
Manager的这个也一样，
它是定义当你想要更新你的ec2实例时，一些通知，联网使它成为VPC的一部分或坚果｡
还有一个数据库，
所以更重要的是，如果您要创建RDS数据库，您可以在此处定义它｡
因此，如果我进入这里，我可以创建整个RDS数据库并输入所有设置，
但它现在不会这样做｡
需要注意的是，如果您在Beanstalk中创建了RDS数据库，那么您将无法创建RDS数据库｡
如果您删除了Beanstalk环境，您的RDS数据库也将随之删除｡
因此，
有时候在Beanstalk内部部署RDS是件好事，有时候在Beanstalk外部部署RDS也是件好事，这取决于您｡
我将单击“保存”或“取消”，这样就足够了｡
最后是针对您的环境的标签｡
哦，对了，我忘了一件事｡
因此，在负载平衡器中，
当您单击“编辑”时，您将选择一个负载平衡器应用程序经典或网络负载平衡器，
并且以后无法更改负载平衡器｡
因此，
如果您选择应用程序负载平衡器，
您必须在环境的整个生命周期中保留一个应用程序负载平衡器，明白吗？
您无法在这三个选项之间切换｡
好的，让我们回到这里，我将回到高可用性自定义预设，
以确保我刚刚配置好｡
然后单击“创建环境”｡
现在，我们将进入相同的流程来创建此环境｡
所以我们要等一段时间｡
好的，五分钟后，
我的生产环境已创建，
如果我打开此URL，我会看到相同的祝贺消息，但这一次，
我们知道我们是由一个高可用性设置提供服务的，因为有一个负载平衡器，
还有一个自动扩展组｡
我们可以对此进行验证，如果我转到ec2管理控制台，
然后转到实例，我可以在这里找到我的prod实例，它有一个公共DNS，
因此这个实例没有弹性IP｡
这个实例实际上是由一个自动缩放组管理的，
我们可以在标记中看到它，这是一个自动缩放组名称｡
现在，我将转到屏幕左下方的自动扩展组｡
正如我们所看到的，
是的，我们有两个自动扩展组，
第一个组具有混合和最小最大值，其中一个是我的开发环境所需的｡
最小值为1，最大值为4，
相对值为1的这一个来自生产环境｡
在这里我们也可以看到我们的实例，所以这一切都非常非常好｡
我们有一个由自动缩放组管理的实例｡
我们可以查看负载平衡器，例如，
对于负载平衡器，
我们可以看到已经为我们创建了一些侦听器，并且一切都已设置妥当｡
顺便说一下，我们还可以进入自动扩展组，
显然，
由于这是一个自动扩展组，因此我们可以看到为我们创建的扩展策略｡
因此，
有两种扩展策略，一种是向下扩展策略，另一种是向上扩展策略｡
所以非常非常好｡
接下来，我们可以转到我们的安全组，
并查看这些组｡
因此，如果我们清除此过滤器，我们可以看到，
许多自动缩放组过滤器的Beanstalk将工作｡
在这里，我们可以看到三个安全组，第一个是负载平衡器安全组，它连接到我们的新负载平衡器，
因此它允许入站规则，HTTP上的端口80，
所以这很棒｡
第二个是附加到我们的ec2实例的普通安全组｡
正如我们所看到的，这里的规则说端口80可以｡
但端口80的源必须是自动扩展，
对不起，是我的负载平衡器的安全组｡
这是我们在本课程中看到的一种最佳安全设置｡
最后一个安全组是用于我们的开发环境的安全组，它允许来自任何地方的端口80上的源｡
所以真的很酷｡
Beanstalk确实以一种完美的方式为我们创建了很多东西，
但现在我们通过这个UI来管理这一切，我认为这相当方便和不错｡
现在，如果我们回到环境，
我们可以看到Beanstalk有两个环境，我们有开发环境和生产环境，这两个环境同时运行｡
因此，这已经是管理应用程序部署的一种更简单的方法｡
希望这对你们有帮助，下节课再见.
  - [ ] 186 Beanstalk Deployment Modes [11:39]
    * 
Stephane：那么，
无论何时更新应用程序，我们都来讨论一下Beanstalk部署选项｡
所以你有几个，在接下来的几张幻灯片中，
我们会用图表来描述它们中的每一个，
所以不要担心｡
但我只想在我们深入研究它们之前给你们一个它们是什么的概述｡
第一种是一次性部署，即一次完成所有部署｡
这是最快的，但您的实例将停止运行，
因为它们将进行更新，因此您将有一些停机时间｡
您可以使用滚动，一次更新几个实例，
然后在第一个存储桶运行正常后，
继续更新下一组实例（称为存储桶）｡
您也可以使用附加批次进行滚动｡
这就像滚动一样，但是您会随着时间的推移启动新实例来更新实例，
这样您仍然可以使用相同容量的旧应用程序｡
你有不变的｡
这是在“自动缩放”组中具有实例时｡
您可以一起部署新实例｡
您将版本部署到这些实例，
然后在一切正常时将所有实例刷出｡
你有蓝色/绿色，在那里你创建一个全新的环境，
然后你切换到准备好了｡
最后，我们有交通分流｡
这是用于金丝雀测试的｡
金丝雀测试是指将一小部分应用程序流量发送到一个全新的部署｡
显然，所有这些内容都将在接下来的几张幻灯片中学习，
所以不要担心，这只是概述，
您将了解所有这些内容的示意图｡
所以让我们一起来谈谈｡
这是我们的四个EC2实例，
它们都运行应用程序的版本1，
即蓝色部分｡
然后，我们将执行一次性部署｡
因此，我们需要部署v2｡
接下来会发生什么，第一个Elastic
Beanstalk将停止所有EC2实例上的应用程序｡
所以我把它标成灰色，意思是他们什么都不做｡
然后我们将运行新的V2，因为Elastic
Beanstalk将把V2部署到这些实例｡
那么我们注意到了什么？
嗯，这是非常快｡
这是最快的部署｡
但是，应用程序会停机，因为您可以看到中间的部分都是灰色的，
因此它们无法为任何流量提供服务｡
我认为它非常适合于当你有快速迭代和开发环境时，
当你想快速部署你的代码时，
你并不真正关心停机时间｡
最后，使用此设置，无需额外成本｡
现在我们来谈谈滚动｡
应用程序基本上会在低于容量的情况下运行，我们可以设置要设置的低于多少，
就像运行容量一样｡
这就是所谓的桶大小｡
所以让我们来看看｡
我们有四个实例在运行v1，
在本例中桶的大小为2｡
所以发生的事情是前两个实例将被停止...
不是实例，抱歉，实例上的应用程序将停止，
因此它们是灰色的｡
但是我们还有另外两个实例在运行v1｡
所以你可以看到我们这里大概有一半的容量｡
然后这两个实例将被更新，因此它们将运行v2，
然后我们将滚动到下一个桶，或下一个批｡
这就是为什么它被称为滚动｡
正如您现在所看到的，底部的两个实例将其应用程序v1降为灰色，
然后更新为v2｡
最后，我们拥有了所有已更新的EC2实例，
以运行v2应用程序代码｡
因此，正如您现在所看到的，
在部署过程中的某个时刻，
应用程序同时运行两个版本｡
而且没有额外的费用，好吗？
您的基础设施中仍然运行相同数量的EC2实例｡
因此，如果您设置了一个非常小的存储区大小，
而您有成百上千的实例，这可能是一个非常长的部署，
对吗？
现在，在本例中，
我们的存储桶大小为2个和4个实例，
但我们也可以有2个和100个实例｡
它只是需要很长的时间来升级一切｡
现在，有一个额外的模式，
称为滚动额外的批次｡
因此，在本例中，应用程序不会像以前那样在容量不足的情况下运行｡
以前，在某个时候，我们只运行了四个实例中的两个｡
所以这是低于容量｡
在这种模式下，我们满负荷运行，
还可以设置存储桶大小｡
基本上，我们的应用程序仍将同时运行这两个版本，
但需要少量的额外成本｡
我们稍后将看到，这一额外的批处理将在部署结束时删除｡
同样，部署将是漫长的｡
老实说，这是一个对付刺激的好方法｡
我们来看看｡
我们有四个v1 EC2实例，我们要做的第一件事是部署新的EC2实例，
这些实例上将有v2版本｡
现在，Elastic Beanstalk从四个实例中自动为我们创建了六个实例，
所以又多了两个｡
你可以看到另外两个已经在运行更新的版本｡
现在，我们将第一批数据放入第一个存储桶（共两个），
然后它们停止，应用程序停止，应用程序更新到v2，
非常好｡
然后这个过程又重复了一次，就像在滚动｡
因此，运行v1的应用程序停止，
然后应用程序更新到v2｡
最后，您可以看到，
我们有六个运行v2的EC2实例｡
所以在它结束的时候，额外的一批被终止并拿走｡
你为什么要这么做？
现在我们可以看到，我们一直在满负荷运转｡
在任何时候，运行应用程序的EC2实例的最低数量都是4｡
很明显，有时我们会超负荷运行，这就是为什么会有少量额外成本的原因｡
房间很小，但是要额外付费｡
有时候考试会问你，
这类东西有额外的费用吗？
然后我们有了不可变的部署类型｡
而且这些部署也是零停机时间，
但这一次将新代码部署到新实例｡
以前，它部署在以前的实例上，
现在它部署在新实例上｡
这些事例来自哪里？
他们是临时助理秘书长派来的｡
因此，成本很高，由于需要一个全新的ASG，
容量会翻倍，而且这是最长的一种部署｡
不过，额外的好处是，在出现故障的情况下可以非常快速地回滚，
因为要减轻故障，只需终止即可｡
不是你，但弹性豆茎会终止新的助理秘书长｡
所以这是一个很好的选择，
如果你愿意采取多一点的成本｡
我的想法是这样的｡
我们有一个当前的ASG，其中三个应用程序v1运行在三个实例上｡
然后，我们将创建一个新的临时ASG｡
首先，Beanstalk将在它上面启动一个实例，只是为了确保一个实例能正常工作｡
如果它工作正常，通过了健康检查，
它将启动所有剩余的｡
所以现在，有三个例子｡
当它满意时，它会将ASG与临时ASG合并｡
因此，它会将所有临时ASG实例移动到当前ASG｡
现在，在当前的ASG中，我们有六个实例？
当所有这些都完成并且临时ASG为空时，
我们就有了当前ASG，
它将终止所有v1应用程序，而v2应用程序仍然存在｡
然后，最后，临时助理秘书长将被删除｡
最后，你可能在考试或白皮书中听到一些东西，
它被称为蓝/绿，它不是Elastic
Beanstalk的一个直接功能，但我会尽量给你我最好的版本｡
它基本上是零停机时间，
它有助于发布设施，允许更多的测试，
等等｡
所以我们的想法是部署一个新的舞台环境｡
因此，它只是另一个Elastic Beanstalk环境，
您将在那里部署新的v2｡
以前，所有部署战略都在同一个环境中，
现在，我们创建了一个新环境｡
因此，新的环境阶段，或绿色阶段，
可以在我们自己的时间独立验证，然后在出现问题时回滚｡
然后我们可以使用像53号公路这样的东西，
例如，来阻止交通进入两个方向｡
因此，我们可以设置加权策略，
并将少量流量重定向到临时环境，
以便测试所有内容｡
然后，当我们满意地使用Elastic
Beanstalk控制台时，
您可以在完成后与测试环境交换URL｡
所以这不是一个非常直接的功能，
实际上需要非常手动的操作｡
它没有嵌入到Elastic Beanstalk中，
所以有些文档会说有蓝/绿，有些会说没有，
但总的来说它是非常手动的｡
我只画了一张图，尽量简单｡
但在蓝色环境中，运行到一个Elastic
Beanstalk环境，我们有所有的v1，
然后我们将部署一个有所有v2的绿色环境，
好吗？
它们同时运行，非常好｡
然后在53号公路上，我们将设置一个加权类型的策略，
将90%的流量发送到蓝色｡
因此，只要让大部分流量流向我们知道有效的实例，
也许只有10%的流量流向绿色环境，只是为了测试它，
确保它工作正常，用户没有任何问题｡
所以网络流量基本上被分成90/10，但它是你想要的，
只要权重去｡
因此，当您对测试环境感到满意时，
当您在v2环境中测量了所需的一切并认为您得到了所需的一切时，
您基本上关闭了蓝色环境，并滑动URL以使绿色成为主环境｡
这就是蓝/绿，对吧？
它很复杂，我认为很手动，
弹性豆茎，但它就是这样｡
您可以使用Elastic Beanstalk进行的另一种部署称为流量拆分｡
这将用于金丝雀测试｡
所以如果你在考试中看到金丝雀测试，
想想交通分流｡
那么什么是金丝雀测试呢？
新的应用程序版本将部署到具有相同容量的临时自动扩展组｡
因此，我们有主自动缩放组和具有相同容量的临时自动缩放组｡
所以三个实例在主实例中，
三个实例在临时实例中｡
所以它的容量翻倍｡
接下来会发生的情况是，
一小部分流量将在可配置的时间内发送到临时ASG｡
我们有一个ALB，我们会说，
“好的，90%的流量流向我的主ASG”，
而10%的流量流向我的临时ASG｡ 所有这些都是自动化的｡
将监视新临时助理秘书长的部署状况｡
如果出现部署故障，
或者指标出错，这将触发自动回滚，
这将非常非常快，因为主ASG已经在这里，我们要回滚所做的就是停止向此临时ASG发送10%的流量｡
因此，不会出现应用程序宕机｡
一旦一切都稳定且正确，
新实例将从临时ASG迁移到原始主ASG｡
然后旧的应用程序版本将被终止｡
我真的很喜欢，因为所有这些都是自动化的，
这可能是一个很大的进步，在蓝/绿技术之上，我刚刚在上一堂课中描述过｡
如果您想比较所有这些方法，
Beanstalk文档中有一个链接，
它向您展示了我刚才解释的所有部署方法之间的差异｡
这真的很酷，因为它提供了方法名称､
失败部署的影响､
部署时间､ 是否为零停机时间､ 是否有DNS更改､
回滚过程是什么以及代码部署到哪里｡
如果你理解了这节课，这张表应该对你有意义｡
因此，我建议您浏览此链接，
通读一遍，并确保表格有意义，
因为考试将根据部署本身的约束和要求，
围绕Beanstalk的部署机制类型向您提出一到两个场景问题｡
这堂课就到这里，希望你们喜欢｡
现在您应该是部署专家了，
我们将在下一节课中再见｡
  - [ ] 187 Beanstalk Deployment Modes [09:06] Hands On
    * 
  - [ ] 188 Beanstalk CLI and Deployment Process [02:14]
    * 
讲师：我们可以使用EB
CLI，但还有一个名为“Elastic
Beanstalk CLI”的CLI，它使从CLI使用Beanstalk变得更加容易｡
还有一系列命令，例如eb create､
eb status､
health､ events､
logs､ open､
deploy､
config､ terminate，
所有这些命令以及更多命令都可以帮助您重现我们在Elastic Beanstalk控制台中执行的操作，但使用的是命令行界面｡
现在，
当您想要自动化您的开发管道时，使用EB CLI是很有帮助的｡
在开发人员考试中，不需要知道这些命令｡
当您参加DevOps考试时，了解这些知识是非常必要的｡
所以我在DevOps考试中会处理这些问题｡
因此，我们不会亲自操作EB
CLI，但您知道，EB
CLI确实存在，它可以帮助您在使用CLI对付Elastic
Beanstalk时提高效率｡
现在，
这个Elastic Beanstalk CLI可以帮助您部署Beanstalk应用程序｡
因此，无论如何，要部署Beanstalk应用程序，
您都需要描述您的依赖项｡
例如，您需要创建一个需求｡
txt或创建一个包｡ json表示节点｡ js的｡
然后将所有代码打包为zip文件，并在该文件中描述了依赖项｡
所以就像我们说的，这两个文件｡
然后将zip文件上传到Beanstalk｡
这将创建一个新的应用程序版本，然后在上传应用程序版本时，
我们可以使用控制台或CLI进行部署｡
我们可以对EB CLI执行完全相同的操作，它将创建一个zip文件，
上载该zip文件并部署它｡
顺便说一句，当你把它上传到Beanstalk时，它实际上会上传到Amazon的历史记录中，
然后从Beanstalk界面引用Amazon是免费的捆绑包｡
好的，完成后，Beanstalk将获取这些zip并将其部署到每个EC2实例上，它们将解决需求､
Python或用于Node的json包的依赖关系｡
js，然后应用程序将启动｡
这是一个理论讲座，应该会向你解释豆茎是如何工作的后端过程｡
如果要重放，请尝试访问文档网站并安装EB
CLI｡
但你要知道，这超出了考试的范围，也超出了本课程的范围，
所以我不想告诉你太多细节，
只想知道它是存在的，希望这对你有帮助｡
我们下节课再见｡ 
  - [ ] 189 Beanstalk Lifecycle Policy Overview [02:45] Hands On
    * 
  - [ ] 190 Beanstalk Extensions [03:51]
    * 
好了，现在我们来谈谈弹性豆茎扩展｡
因此，当我们创建一个zip文件时，
它包含了必须部署到Elastic
Beanstalk的代码，但是我们也可以添加EB扩展｡
因此，我们在UI中设置的所有参数也可以通过使用文件的代码进行配置，这些文件是EB扩展｡
因此要求所有这些配置文件都必须在｡
ebextensions/目录下的文件夹｡
所以它必须在一个名为的目录中｡ b扩展名/｡
它必须是YAML或JSON格式｡
即使它是YAML或JSON格式，该文件的扩展名也必须以结尾｡
config，例如，登录｡ 配置
好吧，它必须以｡ 配置
您可以使用此课程设置文档中的选项修改一些默认设置，我们稍后将看到这一点｡
您还可以使用EB扩展添加资源，例如RDS､ ElastiCache､
DynamoDB和所有其他您不一定能通过Elastic Beanstalk控制台设置的内容｡
因此，
顺便说一下，如果环境消失，由EB扩展管理的任何内容都会被删除｡
这意味着，如果您创建了一个ElastiCache作为Elastic Beanstalk环境的一部分，然后您删除了Elastic
Beanstalk环境，那么您的ElastiCache也会随之消失｡
所以，让我们动手看看我们可以如何发挥这些独特的EB扩展文件｡
好的，现在我在我的代码目录中｡
因此，我创建了一个nodejs-v3-ebextensions目录｡
在其中，我创造了一个｡ ebextensions目录并放置了一个环境变量｡
配置
因此，正如我们所看到的，这个文件以结尾｡
config中，并放置在. ebextensions目录，
你必须有这两件事，它的工作｡
然后是语言，我可以将其设置为YAML，
以显示一些适当的格式｡
所以虽然是一个｡
config文件中，我们可以使用YAML格式｡
所以我们就说，这些都是我已经告诉过你们的｡
我们在这里设置选项设置，我有一个关于此选项设置的参考文档｡
因此，我们在此处设置AWS Elastic Beanstalk应用程序环境变量，
并在此处定义环境变量｡
我们可以让DB_URL等于此URL，并且DB_USER应该具有例如username的值｡
这只是一个例子，我们在应用程序中没有使用这些｡
但是，如果我们要连接到外部RDS数据库（例如Postgresql
RDS数据库），
则需要设置环境变量，我们将使用EB扩展进行设置，并在此处定义这些变量的值｡
这很好，我已经把它压缩到nodejs-v3-ebextensions中了｡
zip档案｡
现在，
如果我单击我的应用程序并转到我的开发环境，因为它的更新速度会更快｡
我可以上传和部署新的应用程序｡
因此，我将选择我的nodejs-v3-ebextensions来向您展示它们是如何工作的｡
例如，版本标签为EBExtensions Demo，然后单击“部署”｡
现在可以继续了，上传应用程序版本并进行部署｡
所以我会等待部署的发生，以看到你，告诉你，
如果它的工作或没有｡
好了，我的应用程序更新已经完成了｡
如果我转到配置｡
我转到“Software”（软件）和“Edit”（编辑），一直向下滚动，
我们可以在“Environment”（环境）属性中看到，这些DB_URL和DB_USER是在我的控制台中为Beanstalk自动设置的，尽管我们已经在EB扩展文件中设置了它们｡
所以这个就在这里｡ 配置
所以这是伟大的｡
这只是一个EB扩展的快速演示｡
显然，
你可以做更多的事情，但这应该足以让你了解你需要的考试｡
希望这对你们有帮助，下节课再见.
  - [ ] 191 Beanstalk & CloudFormation [02:57]
    * 
好的，让我们来了解一下Elastic
Beanstalk的工作原理｡
Beanstalk的底层依赖于CloudFormation，稍后我们将在本课程中介绍CloudFormation，但作为一个简要说明，
CloudFormation用于配置其他AWS服务，因此我们的基础架构是代码｡
因此，弹性豆茎使用CloudFormation作为它的基础来执行它的许多操作｡
我为什么要告诉你这些？
使用情形是使用您的中的CloudFormation资源｡
ebextensions文件夹中，您可以调配任何所需的内容｡
因此，您可以调配ElastiCache､
S3存储桶､ DynamoDB表，以及您将在本课程中看到的任何内容｡
Elastic Beanstalk的优点是，
尽管UI只允许您配置一些内容，但通过EB扩展和CloudFormation，
您可以在AWS中配置任何内容｡
因此，让我们先来了解一下CloudFormation在本课程中是如何使用的｡
我现在在Beanstalk中，我们的应用程序有两个环境｡
现在，我将转到CloudFormation，向您展示幕后发生的情况｡
在CloudFormation中，我可以看到有两个堆栈，
不用担心这个，我有两个堆栈，称为eb-e堆栈和eb-e堆栈，它们是不同的｡
第一个堆栈实际上是，我们可以看一下，
-en的这个是-prod的｡
让我们把它变得非常简单，让我们看一下-en｡
如果我单击堆栈，它对应于一个CloudFormation模板，您可以通过单击模板来查看，
这将显示整个模板｡
现在你不需要知道如何阅读，
不用担心，我们会在本课程的后面学习｡
但是很酷的是，
如果你去资源，它会显示这个CloudFormation堆栈为我们创建的一切｡
如我们所见，它创建了一个自动扩展组，
一个自动扩展组启动配置，
还有一个弹性IP，即EIP｡
有以及EC2安全组，
并有等待条件，我们可以简单地忽略现在｡
如果我转到另一个堆栈，也就是-prod堆栈，
这次他们创建了16个资源｡
我们有一个自动扩展组､
一个启动配置､ 一个扩展策略，就在这里，
还有一个扩展策略，我们可以忽略它｡
CloudFormation､
一个CloudWatch警报､ 另一个CloudWatch警报，这些都用于扩展策略｡
然后是EC2安全组，另一个安全组｡
最后还有弹性负载平衡器以及监听器规则和目标组｡
因此，CloudFormation在幕后用于供应我们的弹性豆茎｡
现在，
我们不需要触及CloudFormation中的任何内容，但您知道，
使用CloudFormation，您可以部署Elasticache､ DynamoDB或S3桶｡
因此，这将允许我们扩展我们的弹性豆茎应用程序，
以包括任何我们想要的｡
Halil的评论到此为止，希望你喜欢
  - [ ] 192 Beanstalk Cloning [01:35]
    * 
旁白：这是弹性豆茎的一个方便的功能｡
它允许您将现有环境克隆到新环境中，并且新环境将具有完全相同的配置｡
如果您已经有了应用程序的投影版本，并且希望部署具有完全相同设置的测试版本，
这将非常有用｡
然后，您只需在生产环境和新环境之间进行克隆，
以便进行测试｡
原始环境的所有资源和配置都将保留，
因此包括负载平衡器类型和配置､ RDS数据库类型（尽管如果您有RDS数据库，
则不会保留数据，但会保留RDS数据库的配置）､ 环境变量等｡
克隆环境后，您可以更改其设置｡
让我们在控制台中快速查看一下这是如何工作的｡
假设我想克隆我的env环境，那么我将单击它｡
然后，
我将执行“环境”操作，即克隆环境，
这将描述当前的配置选项，如您所见，我可以更改新环境的名称，可以更改其URL及其描述｡
我可以只更改平台版本和服务角色来执行此克隆，然后单击“克隆”｡
所以我没有其他选择，
除了这一点，以改变，所以我不能改变配置的加载答案或其他任何东西｡
我不打算克隆它，这只是要创建一个类似的环境，但您可以看到，
更改的选项是有限的，因为我们只是按原样重新克隆环境｡
之后，我们将能够编辑配置，
就像我们在本节中学习的那样｡
好吧，就这样，非常，非常短｡
我要取消这个课程，我们下节课再见.
  - [ ] 193 Beanstalk Migrations [03:19]
    * 
这是一组关于如何执行弹性Beanstalk迁移的理论幻灯片，因为考试中可能会涉及到这一点｡
第一个是负载平衡器，因此在创建Beanstalk环境后，您无法更改弹性负载平衡器类型，
只能更改其配置｡
我们之前已经看到过这种情况，
如果您创建经典负载均衡器，则只能编辑经典bouncer设置，而不能将其升级为应用负载均衡器｡
因此，如果您希望它以某种方式从经典负载平衡器升级到应用程序负载平衡器，
或者从应用程序负载平衡器升级到网络负载平衡器｡
您将需要执行迁移，步骤如下｡
首先，
您将创建一个新环境，该环境具有相同的配置（负载平衡器除外）｡
因此，我们不能使用上节课中介绍的克隆功能，因为克隆功能会复制完全相同的负载均衡器类型和配置｡
因此，您必须手动重新创建相同的配置，
然后将旧环境复制（而不是克隆）到新环境中，在这个新环境中，我将拥有我的应用程序负载平衡器，
然后我们将应用程序部署到新环境中｡
然后，我们需要将流量从旧环境转移到新环境｡
因此，我们可以进行CNAME交换，
也可以使用Route 53进行DNS更新，希望这两种方法都有意义｡
接下来，我们将讨论RDS弹性豆茎｡
因此，RDS可以随Beanstalk应用程序一起调配，如果您希望进行开发和测试，
这将非常有用｡
在您的Beanstalk中，您有自己的RDS数据库｡
但是，如果您正在进行生产部署，这就不太好了，
因为数据库生命周期将与Beanstalk环境生命周期相关联｡
因此，在prod中执行此操作的最佳方法是将RDS数据库与Beanstalk环境分离，并使用连接字符串（例如，
使用环境变量）引用它｡
那么我们该怎么做呢？
如果RDS已经存在于Beannstock堆栈中，我们如何将其分离？
首先，我们将创建RDS数据库的快照，
作为出现问题时的保护措施，这样我们就有了备份或数据，
我们知道我们是好的｡
下一步是转到RDS控制台并保护RDS数据库不被删除｡
这将防止它被删除，
无论如何，然后我们创建一个新的弹性Beanstalk环境，这一次没有RDS｡
我们将应用程序指向现有的RDS数据库，例如，使用环境变量｡
因此，现在我们有了指向同一数据库的新环境｡
然后，
我们执行CNAME交换，因此，蓝/绿色部署或路由53 DNS更新，我们确认它工作正常｡
现在，我们已将所有流量从旧版本转移到新版本，
然后终止旧环境｡
而且，由于我们启用了RDS删除保护，
因此RDS将保留｡
由于这是CloudFormation堆栈，
因此在我们的Elastic Beanstalk环境后面，
将无法删除它，它将处于“Delete Failed”（删除失败）状态｡
所以我们需要进入CloudFormation，手动删除CloudFormation堆栈｡
这样，我们就在Beanstalk环境之外有效地创建了自己的RDS数据库｡
希望这对你们有帮助，下节课再见.
  - [ ] 194 Beanstalk with Docker [06:35]
    * 
教师：好的，
现在我们来讨论一下如何使用Docker和Elastic Beanstalk｡
因此，我们可以将应用程序作为单个Docker容器运行｡
为此，我们要么提供一个Docker文件，在本例中，
Beanstalk将构建并运行Docker容器，要么提供一个名为“Dockerrun“的定义｡
啊! json版本一｡
“我们还描述了已经构建的Docker映像的位置｡
它可以在您自己的ECR存储库中，也可以在Docker Hub上｡
因此，我们定义映像､ 端口､ 卷､ 日志记录等｡
然后Beanstalk将继续在EC2实例上为我们部署Docker容器中的文档｡
请注意，
如果您确实为Docker使用了单个容器模式，那么单个Docker在后台不会使用ECS，它只是在EC2上使用Docker｡
如果你想有一个更复杂的设置，一个更先进的，可能更多的由EB维护的设置，
那么你应该使用多Docker容器｡
多Docker容器帮助您在Elastic Beanstalk中为每个EC2实例运行多个容器｡
因此，这将为您创建更多内容，它将创建一个弹性的ECS群集，
一些配置为使用ECS群集的EC2实例｡
处于高可用性模式的负载平衡器，负责定义和执行任务｡
因此，您只需要编写自己的Dockerrun｡
啊!
json第二版｡
此文件将用于生成ECS任务定义｡
所以，记住这一点非常重要｡
现在，您的Docker映像必须预先构建并存储在存储库中，例如Docker
hub或ECR｡
那么，它看起来怎么样？
我们有配备负载平衡器的Beanstalk环境，
还有ECS群集和ASG，同样由Beanstalk环境管理｡
我们有多个EC2实例，它们将运行多个容器，例如，
php､ nginx和另一个容器｡
因此，它们部署在EC2实例上，然后负载平衡器知道如何连接到每个容器，
例如，通过使用“beanstalk-url：80”转到ngnix的端口80，
或“1234”转到其他容器端口1234｡
所以这就是你需要知道的所有关于多码头｡
请记住，它会创建任务定义并在后台使用ECS，
让我们一起来看看它是如何工作的｡
回到我的应用程序中，我可以继续创建一个新环境｡
这将是一个web服务器环境，
我将单击“Select”，并将其命名为“Docker“｡
“然后，
我将此字段留空，以自动生成值｡
向下滚动，它将是一个托管平台，这次我将选择“Docker”，然后有多个选择，
我可以使用“Docker running on 64
bit
Amazon Linux 2”，这是单个Docker，或者我可以使用“Multi Docker
container running on 64
bit Amazon Linux”｡
“所以，也许很快就会有一些新的东西出来，但无论如何，
如果我们运行一个单一的Docker然后，我没有平台版本，所以也许是的，
在这里，我们去｡
有了这个单一的Docker我可以选择一个平台2. 15.
0，并使用示例应用程序｡
这将在我们的实例上运行Docker容器，但它不利用任何ECS，因此运行起来并不有趣，
但您可以在自己的时间内运行并创建此环境｡
但更重要的是，我想向大家展示多Docker，所以我使用“Docker”作为平台，我将使用“多Docker”，
并使用平台版本2｡
1.  2.
我将再次使用示例应用程序｡
我将单击“Create
environment”（创建环境），然后看到为我创建的所有内容｡
我们还可以做的是，再次转到“Beanstalk示例应用程序zip”，然后返回到文档｡
那么，教程和示例｡
在这里，
如果我向下滚动，我可以找到多Docker容器｡
把这里的拉链拉开｡
如果你看一下zip文件的内容，我们首先找到的是一个Dockerrun｡
啊! 杰森
超级酷｡
这看起来很像我们之前的json形式的ECS任务定义｡
这是因为它是一个任务定义｡
因此，我们定义了卷，我们定义了正在运行的多个容器，
包括内存､ 卷的装载点等｡
nginx的端口映射，以及将所有这些卷和容器连接在一起的挂载点｡
因此，这只是一个复杂的任务定义，但在Dockerrun中定义｡
啊!
json文件，所以请记住这一点｡
穿这个也很酷｡
ebextention，我们可以看到已经为我创建了一个EB扩展｡
现在，
我不会去过它，但你可以在你自己的时间｡
这只是展示了如何创建文件和运行容器命令，当你开始｡
所以我们可以把这事了结了｡
这是一个有点先进的，
但很高兴看到，我们还有另一个EB扩展，以“结束｡
配置扩展名｡
“最后，
我们将直接为我们的php应用程序和代理配置获取一些文件，
这些文件在本卷中直接引用，因此更高级一点，但这是一个简单的应用程序｡
所以我想让你们记住的是，我们确实有一个码头运行｡
啊!
json文件，其中包含一个ECS任务定义｡
现在，让我们回到控制台｡
好的，我的应用程序现在正在运行，
因此它是一个多Docker容器，
如果我们转到ECS控制台，我们应该会看到一个专门为此目的创建的ECS群集｡
现在我明白了，我们有一个ECS集群，名为“我的第一个web应用程序Beanstalk｡
“我们单击它，在其中，我们可以发现一些任务正在运行，因此，
此任务就在此处运行，这与我们的应用程序任务相对应｡
就ECS实例而言，我们可以发现其中一个实例正在运行，而且它也是直接从Beanstalk创建的自动缩放组运行的｡
因此，如果您转到自动缩放组，
您应该能够找到其中一个自动缩放组，以与我们在此应用程序中所需的自动缩放组相对应，好吗？
所以非常非常简单，再一次，它起作用了｡
我想向您展示它在ECS中创建了一些东西，哦，
是的，包括，例如，任务定义｡
如果我转到“Task definitions”（任务定义），在这里我可以找到此应用程序的任务定义，如果我向下滚动，
显然，我将在这里看到容器定义｡
“Php-app”和“nginx-proxy”，它们都运行得很好｡
我们可以查看这个测试定义的实际json文档，它就在这里，
很像Dockerrun｡
啊!
json文件，我们已经从前面创建｡
这就是多功能Docker的全部内容｡
现在，
我们根本不需要这个环境，因此我们可以继续并终止它，
然后单击“enter the name of
the environment”（输入环境名称），这是一个相当长的名称，因此我将复制并粘贴它｡
我们开始了，它被终止了｡
好了，就这样吧，我们下节课再见｡ 
  - [ ] 195 Beanstalk Advanced Concepts [03:40]
    * 
教师：好的，
这里有一个关于Beanstalk中一些先进概念的快速理论讲座，我们不会花时间在这些方面进行实践｡
那么，第一件事是，我们如何在Beanstalk上使用HTTPS？
非常简单，您希望将SSL证书加载到负载平衡器上，因此可以通过两种方式完成此操作，第一种方式是将该SSL证书直接从Elastic
Beanstalk控制台加载到负载平衡器配置上，或者您可以在中创建自己的文件｡
名为securelistener-alb的扩展｡
config，这将以编程方式为您设置证书，证书本身可以使用ACM（即AWS证书管理器）或CLI进行配置，
我们将在本课程稍后部分了解这一点，您还必须配置一个安全组规则，允许HTTPS流量通过端口443进入负载平衡器，
然后我们还可以在Beanstalk上将HTTP重定向到HTTPS，
为此，
我们可以配置我们的实例来执行此操作，
这里有一个示例;或者，我们可以配置一个应用程序负载平衡器（仅ALB），
并使用一个规则来执行HTTP到HTTPS的重定向｡ 您需要确保的一件事是，
运行状况检查本身不会被重定向，以便您在这些运行状况检查中始终获得200
OK｡
好了，以上就是豆茎和HTTPS的全部内容｡
第二个问题是web服务器与工作环境的区别，如果参加DevOPS考试，
您应该非常了解这一点｡
我认为开发人员考试不会涉及这一点，但为了以防万一，我将向您介绍这一点｡ 因此，
如果您执行的任务需要很长时间才能完成，这是为了将您的应用程序分离为两层，这是非常常见的｡
那么，哪些任务可能需要很长时间？
例如，处理视频或生成zip文件，等等｡
为此，您可以将这些定期任务定义到cron中｡
yaml，并将这些处理任务集成到您的应用程序中，体系结构如下所示，您有与负载平衡器和自动扩展组相对应的web层，
然后您会将消息发送到我们尚未看到的SQS队列，您的工作层将从SQS队列中阅读消息，
并为您执行这些长时间的任务，
因此这是一种非常常见的体系结构，而这就是它，你应该只在更高的层次上了解它，所以我们开始吧｡
最后，我们还有一个自定义平台，这是一个非常先进的平台，允许您从头定义操作系统､
附加软件､ Beanstalk在这些平台上运行的脚本，
因此，
自定义平台的唯一使用情形是，您的应用程序语言既不兼容Beanstalk，也不使用Docker，
因此，如果您的应用程序语言与Beanstalk兼容，或者使用Docker，请使用Beanstalk提供的平台，
但如果不兼容，您可以创建自己的自定义平台｡
要创建您自己的自定义平台，您需要使用平台定义您自己的AMI｡
yaml文件，然后您需要使用Packer软件（一种用于创建AMI的开源工具）来构建该平台，这是您在考试中唯一一次看到这一点，
如果它显示Packer，
请考虑自定义平台，我认为这是它在考试中的唯一用途，那么自定义平台和自定义AMI之间有什么不同？
自定义AMI允许您调整现有的Beanstalk平台，因此您可以调整Python，
调整Node｡
js, tweak
Java，其中自定义平台是创建一个全新的Beanstalk平台，它非常先进，
非常复杂｡
好了，你们已经知道了，
在豆茎上考试应该知道的所有东西，希望你们喜欢，
下节课再见.
  - [ ] 196 Beanstalk Cleanup [02:11]
    * 
因此，我们在Elastic
Beanstalk中有两个环境，如果我们让它们处于打开状态，我们就完成了该功能｡
所以我们必须缩小规模｡
我们的想法是，如果转到EC2实例，我们会看到两个EC2实例，
因此只有一个在T2 micro上运行一个月，
因此我们必须缩减环境｡
最后，
对于负载平衡器，我们可以使用一个应用程序平衡器，因此这是很好的｡
在自由层上，您有一个长期运行的应用程序平衡器，但仍然很好，
需要注意的是｡
不要创建第二个应用程序平衡器而不删除它，否则您将跳过该功能｡
因此，对于Beanstalk来说，缩小规模非常容易｡
我将单击我的生产环境，然后它将转到“Configuration”（配置）｡
然后向下滚动到“Capacity（容量）”｡
所以我将它设置为最小零和最大零｡
这意味着我的自动扩展组中的负载平衡器中没有实例EC2实例｡
因此，这意味着我们的应用程序显然是不可访问的，因此，
无论何时在CICD部分，
我们重用Beanstalk，请确保返回到一个实例，以便在实际操作时使用｡
准备就绪后，只需单击“Apply”（应用）｡
这将设置您的配置更改｡
我们的想法是，如果我们进入“自动扩展组”并查看我们的环境，
这个“自动扩展组”的最小值和最大值应该很快都为零｡
所以如果我刷新这个页面｡
现在，
最小值､ 最大值和期望值为零，这使得我们的EC2实例在这里进入终止状态｡
因此，如果我们转到实例，很快就会看到其中一个实例将被终止｡
然后，当部署完成时，显然运行状况将是未知的，
因为我们没有运行任何EC2实例｡
如果我转到这里，你可以看到一个实例被终止了｡
总之，
一个T2微处理器持续运行，一个负载平衡器持续运行，我们就可以开始了｡
我们还在自由层｡
如果您希望重复使用此生产环境，
那么很简单，您可以依次选择“配置”､ “容量”，
然后将实例数重新增加到1个，例如最多4个，这对您很有好处｡
好吧，就这样｡
我们下节课再见｡ 
  - [ ]  Elastic Beanstalk [17 问题] Quiz
    * 
 ## Section 18 - AWS CICD: CodeCommit, CodePipeline, CodeBuild, CodeDeploy [25 个讲座 • 2 小时 6 分钟]
  - [ ] 197 AWS CICD - Section Introduction [00:37]
    * 
欢迎来到CICD部分｡ 既然我们已经了解了如何正确部署应用程序，
那么，我们如何自动部署应用程序呢？ 我们要做的是推送代码，并将代码神奇地部署到我们的生产环境中｡
这称为CICD｡
您可能听说过它，也可能尝试过其他技术，但在本节中，
我们将了解如何在AWS上完成CICD｡
我向你保证，在看到这一节后，如果没有CICD，你将无法完成任何工作｡
它是革命性的，每个开发人员都应该知道这一点｡
考试肯定会问你很多关于CICD的问题｡
我们开始吧
  - [ ] 198 Introduction to CICD in AWS [05:39]
    * 
讲师：好的，
欢迎来到AWS上我最喜欢的部分之一，那就是CICD部分｡
为什么？
因为作为一名开发人员，
CICD非常重要，这一部分实际上是考试的关键｡
因此，在使用所有课程资源之前，
我们已经学习了如何创建AWS资源，手动演示了基础知识｡
我们将学习如何以编程方式与AWS交互｡
这，
否则使用CLI，我们学习如何使用Beanstalk将代码部署到AWS｡
但所有这些步骤都是手工完成的｡
如果我们继续手动操作，我们很可能会犯错误｡
因此，我们最终要做的是将代码推送到目标存储库中｡
然后，我们希望通过该代码自动将其部署到AWS上｡
所以自动地，正确的方式｡
确保所有代码在部署之前都要经过测试｡
有可能进入不同的阶段｡
例如，我们的开发环境､ 测试环境､
试运行环境（即生产前环境和生产环境）｡
有时，即使您希望部署到生产环境，
也可能需要手动批准｡
所以我们想要所有这些东西，所以我们需要学习AWS CICD｡
这些都是非常重要的步骤，因为我们将自动执行所有这些步骤，这一点非常重要｡
好吧，我会的
所以，
这一切都是关于自动化我们在本课程中到目前为止所做的一切，以增加安全性和速度｡
因此，我们学习了CodeCommits来存储代码｡
CodePipeline自动化我们从代码到平台的管道，平台上有Beanstalk或其他地方｡
CodeBuild来构建和自动测试我们的代码｡
到CodeDeploy，将我们的代码部署到EC2实例｡
不是用豆茎，而是用其他的方式｡
CodeStar，它是一种在一个位置管理软件开发活动的方法，
并将CodeCommit､ CodePipeline､ CodeBuild和CodeDeploy重新组合到一个工具中｡
CodeArtifact用于存储､ 发布和共享软件包｡
CodeGuru使用机器学习实现自动化代码评审｡
所以现在，别担心｡
我们将在本课程中逐一了解所有这些内容｡
这只是一个概述｡
那么什么是CICD呢？
首先，是的，这是关于持续整合｡
这意味着开发人员经常会将代码推入一个中央代码库｡
这可以是GitHub，它是AWS的第三方服务，或者CodeCommit，
它是AWS的服务，或者Bitbucket，
它也是第三方服务｡
因此，开发人员将代码推送到代码存储库，
然后将有一个测试或构建服务器，它将检查代码是否正确，并在代码被推送到代码存储库时立即工作｡
如果是AWS，
则可以使用CodeBuild;如果您需要开源工具，则可以使用Jenkins｡
因此，构建服务器将获取代码并对其进行测试｡
然后作为开发人员，我们将获得关于测试或检查是否通过或失败的反馈｡
这样我们就得到了内置测试结果｡
但我们节省了时间｡
这样，
我们就可以及早发现错误并加以修复，因为我们在代码被推入代码库时就开始测试代码｡
因此，开发人员不需要在他们的机器上测试代码｡
他们可以只推送代码并等待构建服务器来完成它，同时他们还可以做一些其他的任务｡
因此，代码将更快地交付，
因为它将被测试｡
由于这一点，
我们将能够经常部署，因为只要它经过测试并准备就绪，我们就可以部署它｡
然后开发人员会更快乐，因为开发人员有一个更健康的开发周期｡
所以我们看到了CI｡
另一种是CD｡
例如，它可以是连续的交付｡
让我们给予个例子｡
因此，
这里有版本1的应用程序服务器，我们希望作为开发人员的代码能够一直推送到这些应用程序服务器｡
因此，我们的做法是，只要我们将代码推送到代码存储库，
我们就继续交付，如果在我们的应用服务器上进行了适当的测试，
就将部署代码存储库｡
所以开发者推了代码｡
代码将由构建服务器进行测试｡
这就是持续集成部分｡
然后，在构建通过后，
绿色也通过了测试｡
然后将有一个部署服务器｡
此部署服务器将把应用程序部署到应用程序服务器上｡
首先是版本1，但如果我们再次将新版本的代码推入代码存储库，
则会得到应用服务器版本2｡
因此，通过持续交付，我们可以确保经常进行部署，
而且部署速度非常快｡
我们也不再抱着“每三个月发布一次”的心态，这是一个漫长的过程｡
你知道，
容易出错，因为它不经常发生｡
让我们自动化，你知道，
多达“一天五个版本”，因为每次我们将代码推入代码存储库，代码将通过一些应用程序服务器运行｡
因此，
为了实现持续交付，我们需要自动化部署工具，
例如CodeDeploy（它具有AWS服务）､ Jenkins CD､ Spinnaker或其他工具｡
所以，如果你看一下AWS上的CICD技术堆栈｡
我们有代码，
代码可以存在于CodeCommits､ GitHub､ Bitbucket或任何第三方代码库中｡
然后是构建阶段｡
构建阶段和测试阶段可以由AWS上的CodeBuild完成，但CodeBuild有一个竞争对手，
它是开源的，称为Jenkins CI，
或者任何第三方CI服务器也可以｡
然后进入部署阶段｡
然后，我们可以使用CodeDeploy, CodeDeploy将查找并部署到本地服务器､
Lambda函数和ECS这两个实例｡
或者，
如果您还想配置基础架构，我们可以使用Elastic Beanstalk作为CodeDeploy的替代方案来执行基础架构的部署和配置｡
然后协调所有这些事情，确切地定义在我们的CICD流程中发生了什么｡
然后，我们可以使用AWS CodePipeline编排所有内容｡
以上就是CICD的概述｡
在这一部分，我们将进行深入探讨｡
显然，
在AWS服务上，但希望你知道我们正在尝试做什么｡
现在，让我们深入了解一下所有这些服务｡
下节课再见｡ 
  - [ ] 199 CodeCommit Overview [04:12]
    * 
现在我们来讨论AWS代码提交｡
所以我们需要引入的概念是版本控制｡
它是理解代码随时间发生的各种变化并可能回滚的能力｡
因此，
为了进行版本控制，这意味着您可以查看过去发生了什么，
谁提交了一些代码，更改了什么，
添加了什么，删除了什么等等，然后回滚｡
为了实现版本控制，
有一种现在非常流行的底层技术叫做Git, Git存储库可以在你的电脑上同步，但它通常也会上传到一个中央在线存储库｡
git repo有一个集中的在线repo的好处是你可以和其他开发者合作｡
因此，它允许组织多达数十万名开发人员同时处理同一代码，
这是令人惊讶的｡
确保代码也备份在某个地方｡
因此代码位于云端，
而不仅仅是某个人的计算机上，确保它是完全可查看和可编辑的，
这样我们就可以看到谁在何时提交了哪行代码，我们就可以还原它们｡
你可以回滚｡
你可以用代码库做很多好事，
所以有了代码提交，我们在AWS和我们的开发人员中有一个代码库｡
例如，Emma和John可以协作，从我们的代码存储库中推送和拉取代码｡ 那么，
我们为什么要使用代码提交呢？
Git存储库可能相当昂贵｡
因此，有些行业提供第三方服务，如github､
Gitlab､ Bitbucket等，但费用可能相当高，
但通过使用AWS上的代码提交，
你可以获得一个私有的git存储库，因为你的代码实际上存在并停留在AWS云上的VPC中｡
回购协议没有大小限制｡
这意味着您可以扩展到千兆字节的代码，
如果您希望它完全受管，具有高可用性｡
正如我所说的，代码只在AWS云中｡
因此，这意味着安全性和合规性得到了提高，
例如，如果您将代码放在其他地方，那么在AWS上也可能会提交安全性，
这是不可接受的｡
因此，它是加密的，
您可以使用IAM等进行访问控制，并且您可以在代码提交和行业标准（如Jenkins或CodeBuild或其他CI工具）中进行集成，这使它成为存储代码的理想选择｡
如果你想它现在代码提交作为非常，非常好的安全性｡
所以交互是用这个标准的Git命令行完成的，但是你需要在它上面进行身份验证｡
它可能使用SSH密钥｡
在这种情况下，作为用户，
您可以配置您的SSH密钥，使其能够进入Git存储库或HTTPS｡
如果你想使用标准登录和密码来获得回购｡
对于授权，您可以使用IAM策略来管理用户和角色对特定存储库的权限，这很好，因为这意味着您只有一种方法来管理AWS
Encryption中的安全性｡
因此，您的代码最终将使用KMS进行加密｡
这意味着除了你以外，没有其他人可以找回它｡
此外，当您将代码推送到代码提交时，
由于您使用HTTPS或SSH协议，因此在传输过程中会进行加密，
这两种协议都是安全的｡
然后在交叉帐户访问的情况下，当然你不会共享你的SSH密钥或你的凭据与别人｡
相反，
您可以在帐户中创建IAM角色，然后使用STS AssumeRoleAPI来访问代码提交存储库｡
所以我先来完成你的概要介绍，因为你可能对GitHub非常熟悉｡
所以CodeCommit和Github在某些方面几乎是一对一的比较，
但是codecommit和Github支持代码重用，也称为拉取请求｡
它既与代码构建相集成，也为codecommit和Github提供了SSL和HTTPS身份验证｡
在安全方面｡ 现在情况大不一样了｡
因此，
Github支持Github用户和SSO（如果您有企业级），但codecommit与AWS完全集成｡
所以你有IAM用户和角色来托管，
而你的代码只在AWS上进行代码提交，而Github，
你可以直接在GitHub上托管日期，或者如果你要得到一个企业，你可以在你自己的服务器上托管它｡
我可以说，codecommit的UI非常小｡
虽然我真的很喜欢GitHub UI，它的功能齐全，
但同样，如果你只是把它用作代码存储库，那么也许你想去代码提交的许多原因，
我刚才说了｡
好吧，我会的
以上就是对codecommit的概述｡
希望你喜欢｡
下节课我会和你们一起练习｡ 
  - [ ] 200 CodeCommit [06:25] Hands On Part 1
    * 
  - [ ] 201 CodeCommit [05:55] Hands On Part 2
    * 
  - [ ] 202 CodePipeline Overview [03:52]
    * 
讲师：好的，现在我们来谈谈CodePipeline，这是一个可视化工作流工具，
可让您在AWS中编排您的CICD｡
因此，通过CodePipeline，您可以显示源代码，例如，
嘿，我的代码在CodeCommit中，
或者我们在ECR中有一个Docker映像，
或者我的代码在Amazon S3中，或者甚至是外部工具，如Bitbucket或GitHub｡
然后，您可以进入构建阶段，即，嘿，
既然我们有了代码，让我们构建它｡
因此，CodeBuild､ Jenkins､ CloudBees和TeamCity都是您的选择｡
然后，一旦你有了构建阶段，
你就可以有测试阶段｡
同样，测试您的代码，例如CodeBuild或Device Farm｡
如果你有一个应用程序，
例如iOS和Android应用程序，或者你想要的任何第三方工具，那么一旦代码经过测试，你想要部署它，
那么CodeDeploy､ Beanstalk､ CloudFormation､
ECS､ S3，所有这些选项都可以由CodePipeline来处理｡
然后当你有了所有这些积木，你就可以建造舞台了｡
因此，每个阶段可以具有顺序动作和/或桨动作｡
我们可以做很多事情｡
这里有一个非常简单的例子：构建､ 测试､ 部署到暂存设备上，
然后进行负载测试以确保暂存设备运行正常｡
负载测试完成后，可能会再次部署到生产环境中｡
现在，您还可以在管道中的任何阶段定义手动批准，例如，
在部署到生产之前，您可以让某人检查负载测试的结果，
例如，
它是否在那里，并确保它说，是的，
看起来不错，绿色，部署到生产｡
所以CodePipeline实际上是用来协调一切的，
它给了你很大的灵活性，这要归功于我们在接下来的课程中会看到的所有构建模块｡
现在，CodePipeline在内部是如何工作的？
因此，让我们假设我们有一个源代码､ 一个构建和一个部署阶段｡
所以源代码是CodeCommit，构建是CodeBuild，
尽管我们还没有看到CodeBuild，部署是CodeDeploy，
尽管我们还没有看到CodeDeploy｡
因此每个管道都可以创建工件｡
工件是从管道中创建的任何东西｡
这些工件将被存储在S3桶中，
并传递到下一个阶段，这就是下一个阶段如何能够做它需要做的事情｡
那么让我们来做一个具体的例子｡
开发人员会将一些代码推入CodeCommit，对吗？
然后CodeCommit将由CodePipeline编排，它将提取所有代码并从中创建一个工件，
然后将该工件放入S3桶中｡
现在，当调用CodeBuild时，提取的相同工件将直接输入到CodeBuild｡
这就是CodeBuild不需要直接访问CodeCommit的原因｡
实际上，是CodePipeline将通过Amazon
S3将代码推送到CodeBuild｡
然后，当CodeBuild构建代码时，
它将创建一些部署工件｡
因此，这些工件将再次由CodePipeline存储在您的S3桶中，
CodePipeline将再次将这些工件推送到CodeDeploy，
CodeDeploy说，“嘿，我有这些工件｡
我需要部署他们｡
让我们开始部署它们｡
“如您所见，这些阶段通过Amazon S3相互交互，
这就是我们在CodePipeline中使用工件的原因｡
现在介绍一些CodePipeline的故障排除｡
因此，如果您需要查看所有这些内容，例如，
您需要查看CodePipeline､ Action或Stage执行状态更改，
您可以使用CloudWatch
Events､ EventBridge来查看它们｡
例如，
您可以为失败的管道创建事件，为取消的阶段创建事件，然后接收电子邮件通知等｡
然后，
如果CodePipeline在某个阶段出现故障，您将直观地看到它，并且可以通过控制台获取信息｡
如果CodePipeline无法执行特定的动作，例如，叫用CodeBuild中的某些程式码，
或从CodeCommit提取程式码，则请检查CodePipeline的“IAM服务角色”，
并确定它具有正确的IAM使用权限｡
此外，如果您需要查看基础架构中的一些被拒绝的API调用，您可以使用CloudTrail，这是一项用于审计AWS
API调用的服务｡
CodePipeline就到这里了，一旦我们开始动手实践，它就会变得更有意义，
我们下一节课再见｡
我希望你喜欢，我们来练习一下｡
  - [ ] 203 CodePipeline [09:59] Hands On
    * 
  - [ ] 204 [DVA-C02] CodePipeline - Extras [04:34]
    * 
讲师：那么，让我们再讨论一下关于CodePipeline的几点内容｡
第一个问题是，您有了启动事件､
Webhook和轮询管道的概念｡
所以，让我们来看看所有这些，
看看哪一个是最好的情况下｡
事件将是CodePipeline中的首选方式，
这将在我们有事件时启动一个管道｡
例如，当我们有CodeCommit时，我们知道在一个新的提交上，
一个事件将在EventBridge中发生｡
与该事件关联的EventBridge规则可以触发和启动CodePipeline｡
这是首选方法｡
而且，它不仅是CodeCommit，
还可以是AWS中的任何类型的事件｡
GitHub不是AWS的一部分，如何让CodePipeline以事件驱动的方式启动？
要做到这一点，您将使用CodeStar源连接｡
这只是GitHub应用程序的一个花哨的名字，
它将把GitHub连接到AWS｡
然后，从这里，您将触发CodePipeline｡
这些都是事件驱动的，而且速度非常快，因为一旦事件发生，
CodePipeline就会被触发｡
触发CodePipeline的一种较老的方法是使用webhook｡
因此，如果您选择该选项，那么CodePipeline将公开一个HTTP端点，
并且该端点可以由脚本触发，无论您想要什么｡
如果该脚本向该webhook上的CodePipeline发送有效负载，
则CodePipeline将启动｡
最后，您可以让CodePipeline拉取源代码，在这种情况下，您可以进行定期检查，
例如，从CodePipeline到GitHub｡
但不建议这样做，
因为它不如事件有效｡
因此，事件是默认和推荐的启动CodePipeline的方式｡
接下来，我们在CodePipeline上提供了这个表，
您不必了解它｡
我只想帮你解密，帮你理解它的意思｡
因此，我们有所有者､ 操作类型､ 提供者，
然后是输入工件的有效数量和输出工件｡
最后两列我们不需要看，
我们将看前三列｡
因此，所有者可以是AWS，
这意味着它是与AWS服务相关的操作｡
它可以是第三方，也就是当一个操作与第三方相关时，
例如GitHub或Alexa Skills Kit｡
或者定制，这是当你有像詹金斯这样的东西｡
因此，请记住，AWS for AWS､ 第三方和自定义｡
现在，Action Type对应于管道的不同阶段｡
例如，您有S3､ ECR､
GitHub､ CodeCommit的源代码｡
我们有CodeBuild和Jenkins的构建版本｡
我们有针对CodeBuild､ Device Farm和Jenkins的测试｡
我们有“Approval”（批准），“Action Type”（操作类型）称为“Manual”（手动），
我们也将在下一张幻灯片中看到这一点，这很重要｡
为Lambda调用｡
以及部署S3､ 云形成､ CodeDeploy､ 弹性Beanstalk､
OpsWorks､ ECS和服务目录｡
现在，如果您不了解其中的一些服务，请不要担心，您将在本课程中了解它们｡
当然，您将很容易理解它们的类型是Source､
Build､ Test等等｡
我为什么要给你们看这个？
嗯，因为手动审批类型是可能出现的考试问题的一部分｡
现在，让我们详细了解一下手动审批的工作原理｡
因此，当您有一个CodePipeline和一个Manual
Approval时，重要的是所有者是AWS，
因为这与AWS内部相关｡
这是AWS服务提供的一种功能｡
操作将是手动的，因为这是手动批准｡
在这种情况下，当您进行手动批准时，
您可以触发SNS主题，该主题反过来可以向用户发送电子邮件，
该用户将在AWS上拥有IAM用户｡
然后你必须批准这个阶段｡
要批准此阶段，它需要权限｡
用户必须具有双重权限｡
第一个是GetPipeline｡
因为，用户必须能够到达您的渠道，
以便实际查看它，并找到“手动批准”步骤｡
因此，我们需要GetPipeline* 类型的Action，
然后我们需要对ApprovalAction本身执行PutApprovalResult
Action，因为我们希望能够说是或否，
我们批准或拒绝｡
你只需要知道这些｡
但是，了解IAM用户权限以及步骤所有者是AWS且步骤的操作是Manual这一事实非常重要｡
好了，这堂课就到这里｡
我希望你们喜欢，
我们下节课再见｡
  - [ ] 205 CodeBuild Overview [05:41]
    * 
现在让我们来讨论CodeBuild｡
CodeBuild就是你只需要一个源代码，比如CodeCommit，
Amazon S3，Bitbucket或者GitHub.
然后在那个源代码中，会有一些构建指令｡
现在，
从考试的角度来看，您需要知道该文件的名称｡
所以它是buildspec｡ yml，并且该文件需要位于代码的根目录中｡
我将在实践中说明这一点，或者您也可以在控制台中插入这些指令，但最好的做法是使用buildspec｡
yml的｡
这就是考试要考你的内容｡
因此，一旦构建了应用程序，输出日志可以存储到Amazon S3和CloudWatch日志中以供以后分析，
您可以使用CloudWatch Metrics查看构建统计信息，使用CloudWatch事件检测失败的构建并触发通知，
例如，如果您有太多的失败，
CloudWatch会发出警报，
然后构建项目本身可能会出现问题，这有点令人困惑，当然是在CodeBuild中定义的，
或者也可以在CodePipeline中调用，但CodePipeline也可以调用现有的CodeBuild生成项目｡
那么，如果我们看看CodeBuild，它可以测试什么？
好吧，如果你有一个Java, Ruby, Python，
Go, Node｡ js､ 安卓系统､ .
NET核心，PHP应用程序，
然后有一个预构建的图像，供您在CodeBuild中运行测试｡
如果你想有任何其他的环境，你可以扩展一个Docker映像，通过扩展它，
你可以测试你想要的任何语言｡
但同样，这取决于您是否支持您自己的环境｡
那么CodeBuild如何工作呢？
我们有自己的程式码，在这个范例中，
是在CodeCommits中｡
我们有源代码，一堆文件，
还有一个非常重要的文件，
它位于存储库的顶部，即buildspec｡
抱怨
现在，CodeBuild将获取此代码，
然后CodeBuild本身将必须拥有一个容器｡
所以，正如我所说的，将有一个构建环境｡
Java､ Go等等｡
这个容器将加载所有的源代码和buildspec｡
yml，并将运行插入到该buildspec中的所有指令｡
yml档案｡
现在，为了构建此容器，CodeBuild将拉取一个Docker映像｡
因此，
要么它是由AWS为我刚才告诉你的环境预先打包的，要么你提供自己的Docker映像来运行你需要的任何代码｡
好的，CodeBuild将运行buildspec中的所有指令｡
yml，有时它们可能相当长｡
因此，有一个特性和CodeBuild能够在S3存储桶中缓存一组文件｡
如果你想在不同的版本中重用一些文件，
这是一个优化，但是有一种方法可以缓存一些文件｡
但这是可选的｡
然后，所有日志都将进入CloudWatch日志和Amazon S3（如果您启用了它），
然后，一旦CodeBuild完成，为了构建您的代码甚至测试您的代码，
它可以生成一些工件，这些工件将从容器中提取出来，放入S3桶中，
在这里您可以找到CodeBuild的最终输出｡
因此，构建规范｡ yml文件是超级重要的｡
这是它的样子，我们会看一下，
显然在这门课上｡
但是一些非常重要的事情是buildspec｡
yml文件必须在你的代码的根｡
在代码目录的最顶端｡
Environment允许您为buildspec的执行定义一些环境角色｡
yml的｡
因此，
变量可以是纯文本，也可以直接从SSM参数存储中提取，
或者直接从Secrets Manager中提取机密｡
这将允许你，例如，直接从一些地方获得数据库的密码，
等等，
当然，你不会想把这些密码以纯文本的形式存储到像buildspec这样的文件中｡
yml的｡
然后是阶段，它实际上是定义CodeBuild要做什么，所以它是一堆安装，例如，说，
“嘿，
你想做什么提交”，安装一些必要的包等等｡
预生成，即要执行的命令｡
就在构建之前｡
构建，实际的构建命令，非常重要｡
然后是post_build，这是最后的修饰｡
例如，
一旦它被构建，可能会创建一个好的zip输出等等，然后是工件｡
因此，Docker容器中的哪些文件应该被提取并发送到Amazon S3中｡
也应该加密｡
最后，还有这个缓存块，它表示您的依赖项将在Amazon
S3中缓存哪些文件，以加快未来的构建｡
好吧，这可能是一个高层次的问题，但从这个文件中，
请记住，对我来说，最重要的是文件的名称，
以及它所在的位置｡
同样，只要了解CodeBuild工作原理的一般概念，
您就可以开始了｡
现在CodeBuild是在云上运行的，
但是如果您需要在日志之外进行一些深入的故障排除，则可以在桌面上本地运行CodeBuild｡
首先，您显然需要安装Docker，
然后利用CodeBuild代理，此处提供了说明，这允许您在计算机上重现CodeBuild构建，
并在出现故障时真正了解发生了什么｡
CodeBuild也可以在VPC内启动｡
因此，
默认情况下，您可以构建容器，实例在您的VPC外部启动｡
这意味着它将运行良好，但它无法访问VPC中的某些资源｡
因此，
您可以使用VPC ID､ 子网ID､ 安全组ID等为CodeBuild指定一个VPC配置｡
因此，CodeBuild容器将能够访问VPC中的资源，如RDS､
ElastiCache､
EC2实例､ ALBs等｡
因此，在本例中，我将RDS数据库放在VPC的专用子网中，
然后我可以在此处直接启动CodeBuild容器｡
然后，
如果需要，我的CodeBuild容器可以访问我的RDS数据库实例｡
因此，
在VPC中使用CodeBuild的用例是进行集成测试､ 数据查询､ 与内部负载平衡器对话等等｡
CodeBuild就到这里了，
希望大家喜欢，让我们进入下一节课进行练习.
  - [ ] 206 CodeBuild [04:49] Hands On Part 1
    * 
  - [ ] 207 CodeBuild [09:15] Hands On Part 2
    * 
  - [ ] 208 [DVA-C02] CodePipeline - CloudFormation Integration [02:40]
    * 
那么让我们来讨论一个我们还没有见过的服务，叫做CloudFormation｡
CloudFormation将用于使用AWS中的API部署复杂的基础设施｡
例如，使用一个CloudFormation模板，
您可以部署一个自动扫描组､ 一个低平衡器､ 一个数据库，
以及任何您想要的东西｡
我们将在本课程中深入了解云的形成｡
但我现在只想向您介绍这个概念，
因为它在代码管道中非常重要｡
所以你可以在代码管道中使用CloudFormation｡
尽管我们不知道云形成是如何工作的，
我还是想向你们展示它的用法｡
假设我们的管道的第一步是使用CodeBuild构建应用程序｡
因此，我们部署，我们构建应用程序，我们有一个工件，
然后从它我们将有云形成｡
CloudFormation将用于实际部署全新的基础架构和应用程序｡
例如，如果我们把CloudFormation设置为创建或更新模式，
那么它将创建一个CloudFormation堆栈｡
无论您将什么定义为堆栈的一部分，
它都可以是低平衡器，也可以是自动扩展组｡
无论我们定义为堆栈的一部分，
都将由CloudFormation创建｡
关键是，这将是我们的测试堆栈，
并将作为代码管道的一部分进行部署｡
当堆栈被部署时，我们可以进入另一个CodeBuild阶段来测试我们的应用程序，
因为CodeBuild可以构建应用程序，但是您也可以在CodeBuild上运行测试套件｡
我们可以对新部署的应用程序运行许多基于HTP的调用，
以确保一切都按预期运行，
没有崩溃等情况｡
因此，所有这些测试都可以在CodeBuild中进行，
然后判断它们是否成功｡
但无论如何，我们将在代码管道和操作中再次使用CloudFormation步骤｡
这一次，它将处于仅删除模式，
通过删除CloudFormation堆栈来删除基础架构｡
当你删除一个CloudFormation堆栈时，
所有作为CloudFormation堆栈的一部分创建的东西也将被删除｡
所以这意味着我们将有一个干净的石板｡
但这样做的好处是，我们能够启动一个测试环境，
针对它进行测试，然后删除该测试环境｡
就像什么都没发生一样，
这就是云关联的力量｡
因此，如果我们删除堆栈，
就可以部署到生产环境｡
通过部署到生产环境，我们可以在创建更新时再次使用CloudFormation，
但这次不会创建堆栈｡
当然，它将更新现有堆栈以部署新的应用程序版本｡
以上就是您所看到的CloudFormation是如何与代码管道一起使用的｡
我希望你们喜欢，
我们下节课再见｡
  - [ ] 209 CodeDeploy Overview [08:30]
    * 
教师：好的，现在我们来讨论AWS CodeDeploy｡
我们的想法是，
随着时间的推移，我们希望将应用程序自动部署到许多实例｡
因此，从应用程序服务器的版本1一直到版本2｡
现在，请注意，
这些EC2实例不是由Elastic Beanstalk管理的，好吗？
这可以是EC2实例或仅在其自身运行的内部部署服务器｡
因此，您可以通过多种方式将应用程序部署到这些服务器上｡
他们可能会使用一些开源工具，例如，
Ansible､ Terraform､ Chef､ Puppet，它们太多了｡
但我们也可以使用AWS的托管服务AWS CodeDeploy｡
那么，CodeDeploy如何工作呢？
例如，我们可以将其部署到EC2实例或内部部署服务器，这将是我们的第一个用例｡
他们都必须运行CodeDeploy代理，
这是非常重要的，考试将测试你｡
因此，
让我们以EC2实例和内部部署服务器为例，它们都运行CodeDeploy Agent｡
那么，作为开发人员，流程是什么？
我们将把代码推送到Amazon S3或GitHub中，
这就是修订位置.
现在，我们知道，我们通常会将代码推送到CodeCommit，
这是真的，我们可以将其推送到CodeCommit，构建它，但构建的构件，
即将部署的代码构件，
必须存储到Amazon S3或GitHub中｡
我们有了源代码，正如你所看到的，在我们的源代码或构建代码上，
我必须说，还有另一个名为appspec的文件｡
yml的｡
和应用规范｡
正如我们将在本课中看到的那样，我们将使用yml来告诉CodeDeploy如何部署我们的应用程序｡
好的，
开发人员在将代码推入修订位置后，将触发CodeDeploy，并说，
“嘿，我们想要进行新的部署｡
“现在，
代理，同时他们一直在做的是，他们不断地要求和轮询CodeDeploy的工作要做｡
比如，“嘿，有什么我应该部署的吗？
“喂，是不是有什么需要我部署的？
“然后，很明显，
当我们在CodeDeploy中触发部署时，
就会有一些东西要部署，所以会发生的是应用程序，
也就是构建的代码和应用程序规范｡
yml文件，将从GitHub或Amazon S3中提取，
然后下载到应用程序服务器上，然后CodeDeploy
Agent将运行文件appspec的所有部署指令｡
yml的｡
然后进行部署，
所有关于部署成功或失败的报告都将从代理报告回CodeDeploy服务，这是CodeDeploy的高级工作方式｡
现在，CodeDeploy有许多组件，
所以我们有一个应用程序，它有一个唯一的名称，并作为一个容器｡
因此，应用程序可能包含修订､
部署配置等｡
一个计算平台，那么它是EC2还是内部部署服务器，
这是一个计算平台，还是Lambda函数，
还是ECS容器？
然后是部署配置，这是一组成功和失败的部署规则｡
因此，正如我所说，我们可以在内部部署到EC2，这样我们就可以指定部署所需的健康实例数量，
或者对于Lambda或ECS，我们可以指定流量将如何路由到您的更新版本｡
接下来是部署组｡
因此，我们可以按组标记EC2实例，
以便逐步部署，或者在EC2目标中包含一个开发组､
一个测试组和一个生产组｡
部署类型，
这就是我们要将应用程序部署到部署组的方式，因此我们有就地部署，支持EC2和内部部署｡
我们有绿色部署，
它只支持EC2实例，因为它们将利用负载平衡器，但我们也可以对Lambda或ECS进行蓝绿色部署｡
在这节课上，我将向你们展示原位和绿色之间的区别｡
然后我们有了IAM实例配置文件，
那么我们要给予EC2实例哪个配置文件，以允许它们从Amazon S3或GitHub访问我们的可部署代码？
应用程序修订是应用程序代码和appspec的组合｡
yml档案｡
服务角色是我们附加到CodeDeploy服务本身的角色，用于对EC2实例､
ASG､
ELB等执行操作，例如，如果我们使用蓝绿色部署｡
最后，目标修订版是我们要部署到特定部署组的修订版｡
现在，
您只需要熟悉这些术语，我们将在实践中再次查看这些术语，因此，
请花些时间来理解它们，当您看到实践时，它们会变得非常直观｡
好的，这个应用程序规范｡ yml文件是超级重要的｡
例如，它包含了如何将代码部署到服务的说明，因此该文件应该再次位于代码的根目录中｡
第一个块是文件块，用于获取一些额外的文件，例如，从Amazon
S3或GitHub到文件系统，因此我们有源和目标｡
钩子将包含实际部署应用程序的所有步骤，因此指令集;因此我们有“应用程序停止”､ “下载捆绑包”､
“安装前”､ “安装”､
“安装后”､ “应用程序启动”，
然后是“验证服务”｡
这些都是我们可以添加一些特殊代码或指令以运行CodeDeploy的步骤｡
因此，您可以在右侧看到，BeforeInstall､ AfterInstall､
ApplicationStart和ValidateService是已指定的内容｡
同样，这些可能是在CodeDeploy执行其任务时要运行的脚本或要解压缩的内容｡
现在，重要的部分是ValidateService是我们在最后运行的，以确保我们的服务正确部署到EC2实例上，因为如果它没有正确部署，
我们可能会失败｡
因此，ValidateService可以检查应用程序是否在工作，
然后CodeDeploy将向CodeDeploy服务报告，“嘿，我们可以开始了｡
“应用程序已成功部署｡
“那么，满怀希望地希望这一切都有道理｡
因此，
ApplicationStop发生在应用程序停止时，因为我们要进行部署，然后所有其余步骤也应该非常直观｡
这就是顺序，请看一下，
并确保您熟悉它，但它们应该很有意义，这是您可以直接从CodeDeploy服务UI中看到的内容｡
因此，对于部署配置而言，它非常重要，
因此我们有不同的选项;因此，当您部署到EC2实例时，
您可以一次执行一个操作，
一次启动和关闭一个EC2实例，如果部署失败，我们应该立即停止它｡
一半的时间是我们将一半的EC2实例从版本1升级到版本2，然后再将另一半或全部的EC2实例从版本1升级到版本2，这样做非常快，
但不会有正常运行的主机，也会有一些停机时间，
我想这对开发环境来说是件好事｡
和自定义，
在那里你可以指定，例如，我想要至少75%的我的健康主机在任何时间点｡
对于失败，我们可以说，“嘿，我应该遇到多少次失败“，
然后才能说整个部署是失败的？
“因此，首先，
如果您有一个EC2实例出现故障，
它将保持故障状态，
然后，
如果您执行新部署，将获得此部署的第一个实例将是处于该故障状态的实例｡
如果您想要回滚，那么您需要重新部署旧的部署，或者启用故障自动回滚，
我们也将看到这一点｡
还有部署组，我们在前面的定义中已经看到了，它是一组标记的EC2实例，
也可以是一个ASG，或者也可以是标记和ASG的混合，
在部署到部署组时具有部署段｡
最后，
您可以在脚本中进行一些自定义，方法是指定“部署组名称”环境变量以标识您所在的部署组｡
那么，什么是一次半就地部署呢？
我们有V1，
我们将关闭其中的一半，然后转到V2，关闭另一半，
并将它们升级到V2，这就是就地部署的样子｡
另一种类型是绿色部署，让我们举一个例子｡
因此，
我们必须有一个自动扩展组和一个应用负载平衡器，它们都在V1中｡
然后，
在V2，将在另一个自动扩展组上启动其他应用程序｡
一旦全部测试完毕，ALB将重定向到版本2上新的自动扩展组的目标组｡
假设它可以部署，
我知道这可能需要很多信息，但实际操作会更有意义，希望您能获得所有信息｡
别担心，本课程将详细讲解所有内容，
您应该不会有问题｡
好了，就这样，我们下节课见｡ 
  - [ ] 210 CodeDeploy [12:15] Hands On
    * 
  - [ ] 211 CodeDeploy for EC2 and ASG [02:46]
    * 
让我们再了解一些CodeDeploy的概念｡
因此，当我们处理EC2实例时，我们将使用appspec｡
yml，然后是部署策略｡
例如，我们可以对您的EC2实例群进行就地更新，然后我们可以使用钩子｡
我们将它们设置在专家Hemel中，以便在每个部署阶段后验证部署｡
我们一次吃一半｡
所以其中一半会被取下，然后升级到第二版｡
另一半会被拿下来｡
我有你的第二个版本，这是一个就地部署｡
现在，
对于ASG代码部署，部署稍微复杂一些｡
所以我们有两个选择｡
我们已部署到位，并提供蓝色/绿色｡
因此，在适当的地方，我们将做完全相同的事情，
我们之前看到的｡ 它将更新现有的EC2实例｡
如果您在ASG中自动创建新的EC2实例，它将通过CodeDeploy进行部署，
这非常好｡
所以这就是它与ASG的不同之处，ASG非常强大｡
这是就地部署，但我们也有蓝/绿色部署｡
在本例中，将创建一个新的自动缩放组，并复制设置｡
然后，我们可以选择保留旧EC2实例多长时间，
你这个旧ASG｡
然后，从一个目标群体转向另一个目标群体的ELB将崩溃｡
所以让我们树立榜样｡
这是我们的蓝色/绿色部署或ELB｡
我们在ASG内的启动模板V1上有EC2实例，然后CodeDeploy将把V1应用程序部署到这些EC2实例｡
现在，
如果我们要升级到版本2，则将创建新实例｡
然后，使用Launch
pad V2，CodeDeploy将应用程序部署到这些EC2实例｡
然后，ELB将接收来自V1和V2实例的流量，
例如，如果一切正常，则V版本1将被关闭，
我们将完成蓝/绿色部署｡
最后是重新部署和回滚｡
回滚是指当您要重新部署应用程序以前部署的修订版时，您希望及时返回，
可以通过两种方式回滚部署：可以是自动的，例如，当我们的部署失败时，
或者当我们的CloudWatch警报被触发并说“嘿，部署失败了”时，
也可以是手动的｡
如果禁用回滚，则不会对此部署执行回滚｡
好吗？
当回滚发生时，
CodeDeploy实际上会将上一个已知的正确修订版本重新部署为新部署，它不会及时返回｡
它实际上使用已知可进行良好部署的最后一个已知良好版本执行新部署｡
所以这不是复原版｡
这绝对是一个新的部署，这是考试可能会测试你的东西｡
这节课就讲到这里，非常理论化，但我知道，
但这对你们的考试会有帮助｡
我希望你们喜欢它，我们下节课再见｡ 
  - [ ] 212 [DVA-C02] CodeDeploy - Extras [01:16]
    * 
讲师：现在我们来讨论一下CodeDeploy的故障排除｡
如果你有一个部署，然后你得到一个无效签名异常的部署错误，
因为签名已经过期，并且这里有一个时间参考，那么，
这是因为CodeDeploy正在尝试部署，然后我们得到一个签名异常｡
这是一个问题，因为我们有一个时间问题，
这来自于缺少准确的时间参考｡
那么这意味着什么呢？
我们需要确保CodeDeploy上的时间（AWS的时间）和EC2实例上的时间（您设置的时间）一致，
例如，它可以与外部服务器匹配｡
因此，如果您的EC2实例或服务器没有正确的时间，
那么CodeDeploy将完全拒绝部署｡
这是因为时间非常重要｡
因此，解决这个问题的简单方法是确保您的EC2实例连接到与AWS同步的正确时间服务器｡
如果您在EC2实例上也有部署问题，无论是什么原因导致的失败，
您都可以在EC2实例上找到日志文件｡
因此，在斜线O-P-T CodeDeploy代理文件夹下，
您将找到代理的日志｡
好了，这堂课就到这里｡
希望你喜欢｡
我们下节课再见｡ 
  - [ ] 213 CodeStar - Overview [01:44]
    * 
教师：那么，让我们来谈谈CodeStar｡
CodeStar是一个集成解决方案的单一视图，
它将对我们之前看到的所有服务进行分组，例如用于存储代码的CodeCommit､
用于构建和测试代码的CodeBuild､ 用于部署代码的CodeDeploy､
用于供应基础架构的CloudFormation､ 用于编排整个管道的CodePipeline､ 用于监视的CloudWatch等等｡
这是所有这些工具的一个视图｡
现在有了CodeStar，很酷的事情是你只需点击，
点击，
点击说，“嘿，我想开始一个使用Python的EC2项目｡
“然后自动为你创建后端的所有这些东西｡
因此，将有一个CodeCommit, CodeBuild, CodeDeploy，
CloudFormation等，
这是非常方便的，如果你作为一个开发人员，只是想让事情的工作｡
CodeStar支持的语言，但它们可以随着时间的推移而发展，是C
Sharp, Go, HTML5，Java，
Node｡ js､ PHP､ Python和Ruby｡
现在在CodeStar中，它真的很酷，因为在它的顶部，
你有一个问题跟踪工具，
它与JIRA或GitHub问题集成，如果这是你用来跟踪你的问题｡
您还可以使用Cloud9工具在云中集成编码｡
你得到了一个web
IDE，所以web的方式来编码你的代码在云中直接｡
并非所有地区都有，但我将在实践中向您展示这意味着什么｡
正如我所说的，您可以通过一个控制面板查看所有组件｡
CodeStar是一项免费服务｡
您只需要为所有其他服务（如CodeCommit､ CodeBuild等）的底层使用付费，CodeStar不是集成视图｡
因此，
您对每个工具的自定义可能有限，但是因为每个工具都是CodeStar的基础，所以您仍然可以在它们自己的控制台中对其进行自定义｡
这节课就讲到这里｡
现在，让我们进入下一节课，
练习使用CodeStar｡
  - [ ] 214 CodeStar [06:52] Hands On
    * 
  - [ ] 215 [DVA-C02] CodeArtifact - Overview [06:01]
    * 
教师：好的，现在我们来讨论CodeArtifact｡
这个想法是当你构建软件的时候，你使用你自己的软件所依赖的其他软件｡
这称为代码依赖项｡
每次构建软件时，
通常都会将软件推送到存储库中，然后其他软件可以在其上构建｡
所以这是整个依赖关系，
整个依赖关系网络被称为工件管理｡
所以传统上，当你使用工件时，你建立你自己的工件管理系统，
这个想法是它可能会相当复杂｡
因此，使用CodeArtifact，您将获得一个安全､
可伸缩､ 经济高效的软件开发工件管理系统｡
CodeArtifact的功能不止这些｡
我将在图中向您展示这一点，
但它集成了常见的依赖性度量工具，
如Maven､ Gradle､
npm､ yarn､ twine､ pip和NuGet｡
这个想法是，使用CodeArtifact，
开发人员和CodeBuild都可以直接从AWS云中的CodeArtifact检索依赖项｡
我们来画个图，这样会更清楚｡
因此，使用CodeArtifact，
您的所有工件都位于您的VPC和AWS中｡
例如，有时候如果您使用其他工件管理系统，它们可能是AWS之外的第三方，
或者如果您部署自己的工件测量系统，它们可能存在于这两个实例上｡
在这种情况下，是的，当然它将在您的VPC中｡
因此，使用CodeArtifact，
您将定义域，每个域只是一组存储库｡
现在，作为一名开发人员，很酷的事情是，
您可以告诉开发人员，嘿，您需要，
例如，您的JavaScript开发人员运行npm命令，
以获取JavaScript包对CodeArtifact的依赖关系｡
CodeArtifact将成为公共工件库的代理｡
因此，不是让JavaScript开发人员自己直接访问公共构件库，
而是访问CodeArtifact, CodeArtifact将连接到公共构件库，请求将被代理｡
为什么要这么做呢，有两个原因，
第一，网络安全｡
因此JavaScript开发人员只与CodeArtifact交互，
CodeArtifact将把请求代理到公共repo｡
但是，当依赖项被获取时，它们将被缓存到CodeArtifact本身中｡
这意味着即使依赖项从公共工件存储库中消失，
您仍然可以在CodeArtifact中拥有自己的副本｡
这有助于确保您的代码在将来总是可以构建的｡
这不仅适用于JavaScript，也适用于带pip的Python｡
它适用于｡ net的NuGet技术和Java的Maven技术｡
好吗？ 所以所有这些东西都可以从CodeArtifact代理到这个自己的存储库中｡
但你能做的第二件事显然是推动你自己的工件｡
因此，您的IT主管或开发人员可以发布并批准将包推送到CodeArtifact内的其他存储库中｡
这意味着您所有的工件都将位于VPC中的一个位置｡
而且一切都依赖于一切，所有已经在CodeArtifact（工件管理系统）中的代码｡
如果开发人员可以从CodeArtifact中获得所有这些工件，
那么CodeBuild当然也可以｡
现在CodeBuild不再从公共存储库中获取信息，
而是可以直接从CodeArtifact中获取所有这些信息｡
接下来，CodeArtifact的更改如何触发AWS下游的一些东西？
稍后我们将详细介绍此服务，但CodeArtifact事件（例如创建､
修改或删除包时）将向EventBridge发出事件｡
EventBridge就像AWS中的事件存储库｡
通过EventBridge，您可以集成和触发许多不同的AWS服务，
例如Lambda函数､ Step函数､
SNS､ SQS｡
如果你现在还不理解这些话，没关系｡
我们将在本课程的稍后部分看到这些内容｡
还有，例如，CodePipeline｡
因此，无论何时更新包版本，CodeArtifact都可以通过EventBridge触发CodePipeline｡
我们为什么要这么做呢？
例如，CodePipeline可以有CodeCommit，
这样我们就知道依赖项已经更新了｡
然后触发CodeBuild使用更新的依赖项重新生成应用程序，
这可能是出于安全原因｡
最后使用CodeDeploy将新应用程序部署到生产环境中｡
因此，这可能是一种很好的自动化方法，
可以构建一个完全自动化的管道，
确保您的构建中的代码始终具有最新的依赖项｡
因此，您帐户中的任何构件存储库都可以由您帐户的用户或您帐户中的角色通过IAM策略轻松访问｡
但是，如果您想授权另一个帐户以及该帐户的用户和角色访问CodeArtifact，
则需要使用资源策略｡
因此，当您授予某人对CodeArtifact存储库的访问权限时，
将会发生的情况是，您要么授予他们对所有包的访问权限，要么不授予他们任何包的访问权限｡
您不能说只访问这些包｡
因此，当您授权另一个帐户访问您的回购协议时，
您就授权了帐户B中的Bob访问该特定回购协议中的所有软件包｡
为了让Bob访问您的帐户，您可以使用一个资源策略，
例如，在该策略中，您授权其他帐户的Bob读取您的代码构件存储库中的包｡
如果没有资源策略，就无法做到这一点，但这只是您在考试中需要知道的一个问题｡
但这是AWS中反复出现的话题｡
每当您有时需要跨帐户访问时（大多数情况下），
资源策略将是最佳选择｡
好了，这堂课就到这里｡
我希望你们喜欢，
我们下节课再见｡
  - [ ] 216 [DVA-C02] CodeArtifact - Upstream Repositories & Domains [05:54]
    * 
教师：那么，让我们更深入地了解一下存储库是如何工作的，
以及上游存储库的概念｡
因此，当您有一个代码构件存储库时，
您实际上可以有多个上游存储库｡
我们来举个例子｡
这里，储存库“my-repo”可以具有储存库A的上游和储存库B的上游｡
那么拥有上游意味着什么，
为什么它是有帮助的？
当你有一个上游存储库时，
任何试图访问你的基本存储库的包管理器，
也可以尝试在所有上游存储库中找到依赖项｡
但是，这样做的好处是，无论是谁连接到您的存储库，
都是针对您的开发人员的，
只有一个存储库端点，因此每个存储库最多可以有十个上游存储库｡
因此，这意味着我们将能够在存储库树中搜索正确的依赖项｡
现在，当你定义一个存储库时，你可以有一个外部连接，
并且每个存储库只能有一个外部连接｡
例如，
存储库A可以连接到一个外部存储库，
这被称为外部连接，它可以是公共的NPM存储库和我们获得的算法｡
我们得到的好处是，
通过连接到一个单独的repo，
我们不仅可以访问我们的私有依赖项，
还可以访问我们通过外部连接定义的任何公共依赖项｡
让我们再多讨论一下这些外部连接｡
因此，当您有一个外部连接时，
默认情况下它是您的一个存储库和外部公共存储库之间的连接｡
例如，对于Java世界，它可以是Maven，
对于JavaScript世界，它可以是NPM，对于Python世界，
它可以是PyPI，对于点网c-sharp世界，
它可以是掘金｡
因此，我们有机会将NPM连接到CodeArtifacts中的存储库，
称为外部连接｡
接下来会发生的是，
如果从NPM获取的包在回购协议A中不可用，那么我们将获取它，
并将其作为现金转移存储在回购协议A中｡
这就是为什么每个公共存储库最多只能有一个外部连接，
才能有一个完美的现金机制｡
但是如果你想拥有多个公共存储库，那么你可以在CodeArtifacts中拥有多个存储库｡
例如，这里我们想连接到npmjs｡ com，因此我们将在您的帐户中配置一个带有外部连接的存储库，
然后您帐户中需要从NPM获取的所有其他存储库可以只将存储库A定义为上游｡
现在我们有了这个，任何从NPM“js”获取的包都将在上游回购协议A中兑现，
然后回购协议B､ C和D将自动访问这些包｡
因此，作为开发人员，当您提取一个包时，
它将在repo A中兑现，然后直接发送到您的构建系统｡
那么在CodeArtifacts中保留这些工件的情况如何呢？
因此，如果您有一个请求的包，并且在上游存储库中找到了它，
那么对它的引用将被保留，并且始终可供下游存储库使用｡
然后，如果您以某种方式更改了上游存储库中的包，
它不会影响您自己在下游存储库中的副本｡
而且任何允许您获取该包的中间存储库都不能出于效率目的保留该包｡
我们来看看｡ 如果我们从npmjs拿一个包裹｡ com，但是为了到达那里，
我们有两个上游，将要发生的是，包管理器将要请求这个包｡
然后它不存在于三个存储库中的任何一个中，
所以它将被获取，然后它将被获取，
它将被保留在存储库A中｡
这是因为它是最下游的存储库，并且是我们从开发人员计算机连接到的存储库｡
存储库C也是如此，
因为它具有到NPM公共存储库的外部连接｡
所以我们将在其中保存一个副本，
仓库B将没有任何内容，因为它在这个链中被视为中间仓库｡
最后，看起来我们到处复制东西，所以我们有点复制包，
但现在是引入域的好时机｡
所以当你有了存储库，
你也可以引入域的概念｡
一个域可以跨越多个帐户和这些帐户中的多个存储库｡
当您有一个域时，实际上您为所有存储库定义了一个存储，
因此您需要消除重复存储，因为如果相同的依赖关系必须位于不同的存储库中，则它将在共享存储中的域中存储一次，然后只有对它的引用才会存储在您的存储库中｡
所以它非常高效｡
然后您可以看到，您可以创建任意多个上行连接｡
您还可以快速复制，
因为当您拉取存储库依赖项时，您只需创建一个对共享存储的新引用，
而不是复制它们｡
此外，跨团队共享域中的内容也非常容易，
因为您拥有相同的元数据､
相同的资产，并且使用相同的KMS密钥对所有内容进行加密｡
最重要的是，如果您想定义存储库访问策略，
您只需定义一个所谓的基于域资源的策略，
该策略将应用于域中的所有帐户和所有存储库｡
并且您可以定义高级规则，
例如谁有权设置和修改外部连接｡
好了，这堂课就到这里｡
我希望你们喜欢，我们下节课再见｡ 
  - [ ] 217 [DVA-C02] CodeArtifact [06:24] Hands On
    * 
  - [ ] 218 CodeGuru - Overview [03:22]
    * 
教师：现在我们来谈谈Amazon CodeGuru｡
这是一个由机器学习驱动的服务，它将做两件事｡
第一是自动化代码评审，第二是应用程序性能建议｡
因此，当开发人员推送我们的代码时，
通常会有另一个开发人员进行代码评审｡
然后，
当代码部署到生产环境中时，您需要能够监视代码的性能，也许您可以通过查看性能来检测错误｡
所以CodeGuru是以自动化的方式来做的｡
CodeGuru Reviewer是通过静态代码分析来进行自动化代码评审的｡
这就意味着当你把代码部署到一个存储库上时，比如CodeCommit或GitHub，
CodeGuru可以查看所有的代码行，然后在它检测到bug或内存泄漏或它以前见过的东西时，
给予你可操作的建议｡
所以，
由于这种机器学习能力，它甚至可以在其他审阅者检测到错误之前检测到错误，这是非常有帮助的｡
然后，CodeGuru
Profiler将在运行时或生产期间为您给予有关应用程序性能的可见性或建议｡
因此，当您构建和测试应用程序时，CodeGuru
Profiler已经能够检测和优化昂贵的预生产代码行｡
然后，当您部署应用程序时，
您将真实的测量应用程序，CodeGuru Profiler将再次确定生产中的性能和成本改进，
并直接在代码中为您给予这些建议｡
这就是CodeGuru的全部力量｡
所以如果我们深入研究，CodeGuru
Reviewer会真正查看你的提交，所以每当你推送代码时，它会告诉你哪些代码行可能是错误的，
所以它会非常非常方便，所以你可以识别关键问题､ 安全漏洞和难以发现的bug｡
因此，例如，
您可以实现编码最佳实践，
您可以发现资源泄漏，在创建安全漏洞时进行安全检测，或者进行输入验证｡
它的方法是使用机器学习和自动推理｡
它是怎么做到的呢？
CodeGuru分析了数千个开源库中的代码评论，以及所有亚马逊网站上的代码评论｡
所以这就是它如何通过机器学习学习成为一个代码评审员｡
它目前支持Java和Python，
并与GitHub､ Bitbucket和CodeCommit集成｡
别引用我的话｡
也许事情会随着时间的推移而演变｡
如果它真的发生了变化，也不用担心：你不需要知道那么多细节｡
只需了解CodeGuru､ CodeGuru Reviewer以及CodeGuru
Profiler即可｡
因此，Profiler是指应用程序处于生产或生产前阶段时的情况，它有助于了解应用程序的运行时行为，
并查看哪些方面（例如，日志记录例程）会消耗过多的CPU容量｡
因此，它将允许您识别并消除代码效率低下的问题，
提高应用程序性能，例如，
降低CPU利用率，
降低计算成本，提供堆摘要以识别哪些对象占用了大量内存空间，
以及异常检测，以防应用程序行为异常｡
它还支持将在AWS云上运行的应用程序，甚至支持内部部署的应用程序｡
而且，使用CodeGuru
Profiler监视应用程序的开销也会很小｡
这节课就讲到这里｡
只要再一次记住CodeGuru､
CodeGuru Reviewer和Profiler的高级别，您就应该可以开始了｡
我们下节课再见｡ 
  - [ ] 219 [DVA-C02] CodeGuru - Agent Configuration [01:38]
    * 
教师：代码大师分析器的功能要归功于代理，
我们可以配置代理来对其进行微调｡
第一个是MaxStackDepth｡
这就是概要文件中要表示的代码量｡
例如，如果你有一个方法A，然后方法A调用方法B，
方法B编码方法C，然后编码方法D，那么我们把它算作深度4｡
因此，如果您将MaxStackDepth设置为2，
那么分析器只会评估和分析方法A和方法B｡
所以记住这一点很重要，
因为如果你想深入研究，
就需要增大这个参数｡
Memory usage limit percentage是允许探查器使用的内存量｡
Minimum time for reporting（毫秒）是发送报告之间的最短时间｡
当然，您可以增加报告间隔（以毫秒为单位），
它将受到最小值的限制｡
因此，以毫秒为单位的报告间隔告诉代理报告其已完成的分析的频率｡
我们还有以毫秒为单位的采样间隔｡
所以这很重要｡
这是用于分析样本的采样间隔｡
因此，如果将其设置为较低的值，则会获得越来越多的采样，
从而获得较高的采样速率｡
所以你可能会捕捉到更多的函数或方法被调用｡
当然，您不必记住所有这些，
但刚才看到了它的名称，如果它在考试中出现，
您应该能够理解此设置如何影响代码大师代理，然后您可以在考试中正确回答问题｡
好了，这堂课就到这里｡
我希望你们喜欢，我们下节课再见｡ 
  - [ ] 220 [DVA-C02] AWS Cloud9 - Overview [01:23]
    * 
导师：现在，我们来谈谈AWS Cloud9｡ Cloud9是一个非常简单的服务｡
它提供了一个IDE，
也就是一个基于云的集成开发环境｡
这意味着您可以直接使用Web浏览器访问Cloud9
IDE｡
所以你有了一个代码编辑器，一个调试器，
甚至在你的浏览器里有了一个终端｡
例如，与在计算机上运行IDE相比，
这有什么好处？
好吧，如果它在云端，
那么你可以在世界上任何地方进行你的项目，
只要你有一个互联网连接到Cloud9｡
除此之外，它还预先打包了您需要的所有基本工具，
适用于流行的编程语言，如JavaScript､ Python､
PHP等｡
所以这个想法是，你真的必须从你的本地机器上删除安装程序，
而你在云上做所有的事情｡
现在你已经有了关于云的想法，
它的好处是你可以开始和你的团队共享你的开发环境，
并且你可以启用结对编程｡
你可以看到有人在你写代码的同时也在写代码｡
除此之外，您还可以将Cloud9与AWS
SAM和Lambda完全集成，
轻松构建无服务器应用｡
所以这很简单，当你参加考试时，
你看到一些关于基于云的代码编辑器的东西，
考虑一下Cloud9｡
好吧，就这样｡
我希望你们喜欢，
我们下节课再见｡
  - [ ] 221 [DVA-C02] AWS Cloud9 [04:09] Hands On
    * 
  - [ ]  AWS CICD [22 问题] Quiz
    * 
 ## Section 19 - AWS CloudFormation [16 个讲座 • 1 小时 6 分钟]
  - [ ] 222 AWS CloudFormation - Section Introduction [00:40]
    * 
既然我们知道了如何以正确的方式自动部署应用程序，
现在我们应该后退一步，了解一下非常重要的基础结构概念，即代码基础结构，即使用确认完成的代码地址｡
确认其实是我最喜欢的话题之一，考试中我们会问你很多问题，但这一部分的水平相当高｡
我会给予你们一个高度的确认，但我们也会练习一下｡
只是感受一下事情是如何运作的｡
你实际上并没有意识到，但是你在使用弹性豆茎的时候一直在使用确认｡
让我们深入了解这一部分，了解发生了什么｡ 
  - [ ] 223 CloudFormation Overview [07:06]
    * 
我们即将进入CloudFormation的精彩部分，CloudFormation是AWS中我最喜欢的主题之一｡
这是我可以讲上几个小时的东西，但我会尽量让它简短，
为你和这次考试｡
那么基础设施作为代码，它是什么呢？
目前我们做了大量的手工工作｡
我们一直在做手动工作，我们已经使用Elastic
Beanstalk实现了一点自动化，
我们已经设置了管道，以便能够使用CodeBuild等自动化我们的CICD｡
和代码管道｡
但是，我们一直在做的所有这些手工工作都坚韧复制，
如果我们想在另一个地区复制，我们又来了，我们到处点击，
这有点无聊｡
如果你想在另一个AWS账户上做，那会更痛苦，
或者即使有人在我的公司里删除了所有东西，对我来说，在我的地区重新创建所有东西将是一场噩梦｡
所以我们真正想要的是我们的基础设施是代码｡
这是一个新概念，
也是一个相当新的现象，是IT世界中的一个新趋势，称为基础架构即代码｡
这意味着我们要编写的代码将能够部署它，它将依次创建､ 更新和删除我们的基础架构｡
这就是CloudFormation的用武之地｡
CloudFormation将成为概述AWS基础设施的声明性方式，适用于任何类型的资源，其中大多数都是受支持的｡
例如，让我们以一个高级伪CloudFormation模板为例，
我需要一个安全组，
需要两台使用该组的EC2计算机，需要这些计算机的两个弹性IP，需要一个S3存储桶，
顺便说一下，我需要一个连接到这些计算机的负载平衡器｡
我们以声明的方式说，
这是声明性的，我们希望CloudFormation做什么，然后CloudFormation按照正确的顺序为我们创建所有这些东西，
并使用我们指定的确切配置，这是一种很好的方式｡
CloudFormation的优势之一是我们将基础架构作为代码获取，因此无需手动创建任何资源，这非常有利于控制，
但我想您对此已经有了很好的了解｡
所有的代码都可以进行版本控制，例如使用git，这样我们就可以对CloudFormation进行版本控制，
这很好｡
而且，
对基础架构的所有更改都将通过代码审查进行审查，这也是非常好的｡
就成本而言，CloudFormation本身是免费的，
但您创建的每个堆栈都有一个标识符，因此您可以轻松跟踪堆栈的成本，并且可以使用CloudFormation模板本身估计资源的成本｡
因此，
如果您希望在开发环境或小型AWS帐户中使用CloudFormation实现节省策略，您可以在下午5点自动删除所有模板，然后在上午8点安全地重新创建模板，
这样，由于您的基础架构是代码，所有内容都会恢复，从而保存大量资金｡
CloudFormation的其他优势是提高工作效率，这样您就可以根据需要随时销毁和重新创建基础架构｡
您可以自动为模板生成图表，如果您创建演示文稿，这是非常好的｡
它是声明性编程，
所以你不需要弄清楚什么在什么之前，在排序或编排方面，CloudFormation会跟踪并为你做这些｡
此外，还实现了真正的关注点分离，因此您可以根据需要为许多应用和许多层提供任意多个堆栈，
因此，使用VPC
CloudFormation堆栈将所有网络创建到子网中是非常常见的｡
有一个应用程序堆栈，因此对于您要部署的每个应用程序，都将有一个应用程序确认堆栈，这是我们实际上已经在Elastic
Beanstalk中看到的东西，每次我们在Elastic Beanstalk中创建环境时，
它都会在后台创建CloudFormation模板｡
我们的想法是，我们希望重用尽可能多的工作，
所以我们不打算重新发明轮子，有很多的CloudFormation模板在网上，我们已经可以利用｡
我们还可以利用文档，顺便说一句，
文档很大，有时很难导航，
但文档中包含了您所知道的一切｡
那么，CloudFormation是如何工作的呢？
我们将在后台在AmazonS3中上传模板，CloudFormation将从S3中提取模板，因此，当我们想要更新模板时，
我们实际上无法编辑以前的模板，我们将在下一节课中看到它，
我们需要做的是将模板的新版本重新上传到AWS，
然后CloudFormation将执行不同的操作，并计算出从版本1更新到版本2需要执行的操作｡
堆栈将由一个名称来标识，
名称可以很长，如果你删除每个神器的堆栈，任何通过CloudFormation堆栈创建的东西都将随之删除｡
这真的很好，因为你可以删除所有这些资源，已经创建了一个点击，
所以你可以肯定，你没有留下任何东西｡
现在要部署CloudFormation模板，有一种手动方式，我们可以编辑模板并执行CloudFormation设计器，
使用控制台输入参数;还有一种自动方式，即使用文本编辑器编辑YAML文件中的模板，然后使用Amazon
CLI或命令行界面部署模板｡
当你想让你的流程自动化时，这是推荐的方式，但是你可以自由选择手动或自动化，
我认为它们都很好｡
在构建模块方面，您将在本节中了解很多｡
但还有模板组件，
因此我们将获取资源，这些资源基本上是我们将在模板中声明的AWS资源，这必须是必填部分，
如果不指定资源，CloudFormation模板将无法工作｡
因此，资源可以是EC2机器､ 弹性IP､ 安全组､
负载平衡器，
等等，所有你能想到的东西｡
和参数，所以这些都是动态输入，你可以要求你的模板，
所以用户只会引用那些｡
映射，它是模板的静态输入，静态变量｡
输出，基本上是说，
好了，我们的模板，我们可以导出一些东西，
其他模板可以引用它｡
条件语句是一个条件列表，所以if语句基本上控制创建什么｡
总体而言，我们将深入了解所有这些元数据，所以不要太担心，
您将在适当的时间了解它们｡
对于模板，你可以得到助手，所以你可以使用引用，
这样你就可以在模板中链接你的东西，你可以使用函数来转换模板中的数据｡
所以我会再次回顾，但我只是想给予你这个101｡
现在，这是对CloudFormation的介绍，
对我来说，正确学习和掌握CloudFormation需要3个多小时，而且我确实在其他地方教过书，所以这一部分实际上是为了让你对它的工作原理有一个很好的了解，
但不要钻得太深，因为考试不需要它｡ 因此，我们的实际操作比其他部分稍微少一些，但实际操作仍然足够，
因此您可以很好地了解工作原理｡
我们将学习所有内容来回答考试的问题，
所以不要担心这个问题，考试不要求你实际编写CloudFormation，它主要会问你应该使用什么功能来执行x，
y, z，所以你应该没事｡
所以考试要求你们理解如何阅读，这门课我们会读很多｡
以上是对云形成的简短介绍，下节课我们会用一个小例子来了解它的工作原理，
下节课再见.
  - [ ] 224 CloudFormation Create Stack [06:08] Hands On
    * 
  - [ ] 225 CloudFormation Update and Delete Stack [07:30] Hands On
    * 
  - [ ] 226 YAML Crash Course [03:36]
    * 
教师：YAML是我们在美国使用的许多类型的语言｡
也适用于云形成｡
所以CloudFormation支持YAML和JSON｡
这些基本上是一些脚本语言或数据语言，你可以用它们来构建云｡
老实说，
我会非常非常诚实地告诉你，JSON对于CloudFormation来说绝对是非常糟糕的｡
它是不可读的，也是不可写的｡
YAML在很多方面都很棒，这是考试时要用到的语言，给你们展示一些CloudFormation模板，
这是我到目前为止一直在用的｡
让我们来了解一下｡
尽管我们已经接触过它很多次了，但我认为现在是时候正式确定YAML是如何的了｡
这是一个YAML文件｡
YAML文件有很多键和值，
它们被称为键值对，对我来说，它们是非常可读的对象｡
好的，在左手，
我们可以看看它，如果我问你，发票号码是多少？
你不需要是一个天才告诉我，发票号码是34843，所以这是伟大的｡
我告诉你日期是什么，你也可以告诉我日期｡
如果我问你，嘿，
我们订购的产品数量是多少？
您可以查看产品，
然后查看产品内部，这是一个数量列表，我们有四个和一个｡
你明白了吧？
使用YAML，
我们可以在顶层拥有键值对，但也可以拥有嵌套对象｡
它支持阵列，
所以如果我们看一下产品，您可以看到这里有一个小减号，它表示阵列，因此产品是一个SKU､
数量､ 说明等的阵列｡
然后我们可以看一下，例如，bill-to，其中有一个嵌套对象，
称为given
Chris､ family､ Dumars，
地址中也有一个嵌套对象，称为lines､
city､ post state和postal｡
如果我们看一下行，我们可以看到有一个多行字符串支持，所以我们在这里有一个小的竖线，
这被称为多行字符串，
所以我们可以很容易地通过YAML添加多行字符串，我们还可以包括评论，虽然它们没有在这个页面上显示｡
所以YAML对我来说是一种很好的阅读和写作的方式｡
显然，一些YAML文件可能相当复杂，
但总体上我们了解了这个想法｡
如果我们看一下我们拥有的云阵，让我们看一下一个简单的云阵｡
我们可以看到这个我们有一个YAML文件｡
第一个顶级键是Resources，然后是第二个嵌套对象MyInstance，其中包含更多嵌套的内容，如Type和Properties，
而Properties再次嵌套为键值对｡
如果我们看另一个，我们可以看到我们有参数顶层，资源顶层，
更多嵌套的东西，如果我们看安全组，因为这里有一个小减号，
它是一个列表，所以我们有一个我们在这里定义的安全组列表｡
第一个安全组和第二个安全组｡
所以我们可以浏览这个模板，
并真正理解它看起来像是我们可以阅读这个YAML模板，只需要使用我们之前学过的小概念｡
我鼓励您上网学习更多关于YAML的知识，甚至练习将JSON文档转换为YAML｡
但总的来说，这是我认为相当容易阅读的东西，你真正应该理解的是，
你可以嵌套由列分隔的对象｡
你得到键和值，然后用减号，你可以分配一个列表｡
YAML就这样了｡
我希望这对你们来说更有意义，我们下节课再见｡
  - [ ] 227 CloudFormation Resources [06:27]
    * 
教师：我们来谈谈资源｡
因此，
资源是CloudFormation模板的核心，它们是强制性的｡
如果没有资源块，CloudFormation模板将无法工作｡
正如名称所示，这些资源代表了不同的AWS组件——这只是一个同义词——它们将被创建和配置｡
而且资源是声明的，它们可以相互引用，
所以你可以把资源链接在一起｡
例如，您可以链接安全组和EC2实例｡
AWS将为我们计算出资源的创建､
更新和删除，这是超级好的，你应该知道有超过224种类型的资源｡
所以我不能全部教你，对吧？
但任何资源都有以下形式｡
它们是AWS，
然后是产品名称，然后是数据类型名称｡
所以通常，你要阅读这个标识符变量，
以确定我们要创建什么｡
那么，我如何找到所有这些资源文档呢？
好吧，有一个很棒的链接，
上面有所有的资源，
所以我不能教你所有的资源，但我可以教你如何找到一个链接，显示它们，然后你就可以阅读文档｡
例如，
我们将一起阅读EC2实例的文档，只是为了了解它｡
我给你参考的第一个网页叫做AWS资源类型参考，它包含了CloudFormation支持的所有参考｡
这里是资源命名约定，如果您向下滚动，
可以看到有很多资源｡
老实说，你可以数他们，太多了｡
因此，我们可以看到，
我们可以为几乎所有的东西创建一个资源｡
让我们向下滚动，看看是否有我们知道的东西｡
是，自动缩放｡
我们知道如何创建自动缩放组｡
我们能够通过此CloudFormation资源创建自动扩展组､ 扩展策略､
启动配置｡
如果我们向下滚动，就可以执行代码构建､ 代码提交､
代码部署和代码管道｡
所以所有这些我们以前见过的事情，我们都能做到｡
如果向下滚动，我们可以看到EC2实例､
弹性IP和安全组｡
让我们看一下EC2实例，因为我认为这是我们最熟悉的一个实例｡
因此，AWS EC2实例会创建一个EC2实例｡
因为这很明显｡
现在，
基本上我们可以向下滚动，查看如何声明此EC2实例的语法｡
我们有一个JSON表单，对我来说有点难读，但是向下滚动，
我们得到了YAML表单，对我来说清楚多了｡
这是EC2实例的YAML表单｡
它的类型必须是AWS EC2，然后是实例，
并且它将具有一些属性｡
所以当你创建资源的时候，
必须有类型，必须有属性｡
而属性将是键值对｡
正如您在这里看到的，您可以为EC2实例自定义很多东西｡
例如，如果你想自定义IamInstanceProfile，
我们点击这个，我们会被传送到那个文档，它说，好的，
你需要一个字符串｡
这不是必需的，
如果你更新了这个，就不会中断｡
这意味着您的EC2实例不会被终止和重新创建｡
它只会将实例概要文件附加到该文件｡
但是，
如果我们更改ImageId，例如，它也是一个字符串，
但不是必需的，那么，如果我们更新它，它基本上会进行替换｡
这意味着它将终止旧的实例，并用新的实例替换它｡
让我们向上翻一翻｡
因此，我们了解到有很多东西可以定制｡
要知道我们应该指定什么，我们应该查看文档｡
现在，我们来看一下之前创建的内容，
以EC2为例，
我们有一个AvailabilityZone､ 一个ImageId和一个Instance Type｡
基本上，我知道如何填写这些内容，因为如果单击AZ，
您会看到必须指定实例所在的AZ的名称｡
所以这是非常棒的，
你可以继续这样做，只要你想｡
现在我们基本上了解了它是如何产生的｡
为了好玩，您可以查看此处的资源，看到我们有一个EC2实例，但也有一个EIP，
如果我们查看EIP，
那么让我们返回上一页，然后在此页面上搜索EIP｡
好了，我们有了EIP｡
这里我们可以看到语法要短得多｡
我们有一个InstanceID和一个域｡
所以InstanceID是我指定的，而Domain我没有指定｡
因此，当我们回到我们的EIP时，我们可以看到，是的，
这是有道理的｡
我确实将类型指定为AWS EC2 EIP，
并且就属性而言，我仅指定了InstanceID｡
我们马上就知道裁判的意思了，好吗？
但是，我们的想法是，
我们能够将文档与我们想要做的事情联系起来｡
显然，对于安全组，
我们需要为入口流量提供安全组规则，
因为我们可以有许多规则，它们是一个数组，所以让我们查看安全组文档来证明这一点｡
安全组就在这里，我们去YAML｡
如果我们查看SecurityGroupIngress，我们可以看到这是Amazon EC2组规则的列表｡
因此，如果我们单击EC2 Group
Rule（EC2组规则），
然后单击它，我们将转到YAML，我们将获得所有可用的参数｡
回到语法，
我们在这里得到了一个小连字符，它定义了一个数组｡
这是第一条规则，这是第二条规则｡
因此，
我们从中得到的是，我们通过UI配置的所有内容都可以作为代码写入到CloudFormation模板中，这就是如何编辑CloudFormation模板的方法｡
这就是资源｡
你只需要知道这些就够了｡
只要记住有一个类型，
有属性，所有这些都在称为资源的块下面｡
因此，
每次声明资源时，您都需要想象在Resources下面有一个小缩进｡
现在是资源的常见问题｡
我可以创建动态数量的资源吗？
不，你不能｡
所有CloudFormation都必须声明，因此您无法执行代码生成｡
您不能有动态类型的程式码产生｡
是否支持所有AWS服务？
答案几乎是否定的｡
只有一些小的问题还没有解决，您可以使用AWS
Lambda自定义资源解决这个问题｡
这里有一点小问题｡
你只需要知道它｡
在本课程中，我们不会向自定义资源Lambda写信｡
以上就是资源，希望您喜欢｡
希望现在能更有意义，我们下节课再见｡
  - [ ] 228 CloudFormation Parameters [04:59]
    * 
现在我们已经看到了资源，第二重要的是参数｡
而参数是一种向AWS CloudFormation模板提供输入的方式｡
如果您想在公司或其他客户或地区重复使用模板，了解这些信息非常重要｡
而且有些输入不能提前确定｡
例如，要链接到实例的保留区域｡
参数是非常强大的，它们可以被控制，并且它们可以防止错误发生在你的模板中，
这要归功于类型｡
因此，我们之前在第一次操作中使用了参数，在第一次操作中，
我们基本上必须指定安全组描述｡
因此，它是一个字符串，我们被要求提供安全组描述，
这在安全组本身中使用｡
因此，
当您问自己“这个CloudFormation资源配置“将来是否可能更改时，应该使用该参数｡
“如果是这样的话，你可以把它做成一个参数｡
通过将其作为参数，您不必重新上载模板来更改内容｡
它更稳定，也更模块化｡
如果你做编程，
我希望你做，你知道参数的好处｡
现在，参数可以有不同的设置，
并且可以通过许多不同的方式进行控制｡
我不认为考试要求你知道所有这些，
但是，为了我，为了你的兴趣，我只想说出它们｡
您可以有类型化字符串､
数字､ 逗号分隔列表､ 类型列表和AWS参数｡
至于描述，你可以有约束，你可以有ConstraintDescription，字符串的最小和最大长度，
数字的最小和最大值，
你可以有默认值，当你想限制用户可以选择的值的数量时，
你可以有AllowedValues，当你想使用不规则表达式验证用户的输入时，你可以有AllowedPattern，
如果你想传递秘密的话，你可以有NoEcho｡
因此，您可以执行许多不同的优化和参数｡
现在，我们所做的唯一一件事就是在我们的东西中使用一个简单的字符串参数，
这就是我认为在考试中你们应该知道的全部内容｡
那么，如何引用参数呢？
好了，像这样你必须使用函数称为Ref｡
这是我们第一次遇到Ref和函数，但是基本上，模板中有趣的函数可以让你把它放大，
把东西联系起来｡
Ref函数是最常用的函数之一，所以你可以用它来引用参数，这样你就可以在模板的任何地方使用参数，
也就是在资源中，
用于任何类型的输入，参数和配置｡
所以，YAML中引用函数的简写是一个小感叹号Ref｡
这就是为什么，这只是一种方法，让我们有一个更好的语法，
更容易识别｡
你也可以在Ref中使用FN列调用，它是你想要的任何东西，但最有可能的是，
它将是这个感叹号Ref，用于速记｡
并且该函数还可以用于引用模板中的其他元素｡
因此，在我们一直使用的模板中，在参数部分，
我们必须找到参数名称安全组描述｡
如果我们一直向下看，就会发现安全组描述用于此安全组描述键，因此我们使用Ref函数来引用它｡
所以，
这个Ref函数基本上是说，“无论用户将把什么作为参数值，“对于这个参数键，
你要使用这个，“在组描述中引用它｡
“所以，这件事想起来很简单｡
只是个参考｡
但是这个引用函数也可以用在其他地方｡
例如，这里就使用了它来表示安全组，因此您可以看到，
此引用函数还引用了在参考资料下创建的SSH安全组｡
因此，Ref函数既可以像前面的函数一样用于引用参数，
也可以用于引用资源｡
因此，
在这里我们引用了两个安全组，在EIP中，我们引用了MyInstance｡
因此，正如您所看到的，引用的名称与Resources下的逻辑值的名称完全相同｡
最后，您可以了解伪参数的概念，这些是我们可以使用的AWS提供参数，
它们在默认情况下随时启用，我们只会得到您可能想要检索的一组值｡
我们可以得到一个帐户ID，你可以只给予我们帐户ID的值，通知ARN，
如果我们不想返回值，就不给值｡
我们还可以询问运行CloudFormation模板的地址所在的区域，例如US-east-2｡
我们还可以为Stack ID或Stack名称获取一个伪参数｡
基本上，你不需要对这些了解太多，也许第一个｡
如果您要在CloudFormation模板中构建一些复杂的ARN值，那么获取帐户ID值的帐户想法非常重要｡
但总的来说，你应该知道伪参数的概念，你可以随时使用它们，只要使用一个Ref，
你就可以了｡
我希望这对你们有帮助，
我希望你们知道它们现在是如何在你们的CloudFormation模板中工作的，我们下节课再见｡
  - [ ] 229 CloudFormation Mappings [02:53]
    * 
画外音：现在我们来谈谈映射｡
映射是CloudFormation模板中的固定变量｡
它们必须是硬编码的｡
如果您需要根据所处的不同环境对某些值进行硬编码，它们非常方便｡
因此，开发与
产品或区域，如AWS区域或AMI类型等...
正如我所说的，所有的值都必须在模板中显式地写出来｡
作为示例，这里有一个映射｡
这是你写的｡
我们有一个映射部分｡
然后您就有了映射的名称｡
那你就有钥匙了｡
下面是键的代码名称和值｡
所以这是一个相当低级的架构类型｡
为了使其更具体，我们可以有一个RegionMap来将区域映射到AMI｡
所以我们说，好吧，你在美国东一号，美国西一号，或欧洲西一号｡
取决于您选择的是32位还是64位类型的体系结构｡
这是您应该使用的AMI ID｡
总的来说，
这只是一个硬编码，根据运行模板的位置，这就是我要使用的AMI｡
那么什么时候使用映射和参数呢？
当你事先知道所有可以取的值时，映射是很棒的｡
例如AMI ID｡
你可以从地区､
AZ､ AWS账户､ 环境等变量中推导出来...
你能想到的都行｡
对我来说，它们允许对模板进行更安全的控制｡
但是如果您需要这些值是真正用户特定的，
那么用户应该输入一个值，而您事先不知道它可以是什么，那么您应该使用参数｡
现在要访问映射值，有一个名为Fn的函数：在地图中查找｡
基本上，它会从特定的索引键传回值｡
下面是一个简短的语法｡
我们使用FindInMap并加上一个小感叹号｡
我们必须给予MapName､ TopLevelKey和SecondLevelKey｡
这里有三个参数｡
这是你考试时应该知道的，
只是语法，好吧｡
因此，如果我们查看这个小CloudFormation模板，
我们可以看到我们有一个之前定义的RegionMap｡
如果我们想要创建一个EC2Instance并引用，获取正确的AMI ID，
然后我们使用FindInMap函数获取ImageID｡
第一个是MapName，
所以我们将使用RegionMap，因为在这里它被称为RegionMap｡
第二，我们希望引用我们所在的AWS区域｡
所以我们要用刚才讲过的伪参数｡
和Ref函数｡
因此，
我们引用AWS区域，即它运行的CloudFormation模板｡
例如，我们在us-east-1中运行，
那么我们就在这个块中｡
然后我们说32作为SecondLevelKey｡
我们看一下32键，从中得到值｡
我们会得到这个amI-6411e20d这是一个将被选中｡
这是您应该了解的有关映射的全部内容｡
只需记住FindInMap函数的语法，以及映射必须在模板中显式写出的事实｡
  - [ ] 230 CloudFormation Outputs [03:08]
    * 
输出，我们来谈谈输出｡
这其实是一个非常流行的考试问题，所以请注意｡
输出部分是可选的，但是我们可以声明可选的输出，如果我们导出这些输出，我们将能够将它们的值导入到其他堆栈中，
我的意思是，通过堆栈，CloudFormation模板｡
因此，您可以开始链接CloudFormation模板｡
我们还可以在AWS控制台中或使用AWS
CLI查看输出，这样我们就可以直接使用UI快速检索输出的值｡
举例来说，您可以有一个网络CloudFormation模板，然后导出输出，例如VPC
ID和子网ID｡
您可以在其他CloudFormation模板中重用这些模板｡
因此，它支持跨堆栈协作，
让专家处理他们自己的VPC和子网部分，而作为应用开发人员，您只需引用这些现成的值｡
但是，
您应该知道，如果您开始使用CloudFormation输出，并且它们开始从另一个CloudFormation堆栈引用，则无法删除仍在其他地方引用输出的堆栈｡
所以这只是需要知道的事情｡
现在，我们来看一个输出示例｡
在此示例中，我们将创建SSH安全组作为模板的一部分｡
因此，
我们将该值导出为输出，基本上其他模板将能够获得该安全组ID的值｡
语法非常简单，
这里有输出部分，还有安全组的名称和描述，即我们公司的SSH安全组｡
这里是值，因此我们提供了在资源中创建的安全组的引用｡
然后，我们必须在此处指定此Export块，这是一个可选块，
如果不指定它，
则不会导出值，也无法导入值｡
因此，
当我们指定导出值时，我们可以说，
这个值，这个SSH安全组ID，将作为名称SSH安全组导出｡
那么现在我们如何导入值呢？
使用交叉堆栈引用｡
因此，我们将创建利用该安全组的第二个模板｡
我们将使用Fn导入值函数，有趣的函数｡
而且我们不能再删除前一个堆栈，直到这个堆栈全部被删除为止｡
如果我们看一下这里的这段代码，我们可以看到，
对于最底部的安全组，
有一个用于导入值的简短语法，然后我们引用与前面完全相同的名称，称为SSH安全组｡
提醒一下，之前我们将值导出为SSH安全组，
现在我们将值导入为SSH安全组｡
所以，你知道，输出和导出是考试中非常，
非常流行的问题｡
特别是，
如果他们开始问你，你如何链接CloudFormation模板？
还是从一个到另一个检索值？
所以你应该知道｡
您应该了解语法，并且应该了解导入值函数｡
我希望这对你们有帮助，下节课再见.
  - [ ] 231 CloudFormation Conditions [02:06]
    * 
解说员：最后，我们要谈谈条件｡
因此，
条件用于控制资源的创建，或基于某些语句的输出｡
逻辑语句｡
这些条件可以是你想要的任何条件，但常见的条件是，
你可能想说，如果你在开发，如果你在测试，或者如果你在生产创建或不创建资源｡
也许它可以基于区域，也许基于参数值｡
每个条件都可以引用另一个条件､ 参数值或映射，
因此您可以组合它们｡
为了更具体地定义它们，我在块条件下创建了一个条件｡
在这里，我们问，好吧，
我们是否要创建生产资源？
为此，您需要有环境类型，
它可能是一个参数｡
这种环境类型就在这里｡
我们需要有引用，所以这个参数的值等于prod, P-R-O-D，
字符串prod｡
所以这里，
基本上，这一切都是真的，只有当环境等于刺激时｡
使用此产品资源，我们基本上能够定义和调节其他资源｡
你自己决定怎么选择，你可以使用的函数是And, Equals，
If，
Not, or, Or.
这些都是逻辑函数，您可以根据需要组合它们｡
现在我们如何使用条件？
正如我所说，
你可以将它应用于资源､ 产出等｡
如果我们查看一个资源，例如，我的MountPoint，
它的类型是AWS EC2 VolumeAttachment，
并且只有在之前的条件CreateProdResources为真时才创建｡
这让你了解了条件是如何使用的，基本上它们和类型在同一层，
就在资源的名字下面.
条件就到这里了，我认为它们非常高级，我不确定考试中是否会问，
但对你们来说，了解它们还是有好处的，知道它们的存在，
你们可以在课堂使命模板中加入更多的逻辑
我希望这对你们有帮助，下节课再见｡
  - [ ] 232 CloudFormation Intrinsic Functions [05:30]
    * 
解说员：考试可能会问你关于内函数的问题，
我们已经看过了，但是这里有一个列表，你绝对应该知道｡
Ref函数､
GetAttributes FindInMap､
ImportValue､ Join､ Sub和条件函数｡
那么，让我们来快速回顾一下它们是什么｡
Ref功能对我来说是最重要的｡
它以前引用参数，
如果引用参数，它将返回该参数的值｡
因此，
我们在实践中已经看到了这一点，当您有安全组描述时｡
和资源｡
因此，
如果您引用CloudFormation模板中的另一个资源，
它将返回底层资源的物理ID｡
因此，
例如，如果我们引用一个EC2实例，我们将获得EC2实例ID｡
现在，这个问题的简称是! 裁判，这是它看起来的样子｡
这里有一个简单的例子，
我们创建一个子网，对于属性VpcId，我们引用之前创建的VPC，因此我们从中得到的是VpcId｡
正如我所说的，当您引用一个资源时，
它返回物理ID｡
所以知道这一点非常重要｡
那么，我们如何从资源中获取其他信息呢？
对不对？ 因为，如果我们只能使用Ref从资源中获取ID信息，
那么我们就很难做某些事情｡
因此，
我们可以使用GetAtt，属性可以附加到您创建的任何资源，
因此，要获得所有资源以及从这些资源公开的所有属性的列表，您必须查看文档｡
让我们快速地看一下，以便有个概念｡
因此，如果我们查看EC2实例，并转到“返回值”，
我们可以看到有一个Ref.
因此，Ref将返回该实例的ID，然后使用GetAttributes函数，
我们能够获取AvailabilityZone､ DNS名称､
私有IP等｡
所以这些东西都暴露了｡
因此，
要了解每个资源中公开了哪些属性，您必须访问该资源，并查看文档｡
现在，举例来说，如果你想获得EC2机器的AZ，
我们可以做到｡
这是我们的资源博客，
我们有一个带有ImageId和InstanceType的EC2实例，例如，当我们创建EBS卷时，我们希望从中获取AZ｡
为此，
我们将在“resources”下创建一个新卷，并将其类型设置为EC2卷｡
条件，
如果我们之前有一个条件，但重要的是，
如果你看看属性，大小是100，AZ使用的是GetAttribute函数，EC2｡
AvailabilityZone，因此EC2实例直接从左手的名称中出来，
然后点表示，
它告诉GetAttribute我们想要从中得到什么，因此我们想要得到AvailbilityZone｡
这也是一个很常见的考试问题，我们如何获得这个资源的属性，答案是使用GetAtt函数｡
您有FindInMap，我们以前见过这种情况｡
我们使用这个FindInMap函数，
简短的语法是这样的，我们必须指定MapName､ TopLevelKey和SecondLevelKey｡
这里有一个简短的总结｡
在本例中，
我们使用FindInMap函数根据我们所在的区域和架构类型（32位或64位）查找Image ID｡
ImportValue用于导入已在其他模板中作为输出导出的值，
为此我们使用ImportValue函数，因此再次记住，
当我们导入值时，我们只需给予导出的ImportValue名称，它应该很容易工作｡
现在开始加入｡ Join我们还没见过，但我们可以用分隔符来连接值，这是一种简化语法，
我们定义Join，得到分隔符名，
然后提供一个逗号分隔的值列表.
为了使它更具体一点，我们创建了a：b：c字符串，
我们可以使用带冒号的Join函数，然后在右边指定a, b，
c｡
如果你在编程的话，这是一个很常见的函数｡
所以，才知道这件事｡
有时候，
也许你会被问到，这个内在函数的输出是什么，如果你使用连接，
你知道你必须把冒号放在a和b之间，b和c之间｡
好了，最后我们有了Sub函数｡
sub函数是替代项的简写｡
它非常方便，
它允许你替换字符串中的值，所以你可以把它和引用或者伪变量一起使用，字符串必须包含这个美元符号，并且用VariableName打开来做一个替换｡
这有点晦涩，但记住，
替换，如果你在考试中看到它，
你就会明白了？
Sub用于替换值｡
最后，条件｡ 条件是当我们定义，
例如，一个条件只创建ProdResources，我们可以在那里使用一堆函数｡
所以我们可以使用的内在函数是And, Equals, If，
Not，
和Or，也许还有其他的函数，随着时间的推移，会被添加到CloudFormation中｡
但这就是你应该使用的内在函数｡
当一个函数有一个FN冒号，或者在函数名前有一个小感叹号时，你就知道这个函数叫做Intrinsic函数.
这是您需要了解的所有CloudFormation函数｡
我希望这对你们有帮助，下节课再见｡
  - [ ] 233 CloudFormation Rollbacks [05:13]
    * 
讲师：我们来快速讨论一下云形成回滚｡
了解它们是如何工作的是非常重要的，
以防它们出现在考试中｡
如果堆栈创建失败，如果你上传了一个堆栈，
但创建失败，默认情况下，所有的东西都会回滚｡
意味着会被删除｡
所以我们可以通过查看日志来了解发生了什么｡
但是，当您创建堆栈时，
您还可以选择禁用回滚，以便对发生的问题进行故障排除｡
从而更深入地了解所创造的东西｡
如果您更新堆栈，
那么它已经创建并且成功，
现在您更新它，如果更新失败，
堆栈将自动回滚到先前已知的工作状态，即您刚刚要更新的绿色状态｡
您可以在日志中查看发生了什么，
这要归功于错误消息｡
所以这节课就是要告诉你们回滚是如何工作的｡
好吧，那我们来练习失败｡
我们先创建一个堆栈，然后上传一个模板文件｡
我要上传的文件叫做triggerfailure｡
Yaml，二号｡
那么这个文件为什么有问题呢？
好吧，如果你触发失败｡ yaml，你看看我的EC2实例的映像ID，
它是一个不存在的映像ID｡
因此它会产生故障｡
让我们单击“下一步”，
我将其命名为TriggerCreationFailure｡
点击下一步｡
这里，在堆栈故障选项下，
我们有两个选项｡
第一是回滚所有堆栈资源｡
这意味着它们将回滚到以前已知的稳定状态，
或者我们可以保留成功调配的资源｡
这将保留成功调配的资源，并将任何失败的资源回滚到其上一次已知的稳定状态｡
因此，如果我们这样做（这是非默认选项），
然后单击“下一步”并提交，如您所见，我们将生成一个SSH安全组和一个服务器安全组｡
如你所见，
我需要，首先，有一个问题，
我没有提供组描述｡
所以这是一个失败的好例子｡
如您所见，
即使无法创建服务器安全组，
也可以创建SSH安全组｡
如果我进入资源，嗯，
一个仍然被保留｡
然而，如果你有一个创建，默认情况下它会失败，
它会删除一切｡
因此，如果需要，这可能是进行故障排除的机会｡
当然，因为这会留下一些剩余部分，你需要完全删除堆栈来摆脱它｡
因此，您无法更新堆栈并修复问题｡
所以我们会删除它现在它不见了｡
因此，这向您显示了创建失败时的选项，
您可以执行完全相同的操作｡
你现在就可以创建一个栈，我将基于一个正确的模板创建一个栈，
叫做just-ec2｡
yaml，
我将称之为更新失败｡
所以现在我们没事了｡
我们知道这是可行的，
因为，好吧，这是我们之前用过的模板｡
所以让我们等待事物被创造出来，正如我们所看到的，
我们很好｡
我现在要更新我的堆栈，
如果你没有看到这个按钮，
就刷新你的页面｡
因此，更新我的堆栈，
但这次我将用名为TriggerFailure的模板文件替换模板｡
所以这一次我们将有一个名为hello的组描述｡
下一个｡
这里，我们再次可以选择回滚所有堆栈资源或保留成功调配的资源｡
所以我们现在会说，“回滚一切，
看看会发生什么｡ 然后我们马上做第二个选择｡
让我们单击“下一步”，
然后单击“提交”｡
这将创建一些安全组，
然后将触发回滚｡
所以我的安全组现在正在创建中｡
现在他们完了｡
如您所见，
创建了实例，
但随后更新失败，因为未找到无效的AMI，
因此会发生什么情况？
因为我们已经指定了要回滚的所有内容，
所以所有内容都将基于最后一个已知状态回滚｡
这意味着我的服务器､
服务器安全组和SSH安全组应该消失｡
所以让我们等待这些事件的发生｡
如您所见，我的SSH安全组和服务器安全组被删除｡
类似地，作为练习，如果您更新堆栈，
但这次您再次选择“触发失败”，我们将再次输入描述｡
在“堆栈故障”选项下，我们只需说：“成功地保留资源调配｡
然后你知道会发生什么，
你可以自己尝试一下｡
这将创建SSH和服务器安全组，
但在发生回滚（堆栈故障）时不会回滚它们｡
因此，这取决于你选择你想要什么，但这两种行为都可以是可取的，
基于你试图做什么｡
所以当你完成后，请继续删除堆栈，你就没事了｡
好吧，就这样｡
我希望你们喜欢，我们下节课再见｡
  - [ ] 234 [DVA-C02] CloudFormation Stack Notifications [01:12]
    * 
解说员：这里有一个关于云形成堆栈通知的快速讲座｡
所以，你可以设置一种方法，让你有所有的堆栈事件被发送到一个SNS主题，
从那里你可以挂钩到你的电子邮件或Lambda等.
所以，你要做的是，
每当你创建一个云形成堆栈，
你进入堆栈选项，你启用SNS集成｡
从那时起，任何发生在CloudFormation
Stack上的事件，如正在创建､ 更新､
删除或发生在它上面的任何事情，都会作为通知发送到指定的SNS主题中｡ 如果您想过滤事件，
您可以这样做，因为CloudFormation Stack会将所有事件发送到您的SNS主题中，无论是什么，您都可以例如，有一个Lambda函数，
它从你的SNS主题中读取，然后只过滤特定种类的事件｡
例如，ROLLBACK_IN_PROGRESS，
然后将这些事件发送到另一个SNS主题中，例如，您可以从该主题中向用户发送电子邮件通知，
说嘿，您的CloudFormation Stack正在进行回滚｡
好了，这堂课就到这里｡
我希望你们喜欢，我们下节课再见｡ 
  - [ ] 235 CloudFormation ChangeSets, Nested Stacks & StackSet [03:26]
    * 
讲师：现在我们来谈谈CloudFormation的一些高级概念｡
我们不会对它们进行实际操作，
但有些我们已经看过，有些我们将在幻灯片中看到｡
第一个是ChangeSets，我们已经看到了｡
当我们更新一个堆栈时，我们需要在它发生之前提前知道会发生什么变化，以便更有信心，
因此ChangeSets不会告诉我们更新是否成功，
就像我们之前看到的那样，但它会告诉我们会发生什么｡
所以，我们有原始堆栈｡
我们通过上传一个新的堆栈来创建一个ChangeSet，这是我们在实践中看到的｡
然后，我们可以查看此ChangeSet并感到高兴｡
我们可以选择更改为，
通过上传一个新的堆栈来修改我们的
  - [ ] 236 CloudFormation Drift [04:20]
    * 
讲师：我们已经看到，CloudFormation非常适合创建基础架构｡
但是，CloudFormation并不保护我们不受手动更改使用CloudFormation创建的配置的影响｡
所以说清楚一点，
不是你的人可以进入控制台，改变一些资源的配置，这些资源确实是用CloudFormation创建的｡
这就是所谓的漂移｡
为了检测漂移，我们可以使用CloudFormation漂移功能｡
因此，
并非所有资源都受支持，但您可以访问此URL查看｡
但我发现覆盖面已经相当相当不错了｡
那么，
让我们来进行实际操作，演示CloudFormation drift是如何工作的｡
接下来，我们通过创建一个堆栈来练习漂移｡
模板已准备好，我将上传该堆栈，
然后选择3-drift-security-group｡ 抱怨
我们可以在设计器中查看此模板，只是为了看一看｡ 如果您查看模板本身，这不是很方便，
这里有两个安全组，一个是SSHSecurityGroup，
另一个是HTTPSecurityGroup，还有一个VPC参数，用于将其链接到安全组｡
因此，我们要做的是确保安全组的配置不会随着时间的推移而更改｡
因此，让我们继续，首先创建模板｡
我已经单击了云上传按钮，这将使我单击“下一步”，
然后我将其命名为DemoDriftSG，我们需要指定一个VPCid，
因此我将使用下拉菜单并指定我的默认值｡
单击“下一步”，向下滚动，然后单击“创建堆栈”｡
这样做的效果是，这将为我创建两个安全组，正如您所期望的，
我将手动更改安全组配置｡
因此，它们应该很快就会完成，安全组的创建正在进行中，
它们现在都已完成｡
因此，
如果我有一个资源，我有一个链接到我的两个安全组｡
因此，如果我转到HTTPSecurityGroup，在入站规则下，
我可以编辑它｡
例如，
我可以更改这个规则，说我想要一个不同的Cidrip，我可以添加一个描述｡
Foobar，然后是这个，
也许我还想从任何位置在此安全组中添加HTTPS｡
好的，点击保存规则｡
至于这里的另一个安全组，我可以进入入站规则，编辑它们，然后删除整个规则，
然后单击“保存｡
很明显，
我们的安全组的配置已经更改，因此我将不得不检测漂移，但现在CloudFormation并不知道发生了任何更改｡
因此，为了让它知道，我们可以单击堆栈操作，
然后单击检测漂移｡
这将启动漂移检测机制，然后在堆栈操作下查看漂移结果｡
我们可以看看结果，正如你所看到的，
它已经完成了｡
漂移状态为漂移｡
因此，有两个已修改的安全组，例如，
我们可以单击其中一个，然后单击“view drift
detail”（查看偏差详细信息）｡
因此，它是说，这是Cidrip的IP是不平等的，并有一个规则添加｡
这里有两个不同之处，它向我们展示了预期配置和实际配置｡
正如我们在这里看到的，它们并不相等，因此我们可以继续更新模板以匹配实际配置，
因为这可能是我们希望在模板中包括的内容，或者我们希望通过确保应用此配置来恢复堆栈｡
例如，我们可以进行云试验，以了解谁更改了我们的安全组，
以及何时真正了解其根本原因｡
对于SSHSecurityGroup，
我可以再次单击“View Drift Details”（查看漂移详细信息），它已被修改，我们可以看到这里有一处更改｡
这个规则已经被删除了，所以预期是这个，实际是那个｡
因此，
看到真正的漂移是非常非常酷的，因为它们非常有助于了解您的CloudFormation模板是否偶尔发生漂移｡
因此，
我建议您尽可能经常运行漂移，您也可以从漂移的左手访问漂移菜单，
这将带您进入漂移菜单，但仅此而已｡
完成后，只需删除这些模板即可｡
我们下节课再见｡ 
  - [ ] 237 [DVA-C02] CloudFormation Stack Policies [01:24]
    * 
讲师：现在，让我们来简要介绍一下CloudFormation
Stack策略｡
所以，当你有一个CloudFormation堆栈更新，
默认情况下，任何操作都将被允许在所有资源上，
所以你可以改变你的堆栈，你想要的，但有时，
你可能想保护你的堆栈，防止更新，或你的堆栈的一部分，
防止更新.
这就是堆栈策略的用武之地｡
堆栈策略是JSON文档，
它们定义了在堆栈更新期间允许对特定资源执行哪些更新操作｡
在这里，我们有一个例子，其中第一个语句是说“允许更新
*”的一切，这意味着你的CloudFormation堆栈中的一切都可以更新，
第二部分是说“拒绝更新 *”的资源生产数据库｡
这意味着CloudFormation Stack中任何名为“生产数据库”的数据库都将受到保护，
以防止任何类型的更新，因此默认情况下，
您的生产数据库是正常的｡
因此，堆栈策略的目标实际上是保护资源免受无意更新，
当您默认设置堆栈策略时，所有资源都受到保护，因此您需要的是为您希望允许更新的资源设置一个显式的“允许”｡
就这样了｡
你应该知道足够的答案，也许在考试中的一个问题｡
我希望你们喜欢，我们下节课再见｡ 
  - [ ]  CloudFormation [17 问题] Quiz
    * 
 ## Section 20 - AWS Monitoring & Audit: CloudWatch, X-Ray and CloudTrail [26 个讲座 • 1 小时 40 分钟]
  - [ ] 238 AWS Monitoring - Section Introduction [00:38]
    * 
好了，我们有了应用程序，它在云中｡
它在运行｡
你的经理在下午2：00一个｡ 米｡ 然后说它不能再运行了｡
发生了什么事？
我们已经部署了她的应用程序，但是我们忘记打开监视功能｡
监视非常重要，它将确保您的应用程序以正确的方式运行｡
例如，您可以通过跟踪和审核指标查看日志中发生的情况，从而了解AWS基础架构中的内容是由谁创建的｡
这一部分是如此重要，因为作为一个开发人员｡
我从来没有在AWS中部署过不启用某种监视的应用程序｡
我知道您对了解监控非常兴奋!
我们走吧｡ 
  - [ ] 239 Monitoring Overview in AWS [02:45]
    * 
好的，
欢迎学习有关监控､ 故障排除和审核的部分｡
我们将学习CloudWatch､ X-Ray和CloudTrail，对我来说，
这是最令人兴奋的部分之一｡
那么，为什么监控很重要呢？
我想你已经知道答案了，但我喜欢大声说出来｡
我们知道如何部署应用程序｡
我们已经看到了如何安全地､ 自动地使用基础设施作为代码､ 利用最佳AWS组件来实现这一点｡
所以我们知道如何进行部署｡
我们不知道的是，
一旦部署了我们的应用程序，用户就不会真正关心我们是如何做到的｡
他们不在乎我们是否使用了Elastic Beanstalk，
也不在乎我们是否将基础架构用作代码｡
这是伟大的，我们这样做，这是一个边缘的实力，
但用户不在乎｡
用户只关心应用程序是否正常工作｡
所以我们知道的工作原理是，例如，延迟｡
应用程序延迟是否会随着时间的推移而增加？为什么？
停机，
如果发生停机，我们的客户体验不应该降低，好吗？
它应该仍然是好的，这就是为什么我们部署高可用性的东西｡
然后，如果用户联系IT部门或投诉，
那就真的很糟糕了｡
我们不希望收到用户的问题警报，我们希望能够提前进行故障排除和补救｡
因此，在内部，我们能否在问题发生之前预防问题，
或者如果问题发生，我们能否在用户之前看到问题？
我们是否还可以监控性能和成本？
我们是否可以从事物的扩展方式和中断模式方面来看待趋势？
我们能学到什么，如何改进？
多亏了这个监控｡
所以对我来说，监控是非常非常重要的｡
现在，在AWS中，云观察｡
而CloudWatch允许您收集指标｡
它允许您收集日志以监视和分析日志文件｡
在AWS环境中发生特定事件时发送通知的事件｡
和警报，以便对指标事件甚至日志做出真实的反应｡
然后我们有X光，
X光是一种新的服务，还不是很流行，但我认为它是最棒的服务之一｡
因此，
它允许您对应用程序性能和错误进行故障排除，这样我们就可以实时看到延迟和错误｡
它允许我们做一些非常酷的事情，称为微服务的分布式跟踪｡
因此，
如果您有许多服务在执行许多任务并相互调用，或者如果您正在跟踪许多AWS组件，例如S3､ DynamoDB等，
那么您可以看到应用程序如何进行调用以及调用所需的时间，并且您可以全程跟踪调用，这非常非常好｡
CloudTrail允许您对正在进行的API调用进行内部监控，还可以审核用户对AWS资源所做的更改｡
总的来说，这三种技术共同为您提供了一个真正可靠的组合来监控AWS｡
我们将在本节中学习这些内容｡
所以下节课再见｡
  - [ ] 240 CloudWatch Metrics [02:54]
    * 
我们在整个课程中已经了解了云监视，现在我们来快速总结一下｡
首先是云观察指标，它将为我们的每一项服务提供指标，你需要了解指标的含义｡
因此，通常指标的名称会很好地指示它是什么，例如CPU利用率､
网络｡
然后，根据度量的行为方式，它让您了解服务的行为方式，您可以据此进行一些故障排除｡
因此，指标属于名称空间，然后您有一个维度，它是指标的属性，
例如，实例ID环境等｡ 等等｡ 每个度量最多可以选择30个维度｡
指标将有时间戳，你可以创建云，指标仪表板｡
例如，在本课程中，我们了解了EC2指标，还了解了EC2详细监控｡
因此，我们知道默认情况下，两个实例每5分钟会有一个指标｡
但如果您启用了详细的监控功能，则需要额外付费｡
然后你每分钟就会得到一个度量数据｡
如果您启用此功能，那么，例如，您将能够更快地对EC2实例的不断变化的指标做出反应，
如果您希望更快地横向扩展和向内扩展，它将为您的SSG带来一些好处｡
现在，该特性允许您获得十个详细的监视指标｡
需要了解的是EC2内存使用情况，因此默认情况下不会推送RAM，需要将其作为自定义指标从实例推送，
我们很快将了解如何推送自定义指标｡
当你在云观察仪表板中时，在左手边，有一些指标，你可以找到所有的指标｡
正如您所看到的，我们在这里看到了所有的名称空间作为我们的指标｡
如果我们看一看，我们有基于服务的解决方案，例如DLP､ 自动扩展､ EBS､ easy
to FS等｡
所以这里给你的很多信息｡
我们可以单击EC2 ，这样就可以获得每个实例的指标，只需查看一个指标，我将键入credit以查看CPU配额余额｡
例如，我将举一个很久以前很关键的例子｡
然后我要做的是选择一个自定义范围，该范围将是一个月，以便在此查找一些数据｡
好的，我们有数据了｡
云观察指标最酷的一点是你可以点击并选择你想要的时间跨度｡
开始了
我们得到了一些关于指标的信息｡
如您所见，我们每隔5分钟就会获得一个指标｡
因此，每个数据点是每5分钟一次，因为没有为此实例启用详细监视｡
但如果我启用了详细监视，我将每1分钟获得一次数据｡
这只是云计算指标的基础，没有什么太花哨的，但我们绝对可以按时间过滤｡
我们可以把它看作一条不同的线，比如堆叠的区域或线或数字或饼图，你可以编辑你的仪表板，你可以用CSV格式，
你可以分享它｡
比色法非常非常方便，你可以根据你想要的区域，根据你想要的维度，你想要的资源，
来查看所有的指标，这样你就可以过滤所有的东西｡
以上就是云指标｡
我希望你们喜欢，我们下节课再见｡ 
  - [ ] 241 CloudWatch Custom Metrics [04:03]
    * 
解说员：到目前为止，我们在本课程中看到的所有指标都是直接从我们默认启用的内部服务中获取的指标，
但您可以通过一种方法来获取CloudWatch的自定义指标，这就是选择，您可以定义自己的自定义指标｡
例如，您希望将RAM的内存使用情况推送到CloudWatch或磁盘库｡
所以对于你的应用程序的登录用户数这一点，你会使用一个名为PutMetricData的API调用｡
您可以向细分市场指标添加维或属性｡
举个例子吧｡ id､ 环境｡
名字，随便你要什么｡
你想怎么命名都行
然后，您可以使用存储分辨率和具有两个可能值的API参数来指定度量分辨率｡
因此，要么它是一个标准的自定义指标，您可以每隔一分钟推送一个指标｡
所以60秒｡
或者它可以实现非常高的分辨率｡
在这种情况下，
您可以每隔1秒､ 5秒､ 10秒或30秒推送一次指标｡
值得注意的是，
使用自定义指标时，当您在过去或将来推送指标时，这也是有效的｡
所以这是一个非常重要的考试点｡
因此，如果你将一个指标推到过去两周或未来两小时，
你不会从CloudWatch得到错误｡
这将按原样接受您的指标｡
因此，这意味着您需要确保当前配置了EC2实例时间｡
如果您希望指标与AWS的实际时间同步｡
因此，让我们推出一个自定义指标｡
为此，我将文档放入CloudWatch，放入指标数据｡
这是一个CLI文档，它向您展示了如何将指标推送到CloudWatch中｡
所以我不打算阅读文档｡
你可以看看这里所有的参数｡
但是可以指定非常重要的时间戳｡
因此，您可以指定一个时间戳，最多为过去两周和未来两小时｡
所以非常非常重要｡
然后你可以指定数据，单位，值的名称，
等等维度，
以及存储分辨率，如果你想让它得到一个高分辨率的度量或者一个标准分辨率，好的｡
所以我现在要做的就是推送一个非常自定义的示例｡
最后是一些示例，您可以使用JS文件的指标来推送这样的指标，如果您希望这样做，
然后使用此API调用，或者如果您希望它运行得更快，
您可以仅使用一个API命令来指定指标的值､
单位､ 字节以及实例ID实例类型等｡
让我在这里执行这个命令，然后打开CloudShell实用程序来推送该指标，好的，CloudShell启动后，
我将粘贴该命令，然后按Enter键｡
因此，这将把一个自定义指标推入CloudWatch｡
现在，您必须想象一下，
如果使用脚本从institute实例完成此操作，
例如，您可以定期推送任何指标｡
现在，我只是使用CLI将一个数据点推送到CloudWatch中，
它已经非常空了｡
如果你知道，CloudWatch的统一代理，
它的作用是使用这个put metric data
API调用定期将指标推送到CloudWatch中｡
因此，
当它被推送时，我们推送了一个名为MyNameSpace的新名称空间｡
这就意味着，如果我返回到CloudWatch指标并刷新它，我需要清除我的图表｡
然后我就可以退役了｡
回到服务会更容易，然后转到所有指标｡
如您所见，我们在这里创建了一个自定义命名空间｡
所有这些名称空间都是由AWS提供的，但现在我们有了自己创建的名称空间｡
因此，
我们在其中有两个维度实例ID和实例类型，它们表示在命令中指定的相同实例ID和实例类型维度｡
因此，
很明显，这取决于您定义这些维度，然后单击它，
您可以看到实例ID､ 实例类型和指标名称缓冲区｡
如果我现在单击它，
我们不会看到太多内容，因为我们没有太多内容，但这里有一个已创建的数据点，这是我的自定义指标的一部分｡
所以，这，这很简单｡
您可以看到如何使用API调用非常轻松地创建自定义指标｡
所以我希望你喜欢｡
我们下节课再见｡ 
  - [ ] 242 CloudWatch Logs [03:31]
    * 
现在我们来谈谈CloudWatch日志｡
因此，当您希望在AWS中存储日志时，最佳位置是CloudWatch
Logs｡
我们的想法是将这些日志分组到日志组中，
这是您要为其指定的名称，但通常它代表一个应用程序｡
在每个日志组中，都有日志流｡
它们代表应用程序中的实例或不同的日志文件名或不同的容器等等，
然后定义日志过期策略｡
例如，您可能永远不希望日志过期，或者您希望它在30天后被删除等等，
因为您在CloudWatch Logs上支付存储费用，
那么从CloudWatch Logs中，您可以通过多个位置导出日志，例如Amazon S3､ Kinesis Data streams､
Kinesis Data Firehose､ Lambda和OpenSearch｡
现在，哪些类型的日志可以进入CloudWatch日志｡
我们可以使用SDK或CloudWatch日志代理或CloudWatch统一代理发送日志｡
现在，CloudWatch统一代理将日志发送到CloudWatch日志代理中的功能已被弃用｡
您有Elastic Beanstalk，它用于将日志从应用程序直接收集到CloudWatch中，
ECS将日志从容器直接发送到CloudWatch中｡
Lambda将从函数本身发送日志，VPC流日志将发送特定于您的VPC元数据网络流量的日志，
API网关将向API网关发送的所有请求发送到CloudWatch日志，CloudTrail，
您可以根据过滤器将日志发送到那里，Route53将记录对其服务进行的所有DNS查询｡
因此，您可以做的另一件非常重要的事情是定义指标过滤器和洞察力｡
这个想法是，你有你的云观察日志，
你可以使用你的过滤器表达式，
例如，找到所有特定的IP在，在日志中｡
因此，找到该IP出现的日志行，
或者找到日志中包含"错误“一词的每一行｡
多亏了这个度量过滤器，
你可以开始计算这些发生的次数，然后这些就变成了一个度量，
好吗？
这个指标可以链接到CloudWatch警报中｡
另外一个值得讨论的特性是CloudWatch
Logs Insights｡
所以这个想法是，CloudWatch日志洞察，
你可以查询日志，并将这些查询直接添加到CloudWatch仪表板.
而且一些常用的查询是由AWS直接添加的，
这是一种非常容易使用的语言｡
首先，我们来谈谈S3导出｡
因此，您从CloudWatch发送到Amazon
S3，这可能需要长达12个小时才能导出｡
API调用是CreateExportTask，
但这将在它自己的时间内完成｡
所以它不是接近实时或实时的｡
相反，如果你想从CloudWatch日志流日志，
你需要使用订阅，现在订阅是什么？
订阅是一个过滤器，您可以在Cloudwatch日志上应用，
然后将其发送到目的地｡
所以它可能是一个λ函数｡
例如，您可以定义自定义或AWS使用的自定义｡
如果你想把数据直接发送到Amazon OpenSearch，
或者它可以是Kinesis数据Firehose，
如果你想把它发送到Amazon S3，
近乎实时｡
因此，这是一个更快的替代方案，与我刚才展示的使用从CloudWatch到S3的导出之前的方案相比，
或者您可以使用Kineses数据流，例如，将数据发送到Kinesis Data Firehose Kinesis Data Analytics､ Amazon EC2或Lambda等｡
最后，使用CloudwatchLogs，
您可以跨帐户和跨区域进行一些日志聚合｡
因此，您可能有多个帐户，例如，
某个地区有订阅过滤器｡
将其发送到普通账户中的Kinesis数据流，账户B也是如此｡
第二区，同样的建筑，等等｡
因此，我们可以将所有这些日志集中到Kinesis数据流中，
例如，然后是Data Firehose｡
再比如亚马逊S3｡
好的｡
以上就是Cloudwatch日志工作原理的概述｡
我希望你们喜欢，我们下节课再见｡ 
  - [ ] 243 CloudWatch Logs [05:09] Hands On
    * 
  - [ ] 244 CloudWatch Agent & CloudWatch Logs Agent [03:16]
    * 
解说员：现在我们来讨论一下如何使用CloudWatch代理从EC2实例获取日志以及指标，并将其放到CloudWatch上｡
因此，
默认情况下，CloudWatch不会从您的EC2实例发送日志｡
为此，
您需要创建并启动一个代理，它是EC2实例上的一个小程序，将推送您想要的日志文件｡
因此，我们的想法是，
您的简单EC2实例将具有CloudWatch日志代理，例如，运行将日志发送到CloudWatch日志中，
以使其工作｡
您的EC2实例必须有一个IAM角色，
允许它将日志发送到CloudWatch Logs，这有意义吗？
值得注意的是，CloudWatch日志代理也可以设置为内部部署服务器｡
因此，您可以将服务､ 虚拟服务器（如内部部署的VM-ware）安装在同一个代理上，
这是一个小型Linux程序，您的日志也将最终保存在CloudWatch日志中｡
现在，您可以在CloudWatch中找到两种不同的代理｡
您有较旧的CloudWatch日志代理和较新的CloudWatch统一代理｡
因此，
它们都适用于虚拟服务器､ 内部部署服务器上的EC2实例等｡
CloudWatch日志代理是旧版本，只能将日志发送到CloudWatch日志｡
而统一代理将收集其他系统级指标，包括RAM､ 进程｡
我将在下一张幻灯片中向您展示这一点，并将日志发送到CloudWatch日志中｡
现在它是统一的｡
它更好，因为它可以执行指标和日志｡
因此，我们将其命名为统一代理｡
但是，
您还可以使用SSM参数存储轻松配置代理，这是以前的代理所不具备的功能｡
因此，
您可以对所有Unified Agent进行集中配置｡
因此，CloudWatch统一代理可以将日志发送到CloudWatch日志｡
但让我们看一下指标｡
所以如果你在你的Institute实例或Linux服务器上安装了它，你就可以收集指标，
它们是什么？
我们可以收集CPU指标，但要在更精细的级别收集，
例如：活动､ 来宾､ 空闲､
系统､ 用户､ 盗用｡
你根本不需要了解他们｡
我只是给你所有这些指标的粒度｡
免费使用总数的光盘指标｡
磁盘IO，以写入､ 读取､ 字节､ IOPS的数量表示｡
空闲RAM､ 非活动RAM､ 已用RAM､ 总RAM､ 缓存RAM｡
Netstats包含TCP和UDP连接数､
网络数据包数､ 字节数，以获取有关进程的一些信息｡
所以在进程的总数中，我指的是你的死亡､
阻塞､ 闲置､ 运行､
睡眠｡
以及交换空间，这是磁盘上的内存溢出｡
那么免费使用和使用百分比是多少呢？
所以你为什么不记得只是拍一张这些东西的心理截图｡
底线是CloudWatch统一代理允许这样做｡
与EC2实例的常规监视相比，
您可以获得更多的度量，以及更多的粒度细节｡
作为EC2开箱即用的提醒，
您可以获得一些关于磁盘､ CPU和网络的信息，而不是内存和交换，
但所有这些都是高级别的，好吗？
如果您希望获得更高的粒度，
请考虑CloudWatch统一代理，好吗？
所以我就这样了｡
希望你喜欢｡
我们下节课再见｡ 
  - [ ] 245 CloudWatch Logs Metric Filters [05:36]
    * 
好的，
现在我们来谈谈CloudWatch日志的另一个概念，即指标过滤器｡
因此，CloudWatch Logs可以使用过滤器表达式，例如，
在日志中搜索特定的IP，或者我们可以使用Metric
Filter，来做一些更高级的事情，例如计算“ERROR”一词在日志中出现的次数｡
因此，
我们可以定义这些指标过滤器，并使用它们来触发警报｡
这就是指标过滤器的全部意义，
它们更高级，它们将在日志中查找特定事件或计数，
如果达到某个阈值，它们将触发警报，您可以对此做出反应｡
因此，
这些筛选器一旦创建，就不会追溯筛选数据｡
筛选器仅发布在筛选器创建后发生的事件的度量数据｡
让我们看一下，
我们将EC2实例上的CloudWatch日志代理流式传输到CloudWatch日志中，然后CloudWatch日志将创建一个指标过滤器，
例如，可以定义指标过滤器来查看日志中的错误数量｡
然后，如果我们达到一个阈值，我们就会触发一个CloudWatch警报，
例如，CloudWatch警报可以将您的数据发送到一个SNS主题中，
我们可以从中制作许多动画｡
让我们来亲身实践一下，看看它是如何工作的｡
我在我的CloudWatch日志中，我想获取nginx访问日志，
我想在这些日志流上创建一个指标过滤器｡
所以我现在要做的就是看看是否有错误代码400｡
我将输入400，如这里所示，
我们可以看到有很多HTTP/1｡
1”400个错误代码，因此我希望在这些代码上创建一个度量筛选器并收到警报｡
这只是一个虚拟用例｡
我将创建一个指标筛选器，可以从此处创建，
也可以返回此处的指标筛选器并创建一个｡
我将创建一个度量筛选器，然后您必须输入一个模式｡
模式可能很复杂，有一个完整的文档介绍了模式的过滤器和语法，
但是现在，我只想找到400个，让它变得非常简单｡
然后，
我们可以发送自定义日志数据进行测试，或者直接从我的日志中获取数据，然后测试模式，
结果是，它在示例日志中的50个事件中找到了14个匹配项｡
所以这意味着，
我的模式，非常，非常简单，工作正常｡
然后，
我将向下滚动并单击“下一步”，然后我必须为该指标筛选器命名，我会说，
MetricFilter400Code，好的｡
然后我们需要给予一个指标名称空间，我将其命名为MetricFilters，然后是指标名称MyDemoFilter，
然后是指标值，
因此，每当出现匹配时，我们可以说，
例如，发布的值编号为1｡
然后，如果没有发布任何值，
则默认值将为零｡
我单击“下一步”，然后创建此指标筛选器｡
现在，已创建此指标筛选器｡
因此，如果我进入我的指标，
在这里，我可以看到，目前，
还没有发布任何内容，因为正如我所说，指标筛选器是不可追溯的｡
因此，我们需要让这个指标筛选器发挥作用，
为此，非常简单，我将进入MyFirstBeanstalk环境，
然后执行一个环境操作，重启应用服务器，
这应该会触发更多日志写入CloudWatch日志｡
当我等待的时候，只要回到这里，
我会等待大约五分钟，等待我的环境得到重建，希望指标筛选器会开始显示在CloudWatch指标中｡
现在，
我的环境已经重新启动，我也要打开它，然后执行/测试，
只是为了触发一些东西，我们就可以开始了｡
好的，
现在让我们回到CloudWatch，我将刷新它，
希望很快，我们将开始看到一些指标｡
好了，现在我已经刷新了CloudWatch指标页面，
谢天谢地，我们开始看到的是一个自定义命名空间，称为指标过滤器，
这是我们创建的，然后我们创建了这个指标，这是MyDemoFilter｡
作为指标，它并不十分有趣，
因为值现在为零，这意味着我们尚未检测到任何400个事件，
但我想向您展示的是，
它不会回填先前事件的数据，因此指标筛选器仅在我创建后添加数据｡
所以，这张图并不是很有趣，
但没关系｡
我们可以使用此指标筛选器执行的另一项操作是单击它，然后创建警报，通过创建CloudWatch警报，
我们可以实现一些自动化，因此我将创建一个虚拟CloudWatch警报｡
因此，我将使用MyDemoFilter，
目前没有任何内容，但我可以说，
好的，如果作为静态阈值，
您大于，我会说50，那么我的web应用程序真的出了问题，
因此，
我将单击“下一步”，我们可以说，好的，
警报应该是“警报中”，我将把警报发送到现有的SMS主题，可能是这个主题，
也许是另一个，然后，我可以说next，然后说DemoMetricFilterAlarm，就这样｡
现在，我们已经在来自CloudWatch日志的MetricFilter之上创建了CloudWatch警报，因此您可以看到，在本例中，
有许多不同的CloudWatch服务组合在一起，并创建了警报｡
现在，我有了通知的依据｡
显然，现在不会发生这种情况，
我不会收到任何通知，但您已经了解了大致的想法，
这就是您如何继续创建自己的指标筛选器｡
因此，
如果我现在刷新此页面，
我应该会看到底部的内容，是的，此指标筛选器链接到名为DemoMetricFilterAlarm的警报｡
所以，这是伟大的｡
我希望你们喜欢，下节课再见｡
  - [ ] 246 CloudWatch Alarms [04:01]
    * 
现在，我们来讨论云手表警报｡
正如我们所知，警报用于触发来自任何指标的通知｡
您可以定义复杂的报警和各种选项，如采样或执行百分比或最大值等｡
报警有三种状态｡
好吧，我会的
表示未触发数据不足表示没有足够的数据供警报确定状态，
警报是指阈值已被突破，因此将发送通知｡
周期是您希望警报在度量上评估的时间长度｡
因此，它可以非常､ 非常短，也可以非常､ 非常长，它还可以应用于高分辨率的自定义指标，
例如，10秒､ 30秒或60秒的倍数｡
现在警报有三个主要目标｡
第一种是对简单的两个实例执行的操作，如停止､ 终止､ 重新启动或恢复实例｡
第二种是触发自动缩放操作，例如，向外扩展或向内扩展｡
例如，最后一个是向SAS服务发送通知｡
从服务中，我们可以将其与lambda函数挂钩，并让landing函数根据警报被破坏来执行几乎任何我们想要的操作｡
现在我们来讨论复合警报，因为我们知道云监控器警报是基于单个指标的｡
但是，如果您希望拥有多个指标，则需要使用复合警报｡
因此，由于复合警报实际上监视多个其他警报的状态，并且这些警报可以各自依赖于一个不同的度量｡
因此，复合警报是将所有其他警报组合在一起的操作｡
你可以使用end或or条件，这样你就可以非常灵活地检查条件了｡
因此，降低警报噪音非常有用，因为您可以创建复杂的复合警报，
例如，如果CPU高而网络高，则不要向我发出警报，因为我只想知道何时CPU高而网络低，
诸如此类｡
让我们举个例子｡
我们有一个实例，我们将在其上创建一个复合警报｡
因此，我们创建了第一个底层警报，称为警报A，它将监视AC 2实例的CPU｡
然后，您创建警报B，它将监视AC两个实例的IOPS，然后将复合警报定义为警报和警报的结合｡
因此，如果报警A处于报警状态，而报警B也是一个报警，这是我们必须自己定义的，
那么复合报警本身将处于报警状态，并可能触发SAS通知｡
如您所见，您可以利用复合警报发挥创意｡
那么，我们来讨论第二个问题的实例恢复｡
我们已经看到了它，但是有一个状态检查来检查EC2虚拟机，还有一个系统状态检查来检查底层硬件｡
您可以在这两个检查上定义云警报｡
因此，您将监视特定的AC两个实例，如果违反警报，则可以启动AC到实例恢复，
以确保将AC到实例从一台主机移动到另一台主机｡
在执行恢复时，您将获得相同的私有公共和弹性IP､ 相同的元数据以及相同的实例放置组｡
您还可以向SNS主题发送警报，提醒您IS 2实例正在恢复｡
现在沙发警报器有一些好东西｡
首先，正如我们所看到的，我们可以在记录指标过滤器的云上创建警报｡
请记住云，它的日志有一个指标过滤器，该过滤器与云警报挂钩｡
然后当我们收到太多关于一个特定单词的实例时，比如说，错误这个词，然后发出警报，
并向亚马逊发送一条消息，一个句子｡
如果你想测试警报通知，你可以使用一个叫做set alarm states的调用｡
当您想要触发警报时，即使警报没有达到特定阈值，这也是很有用的，
因为您想要查看触发的警报是否会导致基础架构采取正确的操作｡
所以说对于警报器｡
我希望你们喜欢，下次课我们再见面练习｡
  - [ ] 247 CloudWatch Alarms [04:38] Hands On
    * 
  - [ ] 248 [DVA-C02] CloudWatch Synthetics [02:54]
    * 
讲师：现在我们来讨论CloudWatch合成金丝雀｡
因此，我们的想法是，您有一个可配置的脚本，
该脚本将从CloudWatch运行，
并将能够监视您的API､ URL或网站｡
这个想法是你定义一个脚本，
这个脚本将通过编程重现你的客户所做的事情｡
我们的想法是，例如，
如果你的客户进入一个产品网页，然后他点击，
他把添加到购物车，去结帐，
把信用卡的详细信息，并确保结帐工作，
你可以测试所有这些，并重现它与CloudWatch合成金丝雀｡
我们的想法是，如果这个脚本失败，这意味着你发现了一个问题，
这对你来说是很好的发现这个问题之前，
你的客户｡
所以这个想法是你可以检查一些流是否在工作｡
我们还可以检查一些端点的可用性和延迟，
您甚至可以存储加载时间数据，甚至可以对UI进行截屏｡
让我们举个例子｡
我们在us-east-1部署了一个应用程序，然后我们将使用CloudWatch
Synthetics Canary来监视该应用程序｡
如果发生故障，将触发CloudWatch警报，
然后调用Lambda函数｡
Lambda函数可能希望将Route
53的DNS记录更新到us-west-2中的另一个实例，
以便重定向到我们知道正在工作的应用程序版本｡
这只是一种做事方式｡
所以这个Synthetics Canary可以运行的脚本可以在Node中编写｡
js或Python｡
最重要的是，从合成金丝雀，你可以访问一个无头谷歌Chrome浏览器｡
所以你可以用谷歌浏览器做任何你想做的事情，
直接从合成金丝雀浏览器｡
您可以选择运行脚本一次或定期运行｡
例如，如果您想检查端点的可用性｡
还有一些蓝图可以利用｡
因此，您可以使用Heartbeat Monitor加载URL､
存储屏幕截图和HTTP存档文件，并确保一切正常工作｡
API Canary测试REST API的基本读写功能｡
您可以使用断开的链接检查器来检查正在测试的URL中的所有链接，
确保没有任何链接实际将您引向断开的链接｡
可视化监控，将金丝雀运行期间拍摄的屏幕截图与之前拍摄的基线屏幕截图进行比较｡
Canary录音机，与CloudWatch合成录音机一起使用｡
这是一种你可以在网站上记录你的行为然后自动生成一个脚本然后你可以直接在Synthetics
Canary上运行它然后自动重复这些行为
最后是GUI工作流生成器｡
例如，您可以验证在您的网页上执行的操作（例如，
使用登录表单）是否正常工作｡
好了，以上就是CloudWatch合成金丝雀的故事｡
我希望你们喜欢，我们下节课再见｡
  - [ ] 249 Amazon EventBridge [06:59]
    * 
讲师：现在让我们来谈谈Amazon EventBridge，
Amazon EventBridge以前的正式名称是CloudWatch
Events，因此您将在考试中看到EventBridge，但您要知道，如果您有AWS的经验，那么它以前的名称是CloudWatch
Events｡
使用EventBridge，你可以做很多事情｡
例如，我们可以在云中调度cron作业，
因此我们可以调度脚本｡
例如，我们说，“嘿，每小时请触发一个Lambda函数”，
Lambda函数将运行一个脚本｡
因此，事件每小时生成一次，因此命名为Amazon
EventBridge，但它不仅仅是像每小时这样的计划，它还可以对事件模式做出反应｡
因此，有一些事件规则可以对服务执行某些操作做出反应｡
例如，您可以在控制台中响应IAM
root用户登录事件｡
因此，当这种情况发生时，也许你想向SNS主题发送消息并接收电子邮件通知，
这样如果有人使用root帐户，那么你将收到电子邮件，
这可能是您帐户的一个很好的安全功能｡
此外，例如，您有不同的目的地，您可以触发Lambda函数，
发送SNS和SQS消息，等等，
我将在第二时间向您展示这一切｡
EventBridge位于中间，
我们有所有可以将事件发送到Amazon EventBridge的源｡
例如，EC2实例启动时，
停止时，终止时，等等｡
例如，如果您有一个失败的构建或S3，
每当有一个事件时，例如，当上传对象时，
或者当您在帐户中发现新的安全性时，或者作为一个很好的组合，您可以将EventBridge和CloudTrail结合起来，
实际上拦截您的AWS帐户中的任何API调用，这是巨大的｡
另外，正如我所说，你可以有一个时间表或cron，
所以你可以说每四个小时或每个星期一上午8点，每月的第一个星期一，这是你可以做的事情｡
然后，这些事件会被发送到Amazon EventBridge，
您可以设置过滤器｡
例如，你说，“嘿，我只想为特定的桶这些事件，
”亚马逊是免费的，例如｡
然后EventBridge将生成表示事件详细信息的相邻文档｡
例如，启动哪个实例，它的ID是不是，
等等｡
很多信息，时间，IP等等｡
一旦完成了，这个JSON文档，这个事件，
就可以被发送到很多不同的目的地，
允许你做非常棒的集成｡
例如，您可以调度和触发Lambda函数，可以在AWS
Batch中调度批处理，可以为Amazon ECS启动ECS任务，
可以向SQS､ SNS甚至Kinesis数据流发送消息，可以启动Step Function，可以使用CodePipeline启动CI/CD
Pipeline或使用CodeBuild启动构建，因此您实际上并不知道所有这些事情｡ 这些是不同的AWS服务，
但我只是概述了您可以执行的操作，例如，您还可以启动SSM自动化或特定的EC2操作，
例如启动或停止或重新启动EC2实例｡
因此，您可以看到可能性是无限的，
这实际上取决于您的用例｡
Amazon EventBridge就是我们所说的默认事件总线，
也就是我们刚才看到的，它代表来自AWS的服务，这些服务将其事件发送到默认事件总线，
但Amazon EventBridge具有更多功能｡
有一种叫做合作伙伴事件总线的东西，
这是与合作伙伴集成的AWS，最有可能的是他们将成为软件即服务合作伙伴，
他们将直接将他们的事件发送到您的合作伙伴事件总线｡
因此，如果您正在使用Zendesk､ Datadog､ Auth0或其他工具，
则需要检查合作伙伴列表｡
然后，他们可以将事件直接发送到指定的合作伙伴事件总线，
这样您就可以直接在您的帐户中对AWS之外发生的更改做出反应｡
好的，最后，有一个自定义事件总线，
因此您可以创建自己的事件总线，
然后您自己的应用程序可以将自己的事件发送到自定义事件总线，因此，由于EventBridge规则，您可以将这些事件发送到不同的目的地｡
此外，您可以访问事件总线，交叉帐户，
使用基于资源的策略，我们很快就会看到｡
你也可以将所有事件或一个子集事件归档到一个过滤器中，
通过归档事件，你可以将其设置为无限期保留或设置保留期，
好吗？
你可以做的是，你可以重播这些存档的事件｡
例如，假设Lambda函数中有一个bug，
你想修复它，所以你修复了它，
然后你想重新测试事件，重放它，然后你可以重放这些存档的事件，这对于调试非常方便，
对于故障排除非常方便，对于修复生产也是如此｡
现在，EventBridge从不同的地方接收很多事件，
因此，您需要了解事件的外观并记住，
这些事件是我们刚刚看到的相邻格式｡
因此，有一个Schema Registry，
它的功能是EventBridge将分析总线中的事件，然后它将推断模式，
而Schema Registry中的模式将允许您为应用程序生成代码，
这些代码将提前知道数据在事件总线中的结构｡
例如，这是一个正在运行的特定CodePipeline的示例｡
有一个模式，你可以直接使用橙色按钮下载代码，
这将直接知道如何推断模式并从事件总线中构建数据｡
此外，模式可以被版本化，
因此您可以随着时间的推移在应用程序的模式之间迭代｡
现在，我们有基于资源的EventBridge策略，这意味着什么？
这意味着您可以管理特定事件总线的权限｡
例如，您可以说特定的事件总线可以允许或拒绝来自其他区域或帐户的其他事件，
例如，它的用例是在您的AWS组织中拥有一个中央事件总线，因此一组帐户和所有这些事件都将被聚合，那么这是如何工作的呢？
我们有一个带有特定帐户的中央事件总线，
我们将添加一个基于特定资源的策略，
允许其他帐户向其发送事件，因此，
例如，这个其他帐户将能够执行放置事件并将事件直接发送到中央事件总线｡
就这样，我们从左到右看过EventBridge，
你知道它的一切｡
请记住，您可以对帐户内发生的事件做出反应，
这要归功于默认事件总线，
但也可以使用自定义总线对合作伙伴事件和您自己的事件做出反应，
您拥有架构注册表功能，然后拥有基于资源的策略，这些策略允许您拥有跨帐户（例如，事件总线功能）｡
好了，就到这里，希望你们喜欢，
下次课再见｡
  - [ ] 250 Amazon EventBridge [07:11] Hands On
    * 
  - [ ] 251 [DVA-C02] Amazon EventBridge - Multi-Account Aggregation [01:23]
    * 
解说员：这是一个简短的讲座，
介绍如何使用EventBridge进行多帐户事件聚合｡
例如，假设您在AWS中有多个帐户，但您希望在中央帐户事件总线中集中管理其中的一些事件｡
假设您要在所有帐户中启动EC2实例，
并且希望在中央帐户中捕获这些事件｡
你会怎么做呢？
您可以在其中一个帐户中定义一个事件模式，
然后为其创建一个事件规则，以便帐户A的所有状态更改都发送到该事件规则｡
事实证明，一个帐户中的事件规则的目标可以是另一个帐户中的事件总线｡
因此，要使其工作，以便帐户A可以向中央帐户发送，
我们需要在中央帐户的事件总线上创建一个资源策略，以接受来自其他帐户的事件｡
所以这是有道理的？
然后，我们可以在帐户B､
D和C中执行完全相同的模式，这样，
我们的EC2实例的所有事件和所有状态更改都将到达中央帐户的事件总线｡
从那里，我们可以在事件总线上创建自己的事件规则，
例如触发SNS通知，或贷方功能，或任何你想要的｡
就这样，在建筑学方面，
还有一件事要知道，
我希望你们喜欢，我们下节课再见｡
  - [ ] 252 [DVA-C02] X-Ray Overview [07:07]
    * 
讲师：所以，对我来说，这是AWS提供的最具革命性的服务之一，
我认为它目前没有得到充分利用｡
这门课叫AWS X射线，我们想让你们了解X射线｡
我想这就是为什么他们问两个问题，
因为他们希望人们使用它，
我真的认为人们应该使用X射线｡
因此，当您调试生产环境时，
我过去也曾调试过生产环境中的应用程序，传统的好方法，
我称之为传统的好方法是在本地测试，
在所有地方添加日志语句，重新部署生产环境，并从日志中尝试找出发生了什么问题，
发生了什么情况｡
真的很痛｡
这不是最佳实践｡
显然，还有更好的方法｡
我只是把事情过于简单化了，但你明白我的意思｡
调试生产并不有趣｡
然后，如果你记录东西，如果你有不同的应用程序，
如果你从不同的应用程序记录到CloudWatch，那么你会知道它们都有不同的格式，很难集中洞察力｡
浏览云监控日志会很困难｡
再加上分析，这将是困难的｡
所以，如果你有一个整体，一个巨大的应用程序做所有的事情是很容易调试的，
但是如果你有分布式服务，你在你的LS帐户中运行一百个微服务，
这就变成了一场噩梦｡
这真的很难调试发生了什么，因为他们都互相交谈，
对不对？
因此，您的整个体系结构､ 整个服务图等都没有通用视图｡
那么，AWS X射线来了｡
因此，X射线将为您提供应用程序的可视化分析｡
这就是我们在实践课上要做的｡
我们将看到，基本上，当客户端向应用程序发出请求时，
我们将看到这些请求中有多少失败或没有失败｡
然后，我们将从应用程序中看到它的功能｡
因此，它将调用其他IP，它将调用SNS，它将调用DynamoDB表｡
因此，正如您所看到的，我们将能够精确地､
可视化地跟踪当我们与EC2实例对话时发生了什么｡
所以，如果我问你们，你们认为这个橙色或黄色的小错误是从哪里来的，
你们会从这个图表中知道吗？
是从这里传来的吗？
不是，是SNS发来的吗？
不，它来自我的DynamoDB表｡
你可以直观地看到它｡
这就是追踪的全部力量｡
显然，你可以做更多，但你开始得到的想法｡
就X射线的优势而言，有很多｡
您可以对应用程序的性能进行故障排除并确定瓶颈｡
您可以理解微服务架构中的依赖关系，
因为您可以直观地看到正在发生的事情以及所有微服务如何相互交互｡
然后我们可以精确地指出哪个服务给我们带来了问题｡
我们可以了解每个请求的行为，然后根据请求查找错误和异常｡
我们可以回答这样的问题，例如，
我们是否在延迟或处理请求的时间方面满足时间SLA？
我们就能知道哪种服务会让我们慢下来，
让我们窒息｡
最后，如果我们愿意，我们可以知道哪些用户受到错误的影响｡
所以，X射线有很多兼容性｡
它兼容AWS Lambda､ Beanstalk､
ECS､ ELB､ API网关和EC2实例或任何应用服务器，
甚至是您内部部署的应用服务器｡
因此，他们真的让X射线尽可能广泛地应用于任何应用程序｡
X射线，它是怎么工作的
它利用了一种叫做追踪的东西｡
而跟踪是对基本上遵循请求的方式的终结｡
例如，当我向应用程序服务器发出请求时，
将处理请求的每个组件可能是我的数据库､ 网关､ 负载平衡器､
应用程序服务器｡
处理该请求的每个组件都将添加自己的跟踪，
因此，跟踪将由段组成，而段可以由子段组成｡
这个想法是，我们还可以向跟踪添加注释，
以提供有关所发生事件的额外信息｡
因此，当所有这些东西都放在一起时，
您就能够跟踪每个请求或一个简单的请求｡
所以，你说我只想得到总请求的一个百分比，
或者每分钟五个请求｡
在安全性方面，有IAM授权，
可以使用KMS进行静态加密｡
所以，一旦你得到了所有这些轨迹，
基本上，X射线提供了它的魔力，并提供了这个漂亮的小图表，
我之前给你看过｡
现在，如何启用X射线？
你有两种方法，
我想这就是考试要问你的问题｡
所以，你要非常小心｡
您的代码可以是Java､ Python､ Go､ Node｡ js和. Net，并且它必须导入AWS
SDK｡
您只需要很少的代码修改，
但仍然需要做一些代码修改｡
然后，应用程序SDK，即X射线SDK，
将捕获对AWS服务的调用､ HTTP和HTTPS请求以及MySQL､ PostgreSQL和DynamoDB的数据库调用｡
它还可以捕获队列调用等｡
现在，修改代码后我们要做的第二件事是安装X-Ray守护进程或启用X-Ray
AWS集成｡
因此，如果我们在机器､ 内部部署服务器或EC2实例上运行，
则需要安装守护进程｡
守护进程基本上是一个小程序，作为一个低级UDP数据包拦截器工作｡
它可以在Linux､ Windows和Mac上运行｡
所以，你必须把它安装在你的机器上｡
如果您使用AWS Lambda或其他已经与X-Ray集成的服务，
那么它们将为您运行守护进程，
您不必担心它｡
现在，每个应用程序还必须具有IAM权限才能将数据写入X射线｡
因此，一个非常常见的问题是，嘿，当我在本地测试时，我的X射线应用程序在我的计算机上工作，
但在我的EC2机器上不工作，
为什么？
答案可能是因为您在计算机上运行的是X-Ray守护进程，
但是当您部署到EC2实例时，它没有运行X-Ray守护进程，
因此X-Ray看不到您的调用｡
现在，为了让它变得非常清晰，这里有一个EC2实例，
您需要在它上面放置应用程序代码｡
因此，您的代码再次需要修改以导入AWS
X-Ray SDK，然后它会将其跟踪发送到运行计算机的X-Ray守护进程｡
因此，正如您所看到的，您还需要运行X-Ray守护进程，
该X-Ray守护进程将每秒向AWS
X-Ray发送一个批处理｡
所以X光确实有魔力｡
那么，要更新这个图表，它是如何工作的呢？
X-Ray将从发送跟踪的所有不同服务收集所有数据，
然后，服务映射将从所有段和跟踪中神奇地计算出来｡
所以，这是一件很酷的事情｡
X射线是图形化的，因此即使是非技术人员也可以帮助排除故障｡
谈到故障排除，如果X射线在EC2上不工作怎么办？
正如我所说的，您需要确保IAM角色具有适当的权限，
并且需要确保EC2实例确实在运行X-Ray守护进程｡
如果你想在Lambda上运行它，它会有一点不同｡
为此，您需要确保Lambda具有IAM执行角色和适当的策略｡
我知道我们还没有知道λ是什么，但这只是一个问题，
你可能会得到｡
因此，您需要确保Lambda具有预期的适当IAM角色，
然后您需要确保导入X-Ray代码｡
最后，您已经激活了X射线上的主动跟踪Lambda选项，
但我们也将在Lambda部分看到这一点｡
这就是X射线的概述，一个小尝试者｡
在下一节课中，我们将在X射线上运行几个应用程序，
以便更好地了解它是如何工作的｡
所以，下节课再见｡
  - [ ] 253 X-Ray [08:13] Hands On
    * 
  - [ ] 254 X-Ray: Instrumentation and Concepts [04:43]
    * 
旁白：好的｡
现在，我们来讨论一些X-Ray的高级概念，首先，
我想向您展示的是如何对代码进行插装｡
所以这个词可能是新的，对我来说是新的｡
因此，
检测意味着测量产品的性能､ 诊断错误和写入跟踪信息｡
所以这是软件工程的一个领域来做所有这些事情｡
所以现在就说得通了｡
当我们想要使用X-Ray对我们的应用程序进行检测时，
我们需要更改代码并使用X-Ray SDK｡
下面是一个示例，
说明如何使用X-Ray SDK对节点js代码进行插装｡
因此，
一旦我们添加了一些代码，例如这里，需要X射线SDK并在我们的Express应用程序中使用它，那么我们的代码将被插入｡
这意味着我们将从代码中获取跟踪信息，并将其导入X-Ray服务｡
因此，X-Ray SDK的使用非常少｡
有时，它只需要更改配置，
您也可以修改应用程序代码｡
如果您想要自定义轨迹和注释数据，或更改X射线将数据发送到快速服务的方式｡
因此，我们可以创建拦截器､ 过滤器､
处理程序和中间件｡
这是相当高级的，但我的意思是，您可以在代码中自定义X-Ray的工作方式｡
现在介绍一些先进的X射线概念｡
因此，段的定义是我们可以在URL中看到内容的方式，因此我们到目前为止一直在研究段，
每个应用程序和服务都将发送它们｡
但如果您希望更精细，则可以定义子细分市场｡
这时，您可以在细分中保留更多详细信息｡
然后，
当您将所有片段收集在一起时，即为跟踪，这将形成API调用或调用的端到端视图｡
这将是一个端到端的跟踪采样｡
我们马上就能看到｡
这是为了减少发送到X射线的请求量，以降低成本，
因为我们可能不需要所有请求｡
现在，非常重要｡
注释是当我们添加一些键值对数据来索引我们的跟踪并与过滤器一起使用时｡
因此，注释在X射线中是极其重要的｡ 
  - [ ] 255 X-Ray: Sampling Rules [02:05]
    * 
这是一个非常简短的实践练习，但我将向您展示X射线中的采样规则｡
在X射线的左侧，您可以看到采样，
然后您可以访问所有采样规则｡
正如我们所看到的，我们可以定义许多具有不同优先级的采样规则｡
如果我们看一下这里的默认采样规则，优先级很高，我们得到的是每秒一个请求的存储库大小和5%的固定速率｡
在任何情况下，
你忘记了，这里有一个描述以及一个信息按钮，告诉你如何修复这些限制｡
在匹配条件中，采样规则更高级一些｡
但这个和所有的东西都吻合｡
所以HTTP的每一个服务，每一种服务类型，每一种方法｡
任何URL､ 任何资源ARN和任何主机｡
您可以取消此操作，然后创建自己的采样规则｡
所以我可以称之为DemoSampling，并给予它5000的优先级｡
如果你转到这里，它会说低优先级在顺序中优先｡
所以这将是一个更好的规则，将首先应用｡
我们可以说一个存储器的大小是每秒10个请求，因此请求更多｡
而且会有一个1%的固定比率，因为我们希望以后的请求更少｡
这取决于你做你的水库和你的固定利率，因为你想根据你的应用要求｡
这里最酷的事情是我们可以深入查看服务或服务类型｡
因此，
如果您只是对某个服务感兴趣，而不是对所有服务感兴趣，并且希望调试它｡
也许你想有一个水库大小作为一个和一个固定的利率为百分之百｡
它的作用是，如果你指定我的服务，
并创建这个规则，
它的作用是，这个服务，我的服务，将把它所有的轨迹发送到X射线｡
因此，它可以真正详细地调试我的服务所发生的事情｡
但是你也可以通过HTTP方法进行过滤，
例如只过滤post和URL的路径､ 主机､ ARN｡
因此，您可以自由地创建采样规则，
然后继续操作｡
正如我所说的，一旦创建了采样规则，它将自动应用于所有的X射线守护程序，
因此您无需担心重新启动代码｡
这使得X-Ray成为一个非常非常灵活的服务，
如果您正在运行分布式服务，您应该使用它｡
我希望这对你们有帮助，我们下节课再见｡
  - [ ] 256 X-Ray APIs [02:55]
    * 
主持人：好的｡
下面我们来讨论一下X射线API，
您需要从较高的层次了解它们并了解它们的作用，因为考试可能会要求您选择这是否是用于X射线的Write
API，以便执行某些操作｡
因此，让我们首先了解一下X-Ray守护程序用于将数据写入X-Ray服务的正确API｡
这是一个托管策略，
称为“X-Ray只写访问”，您可以看到它有五个行项目，我将尝试向您介绍它们｡
第一个是PutTraceSegments，顾名思义，它会将片段文档上传到AWS
X-Ray，如果您想写入X-Ray，
就必须具备该功能｡
然后，我们有PutTelemetryRecords，
这是X射线守护程序上传的一些信息，有关接收､ 拒绝和后端连接错误的数据段数量｡
这有助于衡量指标｡
接下来，我们有一个GetSamplingRules｡
通常我们写东西的时候，会有很多put，因为这是AWS中API的命名方式，每当你写东西的时候，
它会说，“put“｡
“但是这个正确的API有一半是get，这个叫做GetSamplingRules｡
你知道为什么吗？
我们看到，
只要我们在X-Ray控制台中更改采样规则，所有X-Ray守护程序都会自动更新，以了解何时将数据发送到X-Ray｡
因此，
要使X射线守护程序能够了解采样规则的变化情况，则需要GetSamplingRule授权和权限｡
因此，这也适用于GetSamplingTargets和GetSamplingStatisticsSummaries，这两个API是高级API，
但也与采样规则相关｡
所以总结一下，你的X射线要求写入X射线，它需要你有写的权限｡
因此，PutTraceSegments和PutTelemetryRecords，
然后您应该能够获得采样规则｡
因此，获取采样规则｡
非常简单｡
现在，要使此API调用正常工作，
您需要确保您的X射线守护程序具有正确的IAM策略来授权这些API调用｡
这是写侧的｡
那么读取端呢？
这个比较复杂，但这是一个受管理的阅读策略｡
正如你所看到的，所有这些东西都是get, get, get，
get, get，
我们有一个叫做batch get trace的东西，
它也是get｡
因此，GetServiceGraph将获取我们在控制台中看到的主图形｡
BatchGetTraces将检索由ID指定的跟踪列表｡
正如我们所知，每个跟踪都是源自单个请求的片段文档的集合｡
然后，我们使用GetTraceSummary来接收指定时间内可用跟踪的ID和注释，
如果他想要获得完整跟踪，则您可以将这些ID传递到批处理中，获取跟踪API，
最后使用GetTraceGraph来检索一个或多个特定跟踪ID的特定服务图｡
原来如此｡
这是所有的读取API，
这是必要的，当你进入控制台｡
因此，
如果您在考试中看到这些API，您应该准备好了解何时使用哪些以及为什么使用｡
好吧，我会的 希望这对你有帮助｡
我们下节课再见｡ 
  - [ ] 257 X-Ray with Beanstalk [03:11]
    * 
演示者：这里有一个关于如何将X射线与Beanstalk集成的简短讲座｡
Beanstalk平台包含X-Ray守护程序，因此我们不需要包含它，
您只需在Beanstalk控制台中设置一个选项即可运行守护程序，
我们将在实践中看到这一点，您也可以创建一个名为xray-daemon的EB扩展文件｡
配置，
所以再次，在. ebextensions文件夹中添加一个“.
config'扩展名，
看起来像这样，只有一行，它只启用X射线守护程序，非常简单｡
这样做之后，显然您需要确保EC2实例具有带有正确IAM权限的实例配置文件，
以便X-Ray守护进程可以正确运行，
并直接连接到X-Ray服务｡ 当然，您需要确保您的应用程序代码使用额外的SDK进行检测，
以发送这些跟踪，如果您确实运行了multi-docker container，
您需要自己管理X射线恶魔，我们将在下节课程中使用ECS时看到这一点｡
好了，现在只需转到Amazon Elastic Beanstalk控制台，
然后创建一个应用程序｡
这一个叫做演示X射线，我想向你们展示设置X射线时哪些选项是重要的｡
因此，对于平台，
只需选择Node｡ js，然后是推荐的设置｡
我们将使用示例应用程序，然后单击“configure
more options”｡
因此，当我们配置更多选项时，
重要的部分将围绕软件｡
单击“software”并进行编辑，
如您所见，只需单击一下即可使X-Ray守护程序在您的Beanstalk环境中运行，这是您需要执行的第一步｡
因此，您先执行此操作，
然后保存，第二部分是确保EC2实例具有IAM角色，
允许它们连接到X-Ray｡
为此，我们将进入安全性并对此进行编辑，如您所见，
我们需要一个名为IAM实例配置文件的虚拟任务权限，
并从该列表中进行选择｡
所以现在我选择的是AWS
Elastic Beanstalk EC2角色｡
让我们进入IAM，了解一下这个角色的作用｡
在“roles”（角色）下，键入Beanstalk，
我们将拥有Elastic Beanstalk EC2角色｡
如果我们现在查看权限，我将拥有三个权限策略：Beanstalk
Web层､ 多容器Docker和工作者层｡
如果我单击第一个Web层，
即Beanstalk Web层，我可以查看策略摘要，在下面我们可以看到，
我们在此处具有X-Ray权限｡
如果我单击这些权限，我们具有读取权限，
可以获取采样规则､ 统计信息摘要和采样目标｡ 然后，在右侧，我们放置了基本记录和跟踪段，
这使我们可以将数据发送到X-Ray｡
因此，如果您要为您的EC2实例分配另一个EC2实例角色或IAM自配置文件，
请确保您仍然具有必要的额外权限｡
因此，即使您已经在Beanstalk上启用了守护进程，
您仍然需要确保IAM角色是正确的｡
这堂课就到这里｡
只要确保当你完成这个应用程序，并采取了下来，
但现在你知道如何使beanstalk与X射线工作｡
希望你们喜欢，
下次课再见.
  - [ ] 258 X-Ray & ECS [04:10]
    * 
解说员：好的，这是一个关于如何将ECS与X射线集成的理论讲座，以及您将拥有的三种选择｡
首先，您有一个ECS群集，
运行X-Ray守护程序的一种方法是将容器本身用作守护程序｡
那么，这是什么意思？
这意味着我们有两个EC2实例｡
例如，在我们的ECS群集中，
请记住，我们管理这些EC2实例，因此我们将运行X射线守护程序的守护程序任务和守护程序容器｡
所以这里有两个冰到Daemon这个词｡
这意味着X射线守护程序容器将在每个EC2实例上运行｡
如果ECS集群中有10个EC2实例，则将有10个容器（每个EC2实例上一个）作为守护程序容器运行｡
好的，这意味着X-Ray代理现在正在所有这些EC2实例上运行｡
因此，您可以在EC2实例上启动您的应用容器，并在从网络角度正确地将它们匹配后，
使用UDP端口访问X射线守护程序｡
然后您就可以运行所有应用程序了｡
因此，在本例中，每个EC2实例只有一个X射线守护程序容器｡
现在，在ECS集群中运行X射线的第二种模式称为Side
Car模式｡
那么，侧车模式是什么意思呢？
这意味着您仍然拥有EC2实例，
但现在您将在每个应用程序容器旁边运行一个X-Ray守护程序容器，它们将从一个网络连接点连接｡
这就是它被称为Side Car的原因，因为X射线守护程序现在作为我们的应用程序容器并排运行，它是一个Side
Dar｡
现在来看，每个应用容器都有一个Side Car｡
因此，如果您在一个EC2实例下有20个应用容器，
那么我们将有20个X射线侧车｡
这就是它的工作方式，从侧车模式开始.
对于Fargate集群，我们无法控制EC2实例，它只是一个ECS集群，
我们无法控制底层实例｡
因此，
我们不能使用X射线守护程序容器，我们还必须使用X射线容器作为Side Car模式｡
因此，如果您要启动Fargate任务，则需要在各处使用应用程序容器和X射线侧车｡
因此，
这为您提供了运行ECS和X射线的三个选项，希望这能让您更清楚地了解如何进行操作｡
现在，我仍将向您展示一个示例任务定义，但我们不打算运行它，
因为我们需要构建所有映像，这将非常复杂｡
但这里有一些文档中的内容｡
我们在这里看到了什么？
首先，我们应该了解的是，X射线守护程序是否正在运行，
这是此任务定义的第一部分｡
在端口映射方面，容器端口2000被映射到实例上｡
协议是UDP｡
记住这个容器端口2000，协议是UDP｡
一旦X射线守护程序开始运行，
这就是Side Car模式，这就是我们的应用程序｡
这个案子叫“计分Api”
我们需要了解的第二件事是，这个环境变量称为AWS X-Ray守护程序地址，
您需要设置这个环境变量，因为这是X-Ray守护程序知道在哪里查找的方式，抱歉，
这是X-Ray知道如何查找X-Ray守护程序的方式｡
因此，
它的价值是X-Ray Daemon端口2000，而这2000来自上面的2000，最后，
您需要做的最后一件事是，从网络角度将这两个容器链接在一起｡
这就是为什么它说链接X-Ray Daemon，这就是它如何能够将此主机名X-Ray
Daemon解析到此处的容器｡
因此，
这可能会有点复杂，特别是如果您是ECS的新手｡
但请记住，
本幻灯片的要点是，您需要将X射线守护程序的容器端口映射到2000 UDP｡
然后，您需要设置一个环境变量，称为X-Ray
Daemon地址｡
最后，您需要从网络的角度链接这两个容器｡
因此，我希望这能帮助您准确理解如何使用ECS运行X射线｡
我知道这个问题在考试中被几个学生提过好几次｡
所以我想如果你能深入了解这些东西是如何工作的，那会很好｡
好了，
我希望这对你们有帮助，我们下节课再见｡
  - [ ] 259 AWS Distro for OpenTelemetry [02:40]
    * 
现在让我们来谈谈Opentelemetry的AWS发行版｡
因此，Opentelemetry是一个项目，AWS已经创建了该项目的发行版，该发行版受到支持，他们称之为安全和生产就绪｡
什么是OpenTelemetry？
Opentelemetry是一种获得一组API､ 库代理和收集服务的方法，
可以为应用程序收集分布式跟踪和指标｡
它还可以帮助您从AWS､ 资源和服务中收集元数据｡
这个想法是，它非常类似于x射线，但它是开源的｡
所以你有代理，这些代理可以被自动检测来收集痕迹，甚至不需要你修改代码，这看起来非常类似于x射线｡
最重要的是，由于这种收集，可以在您的帐户和应用程序中大规模发生，
所有这些跟踪和这些指标都可以发送到多个AWS服务以及合作伙伴解决方案｡
例如，我们有可以发送到X射线服务的痕迹｡
我们有可以发送到cloudwatch或跟踪的指标，可以发送到Prometheus｡
这个想法是，您将检测在AWS上运行的应用程序，例如EC2，
X, ECS, Fargate或Lambda，或者它可以是在本地运行的应用程序｡
然后，您将使用OPENTELEMETRY标准将这些跟踪和度量发送到x
ray或Datadog等合作伙伴服务｡
因此，Opentelemetry和x ray之间的区别在于，您可能希望从x ray迁移到使用AWS发行版的Opentelemetry如果您希望使用开源API进行标准化，
因为您希望所有内容都使用遥测，或者您可能希望同时将跟踪数据发送到多个目的地，
这是Opentelemetry支持的｡
总而言之，我们有Opentelemetry的发行版，我们在那里收集跟踪，然后传递来自每个应用程序的请求｡
然后，我们可以再次收集每个地图的指标，然后我们也可以收集感谢发行版｡
我们可以收集有关您的资源的上下文数据，这些数据可以发送到x ray cloudwatch Amazon Managed Service
for Prometheus以及Opentelemetry支持的任何合作伙伴监控解决方案｡
原来如此｡
只是一个高层次的概述，但你知道它是什么｡
如果你在考试中看到这个，通常它只能是一个非常高水平的问题｡
希望你们喜欢，下次课再见.
  - [ ] 260 CloudTrail [06:32]
    * 
解说员：现在我们来谈谈CloudTrail｡
因此，CloudTrail是一种为您的AWS帐户获取治理合规性和审计的方法｡
默认情况下启用CloudTrail｡
这将允许您通过控制台､ SDK､ CLI和AWS上的其他服务获取AWS帐户内的所有事件和API调用的历史记录，
所有这些日志都将显示在CloudTrail中｡
现在，您可以做的是，您也可以将这些日志从CloudTrail放入CloudWatch
Logs或Amazon S3｡
如果您想将所有区域中累积的所有这些事件历史记录累积到一个特定的存储区（例如S3存储区）中，
则可以创建要应用于所有区域或单个区域的跟踪｡
例如，当我们使用CloudTrail时，
我们会说有人在AWS中删除了一些东西｡
例如，假设一个EC2实例被终止，
你想找出是谁干的？
好吧，答案是查看CloudTrail，
因为CloudTrail将在其中包含该API调用，并且能够深入了解它并了解谁在何时做了什么｡
因此，总结一下，CloudTrail位于中间，
SDK､ CLI或控制台甚至IAM用户和IAM角色或其他服务的操作都将在CloudTrail控制台中｡
我们可以查看它来检查和审计发生了什么｡
如果你想拥有超过90天的所有事件，那么我们可以将它们发送到CloudWatch日志中，
或者我们可以将它们发送到S3存储桶中｡
所以让我对CloudTrail深入一点｡
所以我们有三种类型的事件，你可以在CloudTrail中看到｡
第一个称为管理事件，
这些事件表示对AWS帐户中的资源执行的操作｡
例如，每当有人配置安全性时，他们将使用名为IAM
AttachRolePolicy的API调用｡
这将出现在CloudTrail中｡
如果您创建了子网，也会显示此信息｡
如果您设置了日志记录，则默认情况下会显示此信息｡
任何修改您的资源或iOS帐户的内容都将显示在CloudTrail中｡
默认情况下，无论发生什么，
都将跟踪配置为记录管理事件｡
您可以区分两种管理事件｡
您拥有不修改资源的读取事件｡
例如，有人列出了IAM中的所有用户，
或者列出了EC2中的所有EC2实例，诸如此类｡
您可以将它们与可能修改资源的写入事件分开｡
例如，有人删除或试图删除DynamoDB表｡
显然，写事件可能更重要，
因为它们可能会破坏您的AWS基础设施｡
而读取事件只是为了获取仍然非常重要的信息，
但可能破坏性较小｡
然后是数据事件｡
因此，它们是独立的，默认情况下不会记录数据事件，
因为它们是高容量操作｡
什么是数据事件？
您有Amazon S3对象级别的活动，例如GetObject､
DeleteObject､ PutObject｡
正如您所看到的，
这些情况在S3铲斗上经常发生｡
这就是为什么默认情况下它们不会被记录，
并且您可以选择再次分离读取和写入事件｡
因此，读取事件将是GetObject，而右事件将是DeleteObject或PutObject｡
CloudTrail中的另一种事件是AWS
Lambda函数执行活动｡
因此，无论何时有人使用Invoke API，
您都可以了解Lambda函数被调用的次数｡
同样，如果你的Lambda函数被执行了很多次，
这可能是非常高的容量｡
CloudTrail中的第三种事件称为CloudTrail
Insights事件｡
因此，我将在下一张幻灯片中详细介绍CloudTrail
Insights｡
现在让我们来谈谈CloudTrail Insights｡
因此，当我们在所有类型的服务中有如此多的管理事件，
并且在您的帐户中有如此多的API快速发生时，很难理解什么看起来很奇怪，
什么看起来不寻常，什么看起来不寻常｡
这就是CloudTrail Insights的用武之地｡
因此，使用CloudTrail Insights，
您必须启用它，并且必须支付费用，它将分析您的事件并尝试检测您帐户中的异常活动｡
例如，在准确的资源调配､ 达到服务限制､
AWS IAM操作的突发､ 定期维护活动的间隙等方面｡
因此，它的工作方式是CloudTrail将分析正常管理活动的外观以创建基线，
然后它将不断分析任何正确类型的事件｡
因此，每当有东西被改变或试图被改变时，
就可以检测到不寻常的模式｡
因此，很简单，管理事件将由CloudTrail Insights持续分析，
如果检测到某些情况，CloudTrail Insights将生成Insights Event｡
因此这些异常，这些洞察事件将出现在CloudTrail控制台中｡
如果你愿意，它们也会被发送到亚马逊行业，以及一个EventBridge事件｡
因此，在CloudWatch中，如果您需要在这些CloudTrail
Insights之上自动化，例如发送电子邮件，
将生成事件｡
这就是CloudTrail Insights背后的想法｡
最后，让我们谈谈CloudTrail事件保留｡
因此，默认情况下，事件在CloudTrail中存储90天，
然后将其删除，但有时您可能希望将事件存储更长时间，
以防您想要返回到一年前发生的事件以进行审计｡
因此，要将事件保存在此期间之外，
您必须将它们记录到S3｡
所以把它们发送到S3，然后你会用雅典娜来分析它们｡
因此，非常简单，您的所有管理事件，数据事件和洞察事件都将进入CloudTrail
90天，保留期｡
然后，您将这些记录到S3存储桶中，
以便长期保留｡
当您准备好分析它们时，
您可以使用Athena服务，它是一个无服务器服务，
用于查询S3中的数据，以查找您感兴趣的事件并了解有关它们的更多信息｡
好的，非常重要的CloudTrail集成需要知道的是与Amazon
EventBridge的集成，以拦截任何API调用｡
假设您希望在用户使用DeleteTable
API调用删除DynamoDB中的表时收到SNS通知｡
因此，每当我们在AWS中执行API调用时，如您所知，
API调用本身将记录在CloudTrail中，
这适用于任何API调用，但所有这些API调用最终也将作为事件记录在Amazon EventBridge中｡
因此，我们可以查找非常特定的DeleteTable
API调用并创建一个规则｡
此规则将有一个目标，目标是Amazon
SNS，因此我们可以创建警报｡
这很简单，但你可以为任何API调用做这件事，
这将关闭CloudTrail的所有主题｡
我希望你们喜欢这节课，
我们下次课再见｡
  - [ ] 261 CloudTrail [01:30] Hands On
    * 
  - [ ] 262 CloudTrail vs CloudWatch vs X-Ray [01:18]
    * 
讲师：这对你来说可能很明显，
但CloudTrail､ CloudWatch和X-Ray之间有什么区别？
我会用一张幻灯片来总结一下｡
因此，CloudTrail将审核用户､
服务甚至AWS控制台在您的帐户中进行的API调用｡
当您希望检测未授权调用或查找由于API调用而导致更改的根本原因时，它非常有用｡
现在，CloudWatch是使用指标进行监控的，
所以CloudWatch Metrics用于监控，CloudWatch Logs用于存储应用程序日志｡
例如，
CloudWatch Alarms可在出现意外指标时发送通知｡
所以所有这些都与监控有关，好吗？
因此，
CloudTrail是API调用，CloudWatch将围绕监视进行｡
X-Ray用于自动跟踪分析和中央服务图可视化，因此，如果您有分布式服务，
这是一种很好的查看方式｡
这对于调试以及从X射线控制台中查看延迟､ 错误和故障分析等内容非常有帮助｡
正如我所说的，您还可以在分布式系统中进行请求跟踪｡
因此，希望这能让我们非常清楚地了解哪些服务用于什么｡
CloudWatch实际上只是用于总体指标，X-Ray是一种更细粒度的､ 面向跟踪的服务类型，
CloudTrail将用于审计API调用｡
好吧，希望这对你有帮助｡
我们下节课再见｡ 
  - [ ] 263 AWS Quick Clean-Up [00:46]
    * 
教练：所以，只是一个快速的清理｡
在此阶段，我们将不再使用Beanstalk，
因此，如果您转到Beanstalk，您可以删除所有这些环境，
为此，您只需删除应用程序，然后单击“删除”，
这将删除其中的所有内容｡
同样，您也可以转到CodeDeploy和CodePipeline，如果您愿意，
也可以删除它们，因此该过程非常简单｡ 您可以转到CodePipeline，
单击您的管道，如果您希望保存一些成本，则可以进行编辑和删除｡ 您还可以删除我们在本课程中创建的所有其他内容，这样您就可以控制成本｡
但目前最昂贵的资源是Elastic
Beanstalk，因此，
如果您已经了解了本课程的内容，请确保删除Elastic Beanstalk｡
  - [ ]  Monitoring & Audit [24 问题] Quiz
    * 
 ## Section 21 - AWS Integration & Messaging: SQS, SNS & Kinesis [27 个讲座 • 2 小时 11 分钟]
  - [ ] 264 AWS Integration & Messaging - Section Introduction [00:44]
    * 
所以现在我们已经部署了一个应用程序，使用弹性豆茎以完美的自动化方式，由云形成支持并完全监控｡
如果您要部署多个应用程序，该怎么办？
为此，他们需要进行沟通，我们将了解您可以在AWS上进行的沟通和集成模式｡
我们将学习SQS，它实际上是最古老的AWS服务，但如果你想真实的流传输大数据，
它也是SNS和Kinesis｡
这一部分实际上是一个深入的探讨，因为考试会问你很多问题，尤其是在这个SQS中｡
所以请注意｡
让我们开始练习，学习如何将我们的应用程序集成在一起｡ 
  - [ ] 265 Introduction to Messaging [02:45]
    * 
讲师：欢迎学习AWS集成和消息传递部分｡
这一部分很酷，因为我们将了解如何使用中间件在不同的服务之间编排内容｡
因此，在本节中，当我们开始部署多个应用程序时，
它们将不可避免地必须相互通信｡
好吧，你们的服务需要共享信息，共享数据｡
因此，将有两种应用程序通信模式｡
这将是一个同步通信，因此您的应用程序将直接连接到您的另一个应用程序｡
例如，我们在网上销售产品，
我们有购买服务，当购买产品时，我们需要与运输服务联系，以便将刚购买的产品发送出去｡
正如您在这里看到的，
我的购买服务和发货服务，它们彼此直接连接，因此存在一些同步通信｡
我的购买服务说，嘿，发生了一些事情，航运服务，
做，好吗？
另一种类型的集成和模式将是异步的或基于事件的｡
因此，将有一个称为队列或其他名称的中间件，
基本上将连接您的应用程序｡
所以这次购买服务说，嘿，有人买了东西，
所以我要把它放到一个队列里，就这样｡
送货服务员说，嘿，排队，
有什么最近买的吗？
队列将返回该元素，运输服务可以做任何它想做的事情｡
因此，
正如您在这里看到的，购买服务和运送服务并不直接相关｡
中间有一个队列｡
因为它们之间不直接对话，所以这是异步的｡
现在，应用程序之间的同步有时可能会有点问题，因为如果一个服务因为突然出现购买高峰或其他原因而压倒另一个服务，
这可能是一个大问题｡
所以如果你需要编码，
比如我们有一个视频编码服务，我们需要编码1，000个视频，但通常是10个｡
我们的编码服务将不堪重负，我们将有中断｡
因此，
当您遇到这些突发的流量高峰或无法预测任何情况时，通常最好将应用程序解耦，并让解耦层为您进行扩展｡
在这种情况下，队列模型可能是SQS，发布/订阅模型可能是SNS，
如果您真实的流传输并拥有大数据，则可能是Kinesis｡
我们将在本节中学习所有这些内容｡
我们将学到的是，现在，
通过使用这三样东西，我们的服务可以独立于SQS､ SNS和Kinesis进行扩展｡
这三个方面的规模也非常非常大｡
这就是整个范例｡
所以在这节课上我们要开始学习这三种技术｡
下节课再见｡ 
  - [ ] 266 Amazon SQS - Standard Queues Overview [10:35]
    * 
教师：现在我们来谈谈SQS, SQS的核心是队列，
因为SQS是一个简单的队列服务｡
因此，
我们有一个SQS队列，它将包含消息｡
为了包含消息，
需要将消息发送到SQS队列中，而将消息发送到SQS队列中的任何东西都称为生成器｡
所以我们有可能有一个生产商，但也有可能有更多｡
您可以让多个生成器将许多消息发送到SQS队列中｡
他想要什么信息都行｡
例如，它可以处理此订单，
或处理此视频｡
您创建的任何消息都将进入队列｡
然后需要处理来自队列的消息并接收它们，这就是所谓的消费者｡
消费者将轮询队列中的消息，
这意味着他们将询问队列，您有给我的消息吗？
然后排队的人说，是的，在这里｡
消费者将轮询这些消息并获得一些信息｡
然后，它将对该消息进行处理，然后将其从队列中删除｡
您可能有多个使用者使用SQS队列中的消息｡
因此，
这里的队列服务是一个缓冲区，用于在生产者和消费者之间解耦｡
现在，SQS是一项复杂的服务，
我们将深入了解，但第一个产品称为Amazon SQS，
用于标准队列｡
SQS是AWS历史上最古老的产品｡
它是AWS上的首批服务之一｡
它已经有10年的历史了，所以它的工作原理已经非常非常固定了｡
它是一个完全托管的服务，将用于分离应用程序｡
因此，每当您在考试中看到应用程序解耦时，请考虑Amazon
SQS｡
为什么SQS如此特别？
我们的吞吐量是无限的｡
这意味着每秒可以发送任意多的消息，并且队列中也可以包含任意多的消息｡
因此，
吞吐量没有限制，队列中的消息数量也没有限制｡
现在，每条消息都是短暂的｡
那是什么意思？
这意味着，默认情况下，邮件将在队列中停留四天，
邮件在队列中的最长时间为14天｡
这意味着，
一旦将消息发送到队列，使用者就必须读取该消息，
并在该保留期内处理完该消息后将其从队列中删除，否则，该消息将丢失｡
然后我们就有了低延迟｡
因此，SQS对他们来说意味着，无论何时发送消息或从SQS读取消息，您都将得到非常快的响应，
发布和接收时间不到10毫秒｡
SQS中的消息必须很小｡
每个发送的邮件必须小于256 KB｡
现在SQS是一个队列服务，因此您可以看到高吞吐量､ 高容量等，
因此可能会有重复的消息｡
这意味着，例如，有时一个消息将被传递两次，
这就是为什么它被称为至少一次传递｡
如果您继续编写应用程序，您需要考虑到这一点｡
它还可能有未按顺序订购的消息，
这意味着它是尽力订购，我们将看到SQS提供的另一种类型的产品可以处理这一限制，但我们将在本节稍后部分看到这一点｡
那么，让我们回到消息生成器｡
因此，生成器会将最大为256
KB的消息发送到SQS｡
它是如何发生的？
生产商将使用SDK（软件开发工具包）将消息发送到SQS｡
将消息发送到SQS的API称为SendMessage｡
很简单的｡
现在，将写入消息，
并将其保存到SQS队列中，直到使用者读取并删除该消息，
这表示该消息已被处理｡
我们知道保留｡
那么，生成消息的用例是什么呢？
例如，
您希望处理订单（如包裹），然后将其运送到中心｡
因此，您希望在自己的时间内完成此操作，以便向SQS队列中发送一条消息，其中可能包含一些信息，
如订单ID､ 客户ID和您可能需要的任何属性｡
例如，地址等等｡
然后，
您的消费者，即应用程序权限中的消费者，将不得不处理该消息本身｡
因此，再次确认，SQS标准具有无限吞吐量｡
我们已经看到了制片人｡ 很简单的｡
现在我们来看看消费者｡
消费者是我们必须使用一些代码编写的应用程序，这些应用程序可以在EC2实例上运行，例如AWS上的虚拟服务器，但如果您愿意，
它们也可以在您自己的内部部署服务器上运行，或者，
我们还没有看到，但它们也可以在AWS Lambda上的Lambda函数上运行｡
我们将在本课程中了解到，这是一种无服务器计算类型的服务｡
这意味着你也可以直接从他们那里读取消息｡
我们稍后会在本课程中看到这一点，请不要担心｡
因此，
回到我们关于EC2实例的简单用例，我们的队列有一个使用者，使用者轮询SQS以获取消息｡
这意味着消费者会问队列，你有给我的消息吗？
并且消费者一次可以接收多达10条消息｡
因此，如果SQS队列中有消息，它将收到一个有效的响应，
说明这些消息正在等待您｡
然后，
消费者，也就是您的代码，有责任处理这些消息｡
例如，将一些订单插入RDS数据库｡
因此，您将继续为每个订单将其插入到您的RDS数据库中，您必须编写一些内容，显然是使用您的代码，
然后，
由于这些消息已被处理，因为它们已被接收并插入到Amazon
RDS数据库中，您的消费者将继续使用DeleteMessage API从队列中删除这些消息｡
这将保证没有其他使用者能够看到这些消息，因此消息处理完成｡
现在我们可以扩大规模｡
我们可以同时拥有多个消费者｡
因此，
我们的SQS队列可以有多个使用者，这些使用者将并行接收和处理这些消息｡
这里我们有三个EC2实例，每个使用者将通过调用poll函数接收不同的消息集｡
因此，
如果某个使用者处理消息的速度不够快，它就会被其他使用者接收到，这就是为什么我们至少有一次传递｡
这也是为什么我们采用尽力而为消息排序的原因｡
现在，
正如我所说的，当消费者使用完这些消息时，
他们必须删除它们，否则，其他消费者将看到这些消息｡
这意味着，如果我们需要通过SQS队列提高吞吐量，因为我们有更多的消息，
那么我们可以添加使用者并进行横向扩展，以提高处理的吞吐量｡
因此，如果您还记得我们说过的话，这是一个将SQS与自动缩放组（ASG）配合使用的完美用例｡
那么，这是什么意思？
这意味着您的使用者将运行在Auto Scaling组中的EC2实例上，
并且它们将轮询SQS队列中的消息｡
但是，现在您的自动缩放组必须根据某种指标进行缩放，
而我们可以使用的一个指标是队列长度｡
它被称为近似消息数｡
这是一个CloudWatch指标，可用于任何SQS队列｡
我们可以设置一个警报，例如，
每当队列长度超过一定水平时，请设置一个CloudWatch警报，此警报应将我的自动缩放组的容量增加X个数量｡
这将保证您的SQS队列中的消息越多（可能是因为您的网站上订单激增），您的自动缩放组将提供越多的EC2实例，
您将相应地以更高的吞吐量处理这些消息｡
这是一个非常常见的集成，您将在考试中看到｡
现在，SQS的使用情形是在应用程序之间进行解耦，也就是应用程序层｡
例如，让我们以处理视频的应用程序为例｡
我们可以只有一个大型应用程序，称为前端，
它将接受请求，
每当需要处理视频时，它将进行处理，然后将其插入S3存储桶｡
但问题是，处理可能会非常，
非常长的时间来做，
它可能只是放慢您的网站，如果你这样做的前端在这里｡
因此，
您可以在这里分离应用程序，并说，
等一下，处理文件的请求和文件的实际处理可以在两个不同的应用程序中发生｡
因此，
无论何时收到处理文件的请求，都将向SQS队列发送一条消息｡
现在，当您发出要处理的请求时，
该文件将位于SQS队列中，
您可以创建第二个处理层，称为后端处理应用程序，
该应用程序将位于其自己的自动缩放组中，以接收这些消息､ 处理这些视频并将它们插入S3存储桶｡
因此，正如我们在此架构中所看到的，我们可以相应地扩展前端，
也可以相应地扩展后端，但这两种扩展是独立的｡
因为SQS队列具有无限的吞吐量，并且就队列而言，它具有无限数量的消息，所以你真的很安全，
这是一种健壮且可伸缩的体系结构｡
此外，对于您的前端，您可以使用最佳类型的EC2实例或架构｡
对于后端，
如果您正在进行一些视频处理，则可以使用一些具有GPU（图形处理单元）的EC2实例，因为您知道这些类型的实例最适合处理此类工作负载｡
这就是考试中要用到的体系结构，也是大家应该了解的，
这是SQS队列的一个非常棒的使用案例｡
最后是SQS安全性｡
因此，我们通过使用HTTPS API发送和生成消息来实现动态加密，
使用KMS密钥实现静态加密，如果需要，我们还可以进行客户端加密，
但这意味着客户端必须自己执行加密和解密｡
它不是由SQS提供的现成支持｡
对于访问控制，IAM策略将能够控制对SQS API的访问，但我们也有SQS访问策略，
类似于S3存储桶策略，当您希望跨帐户访问SQS队列，
或希望允许其他服务（例如我们很快将看到的SNS或Amazon
S3）写入SQS队列时，这些策略非常有用｡ S3事件｡
以上就是SQS的概述｡
我希望你们喜欢它，我们下次课再见，进行一些练习｡
  - [ ] 267 SQS - Standard Queue [06:27] Hands On
    * 
  - [ ] 268 SQS Queue Access Policy [07:08]
    * 
演示者：现在，我们来讨论SQS队列访问策略｡
SQS队列访问策略有两个很好的用例｡
它们类似于S3 Bucket策略，
因为它们都是资源策略，因此您将直接添加到SQS队列中的JSON
IAM策略｡
因此，第一个用例允许跨帐户访问｡
假设您在一个帐户中有一个队列，而另一个帐户需要访问该队列｡
可能它有EC2实例｡
因此，为了使EC2实例能够跨帐户拉取消息，您需要做的是创建一个如下所示的队列访问策略，
并将其附加到第一个帐户中的SQS队列｡
这个Q访问策略将做的是，
它将允许AWS的原则是111122223333，它代表了这个资源上sqs ReceiveMessage右侧的帐户｡
因此，这个队列访问策略实际上是允许您的EC2实例从另一个帐户的SQS队列中提取的｡
SQS队列访问策略的另一个用例是，例如，当您有一个S3
Bucket时，它将向SQS队列发布事件通知｡
例如，您将一个对象上载到S3
Bucket中，
并且您希望自动获得发送到SQS Queue的消息｡
正如您所看到的SQS队列，我们需要向S3 Bucket给予权限，
以便向其写入消息｡
因此，我们需要创建自己的SQS队列访问策略，
如下所示｡
例如，
如果您查看详细信息，操作是sqs：只要条件是存储桶的sourceArn表示名为bucket1的S3存储桶，
并且源帐户需要是S3存储桶的帐户所有者，AWS就会从任何帐户启动SendMessage（主体）｡
因此，一旦您有了它，就允许S3存储桶写入SQS队列｡
这是很重要的一点，因为考试将测试您，例如，
需要哪些内容才能写入SQS队列以进行跨帐户访问或发布S3事件通知｡
所以你有它｡
因此，让我们创建一个队列并设置SQS队列访问策略｡
因此，
我将此事件称为来自S3的事件，因为我们将设置一个S3事件通知以进入此SQS队列｡
我会将其他所有内容保留为默认值｡
哦，
正如我们所看到的，这里有SQS访问策略｡
因此，我们可以在这里定义什么类型的服务可以将数据发送到SQS队列｡
因此，如果我们选择基本方法，
则可以仅选择队列所有者将数据发送到SQS队列中，
这将表示此情况，或者我们可以仅选择此处指定的指定帐户､ IAM用户和角色｡
因此，这是一个获得交叉或帐户访问权限的队列，
谁可以发送消息｡
对于谁可以从队列接收消息，我们有相同的对话框｡
好吧，我会的
消息是不会帮助我们的亚马逊是免费的，或者我们可以做先进的，
并为此编写我们自己的SQS队列访问策略｡
与此同时，我还是选基础吧.
告诉你事情一开始是不可行的，然后我们要修改它，
然后看看事情会在之后可行｡
我们将在这里创建这个队列，
现在进入Amazon S3，好吗？
我将创建一个S3 Bucket｡
从S3 Bucket，设置事件通知以将数据发送到SQS Queue｡
现在，我们创建一个跨demo-sqs-queue-access-policy的存储桶，
然后单击“创建存储桶”｡
好吧，我会的
这就是了｡
然后我将进入“属性”，向下滚动，
找到我们的事件通知｡
我将创建一个事件通知｡
我把它命名为NewObjects，对于所有前缀或后缀以及事件类型，
我们选择所有对象创建事件.
太完美了｡
向下滚动，目标将是SQS队列｡
我们需要从SQS队列中进行选择，
因此我们找到EventFrom S3，单击保存changes｡
正如我们所看到的，我们得到了一个错误，
因为现在它无法验证以下目标配置｡
因此，
我们需要做的是进入该访问策略，并对其进行修改，以允许S3存储桶写入SQS队列｡
因此，
我们可以直接查看文档，看看是否可以找到此策略｡
所以我们只做一个简单的谷歌｡
因此S3事件进入SQS访问策略｡
他们应该给予我们提供我们需要的东西｡
所以，好吧，完美｡
我们有事件通知｡
然后我将进入Amazon SQS｡
所以授予权限｡
我们走吧｡
配置SQS和SNS｡
然后我们要加上这个｡
这是我们需要为SQS队列设置的策略文档｡
所以我要复制它，编辑它，然后粘贴它｡
因此，我们需要改变，以拥有QRN｡
所以让我在这里做一个小的，肮脏的编辑｡
但是资源QRN必须从这里复制并粘贴到那里｡
好吧，我会的
然后我们假设条件是ArnLike，
源存储桶的名称必须与源存储桶的名称相同，所以我们在这里找到源存储桶的名称，我们将把它复制到该策略中｡
源帐户所有者是我们目前拥有的帐户｡
我将在这里找到我的帐户ID，复制并粘贴它｡
所以这个政策，我需要删除旧的｡
因此，此策略允许S3 Bucket将消息发送到SQS
Queue中｡
还算不错｡
我们会保存这个｡
它不是一个有效的JSON，因为我遗漏了一个逗号｡
点击保存｡
我们开始吧｡
现在，
通过这个新策略，我们来看看是否可以保存事件通知｡
是的，我们可以｡
因此，该操作成功完成｡
实际上，如果您进入Amazon SQS并要发送和接收消息，
则有一条消息可用，我们可以提取该消息，查看它，
并查看Amazon发送的测试事件是否免费进入我们的SQS队列｡
就这样，如果我们想上传一条消息，我们可以在Amazon中免费上传一个文件，
然后在SQS中查看｡
但我想在这里向您展示的是，通过修改访问策略，我们确实提供了从S3
Bucket到SQS
Queue的访问，这正是我们想要的效果｡
这节课就讲到这里｡
希望你喜欢｡
我们下节课再见｡
  - [ ] 269 SQS - Message Visibility Timeout [05:18]
    * 
教师：现在，
我们来讨论一个重要的概念，即消息可见性超时｡
因此，当某个使用者轮询消息时，
其他使用者将看不到该消息｡
让我们举个例子｡
时间从左到右，我们有一个使用者执行ReceiveMessage请求，因此，
将从队列中返回一条消息｡
现在，可见性超时开始｡
默认情况下，消息可见性超时为30秒｡
这意味着在这30秒内，信息必须被处理，
好吗？
如果您这样做，
这意味着如果同一个或其他使用者执行消息请求API调用，则不会返回该消息｡
在超时窗口期间再次发送一条消息，则不会返回该消息｡
因此，
在可见性超时期间，该消息对其他使用者是不可见的｡
但是，在经过可见性超时之后，如果消息尚未删除，则消息将被放回队列中，
因此，另一个使用者或执行接收消息API调用的同一个使用者将再次收到该消息，
与之前的消息相同｡
所以，这是非常重要的一点｡
如您所见，
当我们收到消息时，它在可见性超时期间变得不可见｡
现在，
如果我们看一下同一个图，我们会注意到，
如果我们没有在可见性超时窗口内处理消息，那么它可能会被处理两次，对吗？
因为它会被两个不同的消费者接收，或者被同一个消费者接收两次｡
因此，如果使用者正在主动处理消息，但知道它需要多一点时间来处理该消息，
因为否则它将超出可见性超时窗口，则有一个名为ChangeMessageVisibility的API｡
因此，如果使用者知道消息需要多一点时间来处理，而您不想将该消息处理两次，
则使用者应调用ChangeMessageVisibility API来告诉SQS，
嘿，
现在不要使该消息可见，好吗？
我只是需要多一点时间来处理这条信息｡
那么，如何设置此消息可见性超时呢？
如果默认情况下将其设置为非常非常高的值，
比如说小时，那么消费者崩溃时，将需要几个小时，
直到此消息重新出现，在SQS队列中重新可见，这将需要大量时间｡
如果您将其设置为非常非常低的值，例如几秒，那么如果使用者由于某种原因没有足够的时间来处理该消息，
那么它将被不同的使用者多次读取，您可能会得到重复的处理｡
因此，我们的想法是，应将可见性超时设置为适合您的应用程序的值，
并且应对您的使用者进行编程，使其在知道需要更多时间时，应调用ChangeMessageVisibility
API以获得更多时间并增加该可见性窗口的超时｡
但是从考试的角度来理解这个概念是非常重要的，因为会有关于这个的场景｡
现在，
让我们进入控制台，看看它在实践中是如何工作的｡
我将打开发送和接收消息的两个窗口，向大家展示这是如何工作的｡
在第一个窗口中，
我将输入一个hello world，它将被发送到队列中｡
如果您还记得的话，队列的默认超时时间为30秒｡
接下来，我有两个使用者，第一个窗口和第二个窗口使用者，
我将从第一个窗口读取消息｡
让我们来轮询消息｡
现在我的信息就出现在这里，它已经被接收了｡
如果我进入第二个消费者并轮询消息，如您所见，
消息不会出现在这里｡
它没有出现的原因是，我们仍在该消息的可见性窗口超时范围内，因此，
在这30秒内，此消息正试图由该使用者处理，
此时该使用者将看不到它｡
但假设我们停止了投票，好吗？
因此，
我们不删除该消息，并且我们知道该消息将在某个时间点超时｡
接下来会发生的是，是的，我已经在这里了，在第二个窗口中，
在第二个使用者中，
这是第二个使用者，然后消息已经被接收，因为它被放回了队列中｡
现在，
让我们假设我们做了正确的事情，我们删除了该消息，然后我们已经完全处理了该消息｡
但请记住，这条信息收到了两次｡
它说收到的计数是2｡
因此，了解该可见性窗口的工作原理非常重要，
这是一个很好的演示｡
现在，
如果您想更改默认设置，您可以进入“编辑”，然后对于可见性超时，您可以将默认值设置为0秒（绝对不推荐）到12小时之间｡
我认为30秒是可以的，但请记住，
如果使用者需要更多时间来处理消息，您只需调用ChangeMessageVisibility API来编辑该消息的可见性并增加该值，以便另一个使用者不会看到该消息，
而第一个使用者将有足够的时间来相应地处理该消息｡
就这样了｡
我希望你们喜欢，下节课再见｡ 
  - [ ] 270 SQS - Dead Letter Queues [02:46]
    * 
教师：现在我们来讨论SQS中的死信队列｡
其思想是让我们进入这样一个场景：使用者在可见性超时期间内无法处理消息｡
然后我们知道消息会自动返回到队列中｡
所以消费者看了信息，
可能出了故障，可能我们没有足够的时间｡
消息返回队列｡
现在，如果这种情况经常发生，
这可能是一个问题｡
比如，我们再看一遍留言，
可能留言有问题｡
也许我们的消费者不理解信息或无法处理信息｡
然后，消息将返回到队列中，并将再次发生｡
我们将再次从SQS读取消息，
它将再次返回到队列中｡
所以我们可以设定一个阈值来计算这种情况发生的次数｡
而且，这种故障循环可能是一个大问题，
但我们可以设置MaximumReceives阈值｡
如果超过了这个阈值，我们可以告诉SQS说，
“嗯，这个消息看起来有点奇怪｡
它似乎被处理了太多次，
但没有成功｡ 因此，将其发送到死信队列中｡
死信队列将包含该消息并供以后处理｡
因此消息将从第一个队列中移除并发送到第二个队列中｡
为什么我们有死信队列？
死信队列对于调试非常有用，
如果一条消息进入死信队列，因为它是一个SQS队列，
你必须处理它，但至少它给了你时间来理解发生了什么｡
需要注意的是，FIFO队列的死信队列也必须是FIFO队列，
标准队列的死信队列也必须是标准队列｡
最后，因为我们有一个死信队列，
所以您需要确保消息在队列中过期之前得到处理｡
因此，最好设置一个较长的时间，
例如，死信队列中的保留时间为14天｡
管理死信队列的下一个特性是重新驱动到源特性｡
因此，这是一个帮助您使用死信队列中的消息以了解它们的问题所在的功能｡
现在您有了消息，您知道它们尚未在源队列中处理，
因此它们位于死信队列中，您将对这些消息执行手动检查和调试｡
然后，您将修复您的使用者代码，
了解为什么在消息正确的情况下没有处理消息｡
然后，您可以将该消息从死信队列重新驱动到源SQS队列中｡
接下来，使用者可以重新处理该消息，甚至不知道该消息已进入死信队列，然后消息处理已经发生，这是一项很酷的功能｡
现在让我们进入控制台，
向您展示死信队列功能｡
  - [ ] 271 SQS - Dead Letter Queues [03:46] Hands On
    * 
  - [ ] 272 SQS - Delay Queues [02:27]
    * 
教师：现在我们来讨论延迟队列｡
延迟队列就是延迟消息，这样消费者就不会立即看到它们｡
而这可能是最多15分钟的延迟｡
默认情况下，delay参数为零秒｡
这意味着，
只要您将消息发送到SQS队列中，就可以立即读取该消息，但是您可以在队列级别设置默认值，
即所有消息都应延迟X秒数，或者，如果您希望使用DelaySeconds参数，则可以在每次发送消息时设置每个消息的延迟｡
所以我们有一个队列｡
我们的生成器将向该队列发送一条消息，
例如，该队列具有该消息应延迟多长时间的默认值｡
所以可能只有30秒｡
因此，
30秒后，当使用者轮询消息时，它将看到该消息并成功接收｡
现在，让我们进入控制台，
看看它在实践中是如何工作的｡
回到SQS中，我将创建一个队列，
并将其命名为DelayQueue｡
正如我们在这里看到的，我们有一个新的设置，
称为传递延迟｡
默认情况下，它是零秒，
但我们可以将其设置为15分钟｡
我将其设置为10秒，这样消息将等待10秒后才被使用者读取｡
好的，剩下的都是标准的，我们只需单击“Create
queue”｡
现在，我的延迟队列已创建｡
我将继续发送和接收消息｡
让我们输入一条随机消息｡
现在，
如您所见，默认情况下，
已在控制台中创建了交付延迟，它显示为10秒，但我们可以覆盖它｡
例如，
您可以说30秒，也可以说0秒或更长时间，但我们将其保留为默认值10秒｡
我将开始轮询消息｡
如您所见，没有收到任何消息｡
我现在就给你发个信息｡
我们得等10秒钟｡
一二三四五六七八九十｡
希望到目前为止，我的消费者应该会看到这条消息｡
这就是了 已经10秒了｡
所以，正如你所看到的，
在发送和实际传递消息之间有一个延迟｡
对于某些使用情形，
这可能是您想要的，也可能是您所希望的｡
但是作为一个经过认证的AWS人员，你应该知道这个功能是存在的｡
这是一个很短的演示，但我希望它对您有所帮助｡
我们下节课再见｡ 
  - [ ] 273 SQS - Certified Developer concepts [06:19]
    * 
现在，让我们讨论一些您需要了解的关于SXSW的更多概念，但更多的是在开发人员级别｡
第一个叫做长拉｡
因此，当使用者向我们请求消息时，如果队列为空，它可以选择引用unquote wait for
messages to arrive｡
这叫做长轮询｡
让我们举个例子｡
我们有一个SKS队列，它是空的，消费者向队列中执行了一个拉取请求｡
现在，我们可以选择等待｡
等待很有趣，对吧，因为没有留言｡
因此，这意味着如果在等待期间有消息进入队列，则使用者将接收到该消息｡
那么我们在哪里进行长轮询呢？
我们之所以进行长轮询，是因为我们对队列执行的API调用较少，而且最重要的是，
我们知道一旦消息到达队列，队列就会将其发送回使用者｡
因此，我们正在提高效率，因为我们执行的API调用更少，因此使用的CPU周期更少，
而且我们还在降低延迟，因为只要队列收到消息，消费者就会收到它｡
这么长时间的民意调查是一个不用动脑筋的问题｡
长建筑可以设置在1秒到20秒之间，但20秒更好｡
为什么不呢？
总的来说，建议在应用程序中使用长轮询到短轮询｡
您将在考试中看到一些问题，可能会告诉您使用者对队列执行了太多调用，
这会耗费您的资金和CPU周期，并且可能会增加延迟，那么长轮询将是一个选择｡
现在，可以在队列级别（队列级别设置）或API调用级别启用长轮询｡
因此，每当您的使用者对队列进行API调用以使用接收消息等待时间秒参数进行轮询时｡
我们需要了解的第二件事是扩展客户端｡
如我们所知，最大消息限制是256 KB｡
那我们该怎么办？
通过向队列中发送大型消息｡
例如，1GB的邮件｡
为此，我们可以使用一个名为US extended clients的Java库，它做一些非常简单的事情，
您可以用任何其他语言实现｡
但它的想法是，它将使用亚马逊是三桶作为一个大型数据的存储库｡
让我们举个例子｡
制片人想给我们传达一个重要的信息｡
但首先，实际的大消息将最终到达Amazon S3，发送到Rescue的将是一个小的元数据消息，
它具有指向Amazon中较大消息的指针，Amazon有三个桶，因此队列将包含小消息，
Amazon口袋将包含大对象，当消费者使用此库､ 扩展客户端､
然后，它将使用这个小的元数据消息，该消息将对使用者说，嘿，从Amazon
3中读取那个较大的消息，并且使用者将能够从S3中读取和检索较大的消息｡
因此，这方面的一个典型用例是，如果正在处理视频文件，则不会将整个视频文件发送到队列中｡
不，你上传的视频文件到你的亚马逊是三个桶，你发送一个小消息与指针到该视频文件到您的救援｡
这允许您通过此模式来适应任何消息大小｡
最后，我们将介绍一些API调用或通过考试｡
所以这只是你现在应该理解的普通API调用｡
不过，我们还是过一遍吧｡
因此，create queue用于创建队列，您可以使用参数message retention
period来设置消息在被丢弃之前应在队列中保留多长时间，而queue用于删除队列并同时删除队列中的所有消息｡
清除队列是一个API调用，也用于删除队列中的所有消息｡
现在，当我们发送消息时，我们使用发送消息API，如果我们想延迟发送消息，
我们可以使用延迟秒数参数，接收消息进行轮询，删除消息是在消息被使用者处理后删除消息｡
因此，当您默认接收消息时，set参数max number of messages设置为1｡
这意味着您一次可以接收一条消息，但在队列中一次最多可以接收十条消息｡
因此，您可以将received message API的max number of messages参数设置为10，
以接收来自6的一批消息｡
收到的消息Wait time seconds告诉您的使用者在从队列中获得响应之前需要等待多长时间｡
这相当于启用更长的轮询和更改消息可见性｡
它用于更改消息超时，以防您需要更多时间来处理消息｡
现在，如果您想使用批处理API调用，您可以对发送消息､ 删除消息以及更改消息可见性这样做｡
这有助于减少对API的调用次数，从而降低成本｡
原来如此｡
现在让我们看看民意测验在我们身上的作用有多长｡
现在我们进入演示队列，编辑演示队列的设置｡
正如我们在这里看到的，接收消息等待时间当前为零，这称为短轮询，但我们可以将其设置为0到20秒之间的任何值｡
一旦我把它设置为1，你就启用了长轮询，但是我们会说220，这就是说如果队列是空的，
你应该等待20秒才能收到消息｡
因此，我将应用设置，保存队列配置，然后进入发送和接收消息｡
在这里，我将继续启动一个消费者｡
现在，这个消费者正在进行长轮询，因为它被设置在Q级别｡
这意味着只有一个API调用在发生，它在等待来自歪斜的消息，因为现在没有消息｡
但如果我说Hello World，并在按发送键后立即按发送键，则我的消费者收到了该消息｡
这是非常低的延迟，因为我的消费者处于长轮询模式，它正在等待来自我们的消息｡
感谢我们前面提到的等待消息时间设置｡
原来如此｡
非常简单的演示，但希望这是有意义的｡
我们下节课再见｡ 
  - [ ] 274 SQS - FIFO Queues [03:35]
    * 
让我们来谈谈另一种可用的Q，它被称为，亚马逊倾斜FIFO，因为FIFO意味着先进先出｡
这意味着消息将在队列中排序，第一个到达队列的消息将是第一个离开队列的消息｡
所以这是我们从标准队列中可以得到的更多的排序保证｡
因此，让我们举一个生产者将消息发送到SCS队列的例子，第一条消息，然后是第二条､
第三条和第四条｡
因为我们有一个SGS FIFO队列，所以使用者将从school队列中提取消息，
并以完全相同的顺序接收消息｡
现在，由于我们对排序有这样一个约束和保证，因此SCS队列的吞吐量有限，因此在不进行批处理的情况下，
每秒可以获得300条消息，或者如果您发送批处理消息，则每秒可以获得高达3000条消息的吞吐量｡
但多亏了FIFO｡
Q我们得到了更多的保证和更多的约束｡
因此，我们有一个功能，允许我们FIFO队列删除重复的一次发送能力｡
我们还知道，消费者将按顺序处理这些消息｡
因此，无论何时进行解耦，您都应该看到FIFO队列，
但同时也需要维护消息的顺序，并确保满足吞吐量限制，不会向SKU发送太多消息｡
接下来，我们创建第一个FIFO队列｡
现在，我们创建一个队列，我将创建一个FIFO队列｡
正如您所看到的，它是先进先出的传递方式，并且保留了消息顺序｡
好的，我将限制演示队列点FIFO，你必须用FIFO结束它，否则你将没有能力创建这个队列｡
它必须以FIFO结束｡
现在，如果我们看一下配置，它看起来与以前非常相似，但我们多了一个设置，
称为基于内容得复制.
这是为了复制邮件，如果在非常短的五分钟窗口内发送了两次相同的邮件，则将保留访问策略｡
相同的加密等将保持不变｡
因此，我将创建此队列，现在，如果我开始发送和接收消息，我们可以查看消息正文｡
我们可以说Hello world one，然后我必须指定一个消息组ID，我将称之为demo，在整个演示过程中我们将使用相同的消息ID｡
因此，请演示一种感觉和重复数据删除的想法｡
对不起，你好
我会说这是我的第一条信息｡
所以我说IgG一号，发这个信息｡
我会做好相同的消息组ID，我会说重复数据删除D到｡
然后给第三个留言我会在这里说三个｡
最后是第四个｡
我说四个｡
好吧，我会的
现在，消息已经发送，可以接收了｡
因此，我们有四条消息可用｡
如果我调出四条信息，我们会查看所有信息｡
如果我看这个，它实际上是在错误的顺序｡
所以如果我看最下面的一个，也就是第一个，它说你好，世界一号｡
然后如果我看第二条消息，我可以得到第三条消息，我有三条，第四条消息我会有四条｡
所以这是一个保证，你得到的东西五个重点｡
然后，您可以删除这些邮件，这样就完成了｡
原来如此｡
我希望这对你们有帮助，下节课再见.
  - [ ] 275 SQS - FIFO Queues Advanced [05:28]
    * 
让我们来了解一下SQS FIFO的一些高级概念｡
第一个是重复数据删除｡
因此，重复数据消除间隔为5分钟｡
这意味着如果你在五分钟内发送两次相同的信息，那么第二条信息将被拒绝｡
有两种重复数据删除方法｡
第一种称为基于内容的重复数据消除｡
会发生的事情是只要你把一条消息发送到SQS中就会有一个已经用SHA-256方法算法计算出来的消息体｡
如果两次遇到相同的消息正文，则相同的哈希值将相同两次｡
因此，第二条消息将被拒绝｡
或者，您可以在发送邮件时直接显式提供邮件重复数据删除ID｡
如果两次遇到相同的重复数据消除ID，则该消息将消失｡
让我们来看看｡
我们的SQS FIFO在这里｡
然后我们会发出一条你好世界的信息｡
假设我们已经启用了基于内容的重复数据消除｡
在这种情况下，SQS
FIFO队列将生成该消息的SHA-256散列｡
在我的屏幕上可能看起来像这样｡
因此，如果生产者发送完全相同的消息，
它将被散列到完全相同的散列，SQS FIFO将知道它｡
因此，第二消息将被拒绝｡
我们需要了解的第二个高级概念是消息分组｡
因此，如果您为SQS FIFO队列中的消息组ID指定相同的值，
则在将消息发送到FIFO队列时，这是一个强制参数｡
那么你将只有一个消费者｡
所有的消息都将按顺序发送给该用户｡
但是，如果只需要在消息子集级别进行排序，
则应该为消息组ID指定不同的值｡
其思想是，共享公共消息组ID的消息在组内按顺序排列｡
并且每个组ID将具有不同的使用者｡
因此，您可以在SQS
FIFO队列上启用并行处理｡
但不保证跨组排序｡
例如，假设我们有一个FIFO队列｡
我们将邮件分为三组：A､ B和C｡
假设我们有消息A1､ A2､ A3｡
然后我们就可以有一个组A的消费者｡
然后我们有另一组消息：地下一层地下二层地下三层地下四层｡
我们可以为该组再添加一个消费者｡
和另一组消息｡
例如，对于消费者群体，我们有C1和C2｡
比如，有时候你可能不需要对所有消息进行完全排序｡
但您希望对特定客户ID的所有消息进行排序｡
例如，对于某个特定的客户ID，
您可以将其用作消息组ID｡
因此，这意味着您可以拥有与应用程序中的用户一样多的使用者｡
对于每个用户，
由于SQS FIFO队列的保证，消息将按顺序排列｡
回到我们的FIFO队列｡
让我们编辑它，然后启用基于内容的重复数据消除｡
其中，重复数据消除ID将作为我的邮件的SHA-256进行计算｡
所以我点击了保存，现在开始｡
现在，我们来了解一下发送和接收消息｡
我会给你发信息你好世界｡
对于消息组ID，我将暂时保留它作为演示｡
现在，
正如您所看到的，邮件重复数据删除ID是可选的，因为我们已经启用了基于内容的重复数据删除｡
所以让我们把这个信息传递出去｡
正如您所看到的，消息已发送并准备接收｡
而可得到的信息只有一个｡
但是如果我再发送一次那条信息，
一次又一次，一次又一次，可用的信息数量将保持为一｡
因为SQS已经看到了该消息，所以会发生一些重复数据消除｡
但如果我发出不同的信息｡
比如，你好世界二｡
然后，SQS
FIFO中的第二条消息将在此处可用｡
正如我们所看到的，这就是重复数据删除｡
但是，例如，如果我写了另一封邮件，
并使用了您自己的重复数据删除ID｡
例如，您自己的重复数据删除令牌｡
所以1-2-3，然后你再发一次｡
这是因为我们指定了相同的重复数据删除ID｡
那么你只能在两个SQS
FIFO中看到其中一条消息，明白吗？
另一个我想给你看的是群ID｡
所以这不是一件很容易展示的事情｡
但是这个想法是，例如，如果我们有一个用户买了一个苹果｡
并且消息组ID是user123｡
我将删除此邮件重复数据删除ID｡
然后用户买了一根香蕉｡
然后用户买了草莓，对吧？
因为所有这些消息共享相同的消息组ID｡
然后，它们将为该用户按顺序排列123｡
但是如果我现在给一个用户发一个苹果买了｡
还有一个绿色的苹果，一个绿色的苹果｡
我们指定了一个不同的消息组ID：所以用户234｡
现在，该用户234的这些消息将按顺序发送给该用户｡
现在，
在我的SQS FIFO队列中，我可以同时运行多个消费者｡
每个使用者将使用不同的消息组ID，明白吗？
原来如此｡
现在，当您完成时，
您可以提取消息并查看｡
但我会继续，只是简单地删除它们｡
就是这样，
希望你们喜欢，下节课再见.
  - [ ] 276 Amazon SNS [04:18]
    * 
现在我们来谈谈亚马逊SNS｡
那么，如果这次你想发送一条消息，
却有很多很多不同的接收者呢？
因此，您可以进行直接集成，例如，购买服务应用程序可以发送电子邮件通知，
然后向欺诈服务发送消息，向运输服务发送消息，
甚至可能向SQS队列发送消息｡
这是麻烦的，因为每次你必须添加一个新的接收服务｡
您需要创建并编写该集成｡
相反，您可能希望执行的操作称为发布/订阅或发布—订阅｡
其思想是购买服务将消息发送到SNS主题，SNS主题将消息发布到主题｡
这个话题会有很多订阅者｡
和每个订户将能够接收该消息从SNS主题，并有它为自己的｡
这是另一种模式，叫做Pub/Sub模式｡
因此，在Amazon SNS中，
事件生成器只向一个特定的SNS主题发送消息｡
而事件接收者或订阅者，他们想要收听SNS主题通知｡
因此，SNS主题中的每个订阅者都将获得发送到该主题的所有消息，除非您使用了过滤消息的功能，
这也是可能的｡
那么，每个主题可以获得多少订阅者？
每个主题的订阅量可以达到1200万以上，所以相当多｡
而且这个数字会随着时间的推移而变化｡
它不会更新此幻灯片｡
它只是给予你一个概述有多少订阅者，你可以得到｡
在你的账户中，你可以获得多达10万个主题，你也可以增加这个限制｡
这是可以改变的，但同样，只是给予你知道极限可能是什么，
但你从来没有测试过SNS的极限本身｡
所以对于SNS，你要发布你的订阅者，他们会是什么？
你可以直接从SNS发送电子邮件｡
您可以发送短信和移动的通知｡
您也可以直接将数据发送到指定的HTTP或HTTP（S）端点，但SNS也与特定的AWS服务集成，如SQS，
将您的消息直接发送到队列，
发送到Lambda，让函数在接收到消息后执行一些代码，
或发送到Kinesis Data Firehose以将数据发送到，
例如，亚马逊免费或Redshift｡
除此之外，SNS还接收来自大量AWS服务的数据｡
因此，他们直接将其发送到SNS，
因此它可以是CloudWatch警报､ 自动扩展组通知､ CloudFormation状态更改､
预算S3桶､ DMS､
Lambda､ DynamoDB､
RDS事件等｡
所以你不用记住他们｡
但是，
一旦在AWS中发生了某种通知，服务就会将通知发送到指定的SNS主题中｡
现在，SNS，它是如何工作的？
要将消息发布到SNS中，请使用主题“发布SDK”｡
于是你就创造了一个话题｡
然后你创建订阅，或者你发布到SNS主题的一个或多个订阅，
就这样｡
所有订阅者将自动检索该消息｡
或者，
还有一种称为移动的应用程序直接发布的SDK，您需要创建一个平台应用程序，一个平台端点，
然后发布到平台端点中，它适用于Google GCM､
Apple APNS或Amazon ADM的订阅者，这是移动应用程序接收通知的不同方式｡
在安全性方面，
Amazon SNS具有与SQS相同的安全性，
因此它默认具有动态加密（使用KMS密钥的静态加密）和客户端加密（如果您的客户端希望将一些加密消息发送到SNS），但同样，加密和解密由您的客户端负责｡
在访问控制方面，
IAM策略将成为安全的中心，因为所有SNS API都将由IAM策略管理｡
您可以定义与S3存储桶策略非常相似的SNS访问策略，当您希望跨帐户访问SNS主题或允许其他服务（如您的S3事件）写入您的SNS主题时，
这些策略非常有用｡
就是这样，
希望你们喜欢，下节课再见.
  - [ ] 277 Amazon SNS and SQS -  Fan Out Pattern [06:01]
    * 
现在我们来讨论SNS + SQS扇出模式｡
其思想是您希望将一条消息发送到多个SQS队列｡
但如果您将它们单独发送到每个SQS队列，则它们可能是与之相关的问题｡
例如，如果您的应用程序在此期间崩溃，
如果它们的传递失败，或者如果您在以后添加了更多的SQS队列｡
因此，我们希望使用最终模式｡
这个想法是，你将在SNS主题中推送一次，
然后你将订阅尽可能多的SQS队列到SNS主题｡
这些队列是订户，
并且它们都将接收发送到SNS中的消息｡
例如，我们有一个购买服务，
它希望将消息发送到两个SQS队列中｡
相反，它将发送一条消息到SNS主题中，
并且队列是该SNS主题的订户，以便欺诈服务和运输服务可以从它们自己的SQS队列读取所有消息｡
这个概念也是一个完全解耦的模型，
没有数据丢失｡
SQS将为您提供数据持久性､
延迟处理以及工作重试｡
通过这种模式，我们可以添加更多的SQS队列作为SNS主题的订阅者｡
为此，我们需要确保您的SQS队列访问策略，
正如我们之前看到的，允许您的SNS主题写入您的SNS--到您的SQS队列｡
这是使用队列访问策略的又一个用例｡
我们还提供跨区域交付｡
因此，如果安全性允许的话，
一个区域中的SNS主题完全可以向其他区域中的SQS队列发送消息｡
下一个
那么，我们如何将此模式用于其他目的呢？
例如，将S3事件放入多个队列｡
因此，S3事件规则存在限制｡
这适用于事件类型的组合，
例如，正在创建的对象和前缀，例如，
图像/您只能有一个S3事件规则｡
但是，如果您希望将相同的S3事件通知发送到多个SQS队列，
该怎么办？
在这种情况下，可以使用扇出模式｡
例如，我们将S3对象创建为出现在S3桶中的事件｡
我们将把这个事件发送到一个SNS主题中，
我们将把许多SQS队列订阅到SNS主题中，作为扇出模式｡
但我们也可以订阅其他类型的应用程序，电子邮件，
Lambda函数，等等｡
然后我们从中得到的是，由于这种扇出模式，
Amazon S3中发生的事件的消息将到达许多不同的目的地｡
另一个架构是你可以通过Kinesis Data
Firehose直接从SNS发送数据到Amazon S3｡
因此，由于SNS与KDF直接集成，因此您的购买服务可以将数据发送到SNS主题中｡
然后Kinesis Data
Firehose, KDF将接收该信息｡
然后从Kinesis Data Firehose，
您可以将其发送到您的Amazon S3桶中｡
或者，对于这个问题，
任何支持的KDF特定的目的地，它允许你真正以你想要的方式扩展，
也许持久化你的SNS主题的消息｡
因此，我们也可以将扇出模式应用于FIFO主题｡
因此，Amazon SNS具有先进先出的功能，即先出先出，
这可以在主题中对消息进行排序｡
因此，生产者发送消息1､ 2､ 3､ 4｡
并且订户现在只能是按顺序接收消息1､ 2､
3､ 4的SQS FIFO队列｡
因此，我们的想法是，通过SNS FIFO，
我们可以获得与SQS FIFO相同的功能，
即按消息组ID排序｡
我们使用重复数据删除ID或基于内容的重复数据删除来获得重复数据删除，
并且我们可以将SQS FIFO队列作为FIFO
SNS主题的订阅者｡
就吞吐量而言，您是有限的｡
您可以获得与SQS FIFO队列相同的吞吐量，
因为现在只有SQS FIFO队列可以从SNS
FIFO主题读取｡
那么，我们为什么需要这个？
好吧，如果你想用SQS FIFO做一个扇出｡
因此，您需要扇出､ 排序和重复数据删除｡
因此，购买服务会将数据发送到SNS
FIFO主题，然后它会扇出到两个SQS FIFO队列，
这两个队列也可以让欺诈服务和发货服务从FIFO队列中读取数据｡
SNS的最后一个特性是，你可以在SNS中进行消息过滤，
这对于扇出模式来说非常方便｡
那么，什么是邮件过滤？
这是一个JSON策略，用于过滤发送到SNS
Topics订阅的消息｡
因此，如果订阅没有过滤策略，
它将接收所有消息，这是默认行为｡
但是，让我们以设置邮件过滤策略时发生的情况为例｡
因此，我们有一个购买服务，
它发送交易到SNS主题.
例如，交易看起来像是有订单编号｡
有一种产品，比如说，一支铅笔｡
数量（四个）和状态（已放置）｡
现在，我们要创建一个SQS队列，
仅用于已下达的订单｡
不是所有的订单，只是已下订单｡
为此，我们将把SQS队列订阅到SNS主题中，
我们将在JSON中应用一个过滤器策略，并在一个策略中指定我们希望让States等于Placed｡
因此，只有与策略匹配的消息才会进入SQS队列｡
但是，我们可以为取消的订单设置一个SQS队列｡
因此，我们可以为取消的订单创建自己的过滤策略，
并将来自同一SNS主题的订单放入SQS队列｡
因此，下订单和取消订单SQS队列将不会有相同的消息｡
我们还可以使用相同的过滤策略，即已取消的策略，
为已取消的订单创建电子邮件订阅｡
例如，我们可以为被拒绝的订单设置一个过滤策略，
并作为另一个SQS队列｡
或者，我们可以创建一个SQS队列，而不使用过滤策略来包含来自该SNS主题的所有消息｡
因此，使用所有这些扇出模式和消息过滤､ FIFO队列和FIFO主题，
我们会得到许多不同的可能性，考试将尝试对所有这些进行测试｡
这节课就讲到这里｡
我希望你们喜欢，下节课再见｡ 
  - [ ] 278 SNS [04:36] Hands On
    * 
  - [ ] 279 Kinesis Overview [01:16]
    * 
欢迎来到创世记这一节｡
所以你能在认证开发人员考试中sis是你应该深入了解的事情｡
因此，我将花大量时间介绍每项服务的工作原理，以便真正为您提供深入的专业知识，
帮助您在考试中获得最高分｡
让我们先来看看堪萨斯州的概况｡
Kansas使实时收集､ 处理和分析流媒体数据变得很容易｡
因此，实时数据可以是任何东西，如应用程序日志，指标，网站，点击流，
物联网遥测数据｡
只要数据是快速和实时生成的，这就算作实时数据流｡
Kinesis包含四种服务｡
我们将深入研究激酶和数据流，以捕获过程并存储它们的流｡
在我们内部，有一个消防水管可以将数据流加载到一些数据存储中，但在我们外部，还有Kinesis
Data分析可以使用SQL语言或Apache Flink分析数据流｡
最后，一个没有出现在考试中，但仍然值得一提的服务是Kinesis视频流，
用于捕获过程和存储视频流｡
这只是一个非常高层次的概述｡
在接下来的课程中，我们将逐一探讨其中的一项服务，并确保我们获得了关于它们的适当知识｡
我们下节课再见｡ 
  - [ ] 280 Kinesis Data Streams Overview [05:56]
    * 
所以您需要了解的第一个服务是Kinesis数据流｡
Kinesis数据流是一种在系统中传输大数据的方式｡
因此，
Kinesis数据流由多个碎片组成，并且碎片被编号｡
一号二号一直到N号｡
这是您必须提前调配的内容｡
所以当你开始使用Kinesis数据流时，
你会说，嘿，我想要一个有六个碎片的流｡
因此，数据将被分割到所有碎片中｡
好吗？
这些碎片将定义您的流容量，即摄取和消耗速率｡
所以，现在，让我们从这个开始｡
然后我们有制片人｡
因此，生产者将数据发送到Kinesis数据流中，生产者可以是多个｡
它们可以是应用程序，也可以是具有桌面或移动的客户端的客户端，它们可以在非常非常低的级别利用AWS SDK，
或者在更高的级别利用Kinesis Producer Library（KPL），
我们将在接下来的课程中深入探讨这些生成器，
或者它可以是服务器内部的Kinesis Agent，用于流传输，例如将应用程序日志传输到Kinesis数据流｡
所以所有的制作人都做同样的事情｡
他们对SDK的依赖程度非常非常低，
他们会将记录生成到我们的Kinesis数据流中｡
因此，
从根本上讲，记录由两部分组成，一部分是分区密钥，
另一部分是数据blob，即最大为1 MB的值｡
因此分区键将定义并帮助确定记录将转到哪个分片｡
而数据blob就是值本身｡
因此，当您让生成器将数据发送到Kinesis数据流时，它们可以以每秒1兆字节或每秒1000条消息的速率发送数据｡
如果你有六个碎片，
你每秒可以得到六兆字节，或者每秒6，000条消息，总的来说，好吗？
现在，一旦数据进入Kinesis数据流，它就可以被许多消费者使用，这些消费者也可以有许多形式，
我们将在本节中详细探讨它们｡
因此，
我们有一些应用程序，它们可能依赖于SDK或更高级别的Kinesis客户端库，即KCL｡
如果你想在Kinesis数据流上进行无服务器处理，它们可以是Lambda函数｡
它可以是动力学数据消防管，正如我们将在本节中看到的，
或动力学数据分析｡
因此，当消费者收到一条记录时，
它会再次收到分区键､ 表示记录在碎片中位置的序列号以及数据blob，也就是数据本身｡
现在，我们有了不同的Kinesis数据流使用模式｡
我们有每秒两兆字节的吞吐量，
由所有使用者共享，每个碎片，好吗？
或者，如果启用增强型消费者模式（增强型扇出），
则每个消费者､ 每个碎片每秒可获得2 MB｡
因此，我们将在本节中更详细地再次讨论它｡
同样，生产者将数据发送到Kinesis数据流｡
它在那里停留一段时间，然后被许多不同的消费者阅读｡
好的，Kinesis数据流的一些属性｡
第一个优点是可以将保留时间设置为1天到365天之间｡
这意味着默认情况下，您可以重新处理或重放数据｡
一旦将数据插入Kinesis，就无法删除｡
这就是永恒性｡
此外，当您将消息发送到Kinesis数据流时，
您将添加一个分区键｡
共享相同分区密钥的消息将进入相同的分片，
这将提供基于密钥的排序｡
对于制作者，您可以使用SDK､
Kinesis Producer库､ KPL或Kinesis代理发送数据｡
而对于消费者来说，你可以自己写｡
因此，您可以使用Kinesis客户端库､ KCL或SDK，也可以使用AWS上的托管消费者，
例如AWS Lambda､ Kinesis
Data Firehose或Kinesis Data
Analytics｡
现在对于容量模式，您有两个Kinesis数据流选项｡
第一种模式是历史容量模式，称为资源调配模式｡
因此，
您可以选择提供的多个碎片，然后手动或使用API对其进行扩展｡
而Kinesis数据流中的每个碎片将获得每秒1兆字节，或每秒1000条记录｡
对于输出吞吐量，每个碎片将获得每秒2 MB的吞吐量，
这适用于传统或扇出消费者｡
您还可以按每小时调配的碎片付费｡
因此，
您需要提前考虑很多问题，这也是它被称为配置模式的原因｡
但第二种模式是一种称为按需模式的神经模式｡
在这种情况下，您不需要调配或管理容量｡
这意味着容量将随时间推移按需调整｡
您将获得所调配的默认容量，即每秒4
MB或4，000条记录，然后将根据在过去30天内观察到的吞吐量峰值进行自动扩展｡
在这种模式下，你仍然要按每小时的数据流和每GB的数据输入/输出付费｡
因此，我们采用了不同的定价模式｡
因此，如果您不知道容量事件，
请选择按需模式，但如果您可以计划容量事件，则应选择资源调配模式｡
就Kinesis数据流的安全性而言，它部署在一个区域内｡
所以你有你的碎片｡
您可以使用IAM策略控制生成和读取碎片的访问权限｡
在传输过程中使用HTTPS加密，在静止过程中使用KMS加密｡
您可以在客户端实现自己对数据的加密和解密，这称为客户端加密，但实现起来比较困难，
因为您需要自己对数据进行加密和解密｡
但这增强了安全性｡
VPC终点可用于室壁运动｡
这允许您直接从HTTPS访问Kinesis，
例如在私人主题中，而不需要通过互联网｡
最后，所有的API调用都可以使用CloudTrail进行监控｡
以上就是Kinesis数据流的概述｡
希望你喜欢｡
我会在下一节课上看到你们，我们会更深入地探讨Kinesis数据流中的所有活动部分｡
  - [ ] 281 Kinesis Producers [04:42]
    * 
教师：现在，我们来讨论如何在Kinesis中获取数据，为此，
我们将利用Kinesis Producers｡
因此，它们用于将数据发送到数据流中，
正如我们所说的，数据记录由一个序列号组成，该序列号在分片中的每个分区密钥都是唯一的，
分区密钥也是如此，
我们必须在将记录放入流和数据blob（最大为1 MB）中时指定分区密钥｡
生产者可以是任何东西，从SDK创建一个非常简单的生产者到使用Kinesis生产者库，KPL，
它支持不同的语言，如C++或Java，它是建立在SDK之上，
但有一些先进的功能作为API，因此，
例如，
批处理，压缩和重试｡
Kinesis代理是将数据发送到Kinesis的另一种方式｡
它建立在Kinesis Producer库之上，
将用于监控日志文件并将其流到Kinesis数据流中｡
就写入吞吐量而言，我们已经知道了这一点｡
我们得到每秒1兆字节或每秒1，000条记录｡
将数据发送到Kinesis的API称为PutRecord API｡
如果我们使用批处理和PutRecord API，
我们可以降低成本，
从而提高吞吐量，这是Kinesis Producer Library已经为我们做的事情｡
因此，如果我们看生产者端，我们有一个包含六个碎片的流，
我们有一些生产者，例如物联网设备｡
因此，他们将以每秒1 MB或每秒每个碎片1，000条记录的速率发送数据，
并假设我们有一个设备ID 111222333｡
因此，它将生成一些数据，我们选择将分区密钥选为设备ID｡
如您所见，在本例中，
分区密钥是设备ID｡
因此，它将通过一个哈希函数，
这是一个数学函数，它将分区密钥作为输入，我们将计算出将数据发送到哪个分片｡
例如，由于哈希函数的作用，它将进入分片1，
这意味着所有共享同一分区键的数据将进入同一个分片｡
所以设备ID的所有数据都将在分片1中结束｡
现在，如果你有另一个设备ID，
也就是444555666，那么数据blob将有一个不同的分区密钥，但它将通过相同的哈希函数｡
这一次，散列函数可能决定将此数据发送到碎片2中，
因此这意味着此设备ID将使所有这些数据发送到碎片2｡
这就是如何用分区键生成Kinesis数据流｡
现在，正如您所看到的，如果一个设备非常健谈，
发送了大量数据，它可能会淹没一个碎片｡
此外，您还需要确保分区键分布良好，
以避免热分区的概念，因为这样您将有一个碎片比其他碎片具有更多的吞吐量，它们将带来一些不平衡｡
因此，您需要考虑一种拥有分布式分区键的方法｡
例如，如果您有6个碎片和10，000个用户，
则用户ID非常分散｡
但是，如果你有六个碎片，
你只是把Chrome､ Firefox和Safari看作是web浏览器，把web浏览器的名称看作是分区键，
那么Chrome可能会非常热门，
因为世界上有很多很多Chrome用户，而Firefox或Safari用户则是如此｡
谁知道呢？
因此，您需要确保使用分布式分区键｡
这就将我们带入了ProvisionedThroughputExceeded领域｡
因此，当我们从应用程序生成Kinesis数据流时，我们知道我们可以每秒生成1 MB或1，
000条记录，
只要我们这样做，一切都会顺利｡
但是，
如果我们开始向碎片中过度生成，则会出现异常，因为我们将超过供应吞吐量｡
因此，我们会得到ProvisionedThroughputExceeded异常｡
因此，解决这个问题的第一个办法是，确保你使用的是高度分布式的分区键，
因为如果不是这样，这种错误就会经常发生｡
我们需要实现具有指数回退的重试，
以确保我们可以重试这些异常，这是考试中出现的问题｡
最后，你需要扩展分片，
这可能叫做分片拆分，
将分片拆分成多个分片，并增加吞吐量，我们将在以后的课程中看到分片拆分｡
但是，通过增加碎片的数量，
这显然可以帮助解决吞吐量异常，因为如果从6个碎片增加到7个碎片，我们的流中每秒就多了1兆字节｡
这节课就讲到这里｡
我希望你们喜欢它，我们下节课再见｡ 
  - [ ] 282 Kinesis Consumers [05:15]
    * 
男声：现在我们来谈谈使用Kinesis数据流的消费者｡
因此，消费者从流中获取记录并处理它们｡
消费者可以是Lambda函数，也可以是Kinesis Data
Analytics，
也可以是Firehose，还可以是在两种不同模式下使用SDK的自定义消费者，包括经典或增强型扇出和Kinesis客户端库，后者是一个用于简化数据流阅读的库｡
顺便说一下，我有一个关于Kinesis客户端库的专门讲座｡
因此，让我们来讨论一下传统共享扇出使用者和增强型使用者之间的区别｡
因此，
当您以经典的共享吞吐量方式写入消费者时，您的Kinesis数据流将包含大量碎片，所有消费者的每个碎片每秒可获得两兆字节｡
这意味着，
如果您看一下shard，仅在本例中，
我们可以编写一个消费者应用程序A，它将发出一个获取记录API调用，以从shard
1获取记录，但尽可能让许多不同的应用程序从同一个Kinesis数据流中阅读｡
因此，
使用者应用程序B也将发出获取记录API调用，而使用者应用程序C也将在所有使用者之间发出获取记录｡
现在，
在此实例中发生的情况是，它们都在所有使用者之间共享每个碎片每秒2 MB的数据｡
这意味着在本例中，
我们有三个消费者共享，每秒2 MB｡
这意味着每个消费者每秒最多可以获得大约666千字节的数据｡
正如您所看到的，我们在Kinesis数据流中添加的消费者应用程序的数量是有限的｡
我们就越有限制｡
因此，这就把我们带到了AWS最近带来的一种新的消费模式，
即增强型扇出消费者｡
在这种情况下，每个消费者､
每个碎片每秒可以获得两兆字节｡
因此，
它不是跨所有消费者，而是按消费者，按图表｡
这意味着消费者应用程序A将使用名为Subscribe to
Shard的新API代码，
这将使Shard发送数据，并以每秒2 MB的速度将数据推送到我们的消费者应用程序A｡
并且如果第二消费者应用B发布另一个订阅的碎片，则该消费者应用B也发布另一个订阅的碎片｡
将以每秒两兆字节的速度将碎片推送的数据发送到消费者应用程序｡
消费者C也是如此｡
如图所示，我们有三个消费者应用程序，这张图表的吞吐量为每秒6
MB｡
因此，在第一个模型中，我们有一个拉模型，
而在第二个模型中，我们有一个推模型｡
让我们总结一下，
共享传统扇出消费者的拉取模型，它提供了一个低，这是好的｡
当您使用的应用程序数量较少时｡
Ruth的重启速度是所有用户的每个碎片每秒2 MB｡
还有一个限制是，每个碎片每秒最多可以获得五个获取记录和API调用｡
API调用的延迟约为200毫秒｡
当你想把成本降到最低的时候，你会想用这个｡
消费者将使用get
records API调用直接从Kinesis中提取，返回的数据最多可达10 MB｡
然后，它将浮动5秒或多达10，000条记录｡
因此，如果我们使用“增强扇出使用者”（一种推送方法），我们可以从同一个流中获取多个使用应用程序，
每个使用者将获得每个碎片每秒2 MB的数据｡
延迟将大大降低，因为Shard本身会将数据推送到我们的消费者｡
所以70毫秒，成本更高｡
这是一个功能，将花费你更多的AWS｡
正如我所说的，数据是通过一种名为HDB 2的流方法推送的｡
最后，每个数据流有5个消费者应用程序的软限制，
但您可以通过在AWS上添加一个票证来增加这一限制｡
最后，我们还没有深入了解Lambda，
但它是一种无需使用服务器即可使用数据的方法｡
所以我们有Kinesis数据流，有三个碎片｡
我们每个人都将学习函数，
它们的作用是处理记录并将记录保存到dynamodb中，dynamodb是一个无服务器数据库｡
因此，
Lambda函数将调用get batch，将其添加到运动数据流中｡
而数据将被发送到爱尔兰的分区键所要处理的函数｡
然后Lambda函数可以将数据发送到dynamodb，我们有一种方法使用无服务器机制来处理Kinesis数据流｡
因此，在本例中，
Lambda函数同时支持经典和增强扇出消费者模式｡
因此，您可以指定您希望如何使用Kinesis数据流中的数据｡
它将成批读取记录｡
您可以配置批处理大小和批处理窗口｡
如果发生错误，Lambda将重试，直到成功，
否则Kinesis数据流中的数据将过期｡
您还可以同时处理每个碎片最多10个批次｡
那么我们将在Lambda函数中更详细地研究Lambda的运动学？
所以如果你不明白我刚才说的话，不要太担心，
但是我们已经在Kinesis数据流中看到了消费者｡
现在，让我们开始动手实践，
真正练习一下Kinesis数据流｡
所以我们下节课再见｡ 
  - [ ] 283 Kinesis Data Streams [09:38] Hands On
    * 
  - [ ] 284 Kinesis Client Library [03:13]
    * 
教师：现在我们来讨论Kinesis客户端库｡
所以考试可以问你一个场景问题，让我们在场景问题中回顾一下它是如何工作的｡
这是一个Java库，
它可以帮助您通过分布式应用程序从Kinesis数据流中读取记录，我们将分担读取工作负载｡
每个分片只能由KCL实例读取，
这意味着如果您有4个分片，则最多只能获得4个KCL实例｡
如果您有6个碎片，则最多可以获得6个KCL实例｡
如果我只是说，你可以参加考试了，但我希望你解释一下它是如何工作的，
这样你就可以了解Kinesis客户端库是如何工作的｡
因此，
Kinesis客户端库将从我们的Kinesis数据流中阅读，读取进度将被检查点到DynamoDB中，因此运行KCL的应用程序将需要对DynamoDB进行IAM访问｡
由于DynamoDB，它将能够跟踪您的KCL应用程序的其他工作者，
并在碎片之间共享工作｡
KCL可以在任何您想要的平台上运行，但您可以在EC2实例上运行，使用EC2实例角色，
您可以是Elastic
Beanstalk应用程序，也可以是内部部署服务器，只要它们具有正确的IAM凭据｡
显然，记录将按顺序在碎片级别读取，
Kinesis客户端库有两个版本，版本1仅支持共享消费者，版本2支持KCL共享和增强扇出消费者远程｡
因此，如果我们看一个流中有4个碎片的示例，我们可以使用DynamoDB表来检查进度，
这样我们就可以在两个不同的EC2实例上运行同一个一致应用程序的两个KCL应用程序｡
在这种情况下，由于DynamoDB，他们将知道如何共享工作，
因此第一个KCl应用程序将从分片1和2阅读，第二个KCL应用程序将从分片3和4读取｡
现在，应用程序阅读Kinesis数据流的进度将被检查点到DynamoDB中｡
因此，
例如，如果其中一个应用程序出现故障，
DynamoDB和KCL应用程序一起工作，将知道一个应用程序将出现故障，因此将从检查点位置恢复对其他碎片的阅读｡
当您向上扩展时，它也可以工作，
因此如果您有4个分片，现在您运行4个KCL应用程序，
那么它将分别从一个分片阅读｡
因此，将从DynamoDB恢复进度并再次执行检查点操作｡
你们可以看到这是怎么运作的，对吧？
但是我们不能有比碎片更多的KCL应用程序，
因为好吧，否则一个人将什么也不做｡
因此，如果您想读取以缩放Kinesis，
您可以缩放Kinesis并添加6个碎片，因此现在我们仍然有4个KCL应用程序，但现在我们在流中的Kinesis中有6个碎片｡
因此，他们将再次检测到这种变化，并与DynamoDB一起工作，
他们将再次在每个KCL应用程序和分片分配之间划分工作｡
因此，
这意味着一旦我们有6个碎片Kinesis数据流，我们就可以有6个KCL应用程序从中阅读，并检查DynamoDB中的进度｡
如果你已经明白了这一点，那么你就可以很好地去参加考试，
回答问题｡
这节课就讲到这里，希望你们喜欢，
下节课再见｡
  - [ ] 285 Kinesis Operations [02:17]
    * 
教师：这是一个关于如何缩放Kinesis的简短演讲，为此，
我们将讨论碎片分裂和碎片合并｡
因此，“碎片分割”用于将一个碎片分割为两个｡
这意味着我们有更多的碎片，因此它被用来增加Stream的容量｡
因此，如果我们通过拆分一个碎片来添加更多碎片，
那么每次拍摄的吞吐量将增加1MB/秒｡
例如，当您要划分热分片时，可以使用此功能｡
例如，分片2非常热，
会向其发送大量数据｡
我们将拆分碎片，从中得到碎片4和碎片5｡
通过使用新的碎片，我们将流吞吐量从每秒3 MB提高到每秒4
MB｡
因此，我们当然增加了容量，但因为我们是根据流中的碎片数量构建的，
所以我们也增加了Kinesis数据流的成本｡
旧碎片将被关闭，或者碎片2将不再写入碎片2，
旧数据将在一段时间后过期｡
因此，
根据您的保留期在1到365天之间，您将不得不等待这么长的时间｡
然后数据过期，最后碎片将被删除｡
Kinesis Data Streams中没有自动缩放功能，但您可以找到创建自己的自动缩放功能的方法，
并且有一个解决方案架构，
但没有使用Kinesis Data Streams进行自动缩放的设置，因此您只能手动增加或减少容量｡
而且不能在一次操作中将一个碎片分割为两个以上的碎片｡
如果你想这样做，你将需要做许多不同的碎片分裂｡
现在，与碎片拆分相反的操作是合并碎片｡
所以你意识到你想减少容量和节保存成本｡
在这种情况下，您可以将两个流量较低的分片组合为冷分片，
然后将它们合并到一个新分片中｡
因此，在本例中，碎片1和碎片4合并为碎片6，
这用于降低容量和成本｡
然后，
旧碎片将再次关闭权限，一旦碎片中的数据过期，这些权限将被删除｡
你不能在一次操作中出现两个以上的碎片，
通过碎片分裂和碎片合并，你已经看到了如何放大和缩小运动｡
就这样，你只需要知道这些｡
我希望你喜欢这节课，我们下节课再见｡
  - [ ] 286 Kinesis Data Firehose Overview [04:56]
    * 
现在，让我们了解一个新的服务，这是Kinesis数据消防水带｡
因此，这是一个非常有用的服务，可以从生产者和生产者的数据可以是我们所看到的一切动态，
这是流｡
因此，应用程序，客户端，SDK Kpl所有的Kinesis代理都可以生成到您的Kinesis数据消防水管｡
但也要考虑到流可以产生互连的数据firehose, Amazon云监视日志和事件可以产生数据，
firehose或Iot，所有这些应用程序都将记录发送到Kinesis数据firehose，
然后考虑到firehose可以选择使用lambda函数转换数据｡
但这是可选的，一旦数据被可选地转换，那么它就可以批量写入目的地｡
所以考虑一下消防水管｡
从来源获取数据｡
通常最常见的是数据流，它会将这些数据写入目的地，而无需编写任何代码，
因为fIREHOSE知道如何写入数据｡
因此，有三种目的地与Kinesis数据消防水管｡
排名第一的类别是目的地，你需要知道他们的心｡
第一个是亚马逊是免费的，你可以把你所有的数据写入亚马逊S3｡
第二个是AmazonRedshift，它是一个仓储数据库，为此，它首先将数据写入AmazonS3，
然后考虑消防水管将发出复制命令｡
这个复制命令将把数据从Amazon S3复制到Amazon Redshift｡
AWS上的最后一个目的地叫做亚马逊开放搜索｡
也有一些第三方合作伙伴的目的地，所以考虑一个消防水管可以发送数据到Datadog, Splunk，
New Relic, MongoDB和这个列表可以得到越来越大的时间，所以不会更新，如果有新的合作伙伴｡
但正如你所知，他们是合作伙伴，可以识别主机可以发送数据｡
或者最后，如果您有自己的带有HTTP端点的API，那么您可以将数据从数据消防软管发送到自定义目的地｡
因此，一旦数据发送到所有这些目的地，您有两个选择｡
您还可以将所有数据作为备份发送到S3存储桶中，或者仅将无法写入这些目标的数据发送到出现故障的S3存储桶中｡
总而言之，主机数据是一项完全托管的服务｡
因此，没有管理自动化扩展，而且它是无服务器的｡
因此无需管理服务器｡
你可以将数据发送到一个目的地，如红移，亚马逊历史和开放搜索｡
Splunk､ MongoDB､ Datadog､ New Relic等第三方合作伙伴 等等｡ 和定制目的地｡
对于任何HTTP端点，您只需为通过消防水管的数据付费｡
所以这是一个非常好的数据定价模型，而且几乎是实时的｡
为什么？
嗯，因为我们成批地将数据从firehose写入到目的地｡
因此，非完整批处理的延迟最小为60秒，或者您需要等到一次至少有1
MB的数据才能将数据发送到目的地，这使其成为一种接近实时的服务，
而不是实时服务｡
它支持许多数据格式､ 转换､ 变换和压缩，如果需要，您可以使用Lambda编写自己的数据变换｡
最后，您可以将所有失败或所有数据发送到一个备份和三个存储桶中｡
所以考试中经常出现的一个问题是理解何时使用数据流的区别，并能坚持使用数据消防水管｡
所以如果你跟紧了应该很容易｡
但让我们总结一下｡
你能说有流是用于大规模摄取数据的流媒体服务，你写你自己的定制教练，
你的生产者和你的消费者是实时的｡
因此，200毫秒或70毫秒，您可以自己管理扩展，执行碎片拆分和碎片合并以增加规模和吞吐量｡
您还将为您拥有的容量付费｡
准备金｡
数据流中的数据存储可以在1到365天之间｡
这允许多个消费者从同一个流中读取，还支持重放功能，而数据消防是一个摄取服务，
将数据流传输到S3红移开放搜索､ 第三方或自定义HTP中｡
它是完全受管理的｡
没有一项服务可以近乎实时地管理它｡
所以请记住，近实时是你在考试中需要考虑的关键词｡
有自动缩放，所以没有必要为你担心它，你只需要支付什么，
而不是消防水带通过｡
没有数据存储，因此您无法从Kinesis数据消防龙头回放数据｡
所以是的，它不支持重播功能｡
以上就是数据光纤软管的概述｡
我希望这是有意义的，我们下节课再见.
  - [ ] 287 Kinesis Data Firehose [07:52] Hands On
    * 
  - [ ] 288 Kinesis Data Analytics [03:33]
    * 
教师：现在我们来谈谈运动数据分析｡
它有两种口味｡
第一个用于SQL应用程序，第二个用于Apache
Flink｡
我们首先来讨论第一种，
即面向SQL应用程序的Kinesis数据分析｡
所以它位于中心｡
它能够读取的两个数据源是运动学数据流和运动学数据消防管｡
因此，您可以从其中任何一个读取数据，
然后应用SQL语句执行实时分析｡
您还可以通过引用Amazon S3存储桶中的引用数据来连接一些引用数据｡
例如，这将允许您实时丰富数据｡
然后，您可以将数据发送到不同的目的地，
其中有两个目的地｡
第一个是Kinesis数据流｡
因此，您可以从Kinesis
Data Analytics实时查询中创建流，也可以将其直接发送到Kinesis
Data Firehose中，每种方法都有自己的用例｡
如果您直接发送到Kinesis Data Firehose，
那么您可以发送到Amazon S3､ Amazon Redshift或Amazon
OpenSearch，或任何其他Firehose目的地｡
然而，如果您将其发送到Kinesis数据流中，
则可以使用AWS Lambda或在EC2实例上运行的任何应用程序对该数据流进行实时处理｡
请记住此图表，这是针对SQL应用程序的Kinesis数据分析｡
现在，如果我们深入到细节，正如我所说的，
两个来源只有Kinesis数据流和Firehose｡
您可以使用Amazon S3的数据进行丰富｡
这是一项完全托管的服务，
您无需配置任何服务器｡
有自动缩放，你实际上支付任何通过Kinesis数据分析｡
在输出方面，正如我所说的，
您可以进入Kinesis数据流或Kinesis数据消防软管｡
使用情形是执行时间序列分析､
实时仪表盘或实时指标｡
这是第一种运动数据分析｡
第二个是Apache Flink的Kinesis数据分析｡
正如名称所示，您可以在服务上实际使用Apache
Flink｡
因此，如果使用Flink，
就可以使用Java､
Scala甚至SQL编写应用程序来处理和分析流数据｡
所以你可能会说，“嗯，这是同样的事情，
不是吗，从以前？ “也不是｡
所以Flink是一些特殊的应用程序，你需要把它们写成代码｡
它让你可以在Kinesis
Data Analytics的集群上运行这些Flink应用程序｡
但这一切都在幕后｡
使用Apache Flink，
你可以从两个主要的数据源读取，你可以从Kinesis数据流或Amazon
MSK读取｡
因此，通过此服务，您可以在AWS的托管集群上运行任何Flink应用程序｡
我们的想法是Flink将比标准SQL强大得多｡
因此，如果您需要高级查询功能，或者需要从其他服务（如Kinesis
Data Streams或Amazon MSK，由AWS上的Kafka管理）读取流数据，则可以使用此服务｡
因此，借助此服务，
您可以自动调配计算资源､ 并行计算和自动扩展｡
您可以获得应用程序备份，
它们作为检查点和快照实施｡
您可以使用任何Apache Flink编程功能｡
正如你所知道的，使用Flink你只能从Kinesis数据流和亚马逊MSK中读取｡
您无法读取Kinesis数据消防软管｡
如果您需要读取并对Kinesis Data Firehose进行实时分析，
则必须使用Kinesis Data
Analytics for SQL｡
好了，这节课就讲到这里.
希望你喜欢｡
我们下节课再见｡
  - [ ] 289 Data Ordering for Kinesis vs SQS FIFO [07:14]
    * 
教师：我们来讲一讲如何为Kinesis和SQS FIFO排序数据｡
因为尽管这些技术看起来很相似，也有一些相似的功能，
但它们实际上非常､ 非常､ 非常不同｡
让我们来做个案例研究｡
假设您有100辆卡车在路上行驶，每辆卡车都有一个卡车ID｡
一号车､
二号车到100号车，他们在路上，他们会定期将GPS位置发送到AWS｡
所以我们想按顺序使用每辆卡车的数据，这样我们就可以准确地跟踪它们的移动，我们想知道哪里有明显的顺序，
对吗？
那么，我们应该如何将这些数据发送到Kinesis？
现在的答案是您应该使用分区密钥｡
该分区键的值就是卡车ID｡
因此，
第一辆卡车会将其发送到第一辆卡车，然后第二辆卡车会将其发送到第二辆卡车，以此类推｡
为什么？
因为如果我们指定相同的分区键，那么相同的键将始终指向相同的分片｡
现在，让我们看一下图表，
以便更好地理解这一点｡
我们有运动学数据流，它有三个碎片，一，二，
三｡
为了简单起见，
我不会给你们看100辆卡车，但5辆应该足够了｡
所以我们有五辆卡车，他们在路上，
他们把数据发送到Kinesis｡
正如我所说的，我们选择分区密钥为卡车ID｡
这意味着，当我的卡车1发送GPS数据时，它会将其与分区密钥一起发送到Kinesis，卡车1和Kinesis会说，
好的，
分区密钥卡车1，我将对它进行哈希运算，我的意思是我们将进行计算｡
在这个例子中，它计算出一号卡车应该进入一号碎片｡
所以我的数据会进入一号碎片｡
然后，
卡车2也将发送其数据，并且将发送卡车2的分区密钥｡
Kinesis会查看这个分区密钥，并说我已经对它进行了哈希处理，现在看起来应该进入分片2｡
三号车也一样三号车会上路｡
它会派三号车去分区｡
但这一次，
Kinesis数据流服务将把卡车3作为密钥，并说你应该去碎片1，这很好｡
它只是说，它不一定是分片3，它只是说，
这个分区密钥应该属于分片1｡
现在，对于第四辆卡车，它将转到第三个碎片，
而对于第五辆卡车，它将转到第二个碎片｡
这就是我们现在的想法，我们有一个重新分区，它被称为分区，
因此每个卡车的名称分区密钥在每个碎片上基于分区密钥｡
而且，由于卡车1不断发送相同的分区密钥，即卡车1，
因此数据将始终转到相同的碎片｡
因此，
卡车1的下一个数据点将位于碎片1中，卡车3的下一个数据点也将位于碎片1中，依此类推｡
因此，
每当卡车1发送数据时，它都将位于分片1中;每当蓝色卡车､ 分片3发送数据时，
它也将位于分片1中，因为我们指定在一段时间内使用相同的分区密钥｡
我们可以看到，1号和3号卡车始终将数据存储到1号碎片中｡
现在，
如果我们查看分片2，则只有2号和5号卡车将数据放入分片2｡
在本例中，
如果您看一下分片3，我们只有卡车4将其数据发送到分片3｡
现在假设你有100辆卡车和5个碎片，那么每个碎片平均会有20辆卡车｡
但是没有直接的联系，你可以分辨出卡车和每个碎片之间的联系｡
Kinesis必须对分区密钥进行哈希运算，以确定要转到哪个分片｡
我们的想法是，只要我们有一个稳定的分区密钥，那么每个卡车将发送此数据到同一个碎片，
因此我们将有数据在碎片级别为每个卡车的顺序｡
讲得通吗？
接下来，我们将讨论SQS｡
我们知道，SQS标准没有排序，
这就是为什么我们有SQL FIFO，即先进先出｡
因此，如果我们在SQL
FIFO中不使用组ID，
则所有消息将按发送顺序使用，并且我们只能有一个客户｡
在本例中，
我们有一组选项，它们将被发送到SQS FIFO队列｡
因此，它们被发送的顺序将是消费者收到它们的顺序｡
正如我们所看到的，
这里只有一个使用者，它使用两批消息，第一批和第二批｡
正如我们所看到的，这是一个先进先出，
这很容易推理｡
所以我们只能有一个消费者｡
因此，如果我们有卡车，那么所有的卡车都将数据发送到FIFO队列中，
但它们只能是一个消费者｡
因此，
有时您可能希望扩展使用者的数量，并且希望在消息彼此相关时对消息进行分组｡
因此，我们可以使用组ID，
这与Kinesis中的分区密钥的概念非常相似｡
因此，现在使用组ID，
我们的FIFO队列中将有两组FIFO｡
因此，对于您定义的每个组，
您可以拥有不同的消费者｡
在这个例子中，我们有两个组，组A和组B｡
而两个消费者消费者一和二可以独立阅读，组一和组二｡
这里的想法是，我们拥有的组ID越多，
我们可以拥有的消费者就越多｡
所以这是一个与Kinesis非常不同的模型｡
让我们看一下，如果我们有Kinesis和SQS，
我们有100辆卡车，5个Kinesis碎片和一个SQS
FIFO队列｡
因此，如果我们有Kinesis数据流，那么平均而言，
每个碎片将有大约20辆卡车，这要归功于哈希，因此，每辆卡车将被指定为一个碎片，
并将永远留在该碎片中｡
卡车的数据将在每个碎片中排序｡
但是，我们可以并行拥有的最大消费者数量只能是5个，因为我们有5个分片，
每个分片需要一个消费者｡
因此，
Kinesis数据流虽然因为它有五个碎片可以接收高达每秒五兆字节的数据，这是一个相当高的吞吐量｡
现在，关于SQS
FIFO，您只能有一个SQS FIFO队列，明白吗？
所以你不需要定义分片或者分区之类的东西，
你只有一个SQS FIFO队列｡
因为我们有100辆卡车，所以我们可以创建100个组ID，每个组ID都等于卡车ID｡
这意味着，因为我们有100个组ID，我们可以有多达100个消费者，
好吗？
每个使用者将与一个特定的组ID挂钩｡
在规模方面，
SQS FIFO每秒最多可处理300条消息，如果使用批处理，则可处理3000条消息｡
这是不同的消费模式，生产模式，
订购模式.
因此，您必须记住的是，根据使用案例，有时使用SQS
FIFO会更好｡
如果您希望根据组ID的数量获得动态数量的消费者，有时使用Kinesis数据流可能更好，例如您有10，000辆卡车，需要向其发送大量数据，
并且在Kinesis数据流中还具有每个碎片的数据排序｡
我希望这对你们有所帮助，
我知道理解这些东西可能很复杂，而且它们的水平也比较低，
但是考试开始会问你们一些关于这些的问题，所以我想确保你们非常清楚地理解这需要什么｡
我希望你们喜欢，下节课再见.
  - [ ] 290 SQS vs SNS vs Kinesis [03:00]
    * 
老师：好的｡
因此，了解SQS､ SNS和Kinesis之间的区别非常重要｡
因此，
SQS有一个模型，其中消费者通过从SQSQ请求消息来提取数据｡
一旦数据被处理，消费者就必须从队列中删除它，
这样其他消费者就再也不能读取它了｡
你可以拥有你想要的任何数量的工人｡
因此，使用者数量不限，它们一起工作，
使用和删除队列中的所有消息｡
您不需要预先配置吞吐量，
因为它是一种托管服务，可以非常快速地扩展到数十万条消息｡
仅当启用FIFO队列时，排序保证才可用｡
所以是先入先出型队列｡
如果您希望消息在一定时间（例如30秒）后显示给队列中的使用者，则还可以使用单独的消息延迟功能｡
当你看SNS时，这是一个不同的模式｡
这是一个小型潜艇模型｡
因此，
您将数据推送给许多订阅者，他们都会收到您发送的消息的副本｡
每个SNS主题最多可获得12，500，000名订阅者｡
而且一旦数据被发送到SNS，它就不是持久的｡
这意味着，如果它没有交付，
你有机会失去它｡
正如我所说，这是一个酒吧，你可以扩展到数十万个主题｡
您也不需要配置吞吐量｡
如果你想联合收割机它和SQS结合起来，你可以｡
因此，
使用扇出架构模式，您可以联合收割机SNS与SQS结合起来，
或者将SNS FIFO主题与SQS FIFO队列结合起来｡
好吧，我会的
最后，Kinesis有两种消费模式｡
您有标准模式，消费者可以从Kinesis中提取数据｡
在这种情况下，每个碎片每秒可获得2 MB的数据，或者，
如果您有增强的扇出型消费机制，那么您就有Kinesis，抱歉，
它会将数据推送到消费者中｡
在这种情况下，您可以获得每秒两兆字节，每个碎片每个消费者，
这给了您一个更高的吞吐量和能力，有更多的应用程序从您的Kinesis流阅读｡
您可以回复数据，因为数据与新的Kinesis数据流一起保存｡
因此Kinesis将用于真实的大数据､ 分析和ETL｡
您将获得碎片级别的排序，并且必须提前指定每个Kinesis数据流需要多少个碎片｡
因此，您需要自己缩放碎片，
数据将在X天后过期｡
在记录时，数据保留期在1到365天之间｡
在容量模式方面，我们有两种模式，一种是预先指定Kinesis流所需的碎片数量的供应模式，另一种是按需容量模式，
Kinesis流直接为我们调整碎片数量｡
好吧，我会的
这就是这个夏季讲座的内容｡
希望你喜欢｡
我们下节课再见｡ 
  - [ ]  Messaging & Integration [25 问题] Quiz
    * 
 ## Section 22 - AWS Serverless: Lambda [48 个讲座 • 3 小时 7 分钟]
  - [ ] 291 AWS Lambda - Section Introduction [00:46]
    * 
现在，我们进入了真实的的内容，新的开发人员考试将问你很多关于无服务器的问题｡
无服务器，你可能听说过｡
这不仅仅是一个流行语｡
它是一种新趋势､ 新范式｡
我们将从AWS Lambda开始无服务器之旅｡
AWS Lambda正在成为AWS中使用最广泛､ 最受欢迎的服务之一｡
它彻底改变了人们开发应用程序､ 部署应用程序和扩展应用程序的方式｡
了解如何正确使用AWS Lambda非常重要，这一节将致力于了解Lambda是如何工作的，
不仅是在高水平上，而且是在真实的世界中｡
现在，让我们开始编写第一个Lambda函数｡ 
  - [ ] 292 Serverless Introduction [02:19]
    * 
教师：好的，现在我们来讨论一下什么是无服务器｡
因此，无服务器是一种全新的技术｡
当您使用无服务器服务时，您不必再管理服务器｡
所以，这并不是说您不再拥有服务器，
而是您不再管理它们｡
您只需要部署代码，最初，您只需要部署它的功能｡
因此，无服务器最初意味着功能即服务（FaaS）｡
但现在，无服务器意味着更多｡
最初，无服务器是由AWS Lambda开创的，
我们将在本节中看到这一点，但现在也包括了远程管理的任何内容｡
数据库､
消息传递､ 存储，只要您不调配服务器｡
因此，无服务器并不意味着没有服务器，它只是意味着您看不到它们，
或者您没有配置它们｡
因此，如果我们深入了解无服务器的含义，在AWS中，我们有我们的用户，
他们将从我们的S3桶（作为网站或CloudFront
+ S3提供）获得静态内容｡
然后我们会用cognito登录，这是我们的用户将他们的身份存储的地方｡
它们将通过API网关调用REST API, API网关将调用Lambda函数，
而Lambda函数将存储和检索DynamoDB中的数据｡
这只是一个例子｡
本节将专门介绍Lambda DynamoDB､ API
Gateway､ Cognito等相关知识｡
但是，这只是为给予提供一个无服务器应用程序的参考架构｡
在AWS中，有Lambda DynamoDB､ Cognito､ API
Gateway､ Amazon S3，
还有我们已经看到的东西，
如SNS和SQS，是的，我们没有为SQS和SNS管理任何服务器，它可以自行扩展｡
因此，这适合无服务器使用情形Kinesis Data Firehose，
因为它同样基于您的吞吐量进行扩展，您只需为所用资源付费，而无需配置服务器，Aurora无服务器，
当Aurora数据库按需扩展时，无需管理服务器､ 步骤函数和fargate，
因为fargate是ECS的无服务器功能，我们没有配置运行Docker容器所需的基础架构｡
希望这是对无服务器的简短介绍｡
下节课，我们将从AWS lambda开始｡
这将是一个学习的内容很多，但考试确实测试你对你的无服务器知识很重｡
那么我们开始吧｡
-（键敲击）
  - [ ] 293 AWS Lambda Overview [07:19]
    * 
那么什么是AWS Lambda，为什么它对我们有帮助？
让我们举个例子｡
我们将从Amazon EC2开始｡
而Amazon EC2，正如我们所知，
它们是云中的虚拟服务器，我们必须对其进行配置，
因此我们受到要配置的内存和CPU数量的限制｡
它们必须持续运行，我的意思是，
我们可以通过有效地启动和停止它们来优化它们，但除此之外，它们会持续运行，而不管您的实例上是否发生了什么｡
如果您想要扩展，可以使用自动扩展组，
但这意味着您需要执行一些操作来自动添加和删除服务器｡
现在，这是一种做事的方法，
而且效果很好｡
但还有AWS Lambda｡
所以对于Lambda，这些是视觉函数｡
没有要管理的服务器｡
因此，这意味着我们只需提供代码和运行函数｡
它受到时间的限制，
所以我们谈论的是最多15分钟的短处决，在我看来，不是那么短｡
最后，它们按需运行｡
这意味着当你不使用Lambda时，你的Lambda函数就不会运行，只有当你的函数运行时，
你才会被计费｡
当它被调用时，
它将按需运行，这是Amazon EC2的一个巨大转变｡
最后，缩放是自动化的｡
如果您需要的不仅仅是函数､ 出现次数和并发性，
那么AWS会自动为您提供更多的Lambda函数｡
不可思议｡
我们将在实践中看到这一点｡
所以Lambda的好处｡
我相信你见过很多｡
首先，定价是超级容易的｡
你要为Lambda接收的请求数､ 调用数以及你的计算机时间（Lambda运行了多长时间）付费｡
Lambda上有一个非常慷慨的免费层，即100万个Lambda请求和400，000
GB秒的计算时间｡
正如我们将看到的，它还集成了许多一流的服务｡
我们可以在Lambda上使用很多不同的编程语言，所以我们非常自由｡
此外，还可以非常轻松地与CloudWatch进行监控集成｡
最后，如果您希望为每个功能配置更多资源，则可以为每个功能配置多达10
GB的RAM，这是一个很大的容量｡
顺便说一句，你需要知道：如果你增加你的函数的RAM，那么它也会提高你的CPU和网络的质量和性能，
所以｡
现在我们来讨论一下Lambda的语言支持｡
我们有节点｡ js，
用于JavaScript､ Python､ 与Java 8兼容的Java或Java
11，C#用于｡ NET核心，
Golang, C，for Powershell，
Ruby，你可以为Lambda编写几乎任何语言，这要归功于社区支持的自定义运行时API｡
例如，如果你想在Lambda上运行Rust语言函数，
这要归功于一个开源项目｡
所以Lambda有很多语言支持｡
它还支持Lambda容器映像｡
所以这个Lambda容器图像是非常特别的｡
容器映像本身必须实现Lambda运行时API，因此它不是任何可以在Lambda上运行的容器映像｡
关于如何构建容器映像，需要有一些先决条件｡
然后ECS和Fargate仍然是运行任意Docker映像的首选｡
因此，如果考试要求您在Lambda上运行一个容器，除非该容器实现了Lambda运行时API，
否则您将在ECS或Fargate上运行该容器｡
现在，我说Lambda整合了这么多一流的服务｡
所以我给予你们一些关于它们是如何整合的想法｡
在本课程中，我们将看到其中的一些集成｡
因此，API Gateway将创建一个REST API，
它们将调用我们的Lambda函数｡
Kinesis将使用Lambda动态地进行一些数据转换｡
DynamoDB将用于创建一些触发器，
因此每当数据库中发生某些事情时，Lambda函数将被触发｡
亚马逊S3，我们已经看到了｡
Lambda功能将在任何时候被触发，
例如，在S3中创建文件｡
CloudFront，
这里是Lambda@edge，我在这一节有一个专门讲这个的讲座｡
云监视事件或事件桥｡
每当AWS基础架构中发生问题时，我们都希望能够对问题做出反应｡
例如，
假设我们有一个被切断的管道，状态发生了变化，我们想在此基础上进行一些自动化操作，我们可以使用Lambda函数｡
CloudWatch Logs，
可将这些日志流传输到您想要的任何位置｡
SNS对通知和您的SNS主题做出反应｡
SQS处理来自SQS队列的消息｡
最后是Cognito，它可以在用户登录到数据库时做出反应｡
所以，这些只是主要的｡
有很多Lambda积分｡
我想给大家看一个很好的例子，这是一个无服务器的缩略图创建｡
假设我们有一个S3存储桶，我们希望动态创建缩略图｡
因此，将有一个事件，这是新的形象将上传到亚马逊S3｡
这将通过S3事件通知触发Lambda功能｡
Lambda函数将包含生成缩略图的代码｡
该缩略图可以被推送并上传到另一个S3桶或相同的S3桶中，这将是该图像的更小版本｡
此外，
我们的Lambda函数可能希望在DynamoDB中插入一些数据，围绕图像的一些元数据，例如图像､ 名称､
大小､ 创建日期等｡
多亏了Lambda，
我们已经实现了自动化，并拥有了一个反应式架构，以响应在S3中创建的新应用程序和新映像的事件｡
另一个非常流行的例子是无服务器CRON drop｡
因此，CRON是EC2实例上的一种方法，
例如，
每五分钟或每周一上午10：00AM，等等等等｡
但是您需要在虚拟服务器上运行CRON｡
所以一个ECE两个实例等等｡
因此，
当您的实例没有运行时，或者至少您的CRON没有执行任何操作时，您的实例时间就被浪费了｡
因此，您可以创建每1小时触发一次的CloudWatch事件规则或EventBridge规则｡
每隔1小时，它将与Lambda函数集成，
执行您的任务｡
这是一种创建无服务器CRON的方法，
因为在这个例子中，CloudWatch
Events是无服务器的，Lambda函数也是无服务器的｡
现在，让我们以Lambda定价为例｡
所以你可以在这个网站上找到所有的信息，以防这里的信息过时，
但它会给予你一个如何工作的例子｡
所以你按次付费｡
前100万个请求是免费的，然后你要为每100万个额外的请求支付20美分｡
所以这是一个非常非常便宜的请求｡
然后，你要支付每持续时间的增量1（音频剪切）秒｡
因此，
您每月可免费获得前400，000 GB秒的计算时间｡
这意味着，
如果函数有1GB的内存，那么它的执行时间是400，000秒｡
也就是说，如果函数的内存是原来的八分之一，
那么你得到的时间是原来的八分之一，
也就是128 GB, MB的内存.
之后，您将为600，000千兆字节秒支付1美元｡
所以说实话，
你可以计算一下，在Lambda上运行你的代码通常非常非常便宜｡
因此，它是创建应用程序的一个非常流行的选择｡
原来如此｡
现在，让我们进入实践环节，了解Lambda的工作原理｡
  - [ ] 294 AWS Lambda - First [09:49] Hands On
    * 
  - [ ] 295 Lambda Synchronous Invocations [02:01]
    * 
现在让我们详细看看我们已经使用过的lambda函数的第一种调用类型，称为同步调用｡
因此，当您使用CLI､ SDK､
API网关甚至应用负载平衡器时，您正在执行同步调用｡
同步是什么意思？
这意味着您在等待结果，然后结果将返回给您｡
而且返回给您的任何错误都必须在客户端处理｡
这意味着如果我的lambda函数失败了，并且我刚刚从控制台调用了它，
我希望单击retry按钮来重试它｡
所以这意味着，
每当lambda出现错误时，客户端必须找出该怎么做｡
是否要重试，是否要执行指数回退等｡
所以同步意味着一个直接的调用，你可以对它的结果进行加权｡
所以CLI和SDK只会调用lambda函数，lambda函数会执行一些操作，
并给予我们的响应｡
这与我们在后面的章节中使用API网关时的情况相同，因此客户端将调用API网关，
API网关将其请求代理给lambda函数，
因此它将为您调用lambda函数; lambda函数将向您的API网关给予响应，API网关将向您提供响应｡
因此在这个模式中，我们只是在等待使其成为同步调用类型的响应｡
那么，什么服务与lambda同步呢？
首先，任何时候用户调用它都是同步的｡
因此：我们将看到通过应用负载平衡器､ API网关､
CloudFront和Lambda@Edge实现弹性负载平衡｡
粗体字的内容我们会在本课程中看到，非粗体字的内容不会在本课程中看到｡
所以亚马逊S3批处理;所有服务，如Cognito､ 步进功能和其他服务：莱克斯，艾丽莎，
还有Kinesis数据消防管.
在本节中，我们将了解应用负载平衡器､ API网关､
CloudFront，我们将在各自的部分中了解Cognito和Step
Functions｡
好吧，我会的
所以，
现在我们知道了什么服务同步调用lambda函数，让我们来玩一玩｡
  - [ ] 296 Lambda Synchronous Invocations [02:17] Hands On
    * 
  - [ ] 297 Lambda & Application Load Balancer [03:23]
    * 
Stéphane：现在，让我们来讨论一下lambda函数如何与应用程序平衡器集成｡
现在，lambda函数，
可以通过CLI或者SDK调用，
但是有时候如果你想把它们公开到互联网上，你想让人们通过HTTP或者HTTPS端点来使用它们.
因此，你有两种方法来做这件事｡
第一种方法是使用应用平衡器或API网关，我们将在下一节课中看到｡
所以在这节课上，我们将重点讨论ALB｡
为了让它工作，你需要在目标组中注册lambda函数｡
因此，客户端将调用并以HTTP或HTTPS的形式向ALB发送请求，ALB将同步调用目标组中的lambda函数，
因为同步，
因为我们正在等待lambda函数返回到应用平衡器，应用平衡器将依次向客户端返回响应｡
因此问题是，“负载平衡器如何将HTTP请求转换为lambda调用？
“因此，
从ALB到lambda, HTTP被转换为JSON文档｡
这是一个lambda函数的请求负载示例，正如我们所看到的，
在文档的顶部，
有ELB信息，即哪个ELB调用，目标组是什么｡
然后我们得到了一些关于HTTP方法的信息，
所以它是一个GET，路径是/lambda｡
我们以键/值对的形式获取查询字符串参数，因此每个查询字符串都将出现在JSON文档中｡
我们将以键/值对的形式获取头文件，
并获取POST､ PUT的主体，
值是base 64编码的，因此您是否需要对其进行解码｡
因此，
对于这些信息，需要将整个HTTP请求转换为JSON｡
所以我们应该记住查询字符串参数，头和正文，
它们都是经过转换的｡
对于查询字符串参数和标头，它们是键/值对｡
因此，类似地，我们的lambda函数应该返回一些东西，
一个JSON文档，ALB会将其转换回HTTP｡
所以如果我们看lambda函数的响应，非常简单｡
它需要包括状态代码和描述，以及作为键/值对的响应头，
最后是响应的主体和标志，无论它是否是base 64编码的｡
好的，我们知道lambda，
ALB如何在HTTP和JSON之间来回转换，但是现在我们来讨论考试中可能出现的ALB集成的最后一个特性，即多头值｡
因此，
如果我们让客户端与ALB对话，则可以启用ALB设置，即具有多个头值｡
那是什么意思？
这意味着，
如果我们传入多个具有相同值的头或具有相同值的查询字符串，那么我就可以轻松地表示查询字符串｡
因此，在本例中，name=foo和name=bar具有相同的名称，但具有不同的值｡
然后，
我们可以启用该设置，标头和查询字符串参数都将作为数组转换为lambda函数｡
这意味着，当ALB调用queryStringParameters
JSON的lambda函数时，
我将看到name，而不是一个值，我将看到一个值数组｡
所以，喷火和酒吧｡
所以两个值都被转换了，这是考试要测试的内容｡
它会问您：“我们如何支持多标题值？
“这只是ALB上的一个设置，这就是它的作用｡
下节课，我们会继续练习ALB和lambda｡
  - [ ] 298 Lambda & Application Load Balancer [08:09] Hands On
    * 
  - [ ] 299 Lambda Asynchronous Invocations & DLQ [03:13]
    * 
教师：现在我们已经了解了同步调用，下面让我们来了解异步调用｡
因此，它们用于在后台调用其他功能的服务，
如Amazon S3､ SNS主题､ CloudWatch事件等｡
让我们看一个具体的例子｡
假设我们有一个S3存储桶和一个用于新文件的S3事件通知｡
这将进入Lambda服务，
因为它是异步的，所以会发生一些事情｡
这些事件将被放置在内部事件队列中｡
这里有一个事件队列，Lambda函数将阅读该事件队列｡
然后Lambda函数将尝试处理这些事件，
但如果出现问题，Lambda函数将自动尝试重试｡
所以这意味着总共要试三次｡
第一个会马上发生，然后第二个会在一分钟后发生，
第三个会在第二个两分钟后发生｡
我们的Lambda函数总共要重试三次｡
然后，一旦重试发生，这意味着我们的Lambda函数可能会多次处理这些相同的事件，
所以这可能是一个问题｡
所以如果lambda函数不是幂等的，
这可能是个大问题，也就是说Lambda函数应该是幂等的｡
幂等性意味着，在重试的情况下，
结果是相同的｡
因此，
如果你有一个重试发生，会发生什么是你会看到重复的日志条目在CloudWatch日志，因为你的Lambda函数会尝试一遍又一遍.
因此，我们可以定义一个DLQ或死信队列，
用于重试完成后｡
因此，这意味着如果处理失败，并且由于重试而无法成功，
则Lambda函数可以将一些事件发送到SQS或SNS，以便稍后进行进一步处理｡
这就是异步调用背后的全部思想｡
因此，您可能会问我：“为什么我们要使用异步而不是同步？
“首先，有些服务必须使用异步，因此您别无选择;第二种情况是，
例如，
您需要加快处理速度，而不需要等待结果，
那么您可以同时开始处理1000个文件，然后您只需等待所有五个文件都得到并行处理，但您无需等待每个单独的结果，这样可以加快处理时间｡
那么，哪些服务是异步完成的呢？
第一个是Amazon S3，我们使用S3事件通知调用Lambda函数｡
我们有SNS，所以当我们收到通知时，
我们会触发Lambda函数｡
CloudWatch Events或CloudWatch EventBridge，
基本上让我们的Lambda函数对AWS基础设施中发生的事件做出反应｡
我们不一定会在实践中看到的其他服务包括：CodeCommit，
用于在出现新分支､ 新标签或新推送时触发Lambda函数; CodePipeline，用于在管道期间调用Lambda函数，
Lambda必须回调CodePipeline-或其他一些服务; CloudWatch Logs，
用于日志处理; SES，
用于发送电子邮件的Simple Email Service;
CloudFormation､ Config､
Io T和IoT Events｡
因此，从我们的角度来看，我们需要了解Lambda如何与Amazon
S3､
SNS和CloudWatch Events或EventBridge配合使用｡
因此，让我们继续在上机操作中学习异步调用｡
我们下节课再见｡ 
  - [ ] 300 Lambda Asynchronous Invocations [05:59] Hands On
    * 
  - [ ] 301 Lambda & CloudWatch Events / EventBridge [00:28]
    * 
讲师：现在，我们来讨论一下如何将CloudWatch
Events或EventBridge与Lambda集成｡
有两种方法，第一种是执行无服务器CRON或速率｡
因此，我们将创建一个EventBridge规则，然后每隔一个小时（例如，
一个小时），它将触发Lambda函数来执行任务｡
或者我们可以创建一个CodePipeline EventBridge Rule，
例如检测每次CodePipeline状态的变化，并在状态变化时将要调用我们的Lambda函数来执行一个任务｡
非常简单的想法，但让我们看看我们如何在实践中做到这一点｡
  - [ ] 302 Lambda & CloudWatch Events / EventBridge [05:04] Hands On
    * 
  - [ ] 303 Lambda & S3 Event Notifications [01:34]
    * 
教师：现在，让我们看看如何将S3事件通知与Lambda集成｡
这只是一个关于S3事件通知的提醒，
它是一种在创建､ 删除､ 恢复对象时以及在发生复制时获得通知的方式｡
您可以按前缀和后缀进行筛选｡
典型的用例是为上传到Amazon S3的每张图像生成缩略图｡
因此，您可以将事件发送到Amazon S3中，而S3可以将其发送到三个对象，
即SNS和SNS主题，我们可以采用扇出模式将其发送到多个SQ-SQ，
或者我们可以将其发送到SQ-SQ中，并让Lambda函数直接读取该SQ-SQ，或者我们可以使用Amazon
S3事件通知，
直接调用Lambda函数，这是一种异步调用｡
这个Lambda函数可以对数据做任何它想做的事情，然后万一出了问题，我们可以建立一个死信队列，
比如一个SQS，就像我们之前看到的｡
因此，
这些S3事件通知通常在几秒钟内发送事件，但有时可能需要一分钟或更长时间，
因此，如果您希望确保不会丢失任何事件通知，请确保在存储桶上启用版本控制｡
否则，
如果在同一时间对同一对象执行两次写入操作，您可能会收到一个通知，而不是两个｡
这只是文档中的小字，但值得注意｡
好吧，我会的
这是一个简单的模式｡
S3存储桶将具有进入Lambda的新文件事件｡
Lambda函数将处理该文件，可能会将数据插入DynamoDB表，
甚至是RDS数据库中的表｡
很简单的｡
让我们看看如何在实际操作中实现这一点｡ 
  - [ ] 304 Lambda & S3 Event Notifications [04:19] Hands On
    * 
  - [ ] 305 Lambda Event Source Mapping [07:17]
    * 
教师：我们已经看到了异步处理，我们已经看到了同步处理，
现在我们将看到事件源映射｡
这是Lambda如何在AWS中处理事件的最后一个类别｡
因此，
它适用于Kinesis数据流､ SQS和SQS FIFO队列以及DynamoDB数据流｡
因此，所有这些事情的共同点是，
需要从源轮询记录｡
因此Lambda需要请求服务获取一些记录，然后将返回这些记录｡
这意味着Lambda需要从这些服务中进行轮询｡
因此，在这种情况下，
Lambda函数被同步调用｡
让我们来看看，我们有Kinesis和Lambda服务，如果我们将Lambda配置为从Kinesis读取，
那么它们将在内部创建一个事件源映射｡
它负责轮询Kinesis，并从Kinesis返回和获取结果｡
所以Kinesis会退回一批给我们｡
然后，
一旦这个事件源映射有一些数据需要Lambda处理，它将通过一个事件批处理同步调用我们的Lambda函数｡
所以，在它的核心，这就是它的运作方式｡
因此，有两类事件源映射器｡
第一个是流，第二个是队列｡
现在我们来讨论流，
流应用于Kinesis数据流和DynamoDB流，我们很快就会看到DynamoDB流是什么｡
因此，对于流，它们将是事件源映射｡
他们将为每个碎片创建一个迭代器，
因此每个Kinesis碎片或DynamoDB Stream碎片｡
并且这些项目将在碎片级别按顺序处理｡
因此我们可以配置从哪里开始读取｡
您可以只读取新项目，也可以从碎片的开头或特定时间戳开始读取｡
无论何时从碎片中处理项目，
无论是从Kinesis还是DynamoDB中，都不会将其从流中删除｡
这意味着其他消费者可以读取Kinesis或DynamoDB中的数据，这是它们最初的工作方式｡
但我只是想再次强调这一点｡
因此，它的使用情形是低流量或高流量｡
因此，
如果您的流量流较低，则可以在处理之前使用批处理窗口来累积记录｡
因此要确保有效地调用另一个函数｡
然后，
如果您有一个吞吐量非常高的流，并且希望加快处理速度，则可以设置Lambda在分片级别并行处理多个批处理｡
这是来自AWS博客的图表｡
因此，我们有一个分片，有一个记录处理器，
有一种并行的方法，让多个Lambda函数在同一个分片中处理批处理｡
因此，每个分片最多可以有10个批处理器｡
对于每个批次，它们将在分区键级别按顺序处理｡
因此，如果您指定了分区键，
将不会按顺序完全读取分片｡
但碎片中的每一把钥匙都将按顺序读取｡
这就是我们可以并行处理Lambda函数和流的方法｡
错误怎么办？
默认情况下，如果函数返回错误，则将重新处理整个批处理，
直到函数成功或批处理中的项目过期｡
所以这一点非常重要｡
批处理中有错误可能会阻止处理｡
因此，
为了确保按顺序处理，受影响的批处理将暂停，直到错误得到解决｡
所以你可以用几种方法来管理它｡
您可以将事件源映射配置为第一个，即丢弃旧事件｡
或者限制重试次数，或者在出现错误时拆分批｡
这种情况下，这是关于Lambda超时问题｡
所以如果你的Lambda函数没有足够的时间来处理整个批处理，也许你有足够的时间来处理一半的批处理｡
然后，如果您想丢弃旧事件，
则所有事件都可以转到一个目的地｡
我们会在下一节课看到目的地｡
所以这都是关于流的｡
现在，您需要了解队列｡
对于队列，它是SQS和SQS FIFO｡
所以你也有同样的想法｡
SQS队列将由Lambda事件源映射轮询｡
然后，无论何时返回批处理，Lambda函数都将与事件批处理同步调用｡
因此，对于SQS，事件源映射将使用长轮询来轮询SQS｡
所以这将是有效的｡
我们可以指定批处理大小，从1到10条消息｡
这是配置｡
因此，只有批处理大小和SQS队列｡
AWS网站上有一些建议，将队列可见性超时设置为Lambda函数超时的六倍，
这是可配置的｡
然后如果你想使用DLQ，
如果你想确保在SQS中阅读或处理消息时出现问题，它会进入死信队列，
那么你可以在SQS队列上设置DLQ，而不是在Lambda上｡
因此，我们在SQS上设置了DLQ，但不在Lambda上设置｡
为什么？
因为Lambda的DLQ只适用于异步调用｡
而这是一个同步调用｡
或者，
正如我们将看到的，我们也可以使用Lambda目的地来处理故障｡
我们会在接下来的课上看到｡
现在是关于队列和Lambda的信息，很抱歉这很无聊，
但我必须说出来｡
所以Lambda支持按序处理，
如果你有一个FIFO队列，那么就是先进先出｡
并且，为了处理队列而进行扩展的Lambda函数的数量将等于活动消息组的数量｡
这就是组ID设置｡
如果使用标准队列，则不会按顺序处理项目｡
对于标准队列，Lambda将尽可能快地扩展以读取标准队列中的所有消息｡
如果队列中发生错误，则批处理将作为单个项目返回到队列，
并且可能在与原始批处理不同的分组中进行处理｡
有时，即使没有发生函数错误，事件源映射也可能两次从队列中接收到相同的项目｡
因此，您需要确保为Lambda函数提供项有效处理，
以防发生这种情况｡
最后，
当它们被Lambda处理时，Lambda将从队列中删除这些项目，然后它们将永远不会再出现｡
最后，正如我所说的，您可以配置源队列，
以便在无法处理项目时将其发送到死信队列｡
所以希望这一切都是有意义的｡
我们将看看如何设置它｡
那么，扩展性如何呢？
我已经说过了，但我们可以再次总结一下事件映射器的缩放｡
因此对于Kinesis数据流和DynamoDB流，每个流碎片都有一个Lambda调用｡
或者，
如果您使用并行化，则每个分片最多可以同时处理10个批次｡
对于SQS标准，我说Lambda将很快扩展｡
所以是的｡
它每分钟增加16个以上的实例以进行纵向扩展｡
所以这是相当快的｡
然后每秒同时处理的最大批处理量为1000｡
对于SQS FIFO，则稍有不同｡
因此，
无论如何，具有相同组ID的消息传送都将按顺序处理｡
并且Lambda函数将按比例增加到活动消息组的数量｡
同样，它们由组ID定义｡
以上就是Lambda事件映射寻源的全部内容，我知道这是一个相当冗长乏味的理论讲座｡
在下一节课中，当我们进行实际操作时，这会很有意义，
但我们必须复习一下，我建议你们在考试前再看一遍这节课，
因为考试可能会问你们一些关于事件映射器的非常尖锐的细节｡
好吧，就这样｡ 我们下节课再见｡
  - [ ] 306 Lambda Event Source Mapping [07:02] Hands On (SQS)
    * 
  - [ ] 307 [DVA-C02] Lambda Event & Context Objects [02:31]
    * 
教师：让我们来理解一个非常重要的概念，
那就是Lambda函数中的事件和上下文对象｡
让我们举一个例子，其中调用了Lambda函数，
例如，由EventBridge规则调用｡
接下来会发生的事情是EventBridge会创建一个事件，
这个事件会被传递给Lambda函数，Lambda函数会接收到这个事件，它被称为事件对象｡
事件对象包含了很多关于事件本身的细节｡
从何处发出以及服务本身将在事件中包含大量与该事件相关的数据｡
但是我们还有上下文对象｡
这是Lambda函数的第二部分，
更多的是关于函数的元数据，比如来自AWS的请求ID，
函数名，与Lambda函数关联的日志组，内存限制，等等｡
所以这个事件宾语和上下文宾语是非常不同的，
但是非常互补的｡
因此，事件对象是JSON格式的文档，
其中包含函数将要处理的数据｡
因此调用服务，例如EventBridge或SQS或SNS或任何您想要的服务，
将包含Lambda函数处理事件所需的所有信息｡
然后根据您使用的运行时，
这个事件对象将被转换为对象｡
例如，如果你使用Python，
它会被转换成字典｡
因此，任何类型的输入､
参数或调用服务参数都将包含在事件对象中｡
另一方面，context对象提供有关调用本身和运行时环境的数据的方法｡
所以这在运行时被传递给Lambda函数，
从上下文对象，我们可以得到AWS请求ID，
函数名，内存限制，等等，我们也可以在Lambda函数中使用这些概念信息｡
所以在你的代码中，你会看到一个处理程序｡
我用的是Python，
所以处理程序有一个事件和一个上下文，事件会有一些信息，
比如，事件的来源或者事件的区域等等，我们可以把这些信息打印到控制台，或者上下文会有一些信息，比如请求ID，函数ARN，
函数名，内存限制，以兆字节为单位，然后，比如，有关CloudWatch日志的一些信息，
例如流名称或组名称｡
现在，您可以选择正确的事件或上下文来获取考试时要求您提供的特定信息｡
好了，这堂课就到这里｡
我希望你们喜欢，我们下节课再见｡ 
  - [ ] 308 Lambda Destinations [02:30]
    * 
老师：这是2019年11月推出的一个很酷的新功能，叫做Lambda Destinations｡
因此，问题是，当我们执行异步调用或事件映射器时，
我们很难看到它是失败还是成功｡
如果是的话，就去检索数据｡
因此，目标的想法是将异步调用的结果或事件映射器的故障发送到某个地方｡
那是什么地方？
我们马上就知道了｡
因此，对于异步调用，
我们可以为成功和失败的事件定义一个目的地｡
我们所说的成功和失败，是指对该事件的处理｡
因此，
对于异步调用，我们有SQS､ SNS､
Lambda和Amazon EventBridge总线的目标，因此云监视事件｡
其思想是我们的lambda函数是异步调用的，
例如，通过S3事件｡
如果我们成功了，我们可以把它发送到某个成功的事件目的地｡
如果失败，我们可以将其发送到失败的事件目标｡
因此，您现在可能会注意到，
这看起来很像异步调用的DLQ设置｡
因此，
现在的建议是使用目的地而不是DLQ，即使您可以同时使用这两种方法｡
为什么？
因为目的地更新了，它们允许更多的目标｡
DLQ只允许它将失败发送到SQS和SNS，
但目的地允许将成功和失败都发送到SQS､ SNS､ Lambda和EventBridge｡
好的，这是针对异步调用｡
那么，事件源映射呢？
只有当您有一个因为无法处理而被丢弃的事件批次时，才使用此选项｡
因此，我们可以将该事件批处理发送到Amazon
SQS或Amazon SNS中，如图所示｡
因此，我们从Kinesis阅读，将有一个事件源映射，我们将尝试继续处理数据，但随后我们没有成功，
我们可以将丢弃的事件批次发送到失败的事件目的地，而不是阻止我们对Kinesis数据流的整个处理｡
因此，请注意，如果您有一个从SQS阅读的事件源映射，
您可以设置一个失败的目标，也可以直接在SQS
Que上设置一个DLQ｡
你想怎么做就怎么做｡
所以在下一节课中，我们将进入目的地，进行一些实践，
并进行一些练习，以更好地理解这个功能｡
所以我们下节课再见｡
  - [ ] 309 Lambda Destinations [06:49] Hands On
    * 
  - [ ] 310 Lambda Permissions - IAM Roles & Resource Policies [02:35]
    * 
教师：现在我们来讨论Lambda执行角色和权限｡
我们已经在实践中做了很多，所以我相信你们已经完全理解了它是如何工作的，
但是回到理论课上来尝试一下也是很好的｡
因此，必须将IAM角色附加到lambda函数，
这将授予Lambda函数访问AWS服务和资源的权限｡
我们可以重用Lambda的一些简单托管策略，
例如BasicExecutionRole，它允许我们将日志上传到CloudWatch，
但还有KinesisExecutionRole用于从Kinesis中读取，DynamoDBExecutionRole用于从DynamoDB流中读取，
SQSQueueExecutionRole用于从SQS中读取，LambdaVPCAccessExecutionRole用于在VPC中部署Lambda函数，我们将在本节中看到这一点｡
和XrayDaemonWriteAccess将跟踪数据上载到X-Ray，我们将在本节中看到这一点｡
这是托管策略，但我们显然可以为Lambda创建自己的策略｡
因此，
每当我们使用事件源映射来调用函数时，Lambda是我们要阅读数据的对象，
因此，我们必须使用执行角色来读取事件数据｡
另一方面，
Lambda函数由其他服务调用，因此我们不需要具有某些特定权限的特定IAM Role｡
顺便说一下，最佳实践是为每个函数创建一个Lambda执行角色，
就像我们在实践中一直在做的那样｡
这是用于事件源映射，或者如果我们的Lambda函数实际上需要调用其他服务，那么如果我们的Lambda函数被其他服务调用，
那么我们将使用基于资源的策略，
这是为了给予其他帐户或其他AWS服务使用您的Lambda资源的权限，因此，在函数上调用它，这与Amazon S3桶的S3桶策略非常相似｡
所以规则是，
如果这两种情况之一发生，IAM原则可以访问Lambda函数｡
首先，附加到主体的IAM策略会对其进行授权｡
例如，
我们有IAM用户，我们有完全权限，
所以我们可以访问Lambda函数，这是我们到目前为止一直在做的，这要归功于我们的管理员访问策略｡
或者，如果我们有一个基于资源的策略来授权访问Lambda函数，那么当您有一个服务到服务的访问权限时，
这会更有帮助｡
所以我们以前见过，但我们还会再见到｡
当另一个AWS服务（如Amazon S3）想要调用我们的Lambda函数时，
我们需要确保基于资源的策略为其提供访问权限｡
这是控制台在幕后进行的非强制性操作，
但如果您要进行自己的集成，您可以在这里自己进行｡
让我们来看看控制台是如何工作的｡ 
  - [ ] 311 Lambda Permissions - IAM Roles & Resource Policies [03:03] Hands On
    * 
  - [ ] 312 Lambda Environment Variables [00:47]
    * 
旁白：好的｡
现在，
我们已经完成了所有的Lambda调用，现在让我们进入更多的Lambda配置和部署｡
那么Lambda有环境变量的概念，它是什么呢？
这是一个字符串形式的键值对，
它们可以帮助您调整函数行为，而无需更新代码｡
函数､ 环境变量将可用于您的代码，
Lambda服务也将在其自己的系统环境变量中处于最重要的位置｡
当您在编程中使用环境变量时，这是很常见的｡
所以Lambda支持它们｡
最酷的是，
我们可以加密这些环境变量，例如，通过KMS来存储秘密值｡
这些秘密可以通过Lambda服务密钥或您自己的客户主密钥进行加密｡
因此，让我们继续练习环境变量｡
  - [ ] 313 Lambda Environment Variables [02:42] Hands On
    * 
  - [ ] 314 Lambda Monitoring & X-Ray Tracing [01:53]
    * 
教师：现在我们来讨论一下Lambda如何进行日志记录､ 监视和跟踪｡
我们知道的第一件事是Lambda与CloudWatch日志集成，因为所有Lambda执行日志都自动存储在CloudWatch日志中｡
如果您的Lambda函数具有一个执行角色，
该角色具有正确的IAM策略，该策略授权您的Lambda函数写入CloudWatch日志，
并且这包含在Lambda基本执行角色中，正如我们之前所看到的｡
我们还没有看到这一点，但有CloudWatch指标｡
因此，它们显示在CloudWatch指标UI或Lambda UI中｡
它们将提供有关调用､
持续时间､ 并发执行､ 错误计数､
成功率､ 限制､ 异步传递失败的信息｡
如果你从Kinesis或DynamoDB流中阅读，
你的迭代器年龄意味着你读流的进度，你读流的滞后程度｡
我们马上就来看看｡
最后，你可以在Lambda函数中用x射线进行追踪｡
所以这非常简单｡
您只需在Lambda配置中启用它，这称为主动跟踪｡
它将为您运行x射线守护程序｡
现在，您唯一需要做的就是在代码中使用x射线SDK｡
您需要确保您的Lambda函数具有正确的IAM执行角色以写入x射线｡
因此，
有一个名为AWS x射线守护程序写入访问的托管策略｡
如果需要，与x射线通信的环境变量是这三个｡
所以你只需要看他们一次｡
我不会念给你们听，但我只看一次｡
他们可以在考试中取得好成绩｡
我认为最重要的一个是最新的AWS
x射线守护程序地址，它显示了x射线守护程序的IP和端口在哪里运行，与您的Lambda功能有关｡
访问这些环境变量的方式与我们以前访问其他环境变量的方式相同｡
以上就是我们现在要做的，我们来看看它是如何工作的｡
  - [ ] 315 Lambda Monitoring & X-Ray Tracing [04:14] Hands On
    * 
  - [ ] 316 [DVA-C02] Lambda@Edge & CloudFront Functions [05:38]
    * 
讲师：那么，
我们来谈谈边缘定制｡
那么这意味着什么呢？
我们知道我们在特定区域部署功能和应用程序，
但有时使用CloudFront等工具时，我们会让边缘位置分发内容｡
有时，现代应用程序需要在到达应用程序本身之前在边缘执行某种形式的逻辑｡
这些被称为边缘函数，这是你编写的一段代码，
你将把它附加到你的CloudFront发行版中｡
其思想是，您希望在用户附近运行这些函数，
以便在某些情况下最小化延迟｡
所以CloudFront有两种函数，你有CloudFront函数和Lambda@Edge｡
我们的想法是，能够理解什么时候需要它们，
以及它们之间的差异，这节课也会这么做｡
但是使用边缘功能，您不必管理任何服务器，
这些边缘功能是全球部署的｡
例如，它们的用例是定制来自CloudFront的CDN内容｡
此外，你只支付你所使用的，
它是完全无服务器｡
现在，让我们更深入地了解一下这些使用情形｡
第一个是关于网站安全和隐私，然后我们在边缘有动态Web应用程序，
我们可以做搜索引擎优化､ SEO，
我们可以做跨源和数据中心的智能路由､ 边缘的僵尸网络缓解､ 边缘的实时图像转换､
A/B测试､ 用户身份验证和授权､
用户优先级划分､ 用户跟踪和分析等｡
因此，我们可以使用CloudFront函数和Lambda@Edge进行许多不同的自定义｡
现在我们来讨论CloudFront函数的用途及其工作原理｡
这就是进入CloudFront的典型请求的样子｡
因此，客户端将向CloudFront发出请求，
这称为查看器请求，因为客户端将查看它｡
然后CloudFront会向你的源服务器发送一个源请求，
服务器会回复CloudFront，
这样我们就有了一个源响应，
最后CloudFront会把这个响应发送到客户端，这样我们就有了一个查看器响应｡
现在CloudFront函数是用JavaScript编写的轻量级函数，
它们修改了查看器请求和响应｡
它们用于对延迟敏感的大规模CDN定制，
可为您提供亚毫秒级启动时间和每秒数百万次请求的规模｡
正如我所说的，它们仅用于更改查看器请求和响应，
因此查看器请求是在CloudFront收到查看器请求之后，
我们可以修改这一点，或者查看器响应是在CloudFront将响应转发回查看器之前｡
这是CloudFront的一个原生特性，
整个代码直接在CloudFront中进行管理｡
请记住，CloudFront功能的高性能，
高规模只为观众的请求和响应.
现在Lambda@Edge的值多了一点，
因此您可以修改所有这些值｡
这些是NodeJS或Python中返回的函数，
可以扩展到每秒1000个请求，它用于更改CloudFront请求和响应，
多个请求，实际上是所有请求，查看器请求和源请求，在CloudFront将请求转发到源之前｡
您还有源响应（在CloudFront接收到来自源的响应之后）和查看器响应（在CloudFront将响应转发回查看器之前）｡
您在一个区域（us-east-1）中编写函数，
该区域与您管理CloudFront分发的区域相同，然后CloudFront会将此函数复制到其所有位置｡
这里我们有一个表格来区分CloudFront函数和Lambda@Edge｡
因此，一个显著的区别是运行时支持，当然JavaScript只支持CloudFront函数，
然后NodeJS和Python支持Lambda@Edge｡
CloudFront函数的规模非常非常大，
我们讨论的是每秒数百万个请求，
而Lambda@Edge的请求数为数千个｡
现在，触发点发生在哪里是一个很大的不同｡
因此，Lambda@Edge对查看器请求和源都有影响，
而CloudFront函数仅对查看器有影响｡
非常重要的是，CloudFront函数的最大执行时间不到一毫秒，
因此它们是非常非常快速和简单的函数｡
而对于Lambda@Edge，
您可以获得5到10秒的时间，
因此您可以在这些函数中执行大量逻辑｡
剩下的，你可以看看，好吗？
现在，就用例而言，CloudFront函数将用于缓存键规范化，
例如转换请求属性以创建最佳缓存键｡
标头操作，用于在请求或响应中插入､
修改或删除HTTP标头，或者执行URL重写或重定向，
或者请求授权以创建和验证JWT标记，
从而允许或拒绝请求｡
所有这些操作都可以在不到1毫秒的时间内执行，
而Lambda@Edge的执行时间更长，例如，它可能长达10秒｡
CPU和内存可调，
因此可以加载大量库，
因此代码可以依赖于第三方库，
例如SDK（如果您想访问其他AWS服务）｡
您还可以通过网络访问用于处理数据的外部服务，
因此您可以真正执行一些大型集成｡
Lambd@Edge允许您访问文件系统，
或者访问HTTP请求本身，因此您可以进行更多的定制｡
希望这对你有帮助｡
我希望你们喜欢这节课，
我们下节课再见｡
  - [ ] 317 Lambda in VPC [04:21]
    * 
好的，现在我们来讨论一下网络和Lambda函数｡
所以默认情况下，Lambda函数在您自己的VPC之外启动，所以它在AWS拥有的另一个VPC中启动，
明白吗？
因此，它无法访问属于您的VPC的资源｡
那么，您的VPC有什么意义呢？
这可能是您对实例､ RDS数据库､
ElastiCache或内部弹性负载平衡器等的问题｡
因此，
默认情况下，您将了解到Lambda部署如下所示｡
你有云，
你的Lambda函数，它可以访问任何公共网站，好吗？
我们可以访问外部API｡
我们还可以访问其他服务，如DynamoDB｡
但是，如果我们有自己的VPC和私有子网，并且其中有私有RDS，
则Lambda无法访问RDS｡
所以你可能会问我这个问题，我能做些什么来解决它？
我可以在VPC中部署Lynda吗？
你当然可以｡
因此，您必须定义您的VPC
ID､ 子网，并且需要为Lambda函数分配一个安全组｡
而在幕后，Lambda函数将创建一个ENI｡
因此，
要创建此ENI，您的Lambda函数需要一个Lambda VPC访问执行角色｡
回到我们的私有子网，我们在VPC中的Amazon
RDS数据库周围有RDS安全组｡
这个Lambda函数，我们要给予它VPC访问权限｡
因此，一旦我们正确设置了它，
它将创建一个ENI，一个弹性网络接口，与Lambda安全组一起访问您的RDS数据库，您的Lambda将通过您的ENI｡
你知道，
它是无形的，我们看不到它，但这就是它在幕后发生的方式｡
因此，
它将通过ENI进入您的Amazon RDS数据库｡
因此，要使其正常工作，
我们需要确保RDS安全组确实允许来自Lambda安全组的网络访问，例如，就像EC2实例和加载搜索一样｡
好吧，我会的
所以这里有一个警告｡
如果我们在VBC中部署一个Lambda函数，我们是否可以访问公共互联网？
默认情况下，您的VPC中的Lambda函数无法访问互联网｡
所以你可以问我，好吗｡
我不想让你把我的Lambda函数部署在私有子网内｡
我想将其部署在一个公共子网中，而您告诉我Stefan，
公共子网可以访问Internet.
因此，对于EC2实例，
这是正确的，但对于Lambda函数，这不是正确的｡
因此，在公共子网中部署Lambda函数并不会为它提供Internet访问或公共IP｡
很高兴知道这一点｡
所以考试肯定会考你这一点｡
那我们该怎么办？
你可以在一个私有子网中部署Lambda函数，并为它给予互联网访问，你可以使用一个NAT网关，
或者一个NAT实例，就像我们在VPC入门中看到的那样｡
我们在VBC中有Lambda函数，
我们在云中，它部署在私有子网中，而不是公共子网中｡
因此，它位于专用子网中，
我们可以访问RDS，但要访问外部API，我们需要使用NAT设备通过公共子网｡
因此是NAT网关或NAT实例｡
NAT网关或实例将与我们的VPC的互联网网关进行通信，互联网网关将为给予提供外部API的访问权限｡
所有这些都是通过您的路由表和VPC配置进行配置的，明白吗？
接下来，
如果您希望访问DynamoDB，那么，我们可以通过公共路由或通过您的互联网网关访问DynamoDB｡
因此，一旦NAT到位，这将起作用｡
或者，如果您希望以私人方式访问DynamoDB，
则可以使用VPC端点｡
如果您还记得，
VPC端点用于在您的云中私下访问私有AWS服务，而无需访问NAT设备或互联网网关｡
因此，我们将为DynamoDB创建一个VPC端点作为VPC端点网关，Lambda函数将与端点进行通信，
并私下访问您的DynamoDB服务，这非常棒｡
所有这些都是可行的｡
因此，如果您在私有子网中部署Lambda函数，请注意，即使您没有端点或NAT网关，
您的CloudWatch日志也会正常工作｡
CloudWatch Logs是一种无论发生什么情况都能正常工作的工具｡
好了，理论就讲这么多，
现在我们来进行实践｡
  - [ ] 318 Lambda in VPC [04:39] Hands On
    * 
  - [ ] 319 Lambda Function Performance [05:29]
    * 
教师：好的，现在我们来讨论一下lambda函数的配置和性能，
第一个我想讨论的是RAM｡
目前我们使用的是128兆字节的RAM，
但我们可以以1兆字节的增量扩展到10千兆字节的RAM｡
这个想法是，你在lambda函数中添加的RAM或内存越多，
你得到的vCPU信用就越多｡
因此，您无法直接设置vCPU的数量｡
您必须增加RAM以隐式地获得更多的vCPU｡
因此，当RAM达到1，792 MB时，您的函数将具有相当于一个完整vCPU的容量｡
之后，您将获得多个vCPU，因此您需要使用多线程来从添加的vCPU中受益｡
因此，如果你的应用程序是CPU限制的，
这意味着它有很多计算，你想提高你的应用程序的性能，这意味着减少你的函数将运行的时间，
那么你需要增加你的应用程序，你的lambda函数RAM｡
这也是一道很常见的考试题｡
那我们来谈谈暂停吧｡
所以你的lambda函数默认有一个3秒的超时｡
这意味着如果lambda函数运行超过3秒，
它将因超时而出错，
但您可以将超时设置为最大900秒，
即15分钟｡
因此，0秒到15分钟之间的任何执行间隔都是lambda的良好用例｡
任何超过15分钟的时间都不是lambda的好用例，
可能对于Fargate，
ECS或EC2来说会更好｡
这也是考试可能会测试你的东西｡
接下来我们来谈谈表演｡
所以lambda有一个执行上下文｡
它是一个临时的运行时环境，
用于初始化lambda代码的任何外部依赖项｡
因此，您将使用该上下文来建立数据库连接，
以创建HTTP客户端或SDK客户端｡
关于执行上下文的一个很酷的事情是，
它会在预期的另一个lambda函数调用中保持一段时间｡
这意味着如果你连续多次调用lambda函数，
那么调用上下文可以被重用，重用所有这些现有的数据库连接，
GP客户端等，这是非常有帮助的，因为它可以加速和提高lambda函数的性能｡
我马上会给你们看一些伪代码｡
现在执行上下文确实包括/tmp目录，我也将在这节课中讨论，
这是一个可以写入文件的空间，
它们将在执行过程中可用｡
因此，我想向您展示一些利用该执行上下文的代码｡
所以这个代码是坏的｡ 为什么？
所以我们有一个名为get_user_handler的函数，
这就是lambda将要调用的函数｡
如果您阅读了这段代码，我们会得到名为os的DB_URL｡
getenv，
这样我们就得到了一个环境变量，这很棒｡
但是接下来的一行db_client = database｡ 连接DB_URL｡
因此，虽然这看起来是正确的，因为要获得用户，
我们首先需要连接到数据库，每次我们的lambda函数将运行，
这个连接数据库将必须运行｡
因此，无论何时有人调用我们的lambda函数，
它首先必须连接到数据库，然后获取用户｡
这是非常低效的，因为我们的lambda函数可能被多次调用｡
相反，AWS希望你做的，也是最佳实践，是在你的处理程序之外初始化数据库连接，
为什么？
因为它只会被初始化一次，然后它可以在函数调用中重用，
这将大大提高函数的性能｡
因此，这种用例是，再一次，好吧，
在考试中可以出现的东西，
它会向您展示一些伪代码，
并试图让您根据数据库连接客户端或HTTP客户端或SDK客户端打开的位置来理解什么是好的，
什么是坏的｡
最佳实践，任何需要花费大量时间初始化的东西，
都可以将其从函数处理程序中删除，并在执行过程中重用它｡
好了，最后，如果您需要编写一些临时文件并重用它们，
该怎么办？
您可以使用/tmp空间｡
例如，如果你需要下载一个大文件来工作，
或者如果你需要磁盘空间来执行操作，
在这种情况下，将所有这些文件存储在/tmp中，这意味着临时或临时｡
这个想法是，你得到10GB的磁盘空间，你可以使用你的lambda函数，
这个目录包含并保留了你的lambda函数的执行时间｡
因此，即使你的lambda函数停止，
然后它被重新调用，
你也有可能在/tmp空间中重新找到完全相同的文件，
并赢得很多时间｡
这与执行上下文的思想完全相同｡
在这里，我们可以将非常重的文件（最多可达0.5
GB）写入/tmp空间｡
因此，如果您需要永久持久化对象，那么您需要将其存储在一个您知道将跨调用持久化的空间中，
例如，该空间将是Amazon
S3｡
如果你想在/tmp空间加密内容，在lambda上没有这样做的设置｡
您必须使用KMS特性来生成数据密钥，
并使用这些数据密钥对临时空间上的数据进行实际加密｡
因此，我们已经看到了所有可以提高lambda函数性能的方法｡
现在，让我们进入控制台来玩这些游戏｡
  - [ ] 320 Lambda Function Performance [06:00] Hands On
    * 
  - [ ] 321 Lambda Layers [01:51]
    * 
教师：好的，现在我们来谈谈Lambda层｡
它们是Lambda的一个新特性，它们允许我们做两件事｡
第一是为Lambda创建自定义运行时间｡
因此，
这意味着最初并不适用于Lambda，但社区已决定通过Lambda Layers支持的语言｡
例如，我们有C++，还有Rust｡
这两个例子允许你在Lambda函数上使用C++语言或者Rust语言｡
Lambda Layers的另一个更常见的用例是外部化依赖项以便重用它们｡
因此，如果我们看一个压缩的应用程序包，它可能会非常大，
我们有一个Lambda函数，
并且会有一些繁重的库，繁重的依赖项｡
大概是30兆字节｡
我们看到，
要更新另一个函数，我们需要一遍又一遍地重新上传那个zip｡
这意味着，每次我们重新打包应用程序并重新上传所有内容时，我们使用的依赖项有时不会发生变化，
或者变化非常､ 非常､
非常慢｡
所以最好将它们外化到一个层中｡
因此，
我们的目标是让您的应用程序包，也就是您经常可以更改的代码外部化｡
所以这大概有20千字节，非常非常小｡
然后你已经为你的重型图书馆创建了层｡
因此，您创建了第一个10 MB的层，
然后是第二个30
MB的有限层，这些层可以一起引用您的函数，很明显，
您的功能可以引用您的层，因此，我们可以更快地部署我们的函数，
我们不需要每次重新打包依赖项，因为我们的层是外部化的，另一个函数另一个应用程序包可以创建另一个函数可能是60千字节并引用这些相同层｡
这就是我们打包应用程序依赖项和层的全部目的，我们可以在Lynda功能中重用它们｡
现在，让我们通过实际操作来了解这是如何实现的｡
  - [ ] 322 Lambda Layers [03:14] Hands On
    * 
  - [ ] 323 [DVA-C02] Lambda File Systems Mounting [03:36]
    * 
讲师：现在我们来讨论文件系统装载｡
因此，如果Lambda函数在VPC中运行，
则可以访问EFS文件系统｡
为此，我们只需要配置Lambda，
在初始化期间将EFS文件系统挂载到本地目录｡
要实现这一点，
您必须利用EFS的EFS访问点功能｡
假设您有一个EFS文件系统，并且创建了一个EFS访问点｡
然后，如果您的Lambda函数部署在与您的VPC具有私有连接的私有子网中，
那么您就可以开始了｡
这样做的局限性是，对于每个将要出现的Lambda实例，
您将有一个以上的连接到EFS文件系统，因此您需要确保您没有达到EFS连接限制｡
同样，如果你有很多不同的Lambda函数，
一次出现，作为一个突发，那么你也可能达到连接突发限制｡
因此，我想花点时间比较一下Lambda的存储选项，
以便您根据具体情况了解哪种存储选项最好｡
因此，/tmp的临时存储的最大大小为10
GB，这是一个很大的值｡
持久性是短暂的，这意味着一旦Lambda函数实例被销毁，
您将失去存储空间｡
这就是为什么它被称为/tmp，表示临时｡
内容是动态的，您可以根据需要对其进行修改｡
它是一个文件系统，
支持任何文件系统操作｡
它包括为您的Lambda函数高达512兆字节，
然后你支付额外的，
如果你有超过512兆字节｡
而且，只有你的函数可以访问它，
因为它说存储基于你的Lambda函数｡
这是检索数据的最快级别，并且不会在所有Lambda函数调用之间共享｡
所以这应该说得通｡
现在，你的Lambda层｡
每个函数的最大大小为5层，
最多250 MB，不超过最大Lambda包大小｡
持久性是持久的，因为它是不可变的，你不能改变进入Lambda层的内容｡
所以它是归档类型，它是静态的，它包含在Lambda函数的定价中｡
而且，要访问层，您需要确保具有适当的IAM权限｡
它也是访问层上数据的最快速度，
因为它作为存储附加到Lambda函数，
并且它在所有Lambda调用之间共享，
所以它们都共享，请记住｡
不能修改Lambda层上的数据｡
如果你使用的是Amazon
S3，那么你可以想多大就多大，就尺寸而言，
它经久耐用，充满活力｡
存储类型是Object，因此需要使用S3API来访问AmazonS3对象｡
然后是原子操作，因此可以通过版本控制进行get､
put､ post等操作｡
对于你支付的定价，当然，对于亚马逊S3的定价，
所以存储加上请求，加上数据传输｡
要访问Amazon S3，
您需要确保您具有适当的IAM权限｡
这是基于网络的存储｡
所以我们有一个快速的访问，
因为我们有专用的AWS带宽，
但它不是最快的｡
当然，Amazon
S3在您所有的Lambda Invocations之间共享，
因为它是数据的外部存储｡
最后，对于Amazon EFS，我们有弹性｡
它经久耐用，充满活力｡
存储类型是文件系统，因此我们可以使用任何类型的文件系统操作来访问它｡
我们将支付存储､ 数据传输和吞吐量的费用｡
因为它是作为一个网络文件系统挂载在Lambda函数上的，
所以你可以非常快地访问你的数据｡
最后，因为它是一个网络文件系统，
所以它将在所有Lambda调用之间共享｡
希望这对Lambda的不同存储选项有意义｡
我希望你们喜欢，我们下节课再见｡
  - [ ] 324 Lambda Concurrency [06:01]
    * 
教师：现在，我们来讨论Lambda并发和限制｡
因此，
我们调用Lambda函数越多，Lambda函数的并发执行就越多｡
我们知道这一点是因为Lambda可以非常､ 非常容易和快速地扩展｡
这意味着如果我们在低规模下调用Lambda函数，我们可能会有两个Lambda函数的并发执行｡
但是如果我们有一个非常大规模的事件发生，我们可能有多达1000个Lambda函数同时工作来处理任何事情｡
所以我们可以做的是限制Lambda函数可以并发执行的次数，这是我们推荐的｡
因此，我们可以设置一个所谓的保留并发，
它是在函数级别设置的｡
这是一个限制，
我们说，“好的，这个Lambda函数最多只能有“50个并发执行｡
“因此，每次超过并发限制的调用都将触发所谓的节流｡
如果是同步调用，则会有不同的节流行为｡
所以我们直接调用Lambda函数，我们被节流了，它会返回一个节流错误，
429｡
如果是异步调用，
它将自动重试，然后转到DLQ｡
因此，
如果您需要一次超过1000个并发执行，您只需打开一个支持票证来请求更高的限制｡
现在我们知道了货币的概念，如果我们不仔细设置并发性，
就会发生一些事情｡
所以如果你不设置任何保留并发，
也就是对函数并发的任何限制，那么这种情况就可能发生｡
例如，我们将应用平衡器连接到Lambda函数｡
我们还有另一个应用程序，其中有几个用户连接到API网关，连接到另一个Lambda函数，
最后一个应用程序可能使用SDK和CLI调用Lambda函数｡
因此，
当一切都很低级时，比如调用吞吐量很低，一切都很好｡
但是，
假设我们正在进行一次大规模的促销活动，不知何故，
我们得到了很多很多用户对我们的应用程序负载平衡器的攻击，我们非常成功｡
因此，我们的负载平衡器将调用很多很多Lambda函数，Lambda函数可以自动扩展｡
因此，我们将获得多达1000个并发执行｡
这看起来不错吧？
Lambda已缩放｡
但问题就在这里｡
所有并发执行都转到第一个应用程序｡
因此，这意味着我们的API网关的应用程序用户将受到限制｡
这意味着CLI和SDK也将受到限制｡
从这张幻灯片中，您需要记住的是，
并发限制适用于您的帐户中的所有功能，
因此您必须小心，因为如果一个功能超过限制，则其他功能可能会受到限制｡
所以这非常非常重要｡
接下来，我们来讨论并发和异步调用｡
让我们以S3事件通知为例｡
因此，
我们将文件上传到S3存储桶中，这将创建一个新的文件事件，
该事件将调用Lambda函数，并表示我们正在同时放置很多很多文件｡
所以我们有很多很多不同的Lambda并发执行｡
如果函数没有足够的并发可用｡
因此，
如果因为达到了限制而无法扩展，则会限制额外的请求｡
但这是一个异步请求｡
因此，对于任何节流错误和系统错误（如429和500系列），
Lambda都会将事件返回到事件队列｡
因此，请记住，在异步模式下，
有一个内部事件队列，Lambda将尝试再次运行该函数，
最长可达六个小时｡
因此，
由于限制等原因，会发生很多次重试｡
然后，此重试间隔将以指数桶方式增加｡
从一秒到最多五分钟｡
因此，这允许您的Lambda函数不断重试，
希望有一天能找到正确运行的并发性和可用容量｡
好的，接下来我们来讨论一下冷启动和配置并发｡
如果你使用Lambda，你可能以前听过这个词｡
所以冷启动，
这意味着当你创建一个新的Lambda函数实例时，你的代码必须被加载，你的代码必须在处理程序之外运行｡
这对应于所有的初始化｡
所以在里面｡
如果您的初始化工作量很大，
因为您有很多代码和依赖项，您要连接到很多数据库并创建很多SDK，此过程可能会花费很多时间｡
因此，这意味着新实例处理的第一个请求的延迟比其他请求高，
这可能会影响您的用户｡
因此，如果您的用户可能要等待三秒钟才能得到请求响应，
这对他们来说可能非常非常慢，他们可能会遇到冷启动，并可能对您的产品不满意｡
那你能做什么呢？
您可以使用一种称为预配并发的方法｡
这意味着您甚至在调用函数之前就分配了并发｡
所以你要提前分配这种并发性｡
这样，
冷启动就不会发生，所有调用的延迟都将更低｡
要管理这种并发性，您可以...
在此配置并发后，您可以使用应用程序自动缩放｡
例如，对于计划或目标位置，要确保您有足够的保留Lambda函数以备使用，
并最大限度地减少此冷启动问题｡
所以请注意，
每当你以前用来启动一个Lambda函数在一个VPC，用来花永远｡
所以现在有一个博客在2019年10月和11月已经发布了AWS｡
这里是链接｡
这篇博客展示了他们所做的改进，以大幅减少您的VPC中的冷启动｡
因此，
好消息是，如果您在冷启动前使用Lambda，对VPC的影响非常小｡
好的，最后，
有两个图表，
您可以在自己的时间内查看，了解保留并发和配置并发的概念｡
这些图表，我很喜欢｡
这是幻灯片中的链接｡
看看他们｡
他们向你解释他们是如何工作的｡
我认为用幻灯片来描述它们是相当复杂的｡
但在你们自己的时间里看看它们，希望它们能帮助你们更好地理解这个概念，如果我现在不帮你们的话｡
好了，
现在让我们来进行实际操作，看看并发是如何工作的｡
  - [ ] 325 Lambda Concurrency [02:39] Hands On
    * 
  - [ ] 326 Lambda External Dependencies [01:12]
    * 
教师：到目前为止，我们在这门课上已经做了一些非常简单的Lambda函数｡
只是一些代码，没有外部依赖项｡
在真实的世界中，您肯定需要添加更多的包依赖项等等｡
因此，如果您的Lambda函数依赖于额外的库，
例如，X-Ray SDK､ 数据库客户端等｡
然后，
您需要将这些包与代码一起安装，并将其压缩在一起｡
因此，如果您了解JS，
则可以使用NPM和node_modules目录｡
对于Python，您可以使用PIP管理作为目标选项｡
对于Java，您可以包括它们的相关｡
jar文件｡
因此，每种语言都有自己的封装依赖项的方式｡
但你需要记住的是，你把所有的东西都拉在一起｡
因此，代码和依赖项一起压缩在一起，如果小于50
MB，
则直接将压缩文件上传到Lambda，否则先上传到Amazon S3，然后从Lambda引用｡
原生库呢？
好吧，
它们首先需要在Amazon Linux上编译，然后才能工作｡
那么AWS SDK呢？
默认情况下，SDK附带了每个Lambda函数｡
因此，
如果您只是使用AWS SDK，则不需要将SGK与代码打包在一起｡
好的，让我们来动手看看它是如何工作的｡
  - [ ] 327 Lambda External Dependencies [08:44] Hands On
    * 
  - [ ] 328 Lambda and CloudFormation [02:56]
    * 
所以我们可以使用CloudFormation来上传Lambda函数｡
所以我们有两种方法｡
一号是内联的｡
因此我们将在CloudFormation模板中定义Lambda代码｡
我们可以在这个截图中看到Lambda函数的代码｡
所以这是可能的｡
这适用于非常简单的函数｡
我们使用准则｡
ZipFile属性，但是对于这个内联函数，
我们不能包含函数依赖项｡
因此，这只是非常简单的用例，
您希望Lambda函数代码（无依赖关系）位于CloudFormation模板中｡
另一种方法是使用zip文件并通过S3执行此操作｡
这就是CloudFormation模板的样子｡
我们现在就来亲身体验一下｡
因此，
我们必须在Amazon S3中存储Lambda函数的zip，您必须在CloudFormation代码中引用S3的zip位置｡
它可以是S3
bucket属性S3 key，它表示您在S3中的zip的完整路径｡
S3对象版本（如果您有版本化存储桶），并且在覆盖文件时建议使用此版本｡
因此，如果你以某种方式更新了S3中的代码，但你没有更新CloudFormation模板中的S3桶､
S3键或S3对象版本，那么CloudFormation将不会更新你的函数｡
这就是为什么建议使用版本控制，因为如果启用了版本控制，覆盖了文件，并指定了新的S3对象版本，
CloudFormation将获得更改并更新Lambda函数｡
最后，
如果你想通过CloudFormation在多个账户中部署Lambda函数，假设你有一个账户，其中包含一个带有Lambda代码的S3桶｡
现在，您希望将此Lambda代码部署到帐户2和帐户3中｡
那我们该怎么做呢？
首先，我们需要在客户2中启动CloudFormation｡
S3存储桶将引用帐户1中的S3存储桶｡
现在，您需要问自己，
我们如何确保帐户2能够访问帐户1中的Lambda代码？
我们可以使用一个桶策略，在Account
1中的S3桶上使用一个桶策略应该允许CloudFormation访问代码｡
但我们也可以在CloudFormation服务上为模板本身定义一个执行角色，它将允许获取并列出Account
1中的S3桶｡
这两件事结合起来，就可以让CloudFormation从S3桶中检索代码，
从而创建Lambda函数｡
类似地，如果您有一个帐户3，
帐户1上有一个存储桶策略，帐户3中有一个执行角色，我们可以从该存储桶的Lambda中读取代码，访问代码并将其部署到帐户3中的函数上｡
所以你需要知道它周围的一些安全措施，但这一切都应该是有意义的｡
这只是把东西放在一起的问题｡
这节课就讲到这里｡
希望你喜欢｡
下次课我们会亲自动手｡ 
  - [ ] 329 Lambda and CloudFormation [06:05] Hands On
    * 
  - [ ] 330 [DVA-C02] Lambda Container Images [04:40]
    * 
教师：我告诉过你Lambda支持容器图像，
这是一个新特性｡
这允许将Lambda函数部署为ECR中最大10
GB映像的容器，从而允许您将复杂依赖项和大型依赖项打包到一个容器中｡
Docker非常有名，它允许您帮助将应用程序代码､
依赖项和所需的数据集放在基础映像之上｡
并且该基础映像必须实现Lambda运行时API｡
因此，我们的想法是，为了使它看起来简单，
Lambda运行一个虚拟机，容器｡
因此，您使用该容器的基础映像，
添加应用程序代码和依赖项，并将其打包为Lambda可以运行的映像，因为此基础映像实现了Lambda
Runtime API｡
这允许你在Lambda上运行你的容器，但它不是任何Docker容器｡
基础映像必须实现Lambda运行时API｡
所以这些基本图像存在于多种语言中｡
例如，Python､ 节点｡ js､ Java､ . NET､ Go语言和Ruby语言｡
但是，只要实现Lambda运行时API，
您就可以创建自己的Lambda基础映像｡
关于它的规范，你可以在文档中找到｡
这很复杂｡
然后，这还允许您使用Lambda运行时接口模拟器在本地测试容器｡
如果您将Lambda函数作为容器，这将允许您获得发布应用的统一工作流｡
这意味着，无论是ECS的容器还是Lambda的容器，
您都可以以相同的方式构建和发布容器，并将其发送到Amazon
ECR，然后从Amazon ECR将容器部署到Lambda上｡
那么Lambda容器图像是什么样子的呢？
这里有一个例子，我们可以从AWS提供的基础映像构建｡
第一，我们选择一个实现Lambda Runtime
API的映像，它来自amazon/aws-lambda-nodejs
version 12｡
然后复制应用程序代码和文件｡
所以我们复制了这个程序｡ js包｡ json文件和所有的数据到我们的容器｡
然后在容器中安装所需的依赖项｡
所以我们运行npm install｡
最后，我们说明调用Lambda函数时要运行哪个函数｡
所以我们称之为命令应用｡ lambda处理程序｡
这就是你要做的｡
此Docker图像，因为它是从节点的Lambda的基础图像生成的｡
js
12将能够在Lambda函数上运行｡
这是非常神奇的，但这是令人惊讶的，
因为你不需要担心太多的依赖关系，
正确地编译它等等｡
只要Docker容器是从正确的基础映像中正确创建的，
它就能够在Lambda上运行，这是一个很好的替代方案，
例如，如果需要，可以编译自己的Lambda层｡
因此，让我们看看使用Lambda容器映像时的最佳实践｡
首先，您可以优化容器图像｡
要做的第一件事是使用AWS提供的基础映像，
它构建在AmazonLinux2上｡
我们使用它的原因是这些基本图像已经被Lamba服务缓存了，
所以如果你使用它们，那么Lambda服务从你的容器中提取的信息就更少了｡
此外，您应该使用多阶段构建｡
这个想法是，你可以做任何最复杂的事情来构建你的代码在初始的大映像中，
然后你的构建的输出是，你只复制你需要的工件，你创建一个新的最终容器映像，你放弃了所有的初始步骤｡
因此，最终的图像会小得多，
也简单得多｡
你也可以在不同的图层中构建你的图像，
图层从稳定到频繁变化｡
其理念是，更改最多的事情应该在构建阶段结束时进行，
而更改较少的事情，例如在映像上安装基本包，应该尽早进行｡
最后，您应该使用单个存储库来存储具有大型层的函数｡
这个想法是，如果你有很大的层，
他们都在同一个存储库，
那么ECR将有更多的设施来比较这些层在一起，这将避免你上传和存储这些层的副本｡
最后，Lambda容器映像的最佳用例之一是如果您想要上传一个高达10
GB的非常大的Lambda函数｡
然后，您可以创建一个非常大的容器映像，并将其用作Lambda函数的基础，
而不是将一些代码按原样推送到Lambda｡
好了，这堂课就到这里｡
我希望你们喜欢，我们下节课再见｡ 
  - [ ] 331 Lambda Versions and Aliases [03:04]
    * 
让我们讨论一下Lambda版本和别名的概念｡
到目前为止，当我们在函数末尾工作时，我们使用了这个美元符号的最新版本｡
所以这个版本是不可变的，因为我们可以编辑代码等等｡
但是有一件事我们还没有做，那就是当我们对代码状态满意时，我们可以发布lambda函数并创建一个新版本｡
所以一旦我们点击发布，它就会变成v1，v1是不可变的｡
不变是什么意思？
这意味着以后您不能更改代码或环境变量或任何其他内容｡
因此，将其固定为版本｡
所以随着你不断地发布，版本号会不断增加｡
从V1到V2，等等｡ 等等｡ 每个版本都是独立的，并将获得自己的R等Amazon资源名称.
因此，如果我们现在知道版本是什么，那就是你的代码和配置｡
什么都改变不了｡
它是不可改变的｡
因此，每个lambda函数版本都可以访问，最新版本也一样｡
因此，这是伟大的迭代和标记您的进展到您的发布您的lambda函数｡
但如果我们想为您的最终用户提供稳定的端点，该怎么办？
为此，我们可以使用Lambda别名｡
别名是指向你的lambda函数版本的指针，我们可以定义一个dev
test和prod别名，让它们指向不同的版本｡
这次别名是可变的，这就是为什么我们要使用它们｡
所以我们有了最新的，一个版本，一个别名｡
这样就行了｡
然后呢？
V一和v二｡
所以我们要创建一个dev别名，它是可变的，指向lambda函数的最新版本｡
通过这种方式，我们可以编辑代码，并快速查看它是如何进行的，我们的用户将与dev别名交互，
这将反过来调用我们函数的最新版本｡
但是我们可以创建一个测试别名来测试我们函数的v 2版本｡
同样，它是可变的，我们可以创建一个prod别名来测试或不测试｡
实际上to指向了v1函数，我们知道它是稳定的，并且在工作｡
那你会怎么做？
我们用化名｡
它们支持canary部署，因为我们可以为指向的贷方函数版本分配权重｡
例如，对于Prada，我们想从V1功能一直切换到V2功能｡
不需要切换指针，我们可以说95%的流量会流向v1而只有5%的流量会流向v2｡
这样做的目的是，现在我们在prod中测试V2，确保它工作正常，然后才能将全部功率切换到V2，
并确保那里的流量为100%｡
因此别名可以为触发器或用户目的地提供稳定的配置｡
它们可以被稳定地调用，但是它们可以在后端指向我们想要的任何lambda版本｡
所以这些化名会得到他们自己的答案｡
值得注意的是｡
别名不能引用不能引用其他别名｡
在这种情况下，他们只能引用版本，这是考试可能试图欺骗您的地方｡
好的，现在我们来看看它们是如何工作的｡
  - [ ] 332 Lambda Versions and Aliases [05:47] Hands On
    * 
  - [ ] 333 [DVA-C02] Lambda and CodeDeploy [02:51]
    * 
Stephane：与CodeDeploy集成｡
CodeDeploy可以帮助您自动化Lambda别名的流量转移｡
所以它建立在版本和别名之上｡
现在，我们不会在本课程的实践中进行，
但CodeDeploy功能集成在SAM框架中｡
当我们看到无服务器应用程序模型框架或SAM时，
我们将为您的Lambda函数练习CodeDeploy部署｡
但我现在还是会给你这个想法｡
我们有一个PROD别名，我们想把它从Lambda函数版本1升级到lambda函数版本2｡
因此，我们希望将流量从V1的100%转移到V2｡
在本例中，CodeDeploy将使X随时间变化，
直到X等于100｡
这意味着X首先等于10%｡
所以V1上有90%，V2上有10%｡
那可能是50%｡
所以V1和V2各占50%｡
最后，V2上达到100%，V1上为0%｡
那么CodeDeploy有哪些策略呢？
嗯，有线性，
增长流量每N分钟，直到100%｡
所以我们有一个策略叫做每3分钟线性10%｡
Linear10PercentEvery10Minutes，这是非常明确的｡
还有金丝雀，我们尝试X%，然后切换到100%｡
所以我们有金丝雀10% 5分钟｡
五分钟后，V2上会有10%的流量｡
紧接着，你将切换到V2上的100%流量｡
或者我们可以有金丝雀10%每30分钟｡
最后，我们有AllAtOnce用于V1和V2之间的即时流量切换｡
这是最快也是最危险的，因为如果我们没有测试V2功能，
那么事情可能会失败｡
那么回滚怎么样？
我们可以建立前后交通钩来检查我们土地功能的健康状况｡
这个想法是，如果出现任何问题，那么流量挂钩可能会失败，
或者CloudWatch警报可能会失败，
您的CodeDeploy可以知道出了问题｡
因此，它将执行回滚，
将流量全部放回V1｡
如果您使用的是AppSpec｡ yml来使用CodeDeploy部署Lambda，
您需要了解一些重要的参数｡
还有Name，
它是要部署的函数的名称｡
别名，这是必需的，
它是Lambda函数的别名｡
我们有CurrentVersion，
它是流量当前指向的Lambda函数的版本｡
还有TargetVersion，
这是Lambda函数的版本，
流量将被转移到这个版本｡
然后，CodeDeploy将随着时间的推移将别名从版本1更新为版本2，
从CurrentVersion更新为TargetVersion｡
这就是Lambda和CodeDeploy之间的整个集成｡
这节课我们就不练习了｡
但是，当我们进入SAM框架部分时，我们将了解｡
好吧，就这样｡
我们下节课再见｡ 
  - [ ] 334 [DVA-C02] Lambda Function URL [03:55]
    * 
教师：现在我们来讨论Lambda函数URL｡
如果您只想将Lambda函数公开为HTTP端点，
而不必经历使用API Gateway或应用程序平衡器的麻烦，
该怎么办？
你可以使用函数URL，
这给了你一个唯一的URL端点，它永远不会改变你的Lambda函数，
看起来像这样｡
支持IPv4和IPv6协议｡
所以你的Lambda函数，
一旦你把它发布为一个函数URL，
你就可以访问它，并通过网络浏览器，命令行，
邮差或任何HTTP客户端来执行HTTPS请求｡
现在，这个功能的网址只能通过公共互联网访问｡
如果你想私下访问它，想要一个私人的URL，
这是行不通的｡
现在，如果您从不同的域访问此函数URL，
则可以使用CORS配置，
如我们所见｡
出于安全考虑，
我们使用基于资源的策略来管理对Lambda函数URL的访问｡
这可以应用于任何函数别名或最新版本的函数，
但不能应用于特定的函数版本｡
您可以使用控制台或API创建和配置它｡
如果您希望Lambda函数只运行特定的数量，
因此需要进行节流，则可以使用Lambda的保留并发特性来控制Lambda函数可以运行的数量｡
现在，对于URL安全性，它是如何工作的？
我们有基于资源的策略，它会附加到您的Lambda函数，
并且能够指出CIDR或IAM主体的哪些其他帐户或特定IP范围可以访问我们的Lambda函数URL｡
对于CORS，
这类似于我们在Amazon S3中看到的情况｡
因此，如果您从不同的域调用Lambda函数URL，
则必须具备CORS安全性｡
因此，在本例中，我们的S3存储桶由CloudFront处理，例如，我们有一个自定义URL｡
com公司｡
但是API是作为Lambda函数URL托管的，这就是API｡
例子｡ com公司｡
由于域不同，您需要在Lambda函数URL上设置CORS设置才能正常工作｡
现在，为了安全起见｡
因此，如果您将AuthType设置为NONE，那么这将允许对您的Lambda函数进行公共和未经身份验证的访问，
这很酷｡
然后，基于资源的策略将确定您的函数不允许任何请求｡
因此，您必须授予公共访问权限作为资源策略｡
所以这里我有一个允许调用函数URL的主星，
然后这允许人们通过互联网访问我们的Lambda函数作为Lambda函数URL｡
如果您将AuthType设置为AWS_IAM，
那么IAM将用于对Lambda函数的请求进行身份验证和授权｡
因此，基于身份的主要策略和基于资源的策略都将被评估｡
因此，您需要确保在这两项之间，
存在lambda：InvokeFunctionUrl权限｡
现在，如果我们在同一个帐户中，
那么如果基于身份的策略或基于资源的策略允许此API调用，
您就可以开始了｡
这与S3存储桶非常相似｡
但是如果您要进行跨帐户操作，
则需要同时使用身份策略和基于资源的策略｡
在此示例中，我在帐户A上附加了一个基于资源的策略，
如果您查看其主要部分，您会发现这实际上授权帐户B中的角色访问我的Lambda函数，
但这还不够，因为我们处于跨帐户设置中｡
帐户B的IAM角色还必须具有基于身份的策略，
该策略允许调用其他帐户的Lambda函数URL｡
当这两个条件都具备时，安全性就起作用了，IAM角色可以使用帐户A的Lambda函数URL｡
好了，这堂课就到这里｡
我希望你们喜欢，我们下节课再见｡
  - [ ] 335 [DVA-C02] Lambda Function URL [02:49] Hands On
    * 
  - [ ] 336 [DVA-C02] Lambda - CodeGuru Integration [00:57]
    * 
教师：现在我们来讨论一下Lambda和CodeGuru如何协同工作｡
因此，通过使用CodeGuru Profiler，
您将深入了解Lambda函数的运行时性能｡
为此，当你让它工作时，CodeGuru会为你的Lambda函数获得一个分析器组，
Java和Python运行时都支持这个组｡
要激活CodeGuru集成，
您只需从Lambda控制台激活它｡
因此，我们将了解Lambda函数的运行时性能｡
当你激活这个集成时，这个分析，
CodeGuru Profiler层将作为Lambda层添加到你的函数中｡
与CodeGuru相关的环境变量将添加到您的函数中｡
最后，当然，要使其完全工作，您需要具有IAM权限｡
因此，这个AmazonCodeGuruProfilerAgentAccess策略将被添加到功能IAM角色中｡
希望这是有道理的｡
我希望你们喜欢，我们下节课再见｡ 
  - [ ] 337 Lambda Limits [01:44]
    * 
教师：所以在参加考试之前，你需要知道一些Lambda限值，
因为考试喜欢看你是否知道这些限值，这些限值是每个区域的｡
因此，我们有一些执行限制，
然后我们将有一些部署限制｡
因此，执行是内存分配在128兆字节到10千兆字节之间｡
这是以64兆字节为增量的｡
当我们增加内存时，就会有更多的vCPU，
您现在已经了解这一点｡
最长执行时间为900秒，即15分钟｡
因此，以上任何内容都不是Lambda的好用例｡
环境变量，我们最多只能有四千字节的环境变量，
这么一点点的空间量｡
但是，如果您想在创建另一个函数时拉入一些大文件，
则可以使用临时空间｡
这是/tmp文件夹中的容量，
最多可达10 GB｡
我们可以在Lambda函数上执行多达1000个并发操作｡
如果我们提出请求，也可以增加此值｡
但是，最好尽早使用保留并发｡
最后，对于部署，
压缩zip文件的最大大小为50 MB，
未压缩的最大大小为250 MB｡
因此，任何高于此的内容，例如大文件，
都应该使用/tmp空格｡
所以就像我说的，
万一你需要一个大文件（mumbles），
请使用那个目录｡
最后，
环境变量也是4 KB｡
因此，一旦您了解了所有这些限制，
当考试会问您一些问题时，例如我们需要30
GB的RAM，或者我们需要30分钟的执行时间，或者我们需要一个3
GB的大文件，那么您就会知道Lambda不是运行此工作负载的正确方法｡
我希望这对你们有帮助，
下节课再见｡
  - [ ] 338 Lambda Best Practices [01:12]
    * 
教师：我们在这一节学到了很多关于Lambda的知识，这对考试是必要的｡
所以在我们离开之前，我想给你们最后一点忠告｡
最佳实践｡
您需要在函数处理程序之外执行繁重的工作，以最大限度地缩短处理程序的运行时间｡
因此，这意味着您需要在函数处理程序之外连接数据库，
再次在处理程序之外初始化AWS
SDK，并再次在函数处理程序之外构建任何依赖项或数据集｡
您应该将环境变量用于任何会随时间变化的内容｡
数据库连接字符串､ S3存储桶名称等等｡
不要将这些值放入代码中｡
对于密码和敏感值，您可以使用KMS加密这些环境变量｡
接下来，您应该将部署包的大小最小化到其运行时所需的大小｡
所以这意味着如果你的函数太大，请把它分解｡
此外，请记住您的封装大小的Lamda限制等｡
如果您需要重用某些库，可以考虑利用Lambda层｡
最后，避免递归代码｡
好吧，永远不要让Lambda函数调用它自己｡
这将是一场灾难，对你来说将是非常昂贵的｡
好了，这节课就讲到这里.
我希望你们喜欢它，我们下节课再见｡
  - [ ]  Lambda [26 问题] Quiz
    * 
 ## Section 23 - AWS Serverless: DynamoDB [25 个讲座 • 1 小时 47 分钟]
  - [ ] 339 DynamoDB - Section Introduction [00:43]
    * 
因此，我们知道如何使用AWS Lambda进行分布式计算和可扩展｡
但是我们在哪里存储我们的信息在哪里存储我们的数据呢？
如果我们有一个无服务器的数据库就好了｡
不用再看了，数据库将是DynamoDB｡ DynamoDB太棒了｡
这是一个由AWS管理的数据库，它将为您进行扩展｡
它与AWS Lambda和其他AWS服务集成得非常好｡
在本节中，我们将花费大量时间来学习如何正确设计DynamoDB表，
如何启用流并确保DynamoDB表完全安全｡
我希望你很兴奋｡
我们开始吧
  - [ ] 340 DynamoDB Overview [07:47]
    * 
教师：现在，
我们来看看DynamoDB，它是一个NoSQL无服务器数据库｡
如果您考虑一下我们在本课程中看到的传统体系结构，
我们有客户端，它们连接到一个应用层，该应用层可以由一个弹性负载平衡器和EC2实例组成，
这些实例被分组，并通过一个自动扩展组进行扩展｡
然后，数据必须从某个地方获得，
所以我们有一个数据库层，
它可以使用Amazon RDS，它由MySQL或PostgreSQL或这类技术支持｡
现在，这些传统的应用程序将利用RDBMS数据库，
而我们这样做是因为我们有这种SQL查询语言｡
真的很好吃
然后，我们可以定义关于数据应该如何建模的强要求，因为我们有表､
有模式等等｡
我们可以做关节，聚合，复杂的计算，
这一切都很好，工作｡
我们从中得到的是，在扩展的情况下，大多数是垂直扩展｡
如果您需要一个更好的数据库，我现在讨论的只是数据库层｡
如果你想垂直扩展它，你需要更换数据库，
并获得一个更强大的CPU，更大的Ram，或更好的磁盘与IO｡
您可以进行某种水平扩展，但这只是通过提高读取能力来实现的｡
因此，可以通过在应用层添加EC2实例，
也可以通过在数据库层添加RDS读取副本｡
但是，如果您添加读取副本，您将受到可以拥有的副本数量的限制，
因此只能进行横向读取扩展，
而不能进行横向向右扩展，因为RDS不具备这一功能｡
因此，
向您介绍NoSQL数据库，这不仅意味着SQL或非SQL数据库，具体取决于定义｡
因此，我们的想法是，存在非关系数据库，
它们将是分布式的，这给了我们一些水平可伸缩性｡
一些非常著名的技术拥有NoSQL数据库，如MongoDB，当然还有DynamoDB｡
现在这些数据库不支持查询关节或支持非常有限｡
因此，为了简单起见，假设它们没有查询连接｡
因此，现在所有需要的数据都必须出现在数据库的一行中｡
同样，
为了简化起见，我知道它们在不断发展，但让我们假设NoSQL数据库也不执行聚合计算，如SUM或AVG等｡
但它的好处是，由于设计，
NoSQL数据库将横向扩展｡
这意味着，
如果您需要更多的权限或读取容量，您可以在后台拥有更多的实例，并且它将非常好地扩展｡
因此，NoSQL与SQL之间没有对错之分，
它只取决于您如何看待数据建模､ 应用程序､ 用户查询以及扩展需求｡
现在我们来谈谈DynamoDB｡
DynamoDB是一个完全托管的NoSQL数据库，
它具有高可用性，并且可以跨多个AZ进行复制｡
这是一个NoSQL数据库｡
它不是关系数据库｡
所以它不同于RDS｡
它可以扩展到大规模工作负载，并且是完全分布式的｡
这意味着，
无论您的工作负载如何，您都可以扩展到每秒数百万个请求､ 数万亿行和数百TB的存储｡
如此快速而稳定的性能｡
这意味着检索延迟非常低｡
它是一项服务，因此将与IAM完全集成，以实现安全性､
授权和管理｡
您可以使用DynamoDB
Streams来启用事件驱动编程，我们将在本节中看到｡
它的成本低，并具有自动缩放能力｡
您还可以为不同的存储层提供标准和非频繁访问IA表类｡
因此，让我们了解一下DynamoDB的基础知识｡
因此DynamoDB是由表组成的，每个表都有一个主键｡
我们将在接下来的幻灯片中看到主键可以是什么｡
在创建表之前，必须确定主键｡
现在，每个表可以有无限多个行，也称为项｡
因此，
在本课程中，我将交替使用行和项这两个术语，每个项都有属性｡
现在这些属性可能类似于表中的列，好吗？
但这些属性也可以嵌套｡
所以它比列功能更强大一些，它们可以随着时间的推移而添加，您不需要在创建表时定义所有列，
并且其中一些列可以为空｡
因此在某些数据中缺少某个属性完全没有问题｡
现在，和每个项目，或每行将有多达400 KB的数据，
所以这是一个限制｡
支持的数据类型将是标量类型，或字符串､
数字､ 二进制､ 布尔和空｡
将会有列表和地图之类的文档类型，所以它提供了某种嵌套功能｡
和集合类型，
如字符串集､ 数字集和二进制集｡
现在，需要了解的一个非常重要的问题是如何为DynamoDB选择主键｡
而考试肯定会考验你对这方面的知识｡
因此，您有两个主键选项｡
第一种称为分区密钥，也称为散列策略｡
因此，
在这种情况下，分区键对于每个项必须是唯一的，这与普通数据库非常相似｡
因此，分区必须足够多样化，
以便您的数据能够被分布｡
例如，如果考虑user的表为user_ID，
则可以将分区键设置为User_ID｡
属性为“名字”､ “姓氏”和“年龄”｡
然后，您就有了第一个User-ID，
其中填充了一些属性｡
您可以看到，您的第二个User_ID没有姓氏，
但这在DynamoDB中是可以的｡
而第三个分区键，仍然有三个属性附加到它｡
这就是DynamoDB的样子｡
现在看起来像个数据库｡
这很简单
但是，您可以有第二个选项，即分区键和排序键，
也称为散列加范围｡
而现在这两个项目的组合对于每一个项目都必须是唯一的｡
因此，数据将按分区键分组｡
这就是为什么选择一个好的分区密钥是非常重要的｡
因此，
如果您考虑一个users-game表，那么User_ID作为分区键，Game_ID作为排序键｡
让我们看看这意味着什么｡
这意味着用户可以参加多个游戏｡
我们有这四个列属性，但第一个是分区键｡
我们希望数据按User_ID分组，第二个将是排序键｡
这将给予出分区键和排序键组合的唯一性｡
所以这两个都是主键，其余的都是属性.
如果你考虑一个User_ID，那么它有一个在Game_ID上的排序键，然后我们把分数赋予92，
结果获胜｡
同样，
另一个不同的User_ID和另一个不同的Game_ID，所以这也可以工作｡
你输了一局，得分14分｡
更有趣的是，在第三行中，
我们有相同的分区键｡
因此，第二行和第三行具有相同的和分区关键字，但排序关键字不同｡
当然，一个用户参加多个游戏是可以的｡
因此，
你当然希望User_ID和Game_ID的组合是唯一的，但是在不同的排序键中也可以有相同的分区键｡
这就是为什么选择一个非常好的分区键非常重要，这样数据才能得到充分的分布｡
这里有一个练习，这也是考试对你的考验｡
因此，您正在构建一个电影数据库，并且希望选择最佳分区键，
以最大限度地提高数据分布｡
是否为movie_id？
是否为producer_name？
它是领导者_演员_名字还是电影_语言？
好吧，想一想，
如果你选择第一个，你选择第二个，等等？
现在，
答案是选择movie_id，因为movie_id对于每一行都是唯一的｡
因此它是一个很好的划分表的方法｡
如果你有一个电影语言，不好意思，
一个分区键，那么你就不会有你想要的那么多的值，也许你的大多数电影都会倾向于英语｡
所以这不是一个好的选择，
因为没有足够的多样性，而且数据偏向于一个特定的值｡
因此，考试将要求您根据分区键的含义为某些表选择最佳分区键｡
因此，请始终选择基数最大且可以接受最多值的函数｡
以上就是DynamoDB的简要概述｡
我们有一个很长的部分来讨论它，但是让我们回顾一下实际操作，
练习一下使用DynamoDB｡
  - [ ] 341 DynamoDB Basics [08:42] Hands On
    * 
  - [ ] 342 DynamoDB WCU & RCU - Throughput [11:05]
    * 
教师：好的，现在我们来讨论DynamoDB的读写容量模式｡
这就是控制表容量的方法｡
因此必须事先指定读写吞吐量｡
所以实际上有两种模式｡
第一种称为“资源调配模式”，这是默认模式，
在此模式下，我们指定每秒的读取和写入次数，
因此也称为“读取容量单位”和“写入容量单位”｡
您需要事先规划容量｡
你要为将要供应的任何东西付费｡
因此，如果您说我需要10个读取容量单位和5个写入容量单位，
您将按每小时支付相应的费用｡
您可以选择自动缩放，我们很快就会看到｡
第二种模式称为按需模式｡
而且，这一解决方案将根据您的工作负载自动增加和减少读取和写入，
而且不需要进行容量规划｡
因此，您不需要调配容量单元｡
它就在那里｡
您将完全按使用量付费，但它将比调配模式贵得多｡
我们的想法是，
你有不同的使用案例，我们将在这堂课中详细了解它们｡
因此，
您可以每24小时在两种模式之间切换一次，即“资源调配”和“按需”模式｡
我们将深入了解这两个方面，
所以现在不要担心，这只是一个介绍｡
但是，现在让我们深入了解一下资源调配读取容量模式｡
因此，您必须调配读取和写入容量单位（也称为RCU，
即读取吞吐量）和WCU（即写入吞吐量）｡
现在，您可以选择设置吞吐量的自动扩展以满足需求｡
所以你不要想太多关于你的RCU和你的WCU价值｡
您只需说出您的目标容量使用情况，DynamoDB将为您进行扩展｡
现在，
如果您因为消耗或写入的数据量超过了调配的数据量而需要重新配置RCU和WCU，这完全没有问题，因为您可以临时利用所谓的突发容量｡
但是，
如果由于突发容量已被完全使用而耗尽突发容量，则会出现一个名为ProvisionedThroughputExceededException的异常，这一点非常明显｡
如果你得到了这些信息，你显然需要重试，
而重试写或读的策略被称为指数回退重试策略｡
现在，让我们详细了解一下WCU｡
考试会要求你进行一些计算，所以你需要理解计算WCU和RCU的公式｡
因此，一个写入容量单位WCU将表示每秒对大小最大为1千字节的项目进行一次写入｡
如果您的项目明显大于1 KB，
则您将消耗更多的WCU｡
让我们通过例子来理解计算｡
如果你想自己计算的话，你可以暂停这个视频｡
因此，
如果我们每秒写入10个项目，并且项目大小平均为2 KB，那么我们需要多少个WCU？
计算时，我们需要每秒10个项目，即10次，项目大小为2
KB，除以1 KB，
即1
KB的WC单位数，结果为20个WCU｡
这是一个非常简单的例子｡
现在，在示例2中，我们每秒写入6个项目，
而这次项目大小为4｡ 5千字节｡
这个有点棘手｡
所以我们需要6乘以5除以1就是30 RCU，
为什么？
嗯，因为4.
DynamoDB总是将5千字节舍入到上千字节，以了解您使用了多少WCU｡
因此，
请记住，您需要舍入到WCU的上限KB｡
现在，如果你每分钟写120个项目，
项目大小是2
KB，这里的诀窍是我们每分钟有项目｡
我们需要做一个小的计算，即120除以60，得到每秒的项目数，
这样我们就得到了四个WCU｡
写容量单位是非常基本的，而且很容易理解｡
更复杂的应该是在读周围｡
因此，首先，我们需要为DynamoDB定义两种读取模式，
即强一致性读取和最终一致性读取｡
因此，如果您考虑DynamoDB，它当然是一个无服务器的数据库，
但在后台，有服务器｡
您只是看不到它们或无法管理它们｡
我们有服务器，现在我们只考虑三台服务器，这样做非常简单，
但显然要多得多，而且您的数据将在所有服务器上分发和复制｡
现在，
如果您考虑您的应用程序，您的应用程序将向其中一个服务器执行写入操作，DynamoDB将在内部跨不同的服务器（如服务器2和服务器3）复制这些写入操作｡
现在，当您的应用程序从DynamoDB读取数据时，您有可能不是从服务器1读取数据，
而是从服务器2读取数据｡
现在，两件事会发生，对吧？
如果我们处于“最终一致性读取”（默认模式），
那么如果我们在写入后立即执行读取，则可能会得到陈旧数据，
因为如果我们非常快，复制还没有发生｡
但在100毫秒之后，你显然可以开始了｡
但是，如果您执行“强一致性读取“，您会说：“嘿，
我想在写入后立即读取数据”，这样您就可以确保获得刚刚写入的正确数据｡
为此，我们需要在API中将一个名为ConsistentRead的参数设置为True，并且它可以应用于GetItem､
BatchGetItem､ Query和Scan｡
为什么我们要一直这样做呢？
为什么我们不想一直保持强一致性读取？
它将占用两倍的RCU，因此查询开销会更大，
延迟也会稍高｡
因此，您需要问自己：“我需要最终一致性读取，
还是需要强一致性读取？
“现在，让我们来谈谈RCU关于这两件事｡
一个读取容量单位（RCU）表示每秒一次强一致性读取，
或每秒两次最终一致性读取，对于大小最大为4
KB的项目而言，这会使计算变得有点复杂｡
如果你的项目大于4
KB，就会消耗更多的RCU，同样，
它会被四舍五入到最接近的4 KB｡
让我们再看一遍例子，暂停视频｡
因此，如果每秒有10次强一致性读取，
并且项目大小为4 KB，那么我们需要多少个RCU？
我们需要10乘以4千字节除以4等于10个RCU，好吗？
现在，
如果每秒有16个最终一致性读取，并且项目大小为12
KB，那么这会稍微复杂一点，我们将得到16除以2乘以12除以4，即24个RCU｡
因此，在本例中，显然我们需要将16除以2，
因为我们不需要，因为我们在一个RCU中每秒有两个最终一致性读取，然后将12除以4，
得到24个RCU｡
最后一个例子，每秒10次强一致性读取，项目大小为6 KB，
好吗？
所以这一个有点棘手｡ 那到底是什么呢？
是10乘以8除以4｡ 为什么是八个？
我们把六千字节四舍五入到四千字节，所以是八千字节，你必须一直往上，
好吗？
在这种情况下，我们得到10乘以8除以4，即2，
所以20个RCU｡
现在我们已经了解了WCU和RCU，下面我们来讨论DynamoDB如何在后端使用分区工作｡
DynamoDB由表组成，每个表都有分区，而分区只是特定服务器上数据的副本｡
现在，当您的应用程序写入DynamoDB时，您的应用程序将发送一个分区键，
可能是一个排序键，以及一些属性｡
所有这些数据都要经过哈希算法｡
因此，实际上只有分区键要通过哈希算法来了解要转到哪个分区｡
因此，如果我们取ID_13的分区键，它将通过DynamoDB的内部哈希函数，
它将说，
“嘿，每当我看到ID_13时，它都将进入分区1｡
“如果第二行中有ID_45，则ID_45将通过哈希函数，
哈希函数将说，“嘿，此ID_45应转到分区2｡
“这就是数据的分发方式｡
因此，很明显，如果您有所谓的热分区，
数据将始终是热键，数据将始终位于同一分区中｡
要计算分区数，
有一些公式很复杂，考试时不需要知道这些公式，让我们快速复习一下｡
但是，您可以通过将RCU除以3，
000，将WCU除以1，000，
然后将它们相加来计算分区数｡
您还可以查看您拥有的数据量，即数据集的总大小除以10 GB，
然后分区数将是这两项中的最大值｡
现在，
你不需要知道这些公式，所以不用担心，好吗？
但是，
您需要了解的是，如果您有10个分区，并且您提供了10个WCU和10个RCU的新资源调配，那么它们将均匀地分布在各个分区中｡
这意味着每个分区将获得一个WCU和一个RCU，
这是我希望你们记住的一点，好吗？
WCU和RCU将被划分并均匀地分布在各个分区上，这就需要进行节流｡
因此，
如果您超过了RCU或WCU，并且这是在分区级别，那么您将获得ProvisionedThroughputExceededException｡
可能因为有热键，所以从特定分区读取一个分区键的次数太多，
这是因为可能有一个受欢迎的项､
热分区或非常大的项，因为很明显，
在计算WCU和RCU时，它取决于项的大小，因此如果读取或写入非常大的项，将消耗大量的RCU或WCU｡
现在，攻击ProvisionedThroughputExceededException的解决方案是，
第一，
在遇到异常时执行指数级回退，如果您使用的是SDK，这是已经包含的东西｡
你必须尽可能多地分配分区密钥，这是我们在第一节课中做的练习，
用来理解如何选择一个好的分区密钥｡
如果这是一个RCU问题，
因为您阅读一个数据点，并且进行了非常严重的分区，那么我们将了解一个称为DynamoDB加速器或DAX的功能｡
现在，我们需要了解的最后一种模式是按需读/写容量模式，这是一种更容易理解的模式，
它将自动接受任何读和写操作，并将根据您的工作负载进行扩展和缩减｡
因此，不需要进行容量规划｡
不指定RCU或WCU｡ 这是无限的｡
没有节流功能，但显然成本更高｡
您将对实际的读取和写入进行收费｡
这就是它被称为读请求单元（即RRU）和写请求单元（即WRU）的原因｡
计算是相同的，
但我们的想法是，因为我们有每个成功的请求，这不是一个容量，我们谈论｡
这只是我的请求｡
现在，给予我们大致了解一下，
按需大约是2｡
比调配的容量贵5倍，
因此请确保您仅将其用于特定类型的使用情形｡
例如，未知的工作负载或不可预测的应用程序流量｡
以上就是DynamoDB中的容量模式｡
我希望你们喜欢，下节课再见｡ 
  - [ ] 343 DynamoDB WCU & RCU [04:06] Hands On
    * 
  - [ ] 344 [DVA-C02] DynamoDB - Basic Operations [07:54]
    * 
教师：在考试中，您将看到DynamoDB的IPI调用是通过其名称引用的｡
所以能见他们一面对我们有好处｡
所以如果你想写数据，你有几个选择｡
您有PutItem，当您执行PutItem时，
它会创建或完全替换具有相同主键的新项｡
它将消耗写入容量单位｡
这个想法是你想做一个完全替换或者写一个新的项目｡
第二个是UpdateItem，
它与PutItem有点不同｡
这一步将编辑现有的项目､ 属性，如果项目不存在，
我们将添加一个新项目｡
但其思想是，使用UpdateItem，
我们只编辑少数属性，而不是所有其他属性｡
这就是PutItem和UpdateItem之间的区别｡
我们也可以把它和原子计数器一起使用，
我们在这一节也会看到｡
还有条件写入，即仅在满足条件时才接受写入/更新/删除｡
这有助于对项目的并发访问｡
我们将在本节中看到这一点｡
要读取数据，我们有一个GetItem｡
而且GetItem非常简单易懂｡
你根据主键和读的主键再次，可以是一个HASH或者一个HASH+Range，
所以你有两个选择｡
你可以从两种模式中读取｡
因此，您有最终一致性读取模式或强一致性读取模式，
但需要指定它｡
它将需要更多的RCU，
然后可能会有一点更长的延迟｡
您也可以在API中指定投影表达式｡
这个投影表达式将帮助您从DynamoDB中只接收几个属性｡
接下来是查询｡
而且查询是基于一个键条件表达式返回项，
这个表达式是一个分区键，所以它必须是等于运算符｡
所以你说，嘿，我想查询John 123，
还有一个可选的排序键，因为你可以排序，
所以你可以有等于，小于，大于，开始，
介于等等｡
然后可以指定FilterExpression｡
这是为了在查询操作完成之后､
数据返回给您之前添加额外的筛选｡
这是用于非关键属性的｡
因此，不能将FilterExpression与HASH或RANGE属性一起使用｡
显然，查询返回的将是一个项目列表｡
并且根据limit查询参数对检索的项目数量有限制｡
要么你会达到never项的极限要么你会得到1MB的数据｡
但是如果你想得到更多的时间数据，你可以对结果进行分页，
然后要求越来越多的数据｡
现在你可以查询一个表，
或者一个本地辅助索引，或者一个全局辅助索引，
我们也会在下一节课中看到这些｡
最后，您有一个Scan，所以GetItem是针对一个项目的，
然后查询是针对特定的Partition Key和Sort
Key｡
扫描项目是读取整个表｡
如果你愿意，你可以过滤数据，
但这只在客户端完成，
所以效率很低｡
所以Scan实际上是导出整个表｡
而且每次扫描都会返回多达一兆字节的数据，
如果你想继续阅读，那么你需要使用分页技术｡
所以这意味着第一页，第二页，第三页，等等｡
它将消耗大量RCU，
因为您正在读取整个表｡
因此，如果您不想影响正常操作，
您需要使用limit语句影响Scan，
或者减小结果的大小，然后稍微暂停一下｡
相反，如果您希望消耗大量RCU并尽可能快地执行扫描，
那么为了获得更快的性能，您可以使用并行扫描｡
在这种情况下，您定义的多个工作线程将同时扫描多个数据段，
这将增加吞吐量和消耗的RCU｡
而且，如果您希望仍然使用并行扫描并限制其影响，
可以使用限制查询､ 限制条件等｡
然后扫描可以与ProjectionExpression和FilterExpression一起使用｡
所以ProjectionExpression只检索某些属性，
FilterExpression只改变客户端的内容｡
现在，如果您需要从DynamoDB中删除数据，
您有DeleteItem，
它用于删除单个项｡
然后，你也可以做一个有条件的删除，
所以只有当钱等于零时才删除这个项目｡
如果需要删除表中的所有内容，可以使用DeleteTable｡
因此，这是删除整个表及其项｡
这比扫描然后删除表上的每一项要快得多｡
好的，删除表，它会删除所有内容｡
这是考试中可能会出现的问题｡
如果您只想删除所有内容，则无需扫描，
只需使用DeleteTable API即可｡
现在为了提高效率，您实际上可以在DynamoDB中执行批处理操作｡
因此，通过减少对数据库的API调用次数，
可以节省延迟并提高效率｡
所有操作都是批处理的一部分，
将由DynamoDB并行应用，以提高效率｡
因此，由于您有一批操作，批处理的一部分可能会失败｡
在这种情况下，您将重新收到失败的项目，
并且只能重试这些失败的项目｡
因此，在正确的机制中，您有BatchWriteItem，
这允许您在一次调用中执行多达25个PutItem和/或DeleteItem｡
您最多可以写入16兆字节的数据，
但仍然有相同的限制，即每项400千字节的数据｡
并且您不能更新项目，您只能执行PutItem或DeleteItem｡
现在，如果由于某种原因（通常是因为缺少写入容量）而无法写入某些项，
那么您将收到名为UnprocessedItems的内容，
然后您可以重试UnprocessedItems中的项｡
所以有两种方法可以正确处理它们｡
您可以使用指数级备份策略，
不断尝试越来越长的时间，直到成功;或者，如果您总是遇到这些UnprocessedItems和扩展问题，
那么当然，您需要添加写入容量单位，以便高效地完成批处理操作｡
对于批处理GetItem，
您将返回一个或多个表中的项，最多可以接收100项和16兆字节的数据｡
所有这些项目都将被并行检索以最小化延迟｡
同样，如果您丢失了一些项，这是因为您可能有一些UnprocessedKey，
因为您没有足够的容量而导致读取操作失败｡
在这种情况下，您可以使用指数备份重试，
或者添加读取容量单位来增加读取容量｡
此外，我们还有PartiQL｡
我们已经看到，在DynamoDB中，
我们有特定的API调用来做特定的事情，
但有时作为数据工程师或其他人员，
作为开发人员，您所知道的可能只是SQL｡
因此，您可以通过使用PartiQL在DynamoDB上使用SQL｡
这里有一个标准的SQL查询，您可以在其中找到OrderID和Orders表中的Total，
还有一个筛选条件和一个排序条件｡
因此，使用PartiQL，
您可以执行与我们之前看到的完全相同的操作，
即在DynamoDB中选择､ 插入､
更新和删除数据｡
但这次，您可以只使用SQL，而不是使用DynamoDB特定的API｡
您可以跨多个DynamoDB表运行查询，
但不能执行连接，明白吗？
您可以只执行选择､ 插入､ 更新和删除操作｡
所有你可以用API做的事情，
但是你要用SQL来编写这些调用｡
因此，您可以从管理控制台､ NoSQL Workbench
for DynamoDB､ DynamoDB
API､ CLI或SDK运行PartiQL查询｡
它的目标实际上不是向DynamoDB添加新功能，
因为您具有相同的功能，而只是使用SQL针对DynamoDB编写这些API调用｡
希望这是有道理的｡
我希望你们喜欢，我们下节课再见｡
  - [ ] 345 DynamoDB Basic APIs [03:10] Hands On
    * 
  - [ ] 346 [DVA-C02] DynamoDB - Conditional Writes [05:36]
    * 
我之前提到过这一点，
但让我们稍微放大一下DynamoDB的有条件权限｡
这是针对写操作的｡
因此，我们有PutItem､ UpdateItem､ DeleteItem和BatchWriteItem｡
其思想是你可以指定一个条件表达式来决定哪些项应该被修改｡
现在你有几个可能的条件｡
我们将在示例中查看其中的许多内容｡
我们有attributes_exists或attributes_not_exists，
attribute_type，
这是为了检查attribute_exists是否不存在，是否是正确的类型，包含和开头是，
这是为了字符串比较｡
然后我们使用IN关键字检查不同的值｡
例如，产品类别属于两个不同类别｡
价格在低和高之间｡
但我们也可以，
比如，定价高于或低于特定的价值｡
最后，如果我们想检查字符串长度，
我们有size属性｡
好了，你们已经看过了过滤表达式和条件表达式｡
因此，筛选表达式筛选读取查询的结果｡
因此过滤表达式与读取查询相关，
而条件表达式仅用于权限操作，它们告诉DynamoDB哪些权限应该成功或不成功｡
让我们来举个例子，例如，一个更新项｡
所以这里我们更新了表中产品目录的一个项目，
并且我们说，只有当价格超过特定限制时，
我们才希望将价格设置为等于当前价格减去折扣｡
这是我们的条件表达式｡
现在要填写什么是折扣，什么是限额？
我们传入file：//值｡ json，
其折扣为150，
限制为500｡
这意味着，如果DynamoDB表中有此项目，
键为4､ 5､ 6，如果应用此更新项目命令，则将转换为现在的价格为500｡
这是因为在此之前价格确实超过了500的上限因为650大于500.
但是如果我们现在再次应用相同的命令，它将不会成功｡
价格永远不会低于500，因为条件表达式的计算结果为false｡
因此，正如您所看到的，条件表达式随项的值是否超过500而变化，
并且条件表达式将确定该项是否将被更新｡
所以如果我们有删除项目，
如果我们可以检查，例如，属性_not_exists｡
所以只有当属性还不存在并且没有值时，
这个方法才能成功｡
例如，我们说，嘿，删除一个项目或删除许多项目，
如果你有一个批次的权利项目，我们可以删除一个项目，
我们的产品目录，如果属性价格不存在｡
有道理｡
如果我们的目录中有一个项目，但我们没有价格，
我们可能无法出售它｡
因此，我们可能需要清理表并将其删除｡
或者，您可以使用attribute_exists｡
所以它的反面属性不存在｡
在这里我们可以检查是否存在｡
例如，如果我们有产品评论｡
一星的存在意味着我们的产品评论我们的产品实际上有一星，
所以我们可以从DynamoDB表中完全删除它，但我们没有它，
然后什么也不做｡
所以你可以开始看到它的用处｡
因此，attribute_not_exists和attribute_exists是一个很好的用例｡
所以如果我们有attribute_not_exists，
然后我们指定分区键，那么将会发生的是，
如果数据库中已经有这个项目，那么这个条件将被评估为false，然后我们不覆盖这个项目｡
但是如果这个项还不存在，
我们就可以写它｡
因此，这是确保我们永远不会覆盖现有数据的一种方法，
为此，我们执行attribute_not_exists，然后指定分区键｡
如果我们有分区键和排序键，并且我们想确保，永远不会覆盖某些东西，那么你可以指定attributes_not_exists分区键和attributes_not_exists排序键，
然后你就可以开始了｡
对于其他事情，
例如，要检查值，您可以查看产品类别是否在不同的类别中，
或者价格是否在最低价格和最高价格之间｡
同样，我们可以传入这些值｡
json文件中，
我们指定了类别1和类别2，
以及500的下限和600的上限｡
因此，当我们应用删除项目时，
如果项目确实属于此范围，那么我们就可以开始了｡
但是我们可以看到，
例如，即使产品类别Sporting Good符合我们的条件，也就是条件的第一部分，但价格是650，
不在500和600之间｡
因此整个条件为假，在这种情况下，
该项目不会被删除｡
你也可以看看字符串比较｡
因此，您有begins_with和contains｡
例如，这里我们说，
嘿，我想确保删除以http开头的项目｡
因此，
我们不会，也不想在我们的产品目录中保留任何不安全的图像｡
当然，这只是一些例子｡
但我想记住的是，条件表达式帮助您创建条件，
这些条件将告诉DynamoDB是否应用正确的操作｡
好，让我们看看这节课，希望你们喜欢，下节课再见｡
  - [ ] 347 DynamoDB Indexes (GSI + LSI) [04:09]
    * 
好的，现在我们来讨论DynamoDB的索引，
您需要了解两种索引｡
第一个是本地辅助索引｡
因此LSI将为您的表给予一个替代排序关键字｡
因此，
您具有来自基表的相同分区键，但您将获得一个额外的排序键｡
这个排序关键字由一个标量属性组成｡
它可以是一个字符串､
一个数字或一个二进制数，并且每个表最多可以获得五个LSI｡
现在，必须在创建表时定义LSI｡
因此，在创建表之后不能创建它们｡
因此，您需要仔细考虑您希望如何设计表｡
接下来，在LSI上，您可以拥有主表中的部分或全部属性｡
因此，您可以在LSI中进行选择｡
如果您只想拥有一个特定的属性，因为这是您要查询的内容｡
举个例子，这是我们的表，
它包含用户ID､ 游戏ID､ 游戏时间戳､
分数和结果｡
现在我们可以对用户ID和游戏ID进行查询，
非常简单，但是我们不能对用户ID和游戏时间戳进行查询｡
为此，我们需要进行扫描，
然后进行一些服务端和客户端站点过滤｡
因此，如果您希望根据用户ID和游戏时间戳进行查询，则需要执行此操作｡
我们需要创建一个LSI，并在属性游戏时间戳上定义LSI｡
如果我们这样做了，
那么我们就可以做一个查询，嘿，
给予我这个用户在2021年到2020年之间做过的所有游戏，等等，好的｡
这一点非常重要，您需要了解这是与之前相同的分区键，
但LSI的排序键不同｡
其次，我们有GSI或全局二级索引｡
所以这会给予你一个不同的，另一个主键.
因此，
您可以使用不同的散列键､ 不同的分区键，或者也可以使用不同的散列键和排序键｡
从基表｡
因此，
如果您希望它加快对表中非键属性的查询，这将非常有用｡
因此索引可以引起这种上高档属性的应变数的二进制化｡
同样，您可以指定要在该索引上投影哪些属性｡
对于这个索引，
它非常特别，因为它有点像一个不同的新表｡
因此，
对于此索引，您必须置备RCU和WCU｡
现在，
GSI的功能非常强大，因为可以在创建表后添加或修改它们｡
让我们看一个非常简单的表，其中有用户ID､
游戏ID和游戏时间戳｡
使用此表，我们可以根据用户ID进行查询｡
所以它给我这个用户的所有游戏，
但我们不能查询游戏ID，因为我们现在可以看到，
如果你想查询游戏ID，这将是非常困难的，当你做一个扫描，然后过滤客户端的网站｡
所以我们要创建一个GSI，一个全局二级索引｡
这将给予我们能够通过游戏ID进行查询｡
所以现在GSI的分区密钥变成了游戏ID｡
分类关键字可以是例如游戏时间戳｡
这是您要查询的内容｡
这些属性变成了用户ID，因为我们已经对用户ID属性进行了投影｡
在这个例子中，
你可以看到，我们通过定义一个新的分区键和一个排序键，创建了一些完全不同的新查询｡
这就是为什么DynamoDB了解如何查询数据，了解如何创建本地二级索引和全局二级索引是非常重要的｡
我们看到LSI和GSI的用途非常不同，但我们还是来讨论一下这些索引和限制｡
因此，当您有一个GSI时，如果权限是GSI上的威胁负载，
则主表也将是可繁殖的｡
所以这是考试中非常重要的一点｡
因此，即使主表上的WCU没有问题，
如果GSI上存在节流，则无论如何，主表都将受到节流，
因此，
请谨慎选择GSI和部分键，并非常谨慎地分配WCU容量｡
而对于LSI，本地辅助索引将使用主表的WCU和RCU｡
而且，不需要考虑任何特殊的节流因素｡
好吗？
这节课就讲到这里｡
我希望你们喜欢它，我们下节课再见｡ 
  - [ ] 348 DynamoDB Indexes (GSI + LSI) [03:51] Hands On
    * 
  - [ ] 349 DynamoDB PartiQL [03:11]
    * 
让我们快速地讨论一下用于DynamoDB的PartiQL，它允许您使用类似SQL的语法来操作DynamoDB表｡
这就是声明的样子｡
然后，
您可以从DynamoDB表中插入､ 更新､ 选择或删除项｡
因此，它允许那些对使用SQL更有信心的人仍然能够与DynamoDB交互｡
如果需要，它还支持批处理操作｡
现在让我向您展示PartiQL如何在控制台中工作｡
我现在在我的表中，左手是PartiQL编辑器｡
现在我们打开其中一些表，例如，打开用户表，
我清空了它，但我可以真实的添加一个项，这样我就可以有一个user_id 123以及一个新属性，名称Stephan，
这很好｡
对于我的另一个表，用户的帖子，我可以再次添加一些项，
如user_id
123 post_id 456，
并创建项，对于演示索引，我可以创建一个项user_id 123
game times stamp 2022，即使它不是很好｡
然后是game_id456｡
好吧，我会的
我已经在我的所有表中创建了一些项，现在如果转到PartiQL编辑器，
我们可以查看用户的表，我可以删除它｡
我单击“用户”，然后扫描表，它有一个从用户开始的选择，
这是一个SQL语句｡
如果我运行它，它会说语句的格式不正确｡
现在它已经完成了，您可以看到items result已定义，user_id
123也可以在adjascent视图中获得，
如果您愿意的话，因为这是您的代码中用来处理它的内容｡
我们可以将结果下载到CSV｡
接下来，对于更复杂的内容，您可以查看demo
indexes表，
我们可以再次扫描此表，这样我们就可以查看所有项｡
但是你可以做更有趣的事情，比如，你可以查询表，当你查询表的时候，
它会生成一个语句，它说，solid
start from demo indexes，
其中user_id等于，
比如，1，2，
3，然后你还可以有一个结束游戏的时间戳，等于Sort键值，但是这是可选的｡
如果你运行这个，
很明显，我们会得到正确的项目｡
我们可以开始构建一些非常复杂的查询，但因为我们这里有一个索引，所以我们可以使用这个索引来扫描它｡
因此，我们可以选择从演示索引开始，然后选择索引的名称｡
它会根据我的索引返回项目｡
你可以做很多事情，你可以运行插入语句，尽管它们不容易直接从UI运行，
因为它们不是自动生成的｡
您还可以设置项，
以便更新特定项并设置属性值､ 分区键值和排序键值等｡
例如，
您也可以删除一个特定的项，这样就有了一个delete from语句｡
所以这个编辑器只适合那些想在DinamoDB上使用SQL的人｡
我只想非常简短地触发这个功能｡
好吧，我会的 就这样了｡
我希望你们喜欢，下节课再见｡
  - [ ] 350 DynamoDB Optimistic Locking [01:46]
    * 
解说员：DynamoDB有一个叫做乐观锁定的特性｡
因此，您可以在DynamoDB中执行条件写入｡
那是什么意思？
这意味着您要确保在更新或删除某个项目之前该项目未发生更改｡
所以你会说，嘿，我只想在满足这个条件的情况下写这个，
这叫做乐观锁定｡
所以它的工作方式是我们在项目上有一个属性，
它将充当版本号，我们将检查这个版本号的相等条件｡
让我们举个例子｡
我们有一个DynamoDB表，还有一个包含用户ID､ 名字和版本的项，
这是一个｡
现在，两个客户端同时想要更新此项目，因为他们认为第一个名称是错误的｡
所以客户端1说，
嘿，我想把这个更新为name = John，
只要version = 1｡
客户机2说，我只想在版本= 1时更新name
=丽莎｡
显然，其中一个请求将首先发送到DynamoDB｡
然后DynamoDB会继续，也许是第二个，
会将名字更新为丽莎｡
而且还会把版本更新到2，好吗？
接下来会发生的情况是，客户端1的更新将无法完成，因为DynamoDB会说：“嘿，你告诉我，
只有在版本为1时才应该执行此更新，但结果是，现在我的版本为2，
因此，
客户端将收到一条错误消息，说：”嘿，你没有正确的数据｡ “
因此，如果你想更新的话，你应该做一个get并开始尝试更新｡
因此，“条件写入”或“乐观锁定”的这一特性将是本次考试的一项测试内容｡
好吗？
所以这只是一个简短的介绍｡
这不是我能轻易演示的，但希望你们喜欢这节课｡
我们下节课再见｡ 
  - [ ] 351 DynamoDB DAX [02:45]
    * 
播音员：现在我们来谈谈DynamoDB加速器或DAX｡
DAX是DynamoDB的完全托管､ 高可用性和无缝内存缓存｡
其思想是，您将缓存最常用的数据，
因此缓存的读取和查询将有微秒级延迟｡
它不需要您更改任何应用程序逻辑，它与现有的DynamoDB
API兼容｡
您只需创建一个DAX集群，就可以开始了｡
现在，DAX，它解决了什么？
它解决了热点问题｡
因此，如果您阅读非常特定的键或非常特定的项，
太多次可能会限制您的RCU｡
但如果它是由DAX缓存的，那么您就解决了这个问题｡
举个例子，DynamoDB由表组成，
我们的应用程序试图访问这些表｡
现在，
我们将创建一个由缓存节点组成的DAX群集，并且我们必须提前配置这些节点｡
现在，
应用程序将直接与DAX集群交互，DAX集群将从DynamoDB表中获取数据｡
因此，默认情况下，
这意味着一些数据将被缓存，如果您认为缓存，您需要考虑TTL｡
所以TTL是5分钟｡
因此，默认情况下，
每个缓存数据将在DAX集群中保留五分钟｡
现在，DAX集群由节点组成，因此您需要配置这些节点，
集群中最多可以有10个节点｡
在Multi-AZ类型的设置中，建议在生产环境中至少使用三个节点｡
所以每个AZ中有一个｡
而DAX是完全安全的，所以你在休息时就加密了｡
您有IAM应用程序､ VPC安全性､
CloudTrail集成等｡
因此请记住，DAX可以帮助您缓存DynamoDB中最流行的项或查询｡
现在，我们的问题是，DynamoDB加速器､
DAX和ElastiCache之间有什么区别？
好吧，它们可以作为一个组合使用，考试可能会测试你是否最好使用DynamoDB
DAX，或者你是否想使用ElastiCache｡
使用DAX，您要做的是为单个对象､
查询或扫描创建缓存｡
这是非常非常方便的，这就是我所说的简单类型的查询｡
因此，您的对象､ 查询和扫描｡
但是，如果您在执行某种逻辑应用程序，您知道，
您就像在执行扫描，然后执行求和，然后筛选出一些数据，
等等｡
你不想每次都这样做，因为这在计算上是昂贵的｡
你能做的是，你可以把你的应用程序刚刚做的任何事情的结果存储在Amazon
ElastiCache中｡
并直接从ElastiCache中检索数据，而不是重新查询DAX和重新执行聚合客户端｡
因此，这可能是在体系结构中同时使用它们的好方法｡
好吧，我会的
现在，让我们来看看如何创建DAX集群｡
  - [ ] 352 DynamoDB DAX [04:08] Hands On
    * 
  - [ ] 353 DynamoDB Streams [04:26]
    * 
教师：让我们来看看DynamoDB流｡
因此，流是项级修改的有序列表，例如在表中发生的创建､
更新和删除｡
因此，
无论何时插入､ 修改或删除一个项目，该修改都将在流中可见｡
并且流将表示表中随时间变化的所有修改的列表｡
因此，
流记录可以发送到多个位置，如Kinesis数据流，因此您可以将DynamoDB流发送到Kinesis，然后对它执行任何您想要的操作｡
您还可以使用Lambda函数直接从DynamoDB
Streams中读取，或者也可以使用Kinesis客户端库应用程序直接从DynamoDB Streams中读取｡
DynamoDB Stream中的数据保留时间长达24小时，
因此您需要确保将其持久保存在类似Kinesis
Data Stream的位置，在那里您可以拥有更长的保留时间，或者使用任何Lambda或KCL应用程序将其持久保存在更持久的位置｡
使用DynamoDB流的用例是对DynamoDB表中发生真实的时更改做出反应｡
例如，
创建一个流程来欢迎您，向您的用户发送欢迎电子邮件，进行分析，
转换流并在DynamoDB中创建派生表，或者将数据发送到ElasticSearch以在DynamoDB上进行索引并提供搜索功能｡
或者，如果您希望实现全局表和跨区域复制，
则首先需要流｡
因此，
如果我们看一下DynamoDB流的体系结构，我们就有了我们的应用程序，它确实对我们的表执行了创建､
更新和删除操作，而且任何这些更改都将出现在DynamoDB流中｡
因此，Kinesis数据流可以成为DynamoDB流的接收器｡
因为我们使用的是KDS, Kinesis Data
Streams，所以我们可以得到Kinesis Data
Firehose作为结果，然后将其发送到Amazon Redshift，
以便在DynamoDB中的数据上执行一些分析查询，
或者发送到Amazon S3，
以便在需要时对所有这些更改进行存档，或者发送到Amazon ElasticSearch，好吗？以创建索引并在DynamoDB表上创建搜索功能｡
这种架构的最酷之处在于，几乎所有内容都由AWS管理｡
如果您想添加自己的自定义逻辑，您可以使用一个处理层，
在其中创建一个Kinesis客户端库应用程序（可能在EC2上运行）或一个将从DynamoDB流中阅读的Lambda函数｡
从这里，你可以实现任何你想要的逻辑｡
例如，您可以使用Amazon
SNS发送消息或通知｡
您可以进行一些过滤和转换，然后将数据重新插入DynamoDB表中，或者，
如果您愿意，您也可以使用Lambda将数据发送到ElasticSearch中，
好吗？
因此，这为您提供了一种不同的体系结构，以及使用DynamoDB
Streams所带来的所有可能性｡
如果我们考虑流，那么我们有什么？
在数据流中，我们可以选择将出现在其中的信息｡
例如，我们可以只有键，它只显示所有已修改的键属性的列表，
NEW_IMAGE表示修改后的新项，OLD_IMAGE表示修改前的整个项｡
如果您想获得完整的信息，
您可以获得NEW_AND_OLD_IMAGES，它为您提供了项目的新旧图像，因此我们可以看到发生了哪些更改｡
现在，DynamoDB流由碎片组成，就像Kinesis数据流一样，
所以它们非常非常相似｡
这就是为什么Kinesis客户端库同时支持DynamoDB流和Kinesis数据流的原因｡
因此，
DynamoDB Streams最酷的一点是，我们不必提供任何类型的碎片｡
这是由AWS自动完成的，因此它实际上是一种无需干预的方法｡
现在，如果您启用DynamoDB Stream，
正如您所知道的，在启用它之后，
记录将不会在流中进行追溯填充｡
好吧，这是个考试小把戏｡
因此，
一旦启用了流，您将收到基于DynamoDB表中出现的更改的更新｡
最后，让我们看看DynamoDB Streams和Lambda是如何工作的｡
因此，为此，我们需要定义一个事件源映射，
以从DynamoDB流中读取｡
然后，您需要确保Lambda函数具有从DynamoDB流提取的适当权限｡
然后同步调用Lambda函数｡
让我们举个例子｡
该表将进入DynamoDB流｡
Lambda函数将有一个事件源映射，它是一个内部进程，
将从DynamoDB流中批量提取DynamoDB流和检索记录｡
一旦一些记录被传递到Event Source Mapping，那么Event
Source
Mapping将调用您的Lambda函数，与DynamoDB Stream中的一批记录同步，明白吗？
这节课就讲到这里｡
我希望你们喜欢，我们下次课上见｡
  - [ ] 354 DynamoDB Streams [05:38] Hands On
    * 
  - [ ] 355 DynamoDB TTL [05:20]
    * 
教师：那么，现在，让我们来谈谈“生存时间”｡
而“生存时间”允许您在过期时间戳之后自动删除项目｡
我们的想法是，
你有一个列，你要定义，
然后当你说的时间，现在超过了这一列的值，然后请删除项目｡
因此，
由“生存时间”约束删除的项目不会消耗任何WCU，因此没有额外的成本｡
这个时间戳必须是一个代表Unix时期时间戳值的数字，我们将在实践中看到｡
现在过期的物品不会马上过期，有一个保证，它们会在过期后的48小时内过期，
好吧，但在真实的生活中，
这实际上是相当不错的｡
因此，
如果您查看一个表，例如，一个包含User_ID和Session_ID两列的SessionData表，我们希望添加一个过期时间，
该时间将是表的TTL，我们将定义每个会话的过期时间｡
现在，当你进入时，
DynamoDB中有一个过期进程，它会查看当前时间，并说当前时间是这个，
然后它会标记､ 扫描表，并使那些明显具有TTL历元时间（小于当前时间）的项目过期｡
然后第二个进程将扫描并从表中删除这些项，这就是TTL的工作原理｡
现在，这些尚未删除的过期项目仍将出现在读取､
查询和扫描中，
因此，如果您不希望看到它们，则需要执行一些客户端过滤｡
因此，您的查询中可能已经有一些过期的项目｡
您最多需要等待40小时才能看到它被删除｡
当项目被删除时，它们也会从索引中删除，
因此本地辅助索引和全局辅助索引也会被删除｡
每个过期项的删除操作都进入DynamoDB流｡
这意味着任何被删除的项目，
由于TTL，将在一个流，
你可以恢复它，如果你想｡
TTL的用例是通过仅保留当前项目来减少商店数据，
以遵守法规义务，或者，例如，
对于SessionData，它是TTL的完美用例｡
好的，
那么，让我们看看如何在DynamoDB中定义TTL｡
让我们继续创建一个表，我将其命名为DemoTTL｡
现在Partition键将是user_id，我们现在不需要Sort键｡
好的，
我们将自定义设置，我们将设置供应和自动缩小｡
我们将有一个RCU和一个WCU，然后我们将继续创建此表｡
现在我的表已经创建好了，我要做的就是添加一些数据｡
所以我要插入一些项目｡
因此，我将创建一个项，user_id为john_123，
然后添加一个属性，例如，
name将为John｡
然后，我想在属性上设置一个expire_on，
所以expire_on.
本质上，它不是字符串而是一个数字｡
因此，我们确实expire_on，
然后我们需要为John给予一个到期日期｡
所以我把它叫做epoch converter, online，
让我们看看第一个｡
这就是我们如何将时间戳转换为纪元时间戳，我可以将其输入DynamoDB｡
举个例子，如果我从现在开始计算，比如说，
五分钟后，
我们开始，我做人类到时间戳，这里是五分钟后的历元值｡
我将把它粘贴进去，然后单击“Create item”（创建项目）｡
这是已经创建的一个项目，我将创建第二个项目｡
这个是alice_456，有一个user_id，
而Alice的名字将是Alice，我们还需要一个expire_on, expire_on可以是，例如，
从现在起一小时后｡
我有一个10，在这里，点击人类日期到时间戳，
把这个粘贴和创建项目｡
现在我们在DynamoDB表中有两行，这两行都有不同的expire_on属性｡
现在，我们需要在表中定义TTL｡
因此，如果我们查看表，可以看到“生存时间”当前已禁用｡
因此，
我可以做的是转到“附加设置”，向下滚动，然后查找“生存时间”并单击“启用”｡
现在，
我们需要给予出TTL属性名称，那么我希望过期的数据是什么？
我想要在其上过期的列，因此expire_on是我为这个TTL属性名指定的名称｡
然后，我们可以做个预演，好吗｡
所以如果你现在运行一个预览，它会说这两个项目将在一个小时内删除｡
比如说，现在，
这里，
我运行预览，它会说，没有我想删除的项目.
但如果我们从现在开始一小时后做，那么如果我们做，
比如说，10，10：10，它会得到这个纪元时间戳，就在这里，
然后粘贴它，运行预览，只有约翰会过期，好吗.
如果我再晚一点，
那么如果我到10：50并获取您的人类时间戳，转到时间戳并粘贴此内容，运行预览｡
现在将删除两个项目，
您可以指定Epoch值或Custom时间，或者在接下来的60分钟､
24小时或7天内，这对于运行某些模拟来说非常酷｡
我们可以启用TTL，
现在TTL已启用，如果我等待一个小时，我的项目将自动完全过期｡
所以这很酷｡
我们可以做一个图表，显示过去24小时内删除的所有项目，
这要归功于这个功能｡
这是一个CloudWatch指标｡
这节课就讲到这里，希望你们喜欢，
下节课再见｡
  - [ ] 356 DynamoDB CLI [05:15]
    * 
教师：好的，下面介绍一些DynamoDB考试中可能会用到的CLI选项｡
第一个是projection-expression，
通过它，我们可以指定一个或多个要检索的属性｡
我们不想检索所有列和所有属性｡
我们只想检索一个子集，这样可能会有更少的数据，
或者只有我们需要的数据｡
这里有一个filter-expression，
它用来过滤返回给你的项，所以这里会有一些过滤，
我们可以指定一些条件，我们很快就会看到｡
DynamoDB S1还有一些非常重要的分页选项｡
因此，对于DynamoDB，当然是页面大小｡
因此，
页面大小意味着我们仍然希望检索整个数据集，但这一次，我们将对AWS进行的每个子API调用都将更小｡
其思想是API调用不会超时｡
例如，如果您有一个包含10，
000个项目的表，并且您执行了一次API调用，则可能一次检索10，000个项目，并且您将超时｡
但如果您指定页面大小为100，则会发生100个大小为100的API调用，这些调用将在后台进行，
以确保整个API调用成功｡
因此，从这个意义上说，
页面大小是一种优化，
因为它允许您执行更多的API调用，同时还可以避免超时｡
相反，Max-items是指当您从CLI调用返回结果时，
显示有限数量的项目｡
max-items和NextToken一起工作，也就是说，现在你已经收到了，
比如说，
25个项目，我们想得到接下来的25个，所以，你需要使用NextToken来检索接下来的25个项目｡
现在，
我会把这一点说得很清楚，因为我们现在就要练习｡
现在，让我们进入UserPosts表并查看项目｡
这是我们表中的所有项，
我们来玩一玩.
现在，我希望您打开CLI，这样您就可以使用终端（如果您已经配置了终端），
或者我将使用AWS CloudShell｡
另外，请确保您打开了cli-examples｡
sh文件｡
好的，第一件事是我们要执行DynamoDB扫描｡
好吧，我会的
我们应该指定表名，但是我们还将在user_id和content上指定一个projection-expression｡
现在，在这个表中，我们有三个属性｡
我们有user_id､ post时间戳和内容｡
通过使用projection-expression，我们将不检索post时间戳｡
所以我们来证明一下｡
让我们复制并粘贴它｡
按Enter键｡
你也看到了，我拿了些东西回来，好吗？
正如我们所看到的，我们只有内容和user_id｡
结果中没有发布时间戳｡
好吧，我会的
接下来，我们来讨论一个过滤表达式｡
所以我们要扫描这个表｡
但这次，
我们将使用filter-expression过滤所有结果，因此这是在客户端进行的｡
我们将查找user_id = u｡
然后u必须是一个值为john123的字符串｡
因此，这意味着我们只需要检索包含john123的行｡
如我们所见，我们有物品｡
计数为2｡
并且我们只检索john123的内容｡
这是有效的｡
这一切都发生在客户端，好吗？
如果您希望在服务器端使用它，因为user_id是john123，它是一个user_id调用，
因此它是一个主键，
我们可以直接运行一个查询，这样效率会高得多｡
但至少我们展示了过滤表达式的力量｡
我们可以根据user_id进行过滤｡
我们可以根据帖子时间戳进行过滤｡
我们还可以过滤内容｡
接下来，我们要演示页面大小｡
因此，如果您执行此API调用来扫描整个表，那么它将是后台的一个API调用，
当然，此API调用足够小，
但我们检索三个项｡
但是如果你想提高效率，比如说有10，000个项目，
你可以将页面大小指定为1｡
现在，page-size 1只会在后台执行三个API调用，
但您仍然可以在一个命令中检索三个项目｡
如果我按下Enter键，
正如我们所看到的，我又一次收到了我的三个项目，好吗？
但在后台发生的情况是，对DynamoDB进行了三次API调用｡
这就是为避免超时而进行的页面大小优化｡
相反，如果您希望一次检索一个项目，则可以使用max-items，
然后使用一个数字，
因此max-items 1应该只返回一个项目｡
如你所见，我们有这个项目正在返回给我们｡
然后数到三｡
但我们现在有一个NextToken可用｡
所以这个NextToken，我们必须使用这个命令｡
所以我们将使用相同的max-items
1，但现在我们必须输入起始令牌｡
starting-token的值就是CLI中的值｡
因此，在命令中粘贴起始标记，
然后按Enter键｡
现在你得到了第二个职位｡
这是第一个博客｡
我们有一个NextToken｡
现在是我们的第二个博客，我们又有了一个NextToken｡
最后，如果你想取回最后一个，我们再运行一次这个命令，
好吗？
所以我们运行这个命令，这次我们将指定上面的NextToken，它恰好是完全相同的｡
我不想再给你演示一遍这个过程｡
因此，您可以在命令中复制整个标记，然后按Enter键，现在我们将看到“Alice blog
edited“｡
“现在我们没有更多的NextToken了｡
这时候我们就知道我们已经达到了这个表所能扫描到的所有东西的极限了？
因此，希望CLI的这些选项能够发挥作用｡
希望你喜欢｡
我们下节课再见｡ 
  - [ ] 357 DynamoDB Transactions [03:37]
    * 
现在我们来讨论Dynamo DB事务｡
其思想是，通过事务，您将获得对一个或多个表中的多个项的all or nothing操作｡
例如，我们想要更新､ 删除或添加项，而不仅仅是针对一个表，而是跨多个项｡
所有的交易，所有的权利都有效或者都不起作用都叫做交易.
现在，这给了Dynamo DB酸功能｡
所以自动性､ 一致性､ 隔离性和持久性事务可以应用于读模式和写模式｡
用于读取模式｡
您将有三种读取模式｡
因此，在Dynamo DB中，您将获得最终一致性，我们以前和现在都知道的强一致性，
事务一致性，这意味着我希望同时从所有这些表中读取数据，并获得一致的视图，
即事务一致的视图｡
对于模式，您将获得标准和事务｡
标准的做法是，你要对很多表做很多权限，但有些权限可能会失败.
但是事务性的要么所有权限都对所有表起作用，要么所有权限都对所有表不起作用｡
现在，要执行一个事务，它将消耗两倍的写容量单位和读容量单位｡
这是因为该模块将在后台为每个项目执行两个操作｡
它将准备事务，然后提交它｡
现在，您需要了解的这两个操作将是事务处理获取项目（就API调用而言），以执行一个或多个获取项目操作（作为事务的一部分）或事务处理正确的项目（以执行一个或多个放置项目､
更新项目和删除项目操作（作为事务的一部分））｡
事务的用例是任何时候你都会有一个侧面的需求｡
例如金融交易､ 订单管理､ 多人游戏等等｡ 等等｡
任何地方都需要某种一致性｡
让我们举个例子｡
我们有账户余额，它代表账户ID，即余额｡
那么每个账户上有多少美元，以及最后一次在这个账户上进行交易的时间｡
然后我们有另一个表，叫做银行交易，它代表了所有发生在银行的交易｡
还有一个交易ID，一个从账户到账户的交易时间戳和金额｡
所以我们的想法是，我们要添加交易，同时修改帐户余额｡
因此，我们的应用程序将执行一个事务，作为该事务的一部分，
将执行帐户余额的更新项和银行事务的放置项｡
现在使用动态事务，事务可以同时写入两个表，也可以不写入任何表，
这就是事务的强大功能｡
我们可以看到，特别是在这样的金融环境中，拥有这样的交易担保水平是非常非常重要的｡
现在我们来讨论Dynamo DB的容量计算，这对于考试非常重要｡
因此，如果我们希望每秒处理三个事务权限，并且项目大小为5KB，
那么需要什么样的WQ？
那么，你需要3乘以5除以1，因为1个WQ是1千字节，乘以2，
因为事务性操作的成本是2倍，这使得你需要使用30个WQ｡
现在，如果每秒有5个事务性读取，项目大小为5 KB，它们需要5乘以8除以4乘以2，
因为事务性操作的开销是强一致性读取的两倍，强一致性读取需要20次请求，
为什么要得到8次？
好吧，五个确实四舍五入到了我们之前看到的最大的四千字节｡
所以要熟悉这些计算｡
理解Dynamo DB中的事务是什么｡
我不能在控制台上演示，但我希望你们喜欢这节课，下节课再见｡
  - [ ] 358 DynamoDB Session State [02:20]
    * 
讲师：我们知道DynamoDB可以用来存储数据，但它也可以作为缓存来存储会话状态｡
这是您的web应用程序可以使用的东西，因此它们可以根据需要在存储中检索会话状态，
并在所有后端web应用程序之间共享用户登录信息｡
这是DynamoDB非常常见的用例，但我们在ElastiCache中也看到过这种情况｡
因此，ElastiCache和DynamoDB实现了相同的目的｡
因此，您可能会问自己，使用DynamoDB或ElastiCache来存储会话状态有什么区别？
ElastiCache将完全位于内存中，
然后DynamoDB将是无服务器的，两者都将是键值存储｡
因此，
如果考试结果是“好的，我们需要一个会话状态存储“，它将位于内存中｡
“可能是指弹性缓存｡
如果它谈到自动缩放等，那么DynamoDB可能是正确的方式｡
所以，这是你必须在考试中寻找的东西｡
另一种存储会话状态的方法是在磁盘上，您可以在多个institute实例之间共享该磁盘｡
因此，EFS可能是一个很好的选择｡
因此，EFS必须作为网络驱动器连接到您的机构实例｡
因此，例如，它不能与Lambda一起使用｡
因此，EFS是一个非常特殊的用例｡
这可以与DynamoDB进行比较｡
但是EFS是一个文件系统，而DynamoDB是一个数据库｡
所以这里有一个区别｡
您可能会说：“好吧，您刚才说EFS用于存储｡
“那么，我的EBS卷“和我的研究所实例商店怎么办？
“所以，是的，这确实是存储，
但它们只能用于本地缓存，而不是共享缓存，
因为您的EBS驱动器和即时存储只连接到研究所实例｡
因此非常重要的是，这可以用于缓存本地数据集，
但不能用于在多个实例之间共享数据集｡
最后，关于S3，
S3可以用于会话状态吗？
是的，但它的延迟更高｡
它适用于大文件，而不是小对象｡
所以，S3作为一个会话状态，缓存不是一个很好的工具｡
因此，最好的两个是，
我们最好的三个是DynamoDB､ ElastiCache和EFS，
但最好是DynamoDB和ElastiCache｡
这一切都是为了弄清楚您是想要内存中的东西，还是想要更无服务器且具有自动扩展功能的东西｡
好吧，就这样｡
我们下节课再见｡ 
  - [ ] 359 DynamoDB Partitioning Strategies [01:20]
    * 
讲师：那么，我们来简单讲一讲DynamoDB写分片｡
因此，
让我们假设这个用例，其中我们有一个投票应用程序，投票应用程序的用户可以为候选人A和候选人B投票｡
两个候选人｡
现在，如果我们使用分区键作为候选ID，问题是所有结果将只进入两个分区，因为数据将按候选ID
A或候选ID B进行分区，这将产生写入和读取问题，
因此我们将遇到热分区问题｡
那么，我们该如何解决这个问题呢？
一种策略是在分区之间更好地分配候选ID，
为此，我们将向分区键值添加一个后缀或前缀｡
我们现在要得到候选人ID，然后再加上数字11｡
候选项a为11，添加一行，
然后我们将得到候选项b为17，候选项b为18，候选项a为20，
其思想是，现在分区键的分布性更强，因为它采用了更多的唯一值，因此数据集将完全写入Dynamo
DB表，并且完全可从Dynamo
DB表读取｡
现在，有两种方法来创建这个后缀或前缀｡
您可以使用随机后缀，也可以使用哈希算法进行计算｡
这两种方法都有效｡
这个想法是你想得到一个非常非常分布式的分区键｡
仅此而已，
这只是一个理论讲座，但你现在知道这个策略了｡
我希望你们喜欢它，我们下节课再见｡ 
  - [ ] 360 DynamoDB Conditional Writes, Concurrent Writes & Atomic Writes [01:55]
    * 
Stephane：这是另一个关于在DyamoDB上可以进行的所有编写的理论讲座，这样你就可以很好地理解它们｡
第一个是并发写入，我们有一个项目，并告诉用户，
“想要更新该项目｡
“所以第一个人说，“嘿，
把这个项目更新为值等于1｡ “第二个说，
“嘿，我想让你更新价值等于2的项目｡ “现在发生什么事了？
他们都会成功的｡
所以第一个可能会更新为值等于1｡
第二个更新为value相等2｡
所以，
如果第二次写入发生在第一次写入之后，那么第二次写入可能会覆盖第一次写入，
好吗？
但其中一个将被覆盖｡
这并不是一个非常理想的行为，因为其中两个人尝试更新一个项目，都获得了成功，
但显然只有一个人真正成功了｡
这就是它被称为并发写入的原因｡
那么我们该如何解决这个问题呢？
我们可以执行条件写入｡
在条件写入中，
用户说：“嘿，我想得到值等于1的项，但前提是当前值为零｡
第二个人说，“嘿，我想让你计算这个项目的价值，价值等于2，
但前提是价值为零｡
“现在要发生的是，例如，第一次写将被接受｡
因此，值将等于1｡
第二次写操作会失败，因为在计算条件值等于零时，
它会说，
“嘿，你知道吗？
实际上，现在的值是1｡
“所以我们不该写你的文章｡
所以这是解决并发问题的一种方法｡
这就是它被称为乐观锁定的原因｡
现在，您可以执行的另一种写入是原子写入｡
所以在这个例子中，用户说，
“嘿，我想让你把这个值加一，”用户二说，
“我想把这个值加二｡
“现在两个剧本都要成功了｡
而总价值将增加3｡
所以一加二等于三｡
最后，
与这种并发无关，只是批写入是指用户一次写入或更新许多项，好吗？
现在您已经了解DynamoDB中的所有写入类型，在考试中应该会有所了解｡
我希望你们喜欢它，我们下节课再见｡ 
  - [ ] 361 DynamoDB Patterns with S3 [02:46]
    * 
现在，让我们看看使用IMDB和Amazon历史的两种方式｡
第一个问题是如何在数据库中存储大对象｡
正如您所知，在Dynamo DB的表中，最多只能存储400 KB的数据｡
所以很明显，如果你想开始存储一些图像，一些视频，所有这类的东西｡
动态数据库不是最好的地方｡
因此，我们要做的是使用Amazon S3存储桶来包含大对象｡
那么，上载大型对象的过程是什么呢？
好吧，假设我们将一个图像上传到Amazon S3，我们将取回一个对象的密钥｡
我们要做的是将应用程序中的元数据存储到Dynamo DB中｡
因此，我们将有一个产品ID､ 一个产品名称，然后是一个图像URL，它是一个直接指向Amazon历史的指针｡
现在，我们所做的是，我们已经有效地将非常少量的数据存储在products表中，然后存储在IMDB中，
我们已经将大的项目存储在Amazon历史记录中｡
现在，从读取的角度来看，客户端希望首先读取这些数据，从Dynamo DB获取元数据，
然后我们将从Amazon历史记录中获取映像，以重建这些大型对象，这样我们就可以不断地拥有许多不同的产品，
并大规模地使用此策略｡
这个策略最酷的一点是，我们将每项服务都用于我们擅长的领域｡
因此，Amazon非常适合存储较大的对象，而IMDB非常适合存储将使用特定属性进行索引的小对象｡
在这个例子中，我们将Amazon的历史和IMDB完美地结合起来｡
另一种组合或协同作用是使用IMDB作为索引S3对象元数据的方法｡
因此，应用程序将把我们的对象上传到Amazon历史记录中，Amazon历史记录将设置通知，
例如，调用Lambda函数｡
该lambda函数将把对象元数据存储到新的DB表中｡
例如，对象大小､ 日期､ 创建者｡
不管你怎么想这些东西｡
我们为什么要这么做？
因为在Dynamo DB表上构建一些查询要容易得多｡
然后放在S3桶的顶部｡
同样，S3桶并不意味着要真正扫描｡
它是用来存储大对象的，而且应该有某种类型的数据库，它知道这些对象是什么，
它们的属性等等｡
因此，通过在Dynamo DB上创建一个应用程序，我们可以回答一些问题，例如：嘿，
我们希望根据S3存储桶上的特定时间戳查找对象，或者我们希望查找客户使用的总存储量，
或者列出所有对象返回属性，或者查找在某个日期范围内上载的所有S3对象｡
所有这些都通过查询Dynamo DB表来实现｡
然后，我们从IMDB中读回结果，并从S3存储桶中检索必要的对象｡
所以希望这两个策略是有意义的｡
它们很常见，考试时也能考出来｡
我希望你们会喜欢，下节课再见｡ 
  - [ ] 362 DynamoDB Operations [01:50]
    * 
讲师：好的，这是一个关于两个DynamoDB操作的简短讲座，您可能会参加｡
第一个是关于如何进行表清理｡
因此，要做到这一点，您有两种选择｡
首先，
您可以扫描表中的所有项，然后逐个删除它们，
这非常非常慢，并且会在扫描操作上消耗大量RCU，
在删除操作上消耗大量WCU，因此开销很大｡
第二个选项要快得多，它是删除表｡
因此，请删除该表，将其删除，然后重新创建此表｡
所以它快速､ 高效､ 廉价｡
您只需要确保使用与之前相同的正确设置重新创建此表｡
现在，
如果您希望跨帐户､ 地区和地点复制DynamoDB表，有两个选项｡
第一个是使用AWS数据管道｡
这可能是考试中唯一一次看到数据管道，所以我不会花时间在这上面｡
我只是想让你看看它的功能｡
因此，在本例中，我们希望将DynamoDB表复制到另一个表中｡
因此，
后端的数据管道将启动Amazon EMR集群｡
EMR将使用扫描操作从DynamoDB表中阅读，并将其写回Amazon
S3进行存储｡
然后，
在第二步中，它将从Amazon
S3读回数据，然后将其插回到一个新的DynamoDB表中，好吗？
这是数据管道，它将在后端同步和协调所有这些操作｡
第二个选项，我更喜欢它，
是备份DynamoDB表并将其恢复到新表中，这需要一些时间，但它更高效，并且不需要任何其他外部服务｡
第三个问题更棘手｡
您可以自己进行扫描，然后如果您想提高效率，您可以进行放置项目或批处理付款项目｡
您必须编写自己的代码，但同时可以进行一些转换｡
这不是推荐的方式，但你会考虑的另一个选择，好吧｡
这节课就讲到这里｡
我希望你们喜欢它，我们下节课再见｡ 
  - [ ] 363 DynamoDB Security & Other [03:29]
    * 
我们来讨论一下DynamoDB安全性和其他一些特性｡
因此，
出于安全考虑，我们提供了VPC端点，
可以在不使用公共互联网的情况下访问DynamoDB，并且只将所有流量保留在VPC内｡
对DynamoDB的访问完全由IAM控制，这使得它成为AWS中的一个很好的数据库选择｡
您可以使用AWS KMS进行静态加密，也可以使用SSL和TLS进行传输中加密｡
提供备份和还原功能｡
你有两个｡
因此，
您可以使用时间点恢复，即PITR，就像RDS一样，
不会对性能产生影响，或者我们也可以只执行正常的备份和恢复｡
现在有了全局表和DynamoDB的概念｡
因此，
我们的想法是在DynamoDB中拥有一个多区域､ 多活动的完全复制的高性能表｡
以及如何启用它？
您需要首先启用DynamoDB流｡
因此，尽管DynamoDB是一个云服务，但您可以在本地计算机上获得DynamoDB的模拟，
称为DynamoDB
local，其思想是，您拥有一个本地DynamoDB数据库，您可以使用该数据库在本地开发和测试应用程序，
而无需使用DynamoDB web服务，这真的非常方便｡
如果您希望将数据迁移到DynamoDB或从DynamoDB迁移数据，AWS数据库迁移服务是一个很好的选择｡
例如，从MongoDB到DynamoDB，
或动态V2 Oracle､ mySQL､ S3等｡
现在，您需要了解有关DynamoDB的另一个特性是细粒度访问｡
例如，如果您有客户端和应用程序､
web或移动的设备，并且它们需要直接访问我们的DynamoDB表，那么我们不希望为它们给予IAM权限和IAM角色，
即直接从AWS访问用户，
这将是真正低效的，而且会造成安全漏洞｡
相反，我们将使用身份提供者｡
它可以是Amazon Cognito用户池､
Google登录､
Facebook登录､ 开放ID连接或SAML等｡
在简化的流程中，
用户将通过这些身份提供商登录，他们将拥有将刚刚获得的凭据交换为临时AWS凭据的功能｡
这个想法是因为它们是临时的，它们更安全｡
通过它们，可以将它们与IAM角色关联，但必须限制此IAM角色，
因为现在我们的客户端和应用程序可以访问DynamoDB表，您希望它们只能对它们拥有的数据执行操作｡
那么，
我们如何做到这一点，这种细粒度的访问控制？
我们有一个联合登录来获取临时凭据，然后我们可以创建IAM角色，此IAM角色将具有一个条件｡
而这种情况将导致用户可以做什么｡
下面是一个策略示例｡
因此在该策略中，
用户可以对特定表进行取项､ 批取项､ 查询､
放项､ 更新项､ 删除项､ 批对项等操作｡
但有个条件｡
条件是，
Hey，仅当前导键对应于DynamoDB时，然后是连接器标识伪变量，这些伪变量将在运行时由特定用户替换｡
因此，实际上我们所说的是，使用LeadingKey，
我们只根据主键值限制用户的行级访问｡
因此，我们确保用户只能修改和访问他们自己的数据｡
你也可以在属性上指定条件，
这将限制用户在DynamoDB表中可以看到的特定属性，好吗？
总而言之，
通过使用联邦登录并在LeadingKeys上指定条件（如果希望在角色级别或属性上进行限制，如果希望在列级别或属性级别上进行限制），您可以实现细粒度访问控制｡
好了，这节课就讲到这里｡
希望你喜欢｡
我们下节课再见｡ 
  - [ ]  DynamoDB [27 问题] Quiz
    * 
 ## Section 24 - AWS Serverless: API Gateway [21 个讲座 • 1 小时 42 分钟]
  - [ ] 364 API Gateway - Section Introduction [00:43]
    * 
现在，让我们继续服务器之旅｡
我们知道怎么做｡
琳达，我们知道如何在发电机G中存储数据｡ B ......
但如果你想把我们的功能暴露给世界呢｡
如果您希望人们使用REST API访问我们的应用程序，该怎么办？
同样，我们也不想管理服务器｡
因此，我们有API网关，API网关将使我们能够传播我们的应用程序，
将其作为其上的一个休息api｡
我们将了解如何使用Amazon进行用户身份验证｡ com的网站｡
因此，本节将真正将这些内容整合在一起，并为您完成将API部署到云的方法｡
我们开始吧
  - [ ] 365 API Gateway Overview [06:37]
    * 
教师：到目前为止，在我们的无服务器之旅中，
我们已经看到了如何创建Lambda函数，
以及如何使用DynamoDB｡
函数可以使用DynamoDB作为API的数据库，
我们可以创建，读取，更新，删除我们的表，但是我们希望客户端能够以某种方式调用Lambda函数｡
所以有多重的做这件事｡
我们可以让客户端直接调用Lambda函数，
但这意味着客户端需要IAM权限，或者我们可以使用应用程序负载平衡器将其置于客户端和Lambda函数之间，
这将把Lambda函数公开为HTTP端点｡
我们还有最后一件事可以利用｡
它被称为API网关｡
这是AWS提供的无服务器产品，允许我们创建REST
API，这些API将是公共的，可供我们的客户访问｡
因此，客户端将与API网关进行通信，
API网关将把请求代理给我们的Lambda函数｡
因此，它将使用API网关，
因为它提供的不仅仅是HTTP端点｡
它将为我们提供许多功能，
如身份验证､ 使用计划､ 开发阶段等｡
因此，API Gateway具有许多功能，这只是一个概述，
但我们可以集成API Gateway和Lambda，
这将为我们提供一个完整的无服务器应用程序｡
因此无需管理基础架构｡
我们支持WebSocket协议，
因此我们可以通过API网关以两种不同的方式进行实时流传输｡
API网关处理API版本控制｡
所以我们可以从第一个版本到第二个版本和第三个版本，
而不会破坏我们的客户端｡
我们可以处理多个环境，
包括开发､ 测试和生产环境｡
有一个完整的事情关于API网关和安全｡
因此，有很多方法可以在API网关上为身份验证和授权启用安全性｡
我们能够创建API密钥，在某些客户端在我们的API网关上执行过多请求的情况下执行请求限制，
并且我们还可以使用一些常见标准，如Swagger或Open API 3｡
0导入快速定义的API，
也可以将其导出为Swagger和Open
API｡
我们可以在API网关级别转换和验证请求和响应，
以确保调用正确，我们可以生成SDK和API规范，并缓存API响应｡
因此，当您使用像应用程序负载平衡器这样简单的东西时，
API网关附带的许多功能并不一定包括在内｡
那么，API网关与什么集成？
有一个Lambda函数，
我们在上图中看到过，所以它可以调用Lambda函数.
通过这种集成，这是公开REST（一种由Lambda函数支持的API）的最常见和最简单的方式，
以实现完整的无服务器应用程序｡
但也HTTP｡
因此，我们可以在后端公开任何HTTP端点｡
例如，它可以是您内部部署的HTTP
API，也可以是您云环境中的应用负载平衡器｡
你为什么要这么做？
您可以使用API网关来利用速率限制功能､
缓存､ 用户身份验证､ API密钥等｡
因此，在HTTP端点上使用一层API网关肯定是充分的｡
最后，我们可以使用证据服务，这样我们就可以通过API网关公开任何AWS
API｡
例如，在哪些应用程序中，
我们可以启动步骤功能工作流，
我们可以直接从API网关API向SQS发布消息｡
你为什么要这么做？
因为您可能希望添加身份验证､
公开部署一些API或对一些AWS服务进行一些速率控制｡
下面是一个与AWS服务一起使用的API网关示例｡
举个例子，Kinesis数据流｡
因此，我们希望人们以安全的方式将数据发送到Kinesis数据流中，
而不授予他们访问AWS凭据的权限｡
因此，我们要做的是在客户端和Kinesis数据流之间，
我们将使用API网关｡
客户端将HTTP请求发送到API网关｡
它被配置为将信息发送到Kinesis数据流中｡
正如您在此设置中看到的，我们不管理任何服务器｡
然后是Kinesis数据流，
例如，我们可以将记录发送到Kinesis Data
Firehose中，并最终以JSON格式将其放入Amazon
S3桶中｡
因此，您开始看到API Gateway的强大功能｡
实际上，您可以通过API网关向外部公开任何AWS服务｡
有三种方法可以部署您的API网关｡
这称为端点类型｡
因此，第一种类型（默认类型）称为“边缘优化”｡
这是为您的全球客户准备的｡
因此，这意味着您的API网关将可以从世界上的任何地方访问｡
为了提高效率，请求将通过所有CloudFront
Edge位置进行路由，这将改善延迟｡
您的API网关仍然只位于您创建它的一个区域，
但可从每个CloudFormation Edge位置高效访问它｡
然后是区域部署｡
因此，这是我们不想使用CloudFront
Edge位置的时候｡
因此，我们希望所有用户都在我们创建API网关的同一区域内｡
如果您愿意，
您可以创建自己的平台分发，这将为您提供与边缘优化分发相同的结果，但这一次您可以更好地控制位置策略和平台设置本身｡
最后，您可以使用的最后一种API网关是私有API网关｡
所以这次不公开｡
因此，只能从VPC内部访问私有API网关｡
它将使用ENI的接口VPC端点｡
要定义对API网关的访问，
您可以使用资源策略｡
现在，我们来谈谈API网关的安全性｡
因此，您可以通过多种方式在API网关上识别用户｡
第一种方法是通过IAM角色｡
因此，如果您有内部应用程序（例如，运行在EC2实例上的应用程序），
并且它们希望访问API网关上的API，
这将非常有用，它们可以只使用IAM角色｡
如果你想拥有外部用户，例如，
移动应用程序或Web应用程序，那么你会使用一种叫做Amazon
Cognito的东西｡
或者，如果您希望实现自己的逻辑，
则可以使用自定义授权器来实现｡
这是一个Lambda函数｡
此外，您还可以通过与AWS证书管理器或ACM服务集成，
通过自己的自定义域名获得HTTPS安全性｡
因此，如果您使用的是边缘优化端点，
则该证书必须位于us-east-1，但如果您使用的是区域端点，则该证书可能与API网关阶段位于同一区域｡
最后，当然，您必须在Route
53中设置一个CNAME或A别名记录，
以指向您的域和API网关｡
这节课就讲到这里｡
希望你喜欢｡
我们下节课再见｡ 
  - [ ] 366 API Gateway Basics [09:32] Hands On
    * 
  - [ ] 367 [DVA-C02] API Gateway Stages and Deployment [04:01]
    * 
讲师：我们已经在部署阶段通过API
Gateway部署了第一个API｡
因此，我们所看到的是，
无论何时我们对API网关进行更改，直到我们进行部署，
这些更改才会生效｡
所以我们需要做一个部署来让它们生效｡
这是一个常见的困惑来源｡
有些人会去改变API的工作方式，
但忘记进行部署，因此API将不会生效｡
因此，这些更改被部署到各个阶段，您可以拥有任意多个阶段，
也可以使用您想要的命名｡
例如，您可以使用dev､ test和prod阶段，或者使用v1､
v2､ v3来执行任何您想要执行的操作｡
每个阶段都将获得自己的配置参数，并且可以无缝地回滚，
因为在一个阶段上发生的所有部署的完整历史记录都被保留下来｡
让我们举一个例子，我们有两个阶段，我们正在创建一个突破性的API更改｡
因此，支持API网关的Lambda函数将发生变化｡
我们有了v1阶段，
它调用了v1函数，我们已经部署了它，
因此我们的v1客户端将能够通过此URL访问我们的API｡
但是我们正在编写一个新版本的Lambda函数，
名为v2｡
而此v2不考虑相同的数据格式等，
因此我们知道，如果我们在v1阶段部署更改，
它将破坏我们的v1客户端｡
所以我们要做的是创建一个新的stage，
称之为v2 stage，指向v2函数｡
这将创建一个新的URL｡
现在是API｡ 例子｡ com/v2，
其表示v2阶段｡
最酷的是我们的客户端现在可以升级到第二版并访问这个新的URL，
我们可以保持兼容性｡
所以在一段时间内，v1和v2可以作为两个不同的阶段共存｡
我们可以将客户端从版本1迁移到版本2，
然后当没有更多客户端使用版本1时，
我们可以将其关闭并继续使用API网关｡
这是一个非常常见的阶段使用案例｡
现在，我们如何扩展它？
我们可以使用阶段变量｡
因此阶段变量就像环境变量一样，
但是用于API网关阶段｡
并且您可以使用它们来更改配置值，而无需重新部署API｡
所以它们可以用在，例如，
Lambda函数ARN中，
用于HTTP端点，用于参数映射模板｡
所以你可以通过阶段变量改变很多东西｡
用例是自动配置与您的stages通信的HTTP端点｡
是dev､ test和prod，
还是通过映射模板将配置参数传递给Lambda函数，
或者指向正确的Lambda函数，我们稍后将看到｡
这些阶段变量将被传递给Lambda函数中的contact对象，
这样我们就可以记录它，并直接从Lambda函数中访问阶段变量的值｡
现在，在APIGateway中访问阶段变量值的格式是带有S的$stageVariables｡
变量名称｡
这是阶段变量的一个非常常见的用例｡
因此，我们将创建一个stage变量，
它将指示API Gateway应该调用的相应Lambda别名｡
因此API Gateway会自动调用正确的Lambda函数｡
这里有一个例子｡
我们让dev stage指向dev别名，
而dev别名本身将100%的流量指向最新的Lambda版本｡
我们有一个指向Lambda函数的测试别名的测试阶段，
它指向Lambda函数的v2版本｡
最后，prod别名也链接到prod
stage和pointing，但这次，v1上的95%和v2上的5%｡
因此，在本例中，我们可以通过更新不同版本上的百分比在后端进行Lambda别名更改，
但不需要更新API Gateway｡
每个阶段都指向正确的别名，并且每个别名都将重定向到正确的Lambda函数｡
这是API网关的一个非常常见的模式，
我们将在下节课中重新练习｡
下节课再见｡
  - [ ] 368 API Gateway Stages and Deployment [07:51] Hands On
    * 
  - [ ] 369 API Gateway Stages Configurations [01:24] Hands On
    * 
  - [ ] 370 API Gateway Canary Deployments [01:17]
    * 
教师：现在，我们来讨论一种在API网关上执行Canary部署的方法｡
因此，您需要启用一种方法，在对API网关所做的更改上测试少量流量｡
所以通常是在生产中完成的｡
因此，
您可以选择金丝雀通道将接收的流量百分比，这将允许您通过后端Lambda函数或类似的东西测试新版本，例如API网关｡
假设我们的产品阶段当前指向版本1，而我们的客户希望能够测试新版本｡
因此，我们将为版本2创建一个prod stage
canary，
这样做的目的是，我们将允许客户端将例如95%的流量转到现有的prod stage，
我们知道该stage有效，并且在后台自动将5%的流量转到canary stage｡
这样，
我们就可以测试所有更改､ 查看指标､
查看日志､ 查看所有内容，
也许还可以进行调试，看看是否一切正常，如果我们有信心，我们就可以将超过100%的流量转移到金丝雀阶段｡
在本例中，指标和日志是分开的，
这样做是为了更好地进行监控｡
您可以覆盖任何您希望用于canary stage的stage变量，
这相当于使用Lambda和API网关执行蓝/绿色部署｡
让我们来亲身体验一下这是如何实现的｡ 
  - [ ] 371 API Gateway Canary Deployments [03:42] Hands On
    * 
  - [ ] 372 [DVA-C02] API Gateway Integration Types & Mappings [05:53]
    * 
讲师：现在我们来讨论一下将API
Gateway与后端集成的不同方法｡
第一种类型是集成类型MOCK，
它只返回响应，
甚至不向后端发送请求｡
因此，当您正在对API Gateway进行编程和配置，
并且还不想在后端进行任何工作时，
这是非常有用的｡
所以正如你所料，这不是用于生产的东西｡
这只是用于开发和测试｡
然后我们有HTTP或AWS
Lambda和其他服务，API
Gateway将在其中转发我们的请求，但我们可以修改它｡
因此，我们必须配置所谓的集成请求和集成响应｡
当您进行设置时，
我们可以使用映射模板为请求和响应设置数据映射｡
嗯，这意味着我们将能够更改向后端发出的请求，
并在将响应发送到客户端之前更改从后端返回的响应｡
所以这真的很有帮助｡
例如，如果我们创建一个REST API和API网关，
并添加映射模板，然后通过更改､
重命名､ 重新排序将此REST API调用映射到SQS队列上的API调用，
SQS队列等所有这些东西都可以理解API网关发出的API调用｡
所以在这里，API网关有能力改变请求和响应｡
好吧，这不是我们所看到的｡
到目前为止，我们已经看到了一个名为AWS代理的集成，
它意味着Lambda代理，
其中来自客户端的请求将成为Lambda的输入｡
我们没有修改任何请求或响应，因为我们不能，
它是一个代理｡
因此函数只负责请求和响应的逻辑｡
这意味着我们不能使用任何映射模板，
不能更改头､ 查询字符串参数｡
所有这些都将作为参数直接传递给我们的函数｡
这就是我们所看到的｡
因此，当我们登录Lambda时，
我们的请求来自API网关，因此我们记录了事件，
我们可以看到类似于此的相邻文档｡
因此，我们有关于资源､
路径､ HTTP方法､ 头､ 查询字符串参数等的信息，以及阶段变量､
主体和所有其他内容｡
所以这很有帮助｡
然后我们的Lambda函数负责接收这个请求，
了解如何处理它，然后Lambda函数可以返回一个响应｡
我们也设计了这样的回应｡
因此，我们指定了状态码，
指定了头，以及主体｡
因此，在此代理集成中，
所有工作都在后端，API网关只是用于代理请求｡
最后一种集成类型叫做HTTP代理｡
在这种情况下，同样因为这是一个代理，
我们没有任何映射模板，请求本身直接传递，所以代理到后端｡
然后，当后端回复时，
API将再次代理该响应以返回到客户端｡
如果您愿意，可以添加HTTP头（如果需要）｡
例如，您可以在API Gateway和反手之间添加一个API密钥，
但您的用户看不到它｡
让我们举个例子，
一个客户端向API网关发出HTTP请求｡
您将把该请求代理到后端，例如应用程序负载均衡器｡
但是，正如我所说的，
您可以添加可选的HTTP标头，例如API密钥，
它可以真正保证您的API调用能够正常工作｡
因此，客户端不需要知道API密钥，
但您的后端将看到它来自API网关｡
因此，映射模板来修改请求和响应，它们仅适用于我们在AWS或HTTP中集成的情况，
但不使用代理方法｡
因此可以用它们来修改请求和响应｡
使用它，我们可以重命名或修改查询字符串参数，
修改正文内容，添加或修改标题｡
为了做到这一点，它使用了一种叫做VTL的东西｡
Velocity模板语言允许我们得到for循环，
if，等等｡
它是一种用于修改某些请求的脚本语言｡
最后，当我们收到响应时，
我们可以再次使用映射模板从响应中删除一些结果｡
最后，要设置映射模板，必须将内容类型设置为application/json或application/xml｡
因此，考试中可能出现的映射模板的一个具体应用是如何通过API网关将客户端与SOAP
API集成｡
那么什么是SOAP API呢？
SOAP API是基于XML的，我们知道REST
API是基于JSON的｡
因此，我们需要在JSON和XML之间进行转换｡
因此，您可以使用映射模板创建API网关，
客户端将与API网关中的JSON交互｡
但是，由于映射模板，您的API网关可以将此有效负载转换为XML有效负载，
转换为SOAP API，然后再转换回来｡
在这种情况下，
API Gateway应该从请求中提取数据（路径､ 负载或报头），
然后构建后端理解所需的SOAP消息，这就是我们使用映射模板的地方，然后调用SOAP服务并接收XML响应，最后将XML响应转换回所需格式以响应用户｡
下面是另一个示例，我们使用映射模板来使用查询字符串参数｡
因此，我们的客户端与API Gateway集成，
后者直接使用Lambda，而不是作为代理｡
因此我们希望能够映射查询字符串参数，
如果我们发送这样一个带有问号､ name equals
foo和其他等号的请求，我们希望能够在传入Lambda之前重命名这些查询字符串参数，以便创建一个映射模板，然后传入Lambda函数的JSON可以是我的变量foo和其他变量bar｡
在这个例子中我所做的就是重命名变量，
这样你就可以把它们映射到任何你想要的东西｡
这也是映射模板的另一个用例｡
理论就到这里｡
现在，让我们进入实践，看看它们是如何工作的｡ 
  - [ ] 373 API Gateway Mapping Templates [03:56] Hands On
    * 
  - [ ] 374 [DVA-C02] API Gateway Open API [02:51]
    * 
讲师：API网关与OpenAPI规范紧密集成｡
那么什么是OpenAPI规范呢？
这是定义REST API的一种非常常见的方式，
API定义本身就是代码｡
你能做的就是用OpenAPI模型3创建这个规范｡
0，
然后导入到API网关中｡
因此，您需要定义方法､ 方法请求､
集成请求､ 方法响应以及可以为API网关设置的任何AWS扩展｡
您可以直接从API规范中设置这些扩展的每个选项｡
类似地，您可以在API Gateway中获取现有API并将其导出为OpenAPI规范，
而不是将内容导入到API Gateway中｡
为什么？
嗯，因为这个规范可以用来，
例如，生成客户机代码｡
因此，这些OpenAPI规范可以用YAML或JSON编写，
然后当您使用它们时，您可以生成我刚才提到的客户端SDK｡
因此，除了API网关和OpenAPI规范之间的一对一映射之外，
您还可以使用OpenAPI规范在API网关中执行请求验证｡
因此，其思想是，
API Gateway可以验证它是否对应于正确的模式，
而不是将有效负载原样发送到后端｡
因此，如果它不符合正确的验证，
调用者会直接得到一个400错误，这减少了对后端的不必要调用｡
因此，您可以检查请求参数是否在URI､
查询字符串中，您可以测试头是否存在，
以及它们是否为非空｡
然后，您还可以查看有效负载是否符合方法的指定JSON
Schema模型｡
所以现在您只需验证后端在解析和使用该有效负载时不会出现任何问题｡
那么我们该怎么做呢？
我们设置了一个OpenAPI定义文件，其中包含一个x-amazon-apigateway-request-validator｡
在这里我们可以定义我们想要验证的东西，
主体，所有方法上的参数，一些方法上的参数，
等等｡
因此，您可以在所有API方法上启用仅含参数的验证器，
也可以只在POST /validation方法上启用所有验证器，
或者您想要的任何方法｡
因此，您可以自由地验证API上的任何内容｡
希望这是有道理的｡
希望您能看到将OpenAPI与API
Gateway配合使用的强大功能｡
我希望你们喜欢，我们下节课再见｡ 
  - [ ] 375 [DVA-C02] API Gateway Open API [01:49] Hands On
    * 
  - [ ] 376 API Gateway Caching [04:07]
    * 
解说员：现在我们来讨论一下如何在API网关中启用响应缓存｡
那么，什么是缓存？
我们所知道的一切｡
缓存是为了减少对后端的调用次数｡
因此，这意味着当我们的客户端与API网关通信时，
API网关将首先检查缓存，
如果缓存中已存在结果，则返回该结果｡
否则，
如果出现缓存未命中，它将与后端通信以获得响应｡
因此，我们的想法是充分利用大量该高速缓存来减轻后端的压力｡
因此，默认的TTL（即结果在该高速缓存中的生存时间）为300秒｡
所以五分钟，但min是零｡
这意味着没有缓存，最长为一小时｡
高速缓存是在阶段级别定义的｡
因此，
您可以为每个阶段定义一个缓存，并且可以覆盖每个方法该高速缓存设置｡
因此，
如果您希望某个方法不使用缓存，也可以在方法级别指定它｡
该高速缓存可以加密，缓存大小介于0｡
5千兆字节一直到237千兆字节｡
该高速缓存非常昂贵，因此只有在生产环境中才有意义｡
例如，
如果您在开发或测试环境中，它们可能没有意义，因为无论如何，在您的后端上完成的请求并不多｡
因此，缓存实际上是您希望在生产或预生产中使用的东西｡
现在，我们如何使该高速缓存无效？
因此，您可以立即从UI中使整个缓存无效｡
或者，客户端可以使用放置在API网关中的名为Cache-Control max
H等于零的查询中的标头来使该高速缓存无效｡
要使客户端执行此操作，他们需要适当的IAM授权｡
因此，这是一个IAM策略，
它允许客户端使特定资源上该高速缓存无效｡
如果您不强制实施InvalidCache策略，或者如果您在咨询中不需要授权，则任何客户端都可以使API缓存无效，
这可能会造成灾难｡
现在您已经了解了有关缓存的所有知识｡
让我们来看看它是如何工作的｡
现在，我们进入生产阶段，
在这里我可以启用API缓存｡
现在，如果您确实启用了缓存，只需知道它会增加成本，
并且不包括在空闲层中｡
因此，如果您希望保持一个非常低成本的API网关和帐户计费，这可能不是您想要做的事情｡
因此，高速缓存容量可以从0｡
5千兆字节一直到237｡
我不知道为什么我在这里看不到它，
但它可以一直到237 GB｡
您可以加密该高速缓存数据｡
我们还可以在该高速缓存中设置默认的生存时间｡
例如60秒｡
然后，我们可以执行每个缓存的失效｡
那么，我们是否允许客户端使该高速缓存无效呢？
如果是这样，我们是否需要授权？
如果没有，则任何客户端都可以使该高速缓存无效，
这可能是一个大问题｡
或者，
如果您需要授权，那么如果请求未被授权，该怎么办｡
所以我可以说，
现在你不需要授权，但这取决于你｡
完成此操作后，
将为您创建缓存，您将保存所做的更改，就这样｡
现在已为我的舞台启用该高速缓存｡
因此我可以在每个方法级别编辑该高速缓存设置｡
例如，对于房屋，如果我不想对房屋方法进行缓存，那么我可以覆盖此方法，
在这里，我可以向下滚动，对于该高速缓存设置，
我可以禁用缓存方法｡
或者，我们可以更改TTL，
或者只是选择不加密或选择不要求授权｡
因此，
实际上，您可以自定义所有内容，但每个方法都可以针对该高速缓存进行自定义｡
所以这很好｡
这就是我们在API网关上启用缓存的方式，这对我们来说是无缝的，
所以如果我们进入生产环境并打开它｡
正如我们现在看到的，
我们从Lambda v2得到Hello｡
如果我刷新，它将从缓存中获取｡
同样，该高速缓存中获取结果，这次不要调用Lambda函数，
因为缓存设置会缓存该结果｡
现在，我不想产生任何费用，所以我将禁用API缓存并保存我的更改｡
给你｡
非常简单，但是API网关缓存是一个相当强大的特性｡
好吧，就这样｡
我们下节课再见｡ 
  - [ ] 377 API Gateway Usage Plans & API Keys [08:17]
    * 
讲师：我们现在已经创建了API，现在是时候让客户使用它了，我们可能会向他们收取一些费用｡
因此，有一个使用计划和API密钥的概念｡
因此，
我们创建一个使用计划，在其中定义谁可以访问一个或多个API阶段和方法､
他们可以访问的数量和速度，以及哪些API密钥与此使用计划相关联，以识别客户端并计量其访问｡
然后，我们还可以配置带宽限制｡
那么，他们的用户可以以多快的速度瞄准我们的API，以及配额，
如果我们只是想说，例如，
在你需要支付更多费用之前，
我们的API每月只能完成10，000个请求｡
然后我们可以创建API密钥｡
这些只是要分发给客户的字符串，它们看起来像这样｡
这些API密钥允许您的客户安全地使用您的API网关，并验证他们的请求｡
您可以将此功能与使用计划结合使用来控制访问｡
如果您启用了任何节流限制，则会应用API密钥级别｡
总的来说，配额限制是请求的总数｡
因此，通过使用使用计划和API密钥，
正如我们将在上机操作中看到的那样，
我们能够真正为客户监控､ 提供和限制API｡
那么，创建API密钥和使用计划的顺序是什么呢？
因此，
为了配置使用计划，您需要记住它｡
您需要首先创建一个或多个API，然后配置需要API密钥的方法，
最后将API部署到您的阶段｡
然后，您将生成或导入API密钥，
以分发给应用程序开发人员｡
因此，他们是您的客户，将使用您的API｡
然后，
您可以创建一个使用计划，其中包含所需的限制和配额限制｡
最后，您需要将API阶段和API密钥与使用计划相关联｡
这也是我们在这节课上要做的｡
而最后一步，如果你忘记了，
那么事情就不会起作用｡
最后，API的调用方必须在x-API-key头中提供API密钥，
请求进入API｡
因此，
为了让大家更清楚地了解这一点，让我们进入实际操作环节，练习使用计划和API密钥｡
因此，让我们继续创建将由API密钥控制的方法｡
因此，我将创建一个新资源，
在此演示中将其称为API key，
然后创建该资源｡
然后在下面，
我将创建一个方法，这个方法将是一个GET，以使事情变得简单｡
然后这个方法将是一个模拟，使事情变得更简单，
所以我们不需要与任何后端集成｡
我会按保存｡
如果你想知道Mock是怎么做的，
你可以测试它，然后按测试键，
它不会返回任何数据，但至少它会说是的，它工作了｡
因此，回到API执行，
我可以设置一个方法请求｡
在这里，我可以设置我的API密钥是必需的｡
是的，千真万确｡
所以现在在这个方法中，我需要一个API密钥来访问它，否则，
事情就不会正常工作｡
接下来，让我们定义使用计划和API密钥｡
因此，我将从左侧创建一个使用计划，
我将其称为演示计划｡
在这里，我可以同时启用节流和配额｡
节流是指每秒有多少个请求，
我希望得到最大值，可能是10个｡
而突发请求是指我允许客户查看的数量，以防他们有更多突发请求｡
所以也许五年｡
那么，我是否要启用配额？
我想答应你｡
你不能做超过10，000个请求每月，否则，
你会付出更多.
我将单击“下一步”，这是我的使用计划｡
但目前，它与任何阶段都没有关联｡
所以我可以把它和舞台联系起来｡
有了这个API，接下来就是生产阶段｡
现在请注意，我们尚未部署新的资源来进行prod，
因此它不会处于活动状态｡
所以我说是的，开始吧｡
而且，这与prod有关｡
尚未配置任何方法，
因此我们可以配置一个方法限制，但我们将在继续并部署API后执行此操作｡
因此，我将单击“下一步”，然后我们需要将API密钥添加到使用计划中｡
因此，
我需要首先创建一个API密钥，并将其添加到使用计划中，我也可以从左侧执行此操作｡
我将单击此按钮和此API密钥，这就是我的酷客户｡
所以我称之为酷客｡
在API项下，您可以获取自定义值，
也可以自动生成它｡
我会自动生成一个值，API网关会给予我一个值｡
然后按保存｡
因此，这个很酷的客户已经添加到我的使用计划中，然后我可以单击“完成”｡
现在，我们已经创建了第一个使用计划｡
因为我们可以看到，这与prod阶段有关，有速率､
突发和配额｡
我们可以转到API密钥并找到此API密钥｡
所以如果我做使用，我可以看到他们已经使用了多少次｡
因此，
目前什么都没有，通过扩展，我可以创建一个额外的扩展或请求API密钥｡
好的，
如果我单击此API密钥本身，我可以看到我们现在处于API密钥面板中，我可以显示此API密钥｡
这是我将发送给我的客户的内容，这样他们就可以开始使用我的API了｡
这很好，我的API密钥现在与我的使用计划相关联，
这非常重要｡
现在让我们来看看我的API｡
我会找到我的第一个API
我将部署此API，并将其部署到prod.
顺便说一句，
canary是启用的，所以我要禁用canary｡
所以我会去prod，然后去canary把它删掉｡
我们不再需要它了｡
然后返回到我的资源､ 操作､ 部署API､
生产和部署｡
现在，我的产品有一个API密钥路由，好的，
这需要一个API密钥来工作｡
这是我们从客户那里使用的API密钥｡
回到我们的使用计划｡
如果我们转到演示计划，我们可以配置方法节流，如果我们愿意，
可以说，
在它的顶部，这个API关键方法GET，每秒只能执行五个请求，
突发两个请求，所以我们真的能够探查它并测试它｡
有一个市场的概念，
在那里你可以直接在AWS市场上出售你的API密钥，但现在，这超出了范围｡
好的，现在如果我们转到stages，转到prod，
转到这个API密钥方法，
单击它，如您所见，我们会看到消息被禁止｡
这是因为我的API密钥没有被传递，因此一切都不起作用｡
所以现在我们必须让这个请求生效，因为我们被禁止了｡
正如你们现在看到的，我打开了一个叫做“失眠”的网站｡
所以Insomnia是REST的桌面客户端，
所以如果你去Insomnia或者REST，我强烈推荐下载这个｡
这是免费的，
所以这是使用，这将是一个REST客户端为我的桌面，使API调用到这个API，但我现在可以提供一些头｡
因此，
我将创建一个新请求，并将其称为API密钥示例｡
这将是一个GET，在上面，我可以输入这里的URL｡
如果我再次单击“发送”，
我将收到禁止发送的消息，就像我们以前一样｡
但是现在要使用API密钥，我可以继续在请求中指定API密钥头｡
因此，我首先需要为我的酷客户检索我的API密钥｡
这里是值，然后在Insomnia中，
在右侧，我将添加一个名为x-API-key的头，
其值是我的客户的API密钥｡
因此，我可以在这里传递值，现在我已经创建了一个头，
这是一个具有正确的API密钥值的请求头｡
如果我发送它，我会得到一个200，
我的请求现在工作｡
这是一个很酷的演示，因为这个API密钥只使用过一次｡
如果我们转到使用计划，转到演示计划，查看计量，我将转到API密钥，
然后单击使用，
我们可以看到，这将需要一段时间来反映｡
所以它说零个请求，但是很快，当它被我的API网关注册时，
它应该说一个请求｡
这就是API密钥背后的全部思想｡
现在，我可以看到发出了多少请求，可以为这些请求向客户收费，
还可以使用API密钥保护我的API｡
原来如此｡
我希望你们喜欢它，我们下节课再见｡ 
  - [ ] 378 [DVA-C02] API Gateway Monitoring, Logging and Tracing [05:03]
    * 
现在我们来讨论API网关日志记录和跟踪｡
因此，第一个选项是使用CloudWatch日志｡
当您启用CloudWatch日志与API网关集成时，
您将获得有关通过API网关的请求和响应主体的信息｡
如果您只想拥有ERROR日志､
DEBUG日志或INFO日志，
则可以在阶段级别启用它并定义日志级别｡
显然，DEBUG将为您提供最多的信息，
您可以根据每个API覆盖此设置｡
为了让大家明白，我们将让用户向API网关发出请求，
该请求将自动记录到CloudWatch日志中｡
然后，请求将发送到后端，
后端将向API网关提供响应，响应将再次发送到CloudWatch日志，
最后发送给用户｡
因此，获取请求和响应非常有用，但如果您启用此功能，
请小心，否则您可能会将大量敏感信息放入CloudWatch日志中｡
对于X-Ray来说，这是为了获取关于通过API网关的请求的跟踪信息｡
如果您为API网关和Lambda启用了X-Ray，
那么您当然可以了解API的全貌｡
然后可以使用CloudWatch指标及其每个阶段监控API网关，
并且可以启用详细指标｡
因此，在参加考试之前，你需要了解一些指标｡
第一个名为CacheHitCount，
另一个名为CacheMissCount，
它为您提供了有关缓存效率的一些信息｡
因此，如果您的缓存非常高效，
则缓存命中率将非常高｡
如果效率不高，缓存未命中率将非常低｡
计数是给定时间段内的API请求数｡
IntegrationLatency是API将请求中继到后端并等待从后端接收响应所需的时间，
因此它向您指示后端回复API网关所需的时间｡
延迟本身是API网关从客户端接收请求到向客户端返回响应之间的时间｡
这包括IntegrationLatency，
但也添加了API网关正在执行的任何操作｡
例如，这包括检查授权和身份验证､
检查缓存､ 创建一些映射模板等等｡
因此，延迟总是比IntegrationLatency高一点｡
因此，您应该注意到，
API网关可以执行任何请求的最长时间是29秒｡
因此，如果您的Latency或IntegrationLatency超过29秒，
这意味着您将看到API网关超时｡
这是两个，
这是两个非常好的指标｡
那么我们有两种错误｡
我们得到了一些与这些误差相关的指标｡
您有一个4XX指标，称为客户端错误｡
这就是我们在客户端得到的错误数量｡
以及5XXError，这是我们在服务器端得到的错误数量｡
因此，服务器端意味着后端，
客户端意味着使用API网关的客户端｡
好的，我们已经看到API网关可以对使用计划等进行一些节流｡
因此，我们还可以定义帐户限制，
默认情况下，您的API网关将在所有API中以每秒10，
000个请求的速度限制请求，例如软限制，并可根据请求增加｡
因此，这意味着如果其中一个API使用量很大，
其他API也会受到限制｡
如果您看到节流，您会看到什么？
您将看到错误代码429 Too Many Requests（429太多请求），
这是一个客户端错误，因为客户端执行的请求太多，并且可以重试，
但您应该使用类似指数回退的方法来重试这些请求｡
为了提高节流和性能，您还可以设置阶段限制和方法限制，
以确保每个阶段在受到攻击时不会使用请求的所有配额｡
或者，我们以前已经看到，如果我们希望能够按客户进行节流，
我们可以定义使用计划｡
因此，就像Lambda并发一样，如果一个API过载，
如果不限制，它可能会导致其他API被节流｡
我们已经在Lambda
Reserve并发和总体并发中看到了这一点，
但这也适用于API Gateway｡
好的，最后，让我们来讨论一下在API网关中可以看到的错误｡
所以4xx意味着客户端错误，所以客户端使用您的API网关.
403：访问被拒绝，或者Web应用程序防火墙没有接受您的请求｡
429，例如，如果您的配额已被超出，
并且您看到了一些限制｡
和任何与5XX，意味着服务器错误，所以你的后端.
例如，502表示您的Lambda代理集成响应不佳，
或者503表示后端不可用｡
或者504是存在集成失败，这些失败之一是API网关确实请求超时，
并且在29秒之后没有从后端接收到请求，因此我们返回504：由于该超时，集成失败｡
以上就是API网关监控｡
我希望你们喜欢，我们下节课再见｡
  - [ ] 379 API Gateway CORS & [08:33] Hands On
    * 
  - [ ] 380 API Gateway Authentication and Authorization [08:31]
    * 
这里有一个关于API网关安全性的相当沉重的讲座，但您应该掌握它，
因此我尝试包括尽可能多的图表｡
因此，第一种方法是使用IAM权限访问API网关｡
这是有道理的，
这就是我们目前所做的，我们使用IAM策略，
并将其附加到用户注册中，然后我们就可以调用API网关｡
因此，在本例中，身份验证是通过IAM完成的，
授权是通过IAM策略完成的｡
因此，如果在AWS帐户内访问API网关，这是保护API网关的最佳方式，
包括使用EC2实例､ Lambda函数或IAM用户等｡
为了将IAM凭据传递到API网关，
可以利用“签名前”功能，在该功能中，
将对八个凭据进行签名，然后将其放入头中｡
让我们举一个例子，
API网关被部署到一个stage中，并使用IAM权限进行保护，还有一个Lambda函数的后端｡
首先，
我们的客户端将执行一个rest API调用，我们将传递Sig
v4头，然后API网关知道如何解密这些头，
因此它将使用IAM检查用户是否获得授权，因此将进行IAM策略检查，一旦完成，
API网关将与后端的Lambda函数进行通信（如果获得授权），并将结果返回给客户端｡
所以有一个第一许可模式，它非常简单｡
现在，这可以与资源策略相结合｡
因此，资源策略听起来很像Lambda资源策略，
因为它们的目的完全相同，它们允许您在API网关上设置相邻策略，以定义谁和什么可以访问您的API网关｡
因此，资源策略的主要使用情形是使用跨帐户访问，
因此，我们将像这样定义相邻策略，并将其与IAM安全性相结合，
我们能够将其他帐户中的用户或角色的访问权限直接给予我们的API网关｡
因此，
这是针对跨帐户访问，但您也可以使用资源策略来筛选特定IP地址，或仅允许VPC端点｡
因此，这是第一类安全｡
第二类是关于Cognito用户群的，所以我们会在它自己的部分看到Cognito，
但Cognito在一个高层次上它是一个用户数据库｡
因此，
Cognito将全面管理用户生命周期，连接Cognito的令牌将自动过期，因此API网关将通过Cognito验证连接API的人员的身份｡
不需要自定义实现，因此在这种情况下，用户必须使用Cognito用户池进行身份验证，
然后在API网关方法级别设置授权｡
因此，如果我们看一下这里，我们的API网关正在与后端的Lambda函数进行通信，然后，
我们的客户端首先通过Cognito用户池进行身份验证，以检索连接令牌｡
因此，用户已经在重新启动用户池，
然后我们的客户端通过身份验证，他们收到了一个令牌，它将在API调用中将令牌传递给我们的API网关｡
现在，
API网关将与Cognito用户池直接集成，它将使用Cognito用户池评估Cognito令牌，如果令牌正确，它将允许访问您的后端｡
所以这是一种非常简单的安全性，我们将进行探索｡
最后一个是Lambda Authorizer，
以前称为Custom Authorizer，它是最灵活的，
但需要您的参与最多｡
因此，它是一个基于令牌的授权器，
带有一个不记名令牌，
看起来像一个JWT，也就是JSON Web令牌或Oauth｡
因此，
我们可以将基于请求的参数（带有标头或查询字符串）传递给Lambda授权程序，Lambda函数必须评估我们传递给它的内容，
如果它满意，则为发出请求的客户端返回IAM策略，该策略将被缓存｡
所以我将在图表中解释这一点，它会更清楚｡
所以这次的身份验证是外部的，所以你可以在任何地方对用户进行身份验证，
授权必须在Lambda函数中完成｡
这是一个图表，它应该更有意义｡
因此，
API网关有一个后端来实现该功能，我们的客户端首先通过第三方身份验证系统进行身份验证｡
例如，它可能偏离零｡
因此，
我们从第三方身份验证系统中检索一个令牌，然后将此令牌通过标头或请求生物识别技术传递给API网关｡
然后，API网关与Lambda Authorizer集成，
因此这是一个Lambda函数，它们将检索有关上下文的一些信息以及我们从中进行身份验证的令牌｡
Lambda函数是我们必须编写的内容，因此由我们来验证该令牌，可能与第三方身份验证系统进行通信以验证令牌的有效性，
如果令牌有效，则Lambda函数将返回，
并且必须创建IAM主体和IAM策略，并且一旦完成，它将被缓存到策略缓存中，
然后API网关将与Lambda后端通信｡
所以，正如你所看到的，Lambda
Authorizer涉及的内容更多，它主要在你使用第三方身份验证系统时使用｡
那么，我们需要记住什么进入考官？
谢天谢地，这只是一个高级别的安全性｡
如果您的帐户中已经创建了用户和角色，那么使用IAM安全性就非常好，如果您考虑进行跨帐户访问，
那么您需要在这些操作之上使用资源策略｡
它非常适合于以我们已知的方式处理身份验证和授权，而且它利用了Signature
v4作为一种技术｡
当您是第三方用户数据库时，自定义授权器非常有用，而且非常灵活，
因为我们可以选择将返回的IAM策略，并且需要在Lambda函数中启用和处理身份验证和授权｡
即使缓存了结果，
我们仍然要为Lambda调用付费，这可能需要一段时间｡
最后是Cognito用户池，我们在其中管理自己的用户池｡
我们将在Cognito部分了解如何管理｡
我们不需要编写任何自定义代码，
因此这是首选，我们必须在后端Lambda函数中自己实现授权｡
为了安全起见，现在我们进入控制台，
快速查看这些选项｡
让我们看一下安全选项，第一个选项是，
如果我们单击资源中的任何方法，然后单击方法请求，我们可以在此处设置授权，
现在我们可以访问的唯一选项是IAM，
这是检查IAM用户策略和角色，当我们的帐户中包含所有内容时，
这很有帮助，这是Sig v4｡
因此，
这可以结合使用，我不打算这么做，
但这可以与资源策略结合使用，因此可以在左手定义它们，这里我们有免费的模板｡
第一个是跨帐户资源策略，在这里，我们可以用另一个帐户的名称IG来替换，
这样我们将拥有一个允许跨帐户访问的资源策略，或者我们可以拥有一个IP范围黑名单，
以便禁止某些IP访问或不访问我们的API网关｡
最后，
如果您想授权另一个VPC进入我们的API网关，请选择Source
VPC Whitelist｡
因此，此资源策略（例如，此跨帐户访问加上ERIS
IAM类型的安全性）允许我们使用IAM完全控制访问我们API网关的用户｡
现在，我们可以设置其他授权程序，
在左手，我们可以创建一个新的授权程序，目前有两个新的授权程序，因此它可以是Lambda类型的授权程序，
即自定义授权程序，我们需要设置许多设置，您可以看到，
对于Lambda，最重要的是我们应该设置Lambda函数，这将是我们的授权器以及如何缓存授权，这是绝对推荐的｡
或者，
我们可以使用Cognito用户池，在这种情况下，
设置起来要简单得多｡ 我们只需发送Cognito用户池的ARN标识，然后单击“创建”，即可开始｡
现在的安全性是非常先进的，我只是想告诉你在控制台的选项，
如果你想有它玩它｡
但那只是对我而言｡ 我们下节课再见｡ 
  - [ ] 381 API Gateway REST API vs HTTP API [01:23]
    * 
讲师：好的，现在我们来讨论一下可以在API
Gateway中设置的不同API｡
到目前为止，我们一直在使用REST
API，但还有另外两种API｡
有HTTP API和WebSocket｡
我将从高层次上描述它们是什么｡
我不认为他们在考试中出现，
也许WebSocket，但只是，再次，在一个高水平｡
首先是HTTP API，它们是低延迟､ 经济高效的AWS
Lambda代理､ HTTP代理API和私有集成｡
如你所见，这都是代理｡
我们没有可用的数据映射｡
而且它只支持几种授权｡
那么，OIDC和Oauth 2｡ 0.
它还内置了对CORS的支持，但您不会找到任何使用计划或API密钥｡
因此，它们是API网关的一个非常低成本的替代方案｡
它们更新了，它们的名字很可怕，
它们只是更简单｡
REST API具有我们在本课程中看到的所有功能，
除了原生OpenID连接､
Oauth 2. 0.
因此，您可以找到一个突出HTTP和REST
API之间差异的链接｡
但在考试中，您必须记住的是，
HTTP API将比REST
API便宜得多｡
而且他们在支持方面也有轻微的差异｡
例如，REST API支持资源策略，而HTTP
API不支持｡
好吧，就这样了｡
我希望你们喜欢，
我们下节课再见｡
  - [ ] 382 API Gateway Websocket API [06:44]
    * 
导师：我们来讨论一下，WebSocket API与API网关｡
那么什么是WebSockets呢？
WebSocket，无论何时你看到它，
它都意味着在用户的浏览器和服务器之间有一个双向的交互通信｡
它是双向的，因为服务器，
它可以选择将信息推回客户端，而无需客户端向服务器发出请求，明白吗？
因此，这支持有状态应用程序用例｡
因此，WebSocket API通常会用于真实的应用程序，
如聊天应用程序､ 协作平台､
多人游戏和金融交易平台｡
因此，在聊天应用程序的上下文中，客户端将连接到API网关上的WebSocket API，
并将建立持久连接｡
因此，没有多个连接，只是我们的连接是开放的，
并且API网关连接到客户端｡
然后在第一个连接上有一个Lambda函数，叫做onConnect｡
您可以执行任何您想要的操作，例如将连接ID持久化到DynamoDB中，我们将在后面的幻灯片中详细了解｡
然后，每当客户端选择通过这个持久连接发送消息时，
它就可以调用一个新的Lambda函数sendMessage｡
最后，
当客户端发送了很多消息并想要断开连接时，你将向Lambda函数onDisconnect发送一条消息｡
因此，我们可以使用后端中的任何类型的集成API网关｡
它可以是Lambda函数，
也可以是DynamoDB表，或者HTTP端点，或者任何你想要的东西？
其思想是有一个WebSocket API｡
因此，我在此图中没有显示如何将数据发送回客户端｡
但我现在将在幻灯片中向大家展示WebSockets如何工作的细节，因为我认为理解这一点和理解考试的问题对你们来说很重要｡
有一个以wss开头的WebSocket URL，它是一个加密的WebSocket
URL｡
看起来好像有个唯一的ID｡ 执行api｡ 区域中｡ 亚马逊人｡ com/艺名｡
这就是您部署WebSocket API的时候｡
因此，客户端将连接到您的WebSocket
API网关，并与之建立持久连接，
该连接将调用Lambda函数并执行连接ID｡
只要客户端连接到API网关，连接ID就将保持持久性｡
例如，连接ID可以持久保存到AmazonDynamoDB中，
以存储一些元数据，例如用户是谁､ 用户是什么｡
然后，客户端希望向服务器发送一些消息｡
所以我们将使用我刚才给你们的那个网址，这里有一些虚拟数据｡
并通过持久连接将消息发送到WebSocket API中，这些消息称为帧｡
这些帧将调用一个新的Lambda函数，我们将在几分钟后看到路由是如何工作的｡
但连接ID将是相同的｡
因此，Lambda函数可以与DynamoDB交互，
以基于连接ID检索用户信息，执行任何它想要的操作，并可能将一些消息持久化回DynamoDB中｡
因此，
如果客户端选择通过WebSocket API上的API网关发送更多消息，则只会通过同一连接向其发送更多帧｡
因此连接ID不会改变，当调用Lambda函数时，它会被重用｡
现在，服务器（即我们的API网关）如何在客户端不发出请求的情况下与客户端进行通信？
同样，
我们使用相同的WebSocket URL，
并执行与发送消息相同的操作，但现在我们希望返回一些数据｡
当你有一个API网关，
一个连接URL回调，它看起来像这样，它看起来像URL，
但是斜杠添加了连接，/connectionid｡
如果Lambda函数或其他函数通过指定客户端的连接ID，向此连接URL回调发送一个使用IAM Sig v4签名的HTTP
post，则它将从API网关向客户端发送回一条消息｡
这允许双向通信，
这解释了你如何可以明显地设置一个聊天应用程序，因为你可以选择发送消息，也可以接收消息｡
现在，
对于这个URL的操作，即非常具体的/connectionsid
URL，您可以执行post，将消息从服务器发送回连接的WebSocket客户端｡
您可以执行GET来获取已连接的WebSocket客户端的最新连接状态，
如果您希望它断开客户端与WebSocket连接的连接，则可以执行DELETE｡
最后，客户端如何知道要调用哪个Lambda函数或要调用哪个后端？
在WebSocket中，有一个路由的概念｡
因此，传入的JSON消息将被路由到不同的后端｡
如果您不指定路由，它将被发送到默认路由｡
因此，
您可以选择，您可以创建一个路由选择表达式来选择JSON上要从中路由的字段｡
让我们看一个具体的例子｡
比如说，从客户端传入API的数据如下所示，
服务是聊天，
操作是加入，数据是房间，房间1234｡
然后，我们有一个在API网关级别定义的路由关键字表｡
我们定义连接､ 断开､ 默认（强制路由），
然后定义客户路由：加入退出删除等等｡
如果我们指定示例表达式为API网关，$request｡
身体｡
action，它将查看传入数据的action字段，
该字段当前为join｡
因此，该表达式的结果将根据API网关中可用的路由关键字表进行评估｡
我们可以看到连接路由确实存在｡
因此，
API网关知道这个路由连接到一个特定的后端，它可以是一个Lambda函数，或者是API网关集成的任何其他东西｡
如果没有匹配的路由，则将使用默认路由｡
以上就是WebSocket API的工作方式｡
我给予你的信息比你进入考试所需要的要多，但我认为对你来说，
在高水平上理解这是如何工作的是非常重要的｡
因此，
从考试的角度来看，只需记住WebSocket API是用于双向通信的，您需要了解它的路由｡
路由用于确保您可以根据路由表达式路由到特定后端，
因为连接已经打开，并且路由应该是传入数据消息的一部分｡
原来如此｡
我希望这能帮上忙，下节课再见｡ 
  - [ ] 383 API Gateway Websocket API [08:00] Hands On
    * 
  - [ ] 384 API Gateway - Architecture [01:44]
    * 
教师：我来简单介绍一下可以通过API网关实现的微服务架构｡
所以多亏了API网关｡
您可以为公司中的所有微服务使用一个接口，并且可以在后端使用具有各种资源的API端点｡
因此，您可以为客户隐藏复杂性｡
也就是说，
我们有一个API网关和一个/service1路由，它将数据发送到一个弹性负载平衡器，该平衡器支持一个实际的微服务ECS集群｡
或者，我们可以让/docs发送包含一些研究内容的S3桶｡
例如，您的服务文档，
或/service2将ELB连接到Amazon EC2 Auto
Scaling组设备群｡
好吗？
因此，所有这些都允许您定义这些路由，
并将API网关用作单个URL来连接到这些服务｡
然后我们可以使用路由53来注册一个域，而不是API网关的DNS｡
这也允许我们根据客户端给予一些自定义地址｡
那么，客户1｡ 示例中｡
com为其中一个客户端，或customer2｡ 示例中｡ com的第二个客户端｡
我们可以根据这些域应用SSL证书｡
我们还可以在API网关中应用转发和转换规则，以便在将传入数据发送到后端之前对其进行修改｡
我向您展示这张幻灯片，只是为了向您展示可以使用API网关实施的体系结构类型｡
其思想是您希望统一您的微服务并给予一个外部统一URL｡
同时隐藏路由到服务的所有复杂性｡
转换数据并指定SSL证书｡
所有这些都是在API网关级别完成的｡
所以我希望这是有帮助的｡
我们下节课再见
  - [ ]  API Gateway [17 问题] Quiz
    * 
 ## Section 25 - AWS Serverless: SAM - Serverless Application Model [14 个讲座 • 1 小时 4 分钟]
  - [ ] 385 AWS SAM - Section Introduction [00:50]
    * 
好的，我们知道如何以无服务器的方式将适当的API部署到云中｡
但我们如何管理一切呢？
我们可以用云阵但它会很复杂.
AWS开发了一种叫做SAM的东西｡
SAM将允许我们基本上按照应用程序的行为和部署方式编写YAML文件和模板｡
这基本上是一个捷径，做CloudFormation，但它是非常自然的处理作为一个开发人员，
它正在成为一个越来越受欢迎的服务在AWS｡
考试只会询问您有关SAM的非常基本的问题｡
所以你可以看完下一节课就完事了｡
但我想增加一些额外的讲座，因为我希望您了解如何使用SAM进行实际应用｡
我希望你喜欢这节课和这一部分｡
我们开始吧
  - [ ] 386 SAM Overview [04:06]
    * 
Stephane：那么，现在我们来谈谈SAM，即无服务器应用程序模型｡
现在，这真的很酷，
因为我们将看到SAM如何将我们迄今为止看到的所有无服务器开发重新组合到一个工具中｡
SAM是一只小松鼠，它的意思是无服务器应用程序模型｡
它是一个将用于开发和部署无服务器应用程序的框架，所有配置都将在YAML中完成｡
现在，我们的想法是，从这个简单的YAML，
您将使用SAM CLI生成非常复杂的CloudFormation模板｡
因为它与CloudFormation兼容，所以任何CloudFormation构造都可以工作｡
例如，输出､
映射､ 参数､ 资源，所有这些都在SAM中工作｡
现在，只有两个命令可以部署到AWS，
您必须了解它们，所以我将复习它们，
考试将测试您是否使用它们｡
然后，我们将在另一个讲座中看到，SAM可以使用CodeDeploy来部署Lambda函数，
并确保我们在Lambda函数版本之间逐步转换流量｡
最后，我们将在本讲座中看到，SAM可以帮助您在本地运行Lambda､
API Gateway和DynamoDB，
因此您无需部署到AWS即可开始测试应用程序｡
那么，什么是菜谱呢？
SAM有一个YAML模板，在它的顶部，你会发现这个转换头，
AWS
Serverless 2016 10 13.
这意味着这是一个SAM模板，然后CloudFormation将足够智能，知道如何将此模板转换为CloudFormation模板｡
因此，我们将编写一些代码，在SAM
YAML文件中提供了一些附加结构｡
因此，我们可以使用AWS无服务器函数，
它将成为后端的Lambda函数，无服务器Api，
它将成为API网关，
以及无服务器SimpleTable，它是DynamoDB表｡
因此，它们旨在帮助您更快地创建函数､ 数据库和API网关｡
接下来，要打包和部署SAM，需要两个命令｡
第一个是aws cloudformation包，
或者简称为sam包，
然后第二个是aws cloudformation
deploy，或者简称为sam deploy｡
就是这么简单｡
考试会说，我怎么部署？
第一个是sam
package，第二个是sam deploy｡
让我们深入了解一下这些命令｡
我们有一个SAM模板，它是用YAML编写的，还有我们的应用程序代码，我们将执行一个sam
build来在本地构建应用程序，它将创建一个转换后的CloudFormation模板和我们的应用程序代码｡
然后，
我们将运行sam包，或aws cloudformation包，
压缩并上传我们的函数，并将其上传到S3桶中｡
因此，CloudFormation模板和我们的应用程序代码都将被上传｡
然后，使用sam deploy命令，
部署应用程序｡
从S3存储桶开始，
它将在CloudFormation上创建并执行ChangeSet，以开始部署我们的应用程序｡
然后，CloudFormation将部署我们的Lambda函数､
API网关和DynamoDB｡
所以看过程非常重要｡
因此，SAM模板使用sam build转换为CloudFormation，
然后使用sam package命令打包到Amazon S3中，
然后使用sam deploy命令部署到CloudFormation上｡
如果您真正理解了此图，您将在考试中解决大多数SAM问题｡
另一个问题是，如何在本地运行Lambda？
要在本地运行Lambda函数，您可以使用SAM
CLI，因为SAM
CLI能够在本地为您提供类似Lambda的执行环境｡
它是怎么做到的？
我们使用SAM CLI和AWS工具包，
它们允许我们逐步执行代码并进行调试｡
因此，您无需在云上部署Lambda函数，然后逐步执行或尝试查找失败的地方，您可以直接在本地计算机上进行所有您习惯于进行的开发，
而无需部署到AWS｡
因此，SAM CLI具有适用于各种不同IDE的工具包｡
所以我们有Cloud9､ Visual Studio代码､ JetBrains､
PyCharm､ IntelliJ等等｡
这两个功能一起允许我们在本地运行Lambda函数，
然后使用我们喜欢的工具在本地进行调试，例如，逐行执行代码｡
这些工具包使SAM能够在本地调用Lambda，明白吗？
这就是SAM的介绍｡ 希望你喜欢｡
在下一节课中，我们会用它来做一个游戏｡ 
  - [ ] 387 Installing the SAM CLI [01:54]
    * 
  - [ ] 388 Creating first SAM Project [04:12]
    * 
  - [ ] 389 Deploying SAM Project [06:05]
    * 
  - [ ] 390 SAM API Gateway [06:24]
    * 
  - [ ] 391 SAM DynamoDB [08:34]
    * 
  - [ ] 392 SAM - CloudFormation Designer and Application Repository [02:36]
    * 
  - [ ] 393 SAM Policy Templates [02:10]
    * 
教师：下面我们来讨论SAM策略模板或无服务器模型策略模板，因为它们也可能出现在考试中｡
这是一个模板列表，你可以将权限应用到Lambda函数｡
因此，它们是非常简单的模板，它们允许你很容易地推理出你的Lambda函数可以做什么，基于这些模板，
重组一组权限｡
此链接上提供了所有SAM策略模板的完整列表，其中有很多模板，
但我想向您介绍三个重要的示例｡
总的来说，一旦你看到他们一次，
他们的所作所为就非常明确了｡
例如，
如果我们有S3ReadPolicy，这是一个为S3中的对象提供只读权限的策略模板｡
这有道理，对吧？
SQLPollerPolicy允许您的Lambda函数轮询SQS队列｡
还有DynamoDBCrud, C-R-U-D，政策｡
在这种情况下，C-R-U-D表示创建､ 读取､ 更新､ 删除｡
因此，
这意味着您可以通过Lambda函数对DynamoDB表执行创建､ 更新､ 删除和读取操作｡
总的来说，
它是非常明确的，但一旦你看到它是如何定义的，它就有了很大的意义｡
比如说，我们定义一个函数｡
它运行的是Python 2｡
7，我们希望能够从SQS读取｡
在本例中，
我们所做的不是附加I-A-M角色，而是创建SQS｡
我们在这个小橙子框中将策略称为SQSPollerPolicies，
并说“好的，我们希望能够轮询此队列名称，
并且当SAM策略模板已由SAM框架转换时，它将自动成为附加到Lambda函数的IAM策略｡
使用SAM策略模板的想法是，编写您的功能应该做什么变得更加容易，
并防止您过多地担心应该如何提供，呃供应，您的IAM角色｡
好吧，就是这样｡
SAM策略模板的所有须知｡
请确保您只看到一次它们的样子，
如右侧所示，从策略模板的名称中通常可以很明显地看出它们的用途｡
好吧，我会的
好吧，就这样了｡
谢谢大家的收看｡
我们下节课再见｡ 
  - [ ] 394 SAM with CodeDeploy [08:57]
    * 
讲师：在我们了解CodeDeploy如何与SAM框架集成之前，
我向您保证，SAM将使用CodeDeploy更新我们的Lambda函数，这将利用我们在使用别名之前看到的流量转移功能｡
我们还可以定义Pre-traffic hooks和Post-traffic
hooks
Lambda函数来验证部署，并且我们可以使用CloudWatch Alarms进行自动回滚｡
因此，在图中提醒您，我们有一个Lambda别名，
它具有v1 Lambda，我们将触发CodeDeploy部署，无论是使用CICD还是SAM框架，
然后我们希望将别名更新为v2｡
因此，CodeDeploy将使用另一个Lambda函数（可选）运行一些预流量挂钩测试，然后它将根据您的策略使用别名进行流量转移，
然后它将监控cloudWatch警报（可选），以确保部署期间一切正常｡
一旦部署完成，流量转移也完全完成，
我们就可以运行一个后流量挂钩Lambda函数，
这也是可选的，用于对别名运行一些测试｡
如果一切顺利，则别名中的v1函数将消失｡
最后我们只剩下v2了｡
让我们继续练习｡
接下来，SAM将创建一个新的应用程序｡
我已经创建了一个SAM CodeDeploy目录，
我将使用终端进入该目录｡
我创建了一个新的终端，然后进入，
我们到哪里了？
我进入了正确的目录｡
因此，我将进入SAM CodeDeploy目录｡
我在这里，然后我将初始化一个新的SAM应用程序｡
所以我将使用Python3｡
7，它安装在我的系统上｡
因此，我们将使用快速入门模板，将项目命名为SAM-app，
然后在快速入门方面，
我想使用Hello World示例｡
按Enter键，我们就这样完成了｡
接下来，
我将进入SAM-app目录，运行此处的SAM-build命令，以构建SAM应用程序｡
所以我现在就去造｡
既然如此，让我们来看看这个SAM应用程序是做什么的｡
有一个Hello World功能，
还有我们的应用程序｡ py，
它返回了，我们看看它返回了什么，它只返回了一个体，说" hello
world"，这是一个非常简单的应用程序.
而我更想看到的是SAM模板｡
雅莫
因此，如果我向下滚动SAM模板，
我可以看到它为我创建了一个无服务器函数｡
目前，
它也只输出这个函数，SAM ARN和它使用的许多API等等｡
这很好，但我想做的是添加一些有关如何使用CodeDeploy部署此应用程序的信息｡
因此，为此，我需要在此文件中添加一点yamo｡
因此，
我可以在yamo文件创建的CodeDeploy中找到这个yamo，它包含CodeDeploy与我的SAM框架集成所需的代码｡
我将粘贴此内容，您需要确保AutoPublishAlias：住是符合你的活动｡
是啊
因此，它要做的就是说，“好的，
你要自动发布一个别名“，然后你要执行一个10%的“10分钟部署“，
这意味着每次我们部署到别名中时，“我们将有两个版本“，
其中一个版本将在10分钟内拥有10%的流量｡
“如果一切顺利，
“10分钟后，它将切换到100%｡
“这将在后台使用CodeDeploy｡
“所以我要重新运行我的SAM构建｡
所以我要进入我的终端，重新构建SAM｡
所以，
我将进行SAM构建，然后再做一些更好的事情｡
我只需执行SAM部署向导来部署我的功能，这对我来说会更容易｡
因此，我将执行SAM部署———指导，
他们应该会使步骤更加简单｡
我们开始吧｡
显示“未找到SAM配置｡
“所以我只想说，
好吧，我想部署的地区是欧盟西部2区｡
“是否要在部署前显示更改？ “我会说，“是的，
我想｡
““是否要允许SAM CLI角色创建？ “是的｡
“你想保存这些吗？
“是的｡
我们开始吧｡
因此它正在创造所需的资源｡
而且它应该促使我在部署这些资源之前说是或不是｡
所以我在这里等了一会儿｡
现在我的函数正在部署，部署正在初始化｡
并在云形成中创建变化集｡
所以我就等着它发生｡
在这里，
我可以看到我的胫骨套件，它显示了将要创建的所有内容｡
我很乐意，也将为我创建一个CodeDeploy服务角色｡
所以这正是我需要的
所以我会说是的，请继续创造所有这些东西｡
现在，
我们需要等待CloudFormation模板完全创建，并查看所有更改流到我的终端｡
我的筹码已全部建立｡
现在我可以进入我的管理控制台｡
我可以进入Lambda，看看Lambda函数是否已经创建｡
因此，
如果我转到左侧的应用程序，我现在可以看到已创建的SAM应用程序｡
在这里，我们可以看到部署｡
现在已经有一个Lambda应用程序与Alias一起部署｡
让我们来看看这个Lambda函数｡
因此，我将进入我的函数，
并试图找到它｡
所以叫什么“你好世界”｡
所以我一秒钟前就试着找了一下｡
所以如果我们看一下修改较少的地方，我们可以找到它｡
这是我的函数，这是一个SAM函数，如果我转到操作，
对不起，转到限定符，我可以看到我有一个活动的别名，
这是广告版本一｡
所以这代表了我的Lambda函数部署的最新版本｡
所以如果我测试它，创建一个假的测试事件，然后创建它，测试它，
现在我可以看到它已经成功了，只是说，“你好，
世界｡
“这是我别名上的第一个函数版本，live one｡
但是现在我们要使用CodeDeploy｡
现在我们来编辑函数｡
所以我们要去Hello world应用程序｡
这是我函数的一个更新｡
我要重新打包函数｡
因此，我将执行“SAM build”来再次构建我的函数，这将替换应用程序代码，
然后我可以执行SAM
deploy guided，这将部署我的函数｡
所以我说是的，这是堆栈名称｡
这是一个地区｡
是，我想在部署前查看更改｡
是的，再一次，是的，再一次，所以一切都是肯定的｡
现在开始部署，所有内容都上传到云结构中，再次创建更改，
我将能够看到之前的更改，
正如我们在这里看到的，将修改别名，将修改函数，并创建版本，
因此一切看起来都很好，这将涉及CodeDeploy｡
所以我同意｡
现在这个被应用到我的云形成中｡
这就是最酷的事情发生的地方，我应该能够进入代码部署并看到实时发生的事情｡
如果我查看这些别名，请刷新此页面查看我的别名，
现在，我们应该在最底部看到版本1和版本2，权重分别为90和10｡
这是由我的SAM CLI完成的｡
但更重要的是，让我们转到CodeDeploy，
看看CodeDeploy是否正常工作｡
因此，我们仍在考虑部署，
目前Lambda正在进行蓝绿色部署｡
我单击此部署ID，可以看到部署前验证已成功，因为没有任何验证｡
然后，
我们可以查看正在进行的CodeDeploy流量转换，原始流量为90%，
替换流量为10%，这表示我的别名中的90和10｡
这是运行流量转移，这将需要大约10分钟，因为我们已经部署了Lambda
Canary 10%
10分钟部署配置，因此在此结束时，它将执行部署后违规，
然后整个流量在我的版本2上应该是100%｡
所以让我在这里暂停一下，等一等｡
好的，
现在一切都已完成，流量转移成功，部署后违规不存在｡
因此，它是成功的，如果我们向下滚动，我们可以看到发生的所有事件的明细，因此，
如果我返回到我的别名，并刷新此页面，
我应该看到的是，
被更新为“是”的整个别名只是指向版本号2的别名，因此，我们已经使用CodeDeploy和SAM框架完成了Lambda函数的金丝雀部署｡
就是这样，
希望你们喜欢，下节课再见｡
  - [ ] 395 [DVA-C02] SAM - Local Capabilities [02:00]
    * 
讲师：现在我们来讨论SAM框架的本地功能｡
因此，通过使用SAM框架，您实际上可以在本地启动AWS
Lambda｡
因此，如果您执行SAM本地启动-Lambda，
您将可以使用Lambda函数作为计算机上的本地端点，并模拟Lambda框架｡
它的美妙之处在于，
现在您可以开始对这些本地端点运行自动化测试｡
也可以在本地调用Lambda函数｡
为此，您执行SAM本地调用，这将实际调用带有有效负载的Lambda函数｡
因此，您只需执行一次，
然后在调用完成后退出｡
这对生成测试用例非常有帮助，
如果你的Lambda函数与AWS交互，例如，
你正在对DynamoDB进行API调用，
以从中获取任何东西，那么，当然，
你必须启动你的本地函数，或者使用正确的--profile选项进行调用，因为你需要说明你想要在哪个环境下运行｡
您还可以启动本地API网关终结点｡
为此，您执行SAM local start-API，
它将启动一个本地HTTP服务器，该服务器将托管您的所有API和所有函数｡
如果你更新了Lambda函数的代码，
函数会自动重新加载，API也会更新｡
最后，您可以使用SAM本地生成事件函数为Lambda函数生成事件｡
为此，例如，您可以将其与“嘿，
我想为Amazon S3生成一个事件，用于在特定键处放入桶”组合在一起，
然后我们将该输入通过管道传输到我们之前看到的SAM本地调用命令中｡
因此您可以为事件源生成样本负载｡
它可以是任何真正的λ源｡
因此，亚马逊S3，API网关，SNS, Kinesis, DynamoDB，
几乎所有的｡
好了，我们已经看到了使用SAM框架的本地功能｡
希望你喜欢｡
我们下节课再见｡ 
  - [ ] 396 SAM Section [00:53] Summary
    * 
演示者：那么，让我们来讨论一下我们需要了解的有关SAM参加考试的信息｡
SAM构建在CloudFormation之上，因此SAM需要处理两件事：第一，
转换头或YAML指示，表示它是SAM模板的事实，
以及任何CloudFormation模板中必需的资源部分｡
然后是您需要知道的一些命令，SAM构建用于构建提取依赖项和创建本地部署工件｡
SAM包打包并上传到Amazon S3，
生成CloudFormation模板｡
最后，SAM部署到CloudFormation｡
您可以使用SAM策略模板为SAM功能轻松定义IAM策略，最后，
SAM与CloudDeploy完全集成，
将您的Lambda功能和版本部署到Lambda别名，正如我们在实践中所看到的｡
原来如此｡
我希望你喜欢这一节，我们下节课再见｡
  - [ ] 397 Serverless Application Repository (SAR) [01:21]
    * 
讲师：好的，
这是一个介绍无服务器应用程序存储库（SAR）的快速讲座，SAR是使用SAM创建和打包的无服务器应用程序的托管存储库，即无服务器应用程序模型｡
它用于构建和发布可供组织重用的应用程序｡
其理念是，您将使用SAM构建应用程序，然后可以公开共享该应用程序，
或者可以与特定AWS帐户共享并重用该应用程序｡
因此，我们有了SAR，即无服务器应用程序存储库｡
它可以由亚马逊S3 Bucket支持｡
所以我们要用SAM把Lambda函数发布到这个库中｡
因此，
如果我们有许多不同的SAM应用程序，我们可以根据这些应用程序发布许多内容｡
然后，为了部署任何Lambda函数，我们可以直接从无服务器应用程序存储库获取应用程序，
而不是直接使用SAM，以将其部署到指定的帐户｡
因此，这是一种创作lambda函数的方法，可以对它们进行版本控制，
并将它们发布到来自中央存储库的不同帐户中｡
那么我们为什么要这么做？
这样可以避免重复工作，我们直接进入发布阶段｡
我们还可以使用设置和环境变量将SAR中的应用程序自定义到部署中，我将在以后的上机操作中向您展示这一点｡
这只是一个简短的介绍，
一旦我们开始使用它，你会有很多意义｡
我们下节课见，进行实际操作｡ 
  - [ ] 398 Serverless Application Repository (SAR) [13:33] Hands On
    * 
  - [ ]  SAM [6 问题] Quiz
    * 
 ## Section 26 - Cloud Development Kit (CDK) [5 个讲座 • 26 分钟]
  - [ ] 399 CDK Overview [04:51]
    * 
讲师：现在我们来谈谈AWS
Cloud Development Kit或CDK，它允许您使用熟悉的编程语言（如JavaScript或TypeScript､
Python､ Java和）定义云基础架构｡
NET开发的｡
所以你可能会说，
“嘿，看起来这与CloudFormation重叠，
因为CloudFormation我们可以使用YAML定义云基础设施｡
但现在我们可以用编程语言来实现｡
这是什么？ 好吧，这是取代云形成的东西，
我们马上就会看到｡
假设我们想使用TypeScript定义我们的基础架构，
所以我们在这里有这个代码，我们在其中定义了三个不同的东西｡
我们正在定义结构，因此有一些高级组件可以使用，
这要归功于CDK｡
我们使用的第一个构造是VPC｡
所以我们创建一个新的VPC，给它一个名字，
给它三个AZ｡
这为我们创建了一个VPC，其中将包含一些预先制定的配置｡
然后我们定义一个ECS集群｡
ECS集群名为MyCluster，
并链接到我们刚刚定义的VPC｡
然后我们定义一个应用程序负载平衡的Fargate服务，
这是一个带有ALB的Fargate服务，它链接到我们刚刚定义的集群｡
我们定义了多少CPU，我们想要多少任务，
所以六，任务图像选项，
内存限制，我们想要一个公共ALB｡
所以所有这些都是用编程语言定义的，
这意味着如果我们没有功能代码，如果代码无法编译，
那么它会给我们一个错误，这意味着我们的模板无法生成｡
但是如果代码可以被编译，因为它是健全的和类型安全的，
那么它将被编译成一个CloudFormation模板｡
它可以是JSON或YAML｡
因此，我们使用CDK在后端定义CloudFormation模板｡
但这使我们能够更加灵活地使用编程语言｡
因此，这也意味着我们可以一起部署基础设施和应用程序运行时代码｡
所以这对于Lambda函数很好，对于ECS或EKS中的Docker容器也很好｡
所以这是一场革命，因为CloudFormation模板是YAML，
它不是类型安全的，你可以犯错误，
你只知道在最后它是否工作｡
但是使用CDK，您可以使用构造和编程语言来定义它们｡
所以如果你想要一个图表，那么我们有我们的应用程序结构｡
它可以是Lambda函数､ DynamoDB､
Amazon S3､ ECS､ 一些step函数等等｡
我们可以使用编程语言，如Python, TypeScript，
Java｡ NET开发的｡
我想，我们编写CDK文件，
然后使用CDK CLI将其合成为CloudFormation模板，
我们将应用到CloudFormation中以定义我们的基础设施｡
因此，它比CloudFormation高出一步，
使使用CloudFormation更容易｡
那么你可能会问我，CDK和SAM有什么区别？
好吧，SAM将是无服务器的，我们将以JSON或YAML声明式地编写模板，
这对于快速开始使用Lambda非常有用｡
它还在后端利用了CloudFormation，好吗？
但SAM的重点是Lambda函数和无服务器应用程序｡
对于CDK，它是CloudFormation的一个超级集合，
因此它支持所有AWS服务｡
你将使用你知道的编程语言编写你的基础架构，
例如TypeScript, Python，
Java和｡ 它还利用CloudFormation，
因为它生成CloudFormation｡
所以希望这两种服务之间的区别是明确的｡
还有一种方法可以组合CDK和SAM框架｡
因此，您可以使用SAM CLI在本地测试CDK应用程序｡
怎么做？
首先，我们必须运行cdk
synth，当我们这样做时，我们有一个Lambda函数，
比如在CDK应用程序中，我们运行cdk synth命令，
这将生成一个从CDK合成的CloudFormation模板｡
但是，多亏了这个CloudFormation模板，
我们可以使用相同的框架，SAM本地调用引用CloudFormation模板并调用函数｡
这两个框架配合得非常好｡
在下一节课中，我们将动手操作CDK｡
通过这次实践，我们将部署一个应用程序，
该应用程序允许我们部署一个S3存储桶，用户可以将映像放在该存储桶上｡
此S3存储桶将触发Lambda函数，
该函数将向Rekognition发送API调用以分析图像并从Rekognition获取结果，然后Lambda函数将结果保存到Amazon
DynamoDB｡
所有这些都将在CDK脚本中定义｡
我们下节课再讲吧｡ 
  - [ ] 400 CDK [11:33] Hands On
    * 
  - [ ] 401 [DVA-C02] CDK - Constructs [03:58]
    * 
教练：CDK中的构装体非常重要，
我们以前见过｡
这些组件封装了CDK创建最终CloudFormation堆栈所需的所有内容｡
因此，Construct可以是单个AWS资源，
如S3 bucket，
也可以是多个相关资源的组合，如具有一些计算的SQS工作队列｡
那么我们怎么得到这些构装体呢？
有一个Construct Library，
它是CDK中包含的Construct的集合，包含每个AWS资源的Construct｡
你有三个等级的构装体：1级､
2级和3级｡
我们将在接下来的幻灯片中看到它们｡
此外，您还可以使用构造中心｡
这是当你有来自AWS的构件，
但也有第三方和开源CDK社区，让你更快更好地创建你的CDK堆栈｡
下面我们来讨论第1层构造｡
它们被称为CFN资源，因为它们代表了CloudFormation中所有可用的资源｡
在这个例子中，我们做一个桶｡
而且是新款S3｡ 参见铲斗｡
因此，我们定义了与CloudFormation资源规范中的属性完全相同的属性｡
您知道这是第1层，
因为它以Cfn开头｡
因此，CFN存储桶必须具有存储桶所需的所有资源属性｡
所以，桶的名字｡
并且您可以单独配置所有这些组件｡
所以如果你想从CloudFormation迁移到CDK，
一个接一个地，把你所有的资源转换成代码，
你可以使用CFN bucket, CFN SQS
queue，等等｡
这就足够了｡
但这将使用CDK的第1层，因为这是非常基本的｡
然后进入第2层｡
第2层是AWS资源，但级别更高｡
因为现在我们要讨论的是意图｡
这是一个更高层次的结构｡
如果我们看一下底部的内容，这里是S3｡
水桶｡
所以不同的是它不是从Cfn开始的｡
然后，如我们所见，我们已经进行了版本控制：没错｡
然后是加密，S3｡ 桶加密｡ 公里｡
然后，自动地，知道如何去做｡
然后，从这个桶中，我们可以得到，
例如，一个特定对象的HTTP
URL是什么｡
所以我们有额外的方法｡
因此，当您使用第2层构造时，
您具有与第1层类似的功能，
但现在我们有了方便的默认值和样板｡
因此，您不需要了解有关资源属性的所有信息｡
然后你添加了一些方法，
比如bucket｡ 添加生命周期规则｡
这将允许您添加生命周期规则，即使在幕后，
它可能在原始CloudFormation中更复杂一些｡
然后你有第三层构造｡
这些被称为模式，
因为它们代表多个相关的资源｡
这里我们有一个Lambda Rest API｡
然后我们添加资源，添加资源，
进行HTTP集成，等等｡
因此，这个第3层模式将帮助您完成AWS中最常见的任务，
例如，使用API Gateway创建Rest API｡
但不是在后台配置每一个小资源，
而是有一个更容易处理的API，
只需定义API，然后定义资源和方法，以及Lambda函数，
但非常容易｡
例如，您还可以有一个ECS模式，其中您有一个带有Fargate服务的应用程序负载均衡器，
将其编写为原始CloudFormation可能会非常复杂｡
但是使用CDK，您只需填写空白，然后自动将ALB和Fargate服务连接到正确的端口和正确的安全组，
等等｡
以及正确的听众｡
因此，希望您现在了解了CDK构造中所有层之间的差异以及CDK的强大功能｡
希望你们喜欢，
我们下节课再见｡
  - [ ] 402 [DVA-C02] CDK - Commands & Bootstraping [02:42]
    * 
教师：好的，那么CDK需要了解哪些重要命令？
现在你已经有了所有这些，我将带你走一遍，
你马上就会明白了｡
第一步是安装CDK CLI和库，以便开始编写CDK堆栈｡
第二个是cdkinit，它从指定的模板初始化一个应用程序｡
你可以选择Python, JavaScript等等｡
Cdk synth合成并打印CloudFormation模板｡
这就是CDK堆栈代码到CloudFormation模板之间的转换｡
Cdk bootstrap是我们将在下一张幻灯片中看到的东西，
所以我现在就跳过它｡
Cdk deploy是部署堆栈｡
因此，一旦您有了CloudFormation模板，
当然，您需要部署它｡
Cdk diff是看本地CDK的差异｡
所以无论你做了什么改变，以及CloudFormation上实际部署了什么｡
cdk destroy就是销毁堆栈｡
最后一个我们没有深入讨论的小问题是cdk引导｡
那么什么是CDK中的自举？
自举是在将CDK应用程序部署到AWS环境之前为CDK配置资源的过程｡
那么AWS中的环境是什么呢？
嗯，对于CDK来说，
就是一个账户和一个区域的结合｡
因此，在能够部署到某个帐户和区域之前，
您必须部署一个名为CDKToolkit的CloudFormation堆栈，
该堆栈将包含一个S3存储桶和一个IAM角色｡
这些是在指定环境中部署任何CDK堆栈的必要前提条件｡
因此，当您部署到一个新的帐户和区域组合（即一个新环境）时，
您需要执行cdk引导，然后执行aws：//aws_account/aws_region｡
接下来是这样的｡
我们有帐户和地区，用户运行引导程序｡
一个名为CDKToolkit的CloudFormation堆栈将根据我们的需要创建｡
现在，如果您尝试在此之后部署CDK堆栈，一切都将正常工作，
但如果您没有引导到您的环境中，则在尝试部署CDK堆栈时将出现错误，
该错误将指出策略包含具有一个或多个无效原则的语句｡
那是因为你错过了IAM的角色｡
所以这应该说得通｡
希望您现在已经理解了什么是引导以及使CDK工作所需的所有命令｡
我希望你们喜欢，我们下节课再见｡ 
  - [ ] 403 [DVA-C02] CDK - Unit Testing [02:27]
    * 
讲师：这是一个关于CDK测试的简短演讲｡
因为使用的是CDK代码，所以实际上可以用测试普通标准Python代码或JavaScript代码的方法来测试代码，
等等｡
因此，在CDK应用程序中，您有所谓的CDK断言模块，
其中将包含流行的测试框架，如JavaScript的Jest或Python的Pytest｡
有了这个断言模块，我们可以验证特定的资源是否是我们所需要的，
或者是规则､ 条件或参数，等等｡
这是一个简单的测试，我们将看看它是否正确合成｡
这意味着它生成的CloudFormation模板包含了我们需要的内容｡
所以CDK有两种检测｡
第一种称为细粒度断言，
这是最常见的，
您将在其中测试某些特定资源是否具有某些特定属性｡
例如，在这里我们测试Lambda函数是否有一个正确的处理程序，
以及运行时是否为nodejs14｡
十.
然后我们看我们的SNS话题订阅是否只有一个，
好吗？
这就是细粒度断言｡
然后，我们进行快照测试，
根据之前存储的基准模板测试CloudFormation模板，
无论出于何种原因，它都被称为快照测试｡
所以，这是非常有趣的，
因为现在你可以确保，当然，
你的动态数据库表仍然在这里，
我不知道，一些共同的属性｡
你想要什么都行｡
我们如何测试模板呢？
我们有两个选择｡
第一种是从Stack, MyStack创建模板，这就是我们现在要做的，
我们导入一个在CDK中定义的栈，所以我们从Stack，
MyStack创建模板，但是另一种方法是如果你的模板还没有在CDK中，
你可以通过创建模板来导入｡
从字符串｡
字符串中的MyString是您的文件｡
堆栈将在CDK之外构建，因此您的CloudFormation模板在CDK之外，
您仍然可以针对外部CloudFormation模板运行测试｡
而这两个命令，这两个方法从考试的角度来说是非常重要的要记住的｡
所以fromStack和fromString｡
好了，这堂课就到这里｡
希望你喜欢｡
我们下节课再见｡ 
  - [ ]  CDK [1 问题] Quiz
    * 
 ## Section 27 - Cognito: Cognito User Pools, Cognito Identity Pools & Cognito Sync [8 个讲座 • 43 分钟]
  - [ ] 404 [DVA-C02] Cognito Overview [01:20]
    * 
讲师：现在我们来谈谈Amazon Cognito｡
它的目标是给用户一个身份来与Web和移动应用程序交互｡
所以这些用户通常不在我们的AWS账户之内，因此我们命名为Cognito，
因为它为我们还不知道的用户提供了一个身份｡
我们在Cognito中有两种子服务｡
我们有Cognito用户池，
它为应用程序用户提供了登录功能，并与API网关和应用程序负载均衡器有很好的直观性｡
我们有认知身份池，以前叫做联合身份｡
这实际上是为注册到我们应用程序的用户提供临时AWS凭据，
以便他们可以直接访问AWS的一些资源｡
我们将在Cognito用户池中看到一个很好的集成｡
因此，如果您问自己，IAM中不是已经有用户了吗？
答案是肯定的，你知道｡
但Cognito将面向您的Web和移动应用程序用户，
它位于AWS之外｡
因此，请查找关键字，例如数百个用户或移动用户，
或者使用SAML等任何机制进行身份验证｡
好吧，就这样｡
我希望你们喜欢，我们下节课再见｡ 
  - [ ] 405 Cognito User Pools [03:25]
    * 
我们将看到的第一个Cognito调查称为Cognito用户池，或CUP｡
而且，这是一种为web和移动的应用程序用户创建无服务器数据库的方法｡
那么，什么是无服务器数据库呢？
这意味着您的用户可以使用简单的登录､ 用户名或电子邮件以及密码组合来连接到您的应用程序｡
他们显然还可以重置密码，我们可以借助Cognito
User Pools进行电子邮件和电话号码验证，我们可以为用户启用多因素身份验证，
我们还可以告诉用户他们可以使用Google､
Facebook甚至SAML登录，因此这被称为联合身份｡
所以这和你在其他网站上看到的差不多，他们要求你注册用户，
要么创建一个用户名/密码，
要么登录谷歌､ Facebook或其他方式｡
如果用户的凭据在其他地方被泄露，您可以阻止该用户，
因此AWS会扫描网络以查找泄露的凭据，并将您的用户通知到Cognito用户池中，最后，
当您的用户使用Cognito用户池登录时，他们从API返回的是JWT，即JSON
Web令牌｡
那么，在图表中，我们的Cognito用户池是什么样子的呢？
它们是一个用户数据库，因此CUP将拥有自己的内部用户数据库，
我们可以查看这些数据库，
然后我们的移动的应用程序和web应用程序可以登录Cognito用户池，当他们登录后，
CUP将向我们的用户､ 移动应用程序和web应用程序返回JSON Web令牌JWT｡
正如我所说的，
我们还可以通过亚马逊､ 谷歌或Facebook等设施登录Cognito用户池，因此我们可以通过第三方身份提供商进行联合，
并通过社交身份提供商提供社交登录，因此可以通过谷歌登录，通过Facebook登录｡
如果您的身份提供商支持OpenID Connect，我们还可以将更多特定的身份提供商与SAML集成，甚至与OpenID
Connect集成｡
以上是CUP的工作原理，
接下来我们将讨论AWS for CUP中的集成｡
CUP与API网关和应用负载均衡器进行了本机集成，对于API网关，
我们已经了解了其工作原理，用户将通过Cognito用户池进行身份验证，并从中检索JSON
Web令牌，然后将web令牌（JSON
Web令牌）传递给API网关，
API网关将评估Cognito令牌并确保其有效，然后，允许我们访问后端，这就是我们在API网关上提供身份验证的方式｡
但是，非常简单的是，我们也可以使用应用负载平衡器，因此，
使用应用负载平衡器监听器和规则，我们能够根据Cognito用户池验证我们的用户，完成后，
我们可以将我们的用户转发到目标组中的后端，
目标组可以是EC2实例､ Lambda函数或ECS容器｡
以上就是高级别Cognito用户池，
现在让我们在下一节课中进行实践，练习并了解它们的详细工作方式｡
  - [ ] 406 [DVA-C02] Cognito User Pools [10:23] Hands On
    * 
  - [ ] 407 [DVA-C02] Cognito User Pools - Others [06:09]
    * 
讲师：所以，这是一个简短的理论课，
来重申我在实践中说过的话｡
首先，我们可以使用Lambda触发器，
这样Cognito用户池就可以在其中一些触发器上同步调用任何Lambda函数，
我们已经看到了其中的大部分，但重要的是围绕身份验证事件，
例如身份验证前､ 身份验证后和令牌生成前，我们可以使用Lambda触发器来接受或拒绝您的登录请求，以便在成功认证之后记录事件以进行自定义分析，或者增加和抑制令牌声明｡
然后，对于注册，我们可以执行预注册､
后确认和迁移用户Lambda触发器｡
例如，在本例中，这将有助于在用户注册后为自定义分析提供自定义欢迎消息或事件日志｡
最后，我们可以通过Lambda函数定制发送给用户的消息，
最后，我们可以通过添加或删除ID令牌中的属性来修改令牌创建｡
Cognito User Pools的另一个优点是，
我们有一个托管的身份验证UI，这允许我们不在应用程序中编写该UI，
我们可以重用Cognito为我们创建的UI，并使用它来处理注册和登录工作流｡
在使用此托管UI时，我们已经为社交登录､
OIDC或SAML的所有集成打下了基础，因此我们不必重新编程所有内容｡ 如果我们希望将此UI包含到我们自己的应用程序中，那么我们可以自定义徽标（如前所述），还可以自定义CSS，
使其看起来像是属于我们的网站｡
所以这将是一个登录屏幕与您自己的自定义标志在大｡
现在，对于托管UI，您可能希望将其托管在自己的域中，
因此是一个自定义域｡
因此，您需要了解的技巧是，
如果您将自定义域与Cognito
User Pools一起使用，无论它是在哪里创建的，您都必须创建一个证书以使用HTTPS｡
证书必须是ACM的，好吗？
而且它需要进入的地区必须是美国东部地区｡
你别无选择｡
这是一个技巧，因为即使您在eu-west-1中有Cognito用户池，
您也必须在us-east-1（您的证书）中创建它｡
现在是自定义域，您必须在Cognito
User Pools的应用集成部分定义它，因为这将是所有应用声明的配置｡
这是一种常规配置｡
Cognito User Pools的另一个非常好的特性是自适应身份验证｡
因此，我们的想法是允许用户使用其用户名和密码正常登录，
但使用自适应身份验证时，
如果出现可疑登录，则可以阻止登录，
或者我们可以要求进行多因素身份验证｡
它是如何工作的？
Cognito会检查每次登录尝试，
然后根据恶意攻击者或未知登录发出登录请求的可能性，将其分为低､ 中或高风险评分｡ 因此，如果是这种情况，则只有在存在风险时，
才会提示用户进行第二次多因素身份验证｡
作为一个普通用户，Cognito已经习惯了，
也许你在工作场所用自己的电脑登录，所以你很好，
你可以用密码登录，但如果你或其他人试图用你的密码从一个新的位置再次登录，
Cognito可能会说，“嗯，
这看起来像是一个可疑的登录｡
请使用MFA验证您的身份｡ 因此，风险评分基于许多不同的因素，
例如用户是否像往常一样使用同一设备､
位置､ IP地址等｡
在凭据受损的情况下，有帐户接管保护，
并将有电话和电子邮件验证以及｡
最重要的是，自适应身份验证机制所做的任何工作都将在CloudWatch日志中显示，
例如登录尝试､ 风险评分､ 失败挑战等｡
现在，当您使用Cognito用户池登录时，
从池中返回的是JWT令牌或JSON
Web令牌｡
这些是Base64编码的｡
你将得到所谓的报头､ 有效载荷和签名，
因此Base64允许你轻松地通过网络传输，
然后它将被解码，看起来像这样｡
这是一个JWT令牌有效负载｡
头没有表示出来，这是第一行，
令牌签名没有表示出来，这是最后一行｡
我给你们展示的是有效负载，
有效负载表示了很多关于用户的信息｡
我们稍后将讨论它，
但首先，当您接收到JWT时，
要信任有效负载中的内容，您需要验证签名｡
签名是最底层的东西，有一种算法允许您说，
“好吧，如果签名正确，那么我可以信任有效负载中的任何信息，因为否则，
如果不是这种情况，您可以在这里声明任何用户，
因此有一些库可以验证JWT令牌，一旦验证完成，您就可以使用有效负载，因此有效载荷包含用户信息｡
例如，这里有子UUID，它表示Cognito用户池数据库中的用户ID｡
因此，使用该子UUID，您可以恢复存储在Cognito数据库中的任何类型的用户信息｡
因此，从Cognito数据库中，您可以恢复用户的电子邮件､
名字､ 电话号码以及您定义为Cognito用户池一部分的任何属性｡
我们还可以看看其他领域｡
例如，您将拥有用户名､ Cognito组｡
您可能还拥有此Jason Web Token的到期时间，
所有这些信息都是有效负载的一部分，但同样，如果您需要额外信息，
请使用带有子UUID的用户ID在Cognito用户门户数据库中查找用户｡
好吧，就这样了｡
我们已经看到了所有我们需要知道的关于Cognito用户池｡
我希望你们喜欢，我们下节课再见｡ 
  - [ ] 408 [DVA-C02] Application Load Balancer - User Authentication [05:10]
    * 
讲师：我们知道我们可以将Cognito与API网关集成来验证用户身份，
但实际上我们可以使用应用程序负载平衡器来完成同样的事情｡
因此，您的ALB可以安全地对用户进行身份验证，
这使您可以将工作从应用程序中移除，并将此职责交给负载平衡器，以便应用程序可以只关注其业务逻辑｡
因此您可以通过多种方式为应用程序负载平衡器进行身份验证｡
第一种是使用OpenID Connect的身份提供者，
因此符合OIDC｡
第二种选择是使用Cognito用户池，
这适用于Amazon登录､ Facebook登录或Google登录等社交身份提供者，
或者您拥有与SAML､ LDAP或Microsoft AD兼容的企业身份｡
所以第一个，第一个选择是直接集成，
而不使用Cognito用户池，
第二个选择是使用Cognito用户池，
我会在这节课上向你们展示这两个选择｡
现在，要使其工作，必须设置HTTPS侦听器，
S表示安全，然后可以设置authenticate-oidc或authenticate-cognito规则｡
因此，当您配置负载平衡器时，
您将看到类似于此的内容，
正如您在HTTPS上看到的侦听器详细信息一样，
第一个默认操作是进行身份验证，然后转发到后端｡
现在，如果您的用户未经身份验证，我们该怎么办？
我们有选择，我们有三个选择｡
第一个是自然地说请验证｡
这是默认设置｡
但是您也可以完全拒绝请求或完全允许请求，
例如，对于您的登录页面，allow将非常有用，
因为人们会在没有经过身份验证的情况下访问您的登录页面｡
那么这是怎么回事呢？
好吧，假设我们有一个连接到Amazon
ECS的应用程序负载平衡器，
并且我们希望通过Amazon Cognito实现登录，在这种情况下，
用户将执行GET/api/data｡
然后，将使用HTTPS和authenticate-cognito操作设置ALB｡
Cognito会做自己的事情，
对用户进行身份验证，
然后将有效负载和请求传递给Amazon
ECS，并添加从Cognito发出请求的用户的信息｡
这是非常有用的，
因为现在您有更多的信息需要通过应用程序处理Amazon，
例如Amazon ECS，并且您可以返回基于用户信息的特定响应｡
所以设置它非常简单｡
进入ALB UI，
然后首先创建Cognito用户池､
客户端和域｡
您要确保返回ID令牌（JWT令牌），但这是Cognito用户池中的默认值｡
然后，如果您需要，您可以将Cognito用户池连接到您的社交或企业IdP，
然后设置几个URL重定向，然后继续设置更多的回调URL，这些URL非常特定于Cognito用户池，因此我不想在此逗留｡
然后，您只需将Cognito用户池链接到具有特定应用客户端的ALB中，
就可以开始了｡
所以这很简单｡
如果您使用OIDC身份验证，则需要做更多的工作，
因为它没有使用Cognito集成｡
您可以与任何符合OIDC的身份提供者集成｡
让我们举同样的例子｡
它们将是HTTP请求｡
然后，ALB将用户重定向到身份提供者的身份验证端点进行身份验证，
身份提供者将授予授权码｡
授权码将被传递给ALB, ALB将把授权码发送给令牌端点｡
因此，授权码将被切换并交换为ID令牌和访问令牌｡
然后，ALB将再次向身份提供程序的用户信息端点发出请求，
以将该访问令牌交换为用户声明｡
用户声明基本上是说，嘿，
这是用户ID，这是用户属性，
等等｡
一旦获得用户声明，请求将与原始请求和用户声明一起发送到Amazon
ECS｡
我们得到响应，
然后响应被传递给用户｡
因此，功能与Cognito类似，
但ALB和身份提供者之间的请求更多｡
如您所见，还需要配置更多设置｡
我们有授权端点､ 令牌端点和用户信息端点｡
我们需要设置一个客户端ID和一个客户端密码，
然后我们需要允许正确的重定向，
再次像以前一样，以便您的ALB和您的OpenID
Connect端点可以一起工作｡
但是您现在已经看到了使用ALB验证用户身份的两种方法｡
希望你们喜欢，
下次课再见.
  - [ ] 409 Cognito Identity Pools [07:16]
    * 
现在我们来讨论一个服务，我希望它不是这样命名的，
但它是这样命名的｡
这是Cognito身份池，也称为联合身份｡
我希望它不是这样命名的，因为它和Cognito User Pool是不一样的，
但它和Cognito是一个概念，我不喜欢，
但这只是我个人的看法｡
让我们试着了解什么是Cognito身份池｡
因此，我们的用户在AWS环境之外，可能有web应用程序用户或移动的用户，
他们希望访问AWS环境中的内容｡
例如，他们希望访问DynamoDB表或S3存储桶｡
因此，
要访问这些内容，他们需要临时AWS凭据｡
因此，我们无法为这些用户创建正常的IAM用户，
因为他们太多了，无法扩展，
而且我们不信任他们｡
因此，我们将通过Cognito身份池为这些用户给予访问AWS的权限｡
因此，此身份池可以允许您的用户通过受信任的第三方登录｡
这可以是一个公共提供商，例如，通过Amazon､
Facebook､ Google和Apple登录，或者甚至允许已经通过Amazon
Cognito用户池登录的用户，
或者甚至允许OpenID Connect提供商和SAML提供商，或者最后是开发人员身份验证，这是一个自定义登录服务器｡
因此，
在所有这些登录提供商之上，为了允许在用户用身份交换AWS凭据之前为他们给予一个身份，我们可以允许未经身份验证的访客用户访问AWS｡
因此，我们可以定义一个来宾策略，
并为来宾用户给予AWS凭据｡
因此，
一旦用户获得这些AWS凭据，他们就可以通过使用SDK的API调用或通过API网关直接访问AWS服务｡
因此，这些凭据，这些用户获得的凭据，他们有一个IAM策略，
该策略由我们在Cognito身份池中所做的工作定义，
并且可以根据用户ID的值进行自定义，以实现精细控制｡
我们在这节理论课上看到了这一点｡
所以，我会尽量让它变得简单｡
因此，
我们有一个web和移动的应用程序，它们希望访问我们的私有S3 Bucket和DynamoDB表｡
但我们希望确保用户首先获得AWS的凭据，但我们不希望为这些应用程序创建IAM用户｡
那我们该怎么办？
我们将利用Cognito身份池，但首先，我们希望用户获得一个登录名，
并从该登录名中获得一个令牌｡
因此，我们将允许我们的用户连接到Cognito用户池，或连接到Google登录､
Facebook登录､
社交身份提供商､ SAML或OpenID Connect｡
所以他们会用其中任何一个登录｡
他们将获得一个令牌，并与Cognito身份池服务进行通信，
以将令牌交换为临时AWS凭据｡
因此，首先，身份池将使用我们定义的任何提供商验证登录，
然后，
一旦验证通过，Cognito身份池将与STS服务通信，为我们的web和移动应用程序用户获取临时凭据｡
完成此操作后，
凭据将返回给我们的应用程序，应用程序可以使用并直接访问AWS，这要归功于这些凭据和相关的IAM策略｡
这非常简单，
与Cognito用户池有很大的区别，但您可以看到有很多共同点，尤其是在身份提供者方面｡
因此，
问题是，如果我将Cognito身份池与Cognito用户池一起使用，它将如何工作？
答案就在这里｡
我们有相同的图表｡
我们希望用户连接到Private S3
Bucket或DynamDB Table，
但我们希望他们的身份存储在Cognito用户池中｡
好的，
这是与之前相同的图表，但我只是将其扩展到Cognito用户池｡
所以他们需要登录并获得令牌｡
你为什么要这么做？
当然，我是这么做的，因为我们希望所有用户都集中在Cognito用户池数据库中，
因此它可以是一个内部用户数据库，或者我们也可以为Cognito用户池启用社交身份提供商SAML和OpenID Connect，
作为联合身份提供商，
但无论如何，所有用户都将显示在我的Cognito用户池中｡
然后，我们的web和移动的应用程序用户可以将从Cognito用户池获得的相邻web令牌交换到Cognito身份池中，以获取凭据，
因此将对这些令牌进行验证，然后与STS服务进行通信，
以获取将返回给我们的web和移动应用程序的这些凭据｡
然后，
由于这些证书，我们将可以直接访问AWS｡
如果你能理解这一点，我真高兴，
你也可以去参加考试了｡
那么，
Cognito Identity Pools如何决定将哪个角色应用于哪个用户呢？
我们可以为经过身份验证的用户和来宾用户定义一个默认的IAM角色｡
因此，这意味着来宾用户将具有一个IAM角色，
而另一个用户将具有另一个IAM角色｡
我们还可以定义规则，根据用户ID选择哪个角色属于哪个用户｡
然后，我们可以自定义IAM策略，这要归功于使用策略变量，这将允许我们确保用户仅访问他们在DynamoDB或Amazon
S3中需要的内容｡
正如我们在上一张幻灯片中所说的，这些IAM凭证由Cognito身份池通过STS获取｡
角色必须具有Cognito身份池的信任策略，才能使其正常工作｡
我会把它说得更具体一点，这里有一个例子｡
因此，我们希望为来宾用户提供对AWS的访问权限，
因此我们希望创建一个IAM策略，例如，允许任何来宾用户对我的图片（jpeg）的存储桶执行get对象｡
因此，
对于来宾用户，这将给予我们能够通过一个非常简单且明显受限的IAM策略访问AWS｡
然后，对于经过身份验证的用户，您可以在Amazon
S3上定义一个策略变量，
这样我们的用户就可以进行连接，但我们希望确保他们只能访问S3存储桶中的前缀，该前缀代表用户的身份｡
因此，
您可以使用一个策略变量，如这里的绿色部分，这将允许我们的用户仅访问我们定义的存储桶中以其用户ID前缀开头的任何内容｡
因此，
我们有效地为用户提供了访问权限，只访问它可以访问的内容，这要归功于他的用户ID｡
我们可以在DynamoDB上定义相同的内容｡
这里有一个示例策略，我们允许用户在DynamoDB上执行任何操作，
只要DynamoDB的前导键与用户的用户ID相对应｡
由于IAM策略，我们有效地实现了基于行的安全性｡
现在这些都是高级的，
但我只是想给予你先睹为快，看看它们是如何工作的｡
理论课到此为止｡
在下一堂课中，我们将练习认知身份池｡
  - [ ] 410 Cognito Identity Pools [05:15] Hands On
    * 
  - [ ] 411 [DVA-C02] Cognito User Pools vs Cognito Identity Pools [03:36]
    * 
教师：那么，让我们来真正了解Cognito用户池和身份池之间的区别｡
但现在你应该有个好主意了｡
因此，Cognito用户池用于身份验证｡
因此，它将是一个用户数据库，用于您的Web和移动应用程序｡
然后，您可以使用登录联合，因此您可以使用Google､
Facebook､ Amazon或OIDC等社交登录，或者使用SAML的公司登录｡
但我们的想法是，Cognito用户池将是您的用户数据库｡
您甚至可以定制用于身份验证的托管UI，
包括您的徽标，并且您可以在身份验证流程中与Lambda集成，
以进行预验证､ 后验证等｡
您还可以根据不同的风险级别调整登录体验，
例如，使用自适应身份验证｡
以便在适当时候使用多种纤维协定｡
现在对于Cognito Identity
Pools，这是用于授权或访问控制的｡
这是AWS内部的访问控制｡
因此，为了进行比较，如果您有一个移动应用程序，
并且只想拥有一个用户数据库，
那么您可以使用Cognito User
Pools｡
但是，如果您希望这些用户能够访问您的AWS环境，
例如DynamoDB数据库或S3存储桶，则需要为他们提供授权，这可以通过使用Cognito Identity
Pools来实现｡
在这里，您将获得用户的临时凭据，然后登录以获取这些凭据，
交换这些凭据的令牌的方式可以通过社交､
OIDC､ SAML来完成，这些可能会引起混淆，但Cognito用户池也可以｡
因此，这个想法是，无论你的用户被识别，
然后他们可以交换这个令牌的授权｡
因此，您可以将Cognito Identity
Pool与Cognito User Pool一起使用，
但也可以单独使用Cognito Identity Pool｡
使用Cognito Identity Pools的另一个好处是，
用户可以未经身份验证，也可以是访客｡
然后，在身份池中设置用户后，用户将被映射到特定的IAM角色和策略，
您可以利用策略变量，从而使用户能够访问DynamoDB表或S3
Buckets等｡
因此，当您将Cognito User
Pools与Cognito Identity
Pools一起使用时，您将获得第一手身份验证和第二方面授权｡
这就是我试图在这个图表中表现的｡
假设您有一个Web和移动应用程序，并且您希望使用每用户类型的安全性访问您的私有S3
Bucket和DynamoDB表｡
首先，我们将进行最佳实践｡
我们将登录并从Cognito用户池获取令牌｡
因此，您将拥有内部用户数据库，并且可以使用SAML､
OpenID Connect､ Google或Facebook联合登录｡
然后用户将有其身份将得到验证｡
我们可以做的是，我们可以交换您的用户的临时AWS凭据令牌｡
我们可以将Cognito身份池直接与Cognito用户池集成｡
然后，我们将获得临时凭据感谢STS｡
然后，Web和移动应用程序可以直接向AWS发出API调用，
我们将从Cognito Identity Pool确保附加到这些临时凭据的IAM策略允许它们执行所需的操作｡
好了，现在您应该能够真正理解用户池和身份池之间的区别了｡
我希望你们喜欢，我们下节课再见｡ 
  - [ ]  Cognito [7 问题] Quiz
    * 
 ## Section 28 - Other Serverless: Step Functions & AppSync [11 个讲座 • 56 分钟]
  - [ ] 412 Step Functions Overview [04:59]
    * 
教师：现在我们来讨论AWS阶跃函数｡
因此，阶跃函数允许您将工作流建模为状态机，
并且每个工作流都有一个状态机｡
因此，如果您想要订单履行或数据处理､ web应用程序或任何您想要的工作流，
则可以使用此功能｡
其思想是，您将定义发生了什么和接下来发生了什么，然后根据某些条件发生了什么等等，
以定义工作流｡
正如您在右侧看到的，这是一个可视化的工作流｡
我们开始，我们有一个例子，是或否？
如果没有，那你就走到最后｡
如果是，你就等三秒｡
然后你说，，quot，
Hello"和" World"，你把结果编译成" Hello
World"，然后进入结尾.
因此，我们将通过实际操作使其具体化，但我们的想法是，
您在JSON中定义一个工作流，此JSON允许您获得工作流的可视化，然后以可视化方式执行它，
然后我们可以看到执行本身的历史记录｡
因此，
工作流中的每一个小步骤都将是，例如，一个Lambda函数或将数据插入DynamoDB或特定的ECS任务，而步骤函数将是为您编排此工作流的东西｡
要启动工作流，您可以使用SDK API调用､
API网关､ CloudWatch
Events或Amazon
EventBridge，它们都是一样的，或者您也可以从控制台手动启动一个步骤函数，我们将在实践中进行此操作｡
阶梯函数有一堆方框，
就像你在右边看到的，这些方框叫做任务｡
因此，任务状态用于在状态机中执行一些工作｡
因此，任务状态可以是调用Lambda函数，也可以是调用批处理作业或运行ECS任务并等待其完成，
或将项目直接从阶跃函数插入DynamoDB，
或将消息发布到SNS或SQS，甚至启动另一阶跃函数工作流｡
所有这些都可以在任务状态中定义，或者任务也可以运行一个Activity，而该Activity可以是EC2机器､
Amazon ECS任务或内部部署服务器，
它们将从步骤函数中提取一些工作，以执行这些工作，然后将结果发送回步骤函数｡
这里的想法是，我们在这方面更自由，应用服务器不是由step函数调用的，
应用服务器上的step函数实际上是拉取step函数来查找活动和要做的工作｡
这与AWS中名为SWF的服务的工作方式更相似｡
所以我想把它弄得超级结实｡
因此，假设我们要定义一个任务状态来调用Lambda函数｡
因此，我们将定义一个JSON，
如您所见，名称为“Invoke Lambda
function”，类型为task，资源为Lambda function invoke｡
参数是函数名，我们指定函数名，
然后把它传递给Lambda函数.
然后我们说next，进入下一个状态，还有time
out，看看我们的Lambda函数是否超时｡
那么阶跃函数中的状态是什么呢？
我们可以使用这个Choice State来测试将其发送到某个分支或默认分支的条件｡
它可以是“失败”或“成功”状态，以停止执行成功或失败的阶跃函数工作流｡
它可以是通过状态，只是将输入传递到输出，
或者注入一些固定数据而不执行一些工作｡
它可以是一个等待状态，以提供一段特定时间的延迟，
或延迟到指定的日期和时间｡
它可以是动态迭代步骤的“映射状态”，也可以是开始执行的并行分支的“并行状态”｡
从考试的角度来看，你需要记住的最有可能是平行状态｡
很明显，还有我之前给你们看的任务状态｡
所以我想给你们看一下视觉效果｡
所以我们有一个执行工作流，这是一个工作流｡
所以我们提交了一份工作｡
我们等待X秒｡
我们会取得工作状态｡
作业是否已完成？
是或否，如果不是就再等一次，这样就有一个循环｡
当作业完成时，
您可以获得最终的作业状态，因为您成功完成了作业，
或者如果作业失败了，您可能会去处理失败，所有这些都将结束｡
执行开始后，我们将开始提交作业｡
我们要等X秒蓝色的是正在进行的一切｡
然后它进入几个循环，然后工作状态完成，
然后我们得到最终的工作状态，
我们走到最后，这给了我们一个可视化的方面，我们的步骤功能｡
因此，这里的step函数实际上是用来编排您需要做的任何工作，
定义状态机的外观｡
你的工作流程会是什么样子，
我知道现在，这可能是，这到底是在说什么？
这是非常令人困惑的｡
我可以用一个Lambda函数来编程，
但我会在下一节课上给你们演示，一个关于阶跃函数的实践｡
它应该更有意义，然后我会在下一节课中，通过讨论错误处理，
向你们展示状态函数的全部力量｡
我们下节课见｡ 
  - [ ] 413 Step Functions [07:51] Hands On
    * 
  - [ ] 414 Step Functions - Error Handling [06:25]
    * 
教师：现在我们来讨论阶跃函数中的错误处理，并真正定义阶跃函数的全部功能｡
因此，一个阶跃函数将执行许多小任务，
而这些任务只做很少的工作｡
例如，与API对话等等｡
但是所有的错误处理都应该在这些任务之外通过步骤函数本身来进行｡
例如，什么时候会出现错误？
如果状态机存在定义问题，例如，在选择状态中没有匹配的规则，或者如果任务失败，
例如，Lambda函数抛出异常，我们不应该在Lambda函数本身中捕获它，
我们应该在step函数错误处理机制中捕获它｡
或暂时性故障｡
例如，有一个网络分区事件｡
因此，
我们在步骤函数中可以有两种类型的错误处理，一种是重试任务，
另一种是捕获，转换到失败路径｡
而且您应该在状态机中而不是应用程序代码中执行此操作｡
因为你使应用程序变得更简单，
你有所有非常好的机制，以及这些重试的执行历史，这些直接在步骤函数历史中捕获｡
因此，我们有预定义的错误代码｡
所以州｡ 所有，太多的任何错误名称或状态｡
超时，如果任务的运行时间超过超时秒数，
或者没有从活动接收到心跳｡
如果任务本身执行失败，则返回TaskFailed｡
例如，正如我所说的，Lambda函数中的异常｡
或州｡
权限，因为没有足够的权限执行某些代码｡
所以状态本身也可能报告它自己的错误，你可以在阶跃函数中捕获它们｡
因此，让我们来讨论任务或并行状态的重试｡
因此，“重试”允许您定义发生的情况以及根据某些错误重试的次数｡
这是从上到下评估的｡
在这个例子中，
我们有一个Lambda函数正在运行，我们有一次､ 两次和三次重试｡
因此ErrorEquals匹配特定类型的错误｡
因此，如果Lambda函数抛出客户错误，
则为ErrorEquals Customerror;如果Lambda函数只是失败，但没有抛出自定义错误，
则为ErrorEquals TaskFailed;如果尝试捕获Lambda函数中可能发生的所有类型的错误，则为all｡
那么间隔秒就是说，在重试之前要等待多长时间？
在这个例子中，一个，等一秒钟再重试，
或者这个30秒，等30秒再重试，
或者这个5秒｡
然后我们有BackoffRate，它是重试后要乘以延迟的次数｡
为了实现指数回退，在这个例子中，2，2，
2都是一样的｡
然后我们有MaxAttempts，即我们应该重试多少次｡
默认情况下，如果您不想重试，则为3和0，
但在本例中，
MaxAttempts为2，MaxAttempts为2，MaxAttempts为5｡
然后，每当所有尝试都完成并到达时，
Catch块就会启动｡
所以在这个例子中，正如你所看到的，如果你在Lambda函数中定义所有的Retry逻辑，我们会让Lambda函数运行很长很长的时间，
很明显，可能会超时｡
但是如果你想改变你的错误处理逻辑，你必须重新部署Lambda函数｡
但在本例中，我们将重试从Lambda函数外部定义到阶跃函数中｡
因此，我们可以直接在JSON文档中更改Retry和错误处理逻辑，
这样就有了更大的灵活性｡
Lambda函数本身的执行时间很短，而且非常快｡
接下来，如果我们用尽了所有的重试次数，
那么我们进入Catch｡
Catch也有类似的逻辑，它是从上到下求值的，你有ErrorEquals和Next，
让我们来看看｡
在这个例子中，
我们有一个Lambda函数，我们说，
如果你找到ErrorEquals CustomError，那么下一步进入这个名为CustomERrorFallback的状态，它对应于这里的块｡
所以我们说，
“嘿，如果你遇到一个自定义错误，请现在进入状态，
”状态是通过的，也许有一个异常，结束是真的｡
这里的想法是，你可以说重试，重试，重试，
如果重试次数太多，
那么捕捉这个错误，进入下一个状态，然后做一些事情｡
ResultPath是一个路径，它确定将什么输入发送到下一个字段中指定的状态｡
我们将在下一张幻灯片中对此进行深入探讨｡
因此，这里的想法实际上是说，
如果有太多的执行失败或某种特定类型的错误，那么我们希望捕捉它们，并继续使用我们的状态机｡
同样，如果这是我们在代码中定义的东西，
我们的代码可能会变得非常非常复杂｡
但是，如果这是我们在阶跃函数中定义的东西，
我们就有很多灵活性来处理这些错误｡
因此，让我们分析一下ResultPath的工作原理，
因为在考试中了解这一点非常重要｡
假设我们有一个任务，有一个catch, catch是说，
如果有任何类型的错误，
转到下一个任务，ResultPath，$｡ 错误｡
所以$｡ error允许您在输入中包含错误｡
比如说，我们的输入是foo
bar，这要归功于带有define的ResultPath，也就是$｡
错误，输出将像以前一样包含foo栏，但也包含一个错误块，
其中包含错误消息本身和一些关于错误的信息｡
这意味着当这个输出被传递到下一个任务进入下一个状态时，我们可以，
例如，分析发送一些电子邮件等，并根据它进行调试｡
因此ResultPath是您将错误从输入传递到输出，传递到下一个任务的方式｡
这是考试中可以问你的问题｡
这就是阶跃函数｡
希望你喜欢｡
同样，
让我们进行一次实际操作，真正了解如何在step函数中重试和捕获工作｡
所以我们下节课再见｡ 
  - [ ] 415 Step Functions - Error Handling [05:49] Hands On
    * 
  - [ ] 416 [DVA-C02] Step Functions - Wait For Task Token [02:38]
    * 
教师：下面我们来讨论一个称为等待任务令牌的阶跃函数特性｡
这个想法是，你有你的步骤函数，
你有你的执行工作流，但是你想等待一个任务令牌被返回，因为你在等待外部的东西｡
因此，您可能正在等待另一个AWS服务来完成它的工作､
人工批准､ 第三方集成或调用遗留系统｡
因此，为了做到这一点，
你要，在你的任务中的步骤函数中，
附加｡ 将waitForTaskToken添加到资源字段｡
这将告诉步骤函数等待一个特定的任务令牌返回，
然后才能继续执行｡
例如，这里我们有一个名为sqs：sendMessage的资源，
然后我们waitForTaskToken｡
我将在下一张幻灯片中向您展示它是如何工作的｡
因此，任务将暂停，直到它将收到返回的任务令牌，
如果一切正常，则返回SendTaskSuccess，
或者返回SendTaskFailure API调用｡
让我们以工作流为例｡
我们首先要检查客户端信用，这实际上依赖于外部服务｡
那我们该怎么办？
我们将使用任务令牌调用SQS｡
因此，我们将在资源中使用waitForTaskToken，
然后将输入传递给消息中的SQS队列｡
但是，我们还要传递任务令牌，
以便接收应用程序知道如何回调then
step函数｡
因此，您的SQS队列可能会被您拥有的任何应用程序拉取｡
它可以是Lambda函数，可以是ECS，
可以是EC2，也可以是第三方服务器｡
你想要什么都行，对吧？
但你要处理好这条信息｡
然后，当然，
您将获得消息输入正文，但同时，
您将获得任务令牌｡
然后，如果成功或失败，您将使用SendTaskSuccess
API调用，在该调用中，您将传递处理的输出，
以及最初传递到SQS队列的任务令牌｡
然后，一旦阶跃函数工作流接收到带有正确任务令牌和正确输出的API调用，
您就可以继续执行工作流的其余部分｡
但这样做的好处是，在我们回到阶跃函数工作流之前，
我们能够依靠外部系统来执行一些处理｡
这就是你如何与任何一种外部机制整合｡
这节课就到这里，
希望你们喜欢，下节课再见｡
  - [ ] 417 [DVA-C02] Step Functions - Activity Tasks [03:22]
    * 
教师：现在，让我们看一下分步功能中的活动任务｡
其意图可能与我们之前看到的等待任务令牌模式非常相似，
但实现它的方式略有不同｡
这里我们有所谓的活动工作者，他们希望执行步骤函数中的任务｡
因此，这些活动工作器可能运行在EC2实例､
Lambda函数､ 移动设备上，无论您需要什么，
这些活动工作器将定期拉取步骤函数的工作流以查找任务｡
他们将使用GetActivityTask API｡
然后，如果它们从步骤函数中获得工作，它们将执行工作，
完成工作，然后使用SendTaskSuccess或SendTaskFailure发送响应，
这是与之前相同的API调用｡
例如，这里的EC2实例，也就是我的活动工作器，
将使用GetActivityTask来拉取任务，
然后step函数会说是的，
实际上有一些事情需要您去做｡
这是输入，这是任务标记｡
然后，当任务完成时，我们使用SendTaskSuccess发回输出和任务令牌｡
这看起来和我们之前展示的非常相似，但是在活性上有区别｡
在Activity Task机制中，EC2实例或应用程序（无论是什么）从步骤函数中提取某些工作｡
网络也很简单，因为EC2实例只需要能够连接到阶跃函数｡
这里我们有一个拉机制，
很可能是一个简单的网络图｡
当我们查看前一个示例时，我们在外部发送了带有回调的任务，
将要发生的是，步骤函数将事件推出，
例如，推送到SQS队列，因此存在推送机制｡
然后我们需要一些东西，把功从外面拉回来，
并把它放回阶跃函数中｡
因此，这是一种完全不同的工作方式，
因为我们对Activity Task使用了基于拉的机制，
而对具有等待任务令牌的回调模式使用了基于推的机制｡
现在我们了解了两者的区别，
在EC2实例从步骤函数中提取工作的情况下，
它看起来与队列非常相似，
因此我们有几个参数｡
首先是TimeoutSeconds，
它表示正在进行的任务在被视为失败之前可以等待的时间｡
这就是TimeoutSeconds｡
此外还有心跳机制，也就是说，只要EC2实例（活动工作器）将使用Send
HeartBeat API调用，那么我们就认为任务是活动的｡
还有一个HeartBeatSeconds配置，
你可以在阶跃函数上设置，
它定义了等待心跳的最长时间｡
当然，如果你为HeartBeatSeconds设置了10秒，
那么每5秒发送一次任务心跳可能是个好主意，
这样任务就可以经常运行｡
现在，如果您配置了一个非常长的TimeoutSeconds，
并且您一直发送心跳，那么实际的Activity
Task最多可以等待一年｡
好了，活动任务就到这里｡
我希望你们喜欢，我们下节课再见｡ 
  - [ ] 418 [DVA-C02] Step Functions - Standard vs Express [03:32]
    * 
因此，我们有不同的方法来运行阶跃函数工作流｡
第一个是使用标准工作流｡
这是默认设置｡
第二个是使用快速工作流｡
在快速工作流中，
我们有异步工作流和同步快速工作流｡
所以，我们会看看所有的｡
因此，对于标准的默认阶跃函数工作流，单个工作流的最大持续时间长达一年｡
执行模型是一次执行，每秒可以执行大约2，
000个标准工作流，这是一个不错的速度｡
在执行历史记录方面，您可以在控制台历史记录中获得长达90天的时间，
或者您可以使用CloudWatch来拥有更多日志，并且您可以通过CloudWatch中的日志保留设置永久保留日志｡
定价将取决于状态转换的次数，
即从一个状态转换到另一个状态｡
使用标准工作流的用例是用于非幂等操作，
例如支付处理｡
接下来，我们有快速工作流，正如其名称所示，
它们适用于较短的工作流，因此，执行时间最多为5分钟｡
但你有极高的容量极高的利率｡
所以，你每秒可以执行超过100，000次｡
所以相当大的音量｡
现在，没有办法跟踪控制台中的东西｡
获取执行结果和分析的唯一方法是使用CloudWatch日志｡
您将根据执行次数､
执行持续时间和内存消耗量来计费｡
因此，express for Cloud的使用情形可能是，
例如，执行IOT数据摄取､ 流数据或移动应用后端等｡
现在，在Express中，我们有异步和同步两种类型，
我希望大家记住的主要区别是异步Express工作流至少有一个执行模型保证，
而同步类型的Express工作流最多有一个执行模型保证，考试将测试这一点｡
所以，当你使用异步快速工作流时，工作流的执行就开始了，
我们不会等待结果，我们如何知道它是否已经结束，
如果结果是正确的，那么，我们将不得不检查CloudWatch日志｡
所以，这是你不需要立即回应的时候｡
例如，对于消息传递服务，
您只想发送消息，您就这样做，但无论消息是否成功发送，
您都不等待响应｡
因此，由于我们有至少执行一次的保证，如果出现错误，
我们可以直接重试，自动从步骤函数中重试，因此同一操作可以执行两次｡
所以在这种情况下，你必须在幂等性上进行管理，
以确保如果你运行相同的操作两次，你不会得到两次相同的效果｡
对于同步，最多一次，
这是当我们调用快速工作流，但我们等待工作流完成，当我们得到它的结果｡
例如，当您需要工作流本身的即时响应时，
就会出现这种情况｡
因此，例如，如果您编排微服务，
并且希望在停止执行之前确保一切正常工作｡
在这种情况下，对于同步工作流，
您可以从API网关或Lambda函数调用它们，
并从中获得响应｡
最多一次，因为如果出现故障，
步骤函数不会为您重新启动工作流｡
如果你愿意，你可以再试一次，
但这是你需要实现的逻辑｡
好了，这堂课就到这里｡
我希望你们喜欢，我们下节课再见｡ 
  - [ ] 419 [DVA-C02] AppSync Overview [04:30]
    * 
现在我们从考试的角度来讨论AWS AppSync和AppSync，
有两个角度｡
第一个是它是一个托管服务，我们使用GraphQL｡
因此，如果她想在AWS上构建GraphQL API，
AppSync是最佳选择｡
什么是GraphQL？
嗯，GraphQL使应用程序很容易获得它们所需要的数据，
这是一种新型的API｡
其思想是，您只需请求所需的字段，
GraphQL就会返回这些字段｡
GraphQL的理念是，您可以将来自一个或多个源的数据组合到一个图中，
这意味着GraphQL背后的数据集可以包括NoSQL数据存储､
关系数据库､ HTTP API，并且它们都组合在一起｡
AppSync中的GraphQL与DynamoDB､ Aurora､
OpenSearch和其他源直接集成，
如果您希望使用Lambda扩展模式，
则可以从任何位置获取任何数据｡
在AWS中使用AppSync的第二个角度是在WebSockets上实现实时WebSockets集成或MQTT｡
我们的想法是，如果您正在构建需要访问数据感觉的实时应用程序，
您有许多方法，但其中一种方法是AppSync与WebSockets｡
您还可以使用平衡器或API网关上的应用程序，
但AppSync是其中一个选项｡
然后，如果您有移动应用程序，并且希望进行本地数据访问和数据同步，
AppSync也可以取代我们所看到的过时的cookie
to sync｡
所以这也会在考试中出现｡
最后，要开始使用AppSync，
您只需上载一个GraphQL架构，我们将在实践中看到这一点｡
在示意图中，AppSync位于中间，要开始使用AppSync，
您需要创建GraphSQL架构｡
所以我们上传这个模式，
这就是模式的样子｡
然后，您有一个客户端，该客户端会说：“嘿，
我希望您在AppSync上执行此查询？ 比如说，在这个研究中，你指定了这个人的名字，
然后你想知道他的名字，
我们想知道他在哪部电影里出现，在哪艘星际飞船里出现｡
然后AppSync将运行自己的解析程序，
这就是方法，这就是GraphQL的魔力｡
它与解析器一起工作，其中一个结果解析器可能是DynamoDB，
因此这意味着从DynamoDB获取数据｡
然后，AppSync知道如何自动将JSON格式的数据返回给客户端，
以完全符合所要求的确切查询｡
正如我们所看到的，它是一个非常JSON的｡
但是，使用GraphQL，您可以请求任何字段，
AppSync将自动返回该字段｡
这就是总体思路，显然在考试中，你不知道如何编写模式或查询等｡
只是需要你知道高层，但我想让你看看幕后｡
因此，在较高级别上，AppSync不仅集成了Web应用程序､
所有使用GraphQL的移动应用程序，而且还集成了任何实时应用程序｡
例如，它可以是实时仪表板，
也可以是任何需要离线数据同步的应用程序，
并可以替代convert to sync｡
AppSync的核心是GraphQL架构､
上载和解析程序，以指示如何提取数据｡
对于这些解析器，我们通过Lambda函数或现有的公共HTTP端点与DynamoDB､
Aurora､ OpenSearch或任何您想要的东西直接集成｡
如果您要记录AppSync中发生的任何事情，
它将与CloudWatch指标和CloudWatch日志集成以获取此信息｡
最后，因为我们在AWS中创建API，
所以需要讨论安全性｡
因此，您可以通过四种方式授权应用程序与AppSync
GraphQL API交互｡
第一个是API_KEY，因此您可以像API网关一样生成这些密钥并将其提供给用户｡
第二个是使用AWS_IAM允许IAM用户角色或跨帐户访问您缺少的API，
这也与我们在API网关中看到的非常相似｡
然后，如果您希望与OpenID Connect提供程序和JSONWeb令牌集成，
我们会提供OPENID_CONNECT，
最后，我们会提供AMAZON_COGNITO_USER_POOL以与现有用户池集成，
您在Cognito中通过Cognito用户池进行了升级，
然后您可以通过其他社交登录提供程序进行联合｡
最后，如果您希望通过自定义域在AppSync上获得HTTP安全性，
建议的解决方案是在AppSync之前使用CloudFront｡
这堂理论课就到这里，
我们要动手练习｡
  - [ ] 420 AppSync [05:27] Hands On
    * 
  - [ ] 421 [DVA-C02] AWS Amplify [04:59]
    * 
主持人：谈谈AWS Amplify｡
Amplify是一项服务，
它允许你创建移动和网络应用程序，
它由不同的组件组成｡
我们有Amplify
Studio，它允许您可视化地构建前端UI和后端的全栈应用程序｡
我们有Amplify CLI来做完全相同的事情，
但使用CLI｡
此外，我们还提供Amplify Libraries，
用于将您的应用连接到现有AWS服务，例如用于登录的Cognito或用于存储的S3等｡
然后是Amplify Hosting，
在AWS上托管你的Amplify应用程序，
并以非常非常快的速度交付｡
因此，这可能会相当复杂，
但让我们一步一步地了解这些组件｡
所以AWS Amplify first是一套开始使用移动和网络应用程序的工具｡
你应该把它想象成移动和网络应用程序的弹性豆茎｡
我们从Amplify Studio或CLI开始，
在CLI中输入amplify，它会初始化Amplify应用程序｡
所以Amplify给了我们必须具备的功能，
如数据存储，身份验证，文件整体数据的存储，
和机器学习｡
所有这些都由AWS服务提供支持｡
在后端，Amplify依赖于DynamoDB､ AWS
AppSync for GraphQL API､ Cognito､ Amazon S3等｡
然后Amplify也会给你前端文库｡
它们可以用于不同的框架，如React､ View､
JavaScript､ iOS､ Android､ Flutter等｡
所以AWS Amplify将会是一个一站式的商店，
把所有这些东西整合在一起｡
它结合了可靠性､ 安全性和可伸缩性方面的最佳实践｡
然后，我们可以使用Amplify
CLI或Amplify Studio来部署此应用程序｡
而且考试可能会问你关于Amplify的一些重要功能｡
他们来了｡
第一个是Amplify为您提供开箱即用的身份验证｡
为此，我们确实放大了add auth，
这是利用Amazon Cognito｡
您可以进行用户注册､ 身份验证､ 帐户恢复和其他操作｡
它支持MFA，社交签名，等等｡
您可以获得预构建的组件，以便在前端构建此功能并与Cognito集成｡
最后你得到了你的授权｡
第二个功能是围绕数据存储区｡
因此，您确实放大了add api，它将利用Amazon
App Sync作为API，利用Amazon DynamoDB作为数据存储｡
这个想法是，通过数据存储，
你可以处理本地数据，然后你可以自动同步到云，
而不需要任何复杂的代码，这要归功于Amplify框架｡
它总体上由GraphQL和AppSync提供支持，
为您提供离线和实时功能，您甚至可以使用Amplify
Studio对数据进行建模｡
最后，我们得到放大主机. 这就是您希望开始部署应用程序的时候｡
所以你确实放大了添加托管，它允许你构建和托管现代的网络应用程序｡
您执行CICD，例如构建测试和部署｡
你可以预览你的拉取请求，你有你的自定义域，
你可以有监控，你可以设置重定向和自定义标题和密码保护｡
所以它看起来像，
例如，如果你知道竞争服务，如Netlify逆转，
放大主机是类似的｡
所以你要在某个地方得到你的代码｡
比如GitHub或者Bitbucket, GitLab，
甚至CodeCommit｡
然后，您的CICD将在您所拥有的任何东西中构建前端，
然后将其部署到CloudFront｡
同样，您可以让CICD构建后端，
并将后端部署到Amplify中｡
同样对于放大，您可以选择运行测试｡
有两种测试，
单元测试和端到端测试｡
因此，您可以在Amplify的测试阶段运行端到端测试｡
进行端到端测试的目标是，
您可以在将代码推向生产之前捕获回归｡
因此，您可以使用测试步骤在构建时运行任何测试命令，
并在放大器中定义测试步骤｡
yml文件｡
然后，您可以使用Cypress测试框架生成端到端测试｡
使用Cypress测试框架的好处是，
您将获得测试的UI报告，并且可以定义Web点击｡
Cypress可以生成并模拟一个网络浏览器，
你只需说，“点击这里，
做这个，做那个，做那个”，然后验证它是否工作｡
这被称为端到端测试，
因为我们部署应用程序，并从可用性角度验证应用程序是否按预期工作｡
总之，我们有构建级测试，即在构建应用程序时运行单元测试，
这是为了测试代码是否应该执行它应该执行的操作｡
然后进行端到端测试，
即部署应用程序的时间｡
您将运行端到端测试，例如使用Cypress框架，
以确保它按照预期的方式运行｡
最后，您可以部署应用程序｡
好了，这就是放大器｡
希望你喜欢｡ 我们下节课再见｡ 
  - [ ] 422 AWS Amplify [06:56] Hands On
    * 
  - [ ]  Other Serverless [6 问题] Quiz
    * 
 ## Section 29 - Advanced Identity [4 个讲座 • 23 分钟]
  - [ ] 423 STS Overview [03:43]
    * 
我们来谈谈STS，它是一种安全令牌服务｡
因此，
STS允许您获得最多一个小时的临时安全凭据，以直接访问这些资源｡
因此，
在考试中，您需要对一系列API有较高的了解｡
第一个是AssumeRole，在您的客户或跨客户中承担角色，
这是基础｡
AssumeRoleWithSAML如果您的用户使用SAML登录，这将允许我们获取他们的临时凭据｡
假设AssumeRoleWithWebIdentity会传回使用者的角色（如果使用者已使用识别提供者登入）｡
所以Facebook登录，谷歌登录，
或OIDC兼容. 但我们现在已经不用这个了｡
现在我们使用Cognito身份池｡
而不是使用具有Web身份的假定角色｡
然后是GetSessionToken，我们将深入了解这一点，
这是用户或AWS根帐户的MFA｡
然后使用GetFederationToken获取联合用户的临时凭据｡
GetCallerIdentity，返回有关在API调用中使用的IAM用户或角色的详细信息｡
因此，如果您在使用AWS时不知道自己是谁，
只需调用STS GetCallerIdentity，您将获得有关您是谁和您的帐号的信息｡
我们在一开始也看到了这个｡
DecodeAuthorizationMessage用于在AWS API被拒绝时解码错误消息｡
因此，
考试中最重要的几项将是假设角色､ 获取会话令牌､ 获取呼叫者身份和解码授权消息｡
所以STS可以用来承担一个角色，让我们看看它是如何工作的｡
因此，如果我们要在客户中使用AssumeRole，
我们首先要在客户中定义IAM角色｡
或者如果你想做交叉帐户的话，在另一个帐户里｡
然后，
您定义哪些主体可以访问此IAM角色，我们使用IAM策略对所有内容进行授权｡
然后，我们将使用STS
API来执行AssumeRole
API调用，以模拟我们有权访问的IAM角色｡
然后凭证的有效期在15分钟到1小时之间｡
因此，在图表中，
我们的用户希望访问同一帐户或另一帐户中的角色｡
为此，
它将在STS上执行AssumeRole API｡
STS将检查权限是否正确｡
然后将返回给我们临时安全凭据，这将允许我们像角色一样行动｡
对于跨帐户访问，这非常类似，
我们将在另一个帐户中创建角色｡
然后，我们将正确的权限写入我们自己的帐户和目标帐户，最后运行AssumeRole
API来访问目标帐户｡
例如，
该角色允许我们访问S3存储桶，然后我们就可以将该S3存储桶访问到我们的帐户中，非常好｡
最后，
对于采用MFA的STS，了解这一点非常重要，因为要参加认证开发人员考试｡
因此，您可以使用STS中的GetSessionToken
API来获取会话令牌｡
使用MFA设备的API登录后，我们在CLS部分中看到了这一点｡
然后，我们需要具有适当IAM条件的IAM策略｡
然后，在IAM策略中，您需要添加以下aws：存在多因素验证：true，非常明确，
看起来像这样｡
例如，此角色仅允许我们在启用MFA的情况下停止实例或终止实例，
因此MultiFactorAuthPresent：是的｡
这就是我们如何使用它｡
因此，GetSessionToken是要使用的API，为什么要使用它？
因为它会返回一个访问ID､ 一个密钥以及一个我们必须包含的会话令牌｡
我们的API调用需要做三件事，最后一件事是GetSessionToken返回凭据的到期日期，这样我们就知道何时续订凭据｡
好了，STS的课程就到这里，希望大家喜欢，
下次课再见!
  - [ ] 424 Advanced IAM [10:17]
    * 
教师：因此，进入考试，
我们需要对高级IAM概念有更好的理解｡
所以这节课将专门向你们解释一些你们认为理所当然的事情，但最好用图表来概括｡
第一个是授权模型以及如何评估策略｡
因为这是一个简化的模型，
所以它要复杂得多，但希望这能让你对它的工作原理有个好的了解｡
如果策略中有明确的拒绝，则以拒绝结束决策｡
如果存在允许，则以允许结束决策｡
否则，你就否认｡
那它看起来像什么？
例如，假设一个用户想要创建一个DynamoDB表，则决策从deny开始｡
所以默认的话，这件事就做不到了｡
然后，将评估附加到该用户的所有策略｡
例如，
如果我们有一个附加到用户的策略，这将是所有适用策略中的内容｡
然后我们再看政策｡
策略中是否有明确的拒绝？
在策略中是否有地方说“用户不能创建DynamoDB表”？
如果是这样的话，最后的决定就是否定，无论如何｡
然后，只有到那时，才会对允许进行评估｡
那么，是否存在允许用户创建DynamoDB表的allow语句呢？
是的，那么最后的决定就是允｡
不，那么最后的决定就是否定｡
因此，如果策略中同时存在显式拒绝和显式允许，正如您所看到的，拒绝将获胜，
因为首先评估显式拒绝条件｡
记住这个图表，它非常重要｡
现在有趣的部分来了｡
IAM策略如何与S3存储桶策略一起使用？
我们知道IAM策略与用户､ 角色和组关联，而S3存储桶策略与存储桶关联，
它们都定义了用户可以在存储桶上执行的操作｡
所以当我们在IAM中求值时，IAM原则也许可以把一个对象放到一个S3桶中｡
要评估的是IAM策略和S3存储桶策略的并集｡
所以这是一件不太为人所知的事情｡
因此，如果您在S3中执行操作，
您将看到IAM策略和S3存储桶策略的联合，因此所有这些规则都加在一起，这将为给予提供将从安全角度进行评估的总策略｡
一些需要了解的事情｡
因此，
这意味着，例如，
如果您有一个EC2实例，并且您删除了IAM策略中的S3策略，但仍有一个S3存储桶策略授权EC2实例执行某些操作，则它仍可以在S3中执行某些操作｡
所以知道这点非常重要｡
让我们看四个例子，以确保这一点非常清楚，
如果需要，请暂停视频，以确保您正确理解｡
假设您有一个IAM角色连接到EC2实例，它授权对我的bucket进行读写｡
没有附加S3存储桶策略｡
在这种情况下，EC2实例是否可以对存储桶进行读写？
是的，它可以｡
因为这两件事的结合，就是我们的EC2实例有权对我的bucket进行读写｡
好的，第二个例子｡
我们有一个IAM角色附加到EC2实例，它授权对我的存储桶进行读写，
但这次，
S3存储桶策略附加到S3存储桶，并且对该EC2实例使用的IAM角色有一个显式拒绝｡
在这种情况下，是允许还是拒绝EC2实例写入存储桶？
它不能从桶中读取，
因为在联合策略中现在有一个显式拒绝，我们已经看到显式拒绝的优先级高于显式允许｡
因此，
在本例中，我们的EC2实例无法对我的存储桶进行读写｡
例三｡
我们有一个IAM角色附加到EC2实例，其中没有S3存储桶权限｡
这是一个空角色｡
从附加到S3存储桶的S3存储桶策略来看，EC2实例使用的IAM角色具有明确的读写权限｡
在这种情况下，EC2实例是否可以读写存储桶？
答案是肯定的，
它可以，因为联合策略同样具有来自S3存储桶策略的读写允许，
因此我们的EC2实例，即使在其IAM角色中未指定它可以在S3中执行操作，S3存储桶策略仍将允许此操作，因此我们的EC2实例可以读写我的存储桶｡
最后一个示例，附加到EC2实例的IAM角色有一个显式拒绝，
而S3
bucket允许它，在这种情况下，您可能知道答案，EC2实例由于该显式拒绝而无法读写我的bucket｡
因此，希望通过这四个示例，可以更清楚地了解当您同时具有IAM角色和S3存储桶策略时，
如何评估策略｡
现在，让我们考虑另一个称为动态策略的高级IAM概念｡
那么，
如何在S3存储桶中分配一个/home/user文件夹呢？例如，IAM组织中的每个用户都将拥有自己的文件夹，并且只能对该文件夹进行读写｡
例如，选项一可以创建一个IAM策略，
允许您的Georges访问/home/georges｡
也许您创建了另一个IAM策略，允许IAM中的用户Sarah访问/home/sarah｡
也许为马特做这件事，/家/马特｡
因此，您将为每个用户创建一个IAM策略，
并且每次添加新用户时，都必须创建一个IAM策略，以允许他们访问自己的主目录｡
所以这显然不能扩展，对吧？
第二个选择是，
正如您所期望的，在IAM中使用动态策略，并且只创建其中的一个｡
您将利用名为${aws：使用者名称}｡
在运行时，
由于它是动态的，因此将被AWS用户名的值替换｡
现在，您可以做的是，
如果您希望允许用户写入他们自己的文件夹，您可以使用这个非常简单的动态策略，在其中您可以将此策略附加到所有用户，
也就是说，您有权访问/home/${aws：username}就是这样，
非常简单，
但现在您知道了IAM中存在动态策略和动态变量，它大大扩展了IAM的可能性｡
其理念是，您不希望每个用户都有一个策略，您希望每个用户都有一个策略，但由于AWS用户名的动态替换，
该策略是基于每个用户定制的｡
最后但并非最不重要的一点是，让我们来讨论内联策略和托管策略之间的区别｡
AWS中有三种策略｡
还有AWS托管策略，顾名思义，这些策略由AWS维护，
您无法对其进行任何控制，如果您希望定义高级用户或管理员或基于工作职能，
这些策略非常有用｡
如果AWS创建了新服务或引入了新的API，它们将由AWS进行更新｡
因此，
如果你想让你的管理员，他们是非常有用的，
例如，我们一直在使用这些沿着
然后您就有了客户管理策略｡
这一次，
由您来创建这些策略，如果您希望进行更精细的控制，最好使用这些策略｡
它们将是可重用的，它们可以被应用到你想要的任意多的原则中｡
他们将有版本控制，如果你想的话，你可以及时回滚这些策略｡
有一个中央变更管理，
所以你可以看到谁做了什么，谁｡
它们很棒，根据AWS文档，
它们是最佳实践｡
最后，
您有内联策略，内联策略直接位于原则内｡
它们之间是严格的一对一关系的政策和原则｡
它们不是版本控制，你不能回滚它们，
你不能很容易地改变它们｡
如果删除IAM原则，则会删除策略｡
所以请记住这三者之间的区别｡
让我向您展示它们在IAM控制台中的情况｡
所以我现在在AWS IAM中｡
在左侧，
我可以单击“Policies”（策略），在这里我可以看到已创建的所有策略｡
我可以通过AWS托管策略对它们进行筛选，例如，
我们可以看到，
这是AlexaForBusinessFullAccess或AlexaForBusinessReadOnlyAccess，几乎每项服务都有这些访问权限｡
如果我输入DynamoDB，我会看到所有这些策略｡
我们有DynamoDBFullAccess､ 带数据管道的DynamoDBFullAccess､
只读访问､
自动缩放､ Lambda，所有这些功能，以及复制服务｡
因此，
我们可以很快看到所有策略，如您所见，这些策略都是AWS管理的｡
您还可以看到您的客户管理策略，它们就是我们在本课程中创建的策略，
让我去掉筛选器｡
因此，我们有一些CodeBuilds､ CodePipeline､ Lamda等，
这些都是客户管理的｡
例如，如果我单击其中一个，
我可以看到权限和版本，
即策略版本，因此在本例中只有一个版本，我可以看到策略使用情况，即使用此策略的对象｡
因此，
这使得它非常容易，可审计和可定制的同时｡
最后，
还有内联策略，您在这里找不到它们｡
您可以在“Users（用户）”中找到它们，在右侧的“my
name（我的名字）”中，
我可以通过服务添加内联策略（例如EC2），并为自己给予列表权限｡
现在我想给你们看一些东西，我会说，“好的，
列出权限｡
“有95人被选中，这是非常好的｡
在“资源”中，我不需要指定任何资源｡
我单击“Review policy”（查看策略），将其命名为“MyInlinePolicy”，
然后单击“Create policy”（创建策略），此时您会注意到，我无法创建此策略，
因为我的策略最大字节数是2 KB，
而对于此用户，已超出此值，
因此使用内联策略实际上无法指定许多不同的内容｡
因此，
在本例中，如果我们之前查看JSON，
您可以看到有许多不同的文本，可能超过2 KB，因此我无法使用此策略｡
相反，我可以选择这些属性中的一个，而不是使用List，
现在希望我的内联策略能够工作｡
是的，它起作用了｡
正如我们现在看到的，我现在已经连接到我自己的用户MyInlinePolicy，这是一个内联策略｡
从那里，它实际上链接到我的用户，
但正如你所看到的，
它不是很方便，不是很可审计，它有一些大小限制｡
就是这样，希望对大家有所帮助｡
我希望你在IAM中学到了很多东西，并且你会相应地使用这些概念，我将在下一节课中见到你｡
  - [ ] 425 Granting a User Permissions to Pass a Role to an AWS Service [03:39]
    * 
解说员：这是我们在IAM中使用的另一个功能，但我们并不真正了解它，
但它对了解AWS至关重要｡
因此，当我们配置许多AWS服务时，我们为它们提供了IAM角色，
并为此提供了我们传递给它们的IAM角色的关键字｡
这通常是在我们第一次建立服务时完成的｡
因此，一旦服务具有IAM角色，它就可以承担该角色并执行所需的操作｡
因此，
当我们将一个角色传递给另一个服务时，例如，当我们创建一个EC2实例角色并将其分配给EC2实例时，我们实际上传递了该角色｡
或者是一个Lambda函数，我们在其中创建了一个IAM角色，然后传递给它以学习该函数，
以便它可以调用Amazon
S3或ECS任务，或者当我们将一个角色传递给CodePipeline时，允许它调用其他服务｡
总而言之，
当我们想要将角色传递给另一个AWS服务时，我们需要名为iam的IAM权限：PassRole，通常它还附带另一个名为iam的权限：GetRole可查看正在传递的角色｡
因此，这里的关键是，要将角色传递给另一个服务，
您需要IAM传递所有权限｡
那么具体地说，IAM策略是什么样子的呢？
看起来像这样｡
因此，如果这个IAM策略被分配给我，
它允许我在EC2上做任何我想做的事情，比如创建实例､ 终止实例等｡
等等｡
但语句的第二部分允许我传递一个角色，该角色称为S3Access｡
因此，这意味着我可以分配给EC2实例的唯一角色就是这一个S3访问角色｡
因此，我需要以下操作iam：PassRole来执行此操作｡
所以问题是，任何角色都可以传递给任何服务吗？
答案是否定的｡
角色只能根据其信任所允许的内容传递给服务，因此角色的信任策略是一个指示，
表明哪个服务可以承担该角色｡
这是一个普通的IAM角色，这是一个IAM角色的信任策略｡
也就是说，只有EC2服务，也就是主体服务EC2中的EC2服务，
只有该EC2服务具有允许承担该角色的信任，因此我们一直在IAM策略中使用该服务，而不知道该角色，
让我们来看看｡
但在IAM中，我转到角色，
我们可以看到这里有一个角色名称，这里有一个受信任的实体，
因此这允许特定的服务承担该角色｡
例如，
如果我们查看这个AWS CodePipeline服务并打开它，
我们可以看到我们在这个CodePipeline服务上允许的权限，它们在JSON中，但第二次在这里被称为信任关系，而这个信任关系是一个策略文档｡
因此，我将单击“显示策略文档”，这是允许CodePipeline服务承担该角色的信任策略｡
因此，这就是为什么这里您可以看到受信任的身份提供者是代码管道｡
亚马逊人｡
这就是信任政策背后的全部理念｡
但是，
您可以看一下，这里有一个所有受信任实体的列表｡
例如，如果我向下滚动，查看Lambda函数，
如果我转到Lambda，查看lambda-dynamodb-demo-role，这有一堆策略，但如果我转到信任关系，
我们可以看到信任提供程序是lambda｡
亚马逊人｡
如果我看一下JSON文档，它是这样的｡
原来如此，这就是幕后黑手｡
因此，
要传递角色，我们首先需要创建正确的信任关系，以允许目标服务承担该角色，最后我们需要具有iam：将角色传递到目标服务的PassRole权限｡
所以我就这样了｡
我希望你们喜欢，下节课再见｡
  - [ ] 426 AWS Directory Services [05:33]
    * 
-好的—好的
现在，我们来谈谈微软的活动目录和AWS目录服务｡
因此，如果你不知道什么是微软AD，它是一个软件，
是在任何Windows服务器上找到的AD域服务｡
它是一个对象数据库，对象可以是用户帐户､
计算机､
打印机､ 文件､ 共享安全组｡
因此，您在内部部署的整个Microsoft生态系统中管理的所有用户都将由Microsoft Active
Directory进行管理｡
而且将有一个集中的安全管理｡
您可以创建帐户､ 分配权限等｡
并且所有的对象将被组织成一个树｡
而一群树被称为森林，那只是出于某种术语｡
那么，让我们举一个例子｡
我们有一个域控制器，我们将在其上创建一个帐户｡
我们创建一个帐户｡
用户名是“John”，密码是“password”｡
我们的想法是，我们网络中的所有其他Windows计算机都将连接到域控制器，这样，
如果我们在第一台计算机上使用John密码，将在控制器中查找该密码，然后说，是的，
我们有该登录名，然后允许您从该计算机登录｡
因此，所有这些计算机都将连接到您的域控制器，
这样您就可以在任何一台计算机上访问用户｡
这就是Active Directory背后的全部理念，非常高的层次｡
现在我们有了AWS目录服务，它是为你提供一种在AWS上创建活动目录的方法｡
我们有三种口味｡
我们不需要对它们做深入的研究，但你必须了解这三种口味之间的区别｡
第一个是AWS，管理微软AD在AWS中创建自己的活动目录｡
您可以在本地管理用户，并且它支持多因素身份验证｡
其理念是，通过此独立Active
Directory，
您还可以创建与内部部署AD的信任连接，其中您也有自己的用户｡
这意味着，例如，您在这里的AD可以与内部部署AD一起信任｡
因此，AWS信任内部部署AD，内部部署AD也信任AWS｡
这意味着，如果您的用户对权限进行验证，使用不受AWS管理的帐户，它可以在内部部署的Active
Directory中查找帐户｡
同样，
如果内部部署目录用户使用AWS帐户访问您的内部部署AD并进行身份验证，则可以信任该用户访问并查找该目录｡
在这里，
我们的用户将在我们的内部部署Active Directory和AWS之间共享｡
好吧，我会的 有点复杂｡
我知道你是新手，但希望你能理解｡
AD连接器有点不同｡
这是一个直接网关代理，用于重定向到内部部署AD，
如果您需要多因素身份验证，它支持MFA｡
用户仅在内部部署AD中进行管理｡
这是一个例子｡
在本例中，我们的AD连接器只是充当代理｡
因此，如果您的用户使用我们的AD连接器进行身份验证，
它会将请求代理回我们的内部部署AD并进行查找｡
这里的想法是，在第一种情况下，微软管理微软AD，我们让用户在AWS中管理AD，
而用户在内部部署AD中｡
而使用AD连接器，
正如其名称所示，它将代理､
查询､ 连接请求连接回我们的内部部署Active Directory，并且我们可以管理用户的唯一位置将位于内部部署AD上｡
最后，您有一个简单的AD，它是AWS上与AD兼容的托管目录｡
它不使用Microsoft目录｡
并且它不能与非内部部署的Active Directory连接｡
因此，如果您没有内部部署的AD，但需要为AWS云部署Active
Directory，那么您可以将一个简单的AD作为一个独立的组件｡
这里的想法是，
使用Active Directory，您可以轻松地创建两个运行Windows的实例｡
这些Windows实例可以加入网络的域控制器，并共享所有登录信息和凭据等｡
因此，这就是为什么我们希望在AWS中有一个目录，
以便有一个更靠近运行Windows的EC2实例的目录｡
希望这是有意义的｡
现在，考试将询问您一些非常高级别的问题，例如，
我们希望将用户代理到内部部署，因此您需要AD连接器;或者，我们希望在AWS中管理云上的用户，并拥有MFA，
因此您需要AWS管理AD;或者，我们只需要简单的AD，
并且我们没有任何内部部署内容｡
在本例中，您需要一个简单的AD｡
因此，如果您转到控制台并键入directory service，
我们可以看到提供给我们的不同选项｡
我将从较高的层次介绍它们，因为单独设置它们可能会很复杂｡
但是我们有四个选项，实际上第四个是Amazon Cognito
User
Pool，它会将您重定向到Cognito服务，因此不将其计入目录服务｡
因此，我们让AWS管理Microsoft AD，其中我们可以有一个将与AWS云集成的Active Directory，
并且可以与您的内部部署目录建立信任关系｡ 要设置该目录，您可以看到它增加了两项功能：标准版最多可包含30，
000个对象，
企业版最多可包含500，000个对象｡
所以多了很多｡
然后，您需要进行设置，
但不需要进行详细的设置，
因为这是更具体的AD，您不需要了解这些内容来参加考试｡
下一个是简单AD，它将是一个独立的托管目录，具有Active
Directory兼容API，
但无法连接到您的内部部署Active Directory｡
或者AD连接器，它是一个代理，用于将目录请求重定向到您现有的内部Microsoft
Active Directory，它是为您设计的，
有两个级别｡
您的连接器最多可连接500个用户，
或者您的连接器最多可连接5，000个用户｡
好吧，我会的 记住，第一个支持MFA｡
第二个是独立的，AD连接器是一个代理｡
好了，这节课就讲到这里｡
我们下节课再见｡ 
  - [ ]  Advanced IAM [5 问题] Quiz
    * 
 ## Section 30 - AWS Security & Encryption: KMS, Encryption SDK, SSM Parameter Store, IAM & STS [21 个讲座 • 1 小时 39 分钟]
  - [ ] 427 AWS Security - Section Introduction [00:44]
    * 
这一部分是最重要的一部分，考试将询问您许多有关安全性的问题｡
你们可能已经注意到，在之前的所有课程中，我都多次谈到了安全性｡
我说了不同的AWS服务是如何与安全性集成的，我相信您对此有了很好的了解，但我想用一整节的时间来回顾我们学到的知识，
了解KMS､ 正确加密､
参数存储等｡
这一部分将真正为您在安全方面所看到的一切带来光明｡
我希望你会喜欢｡
它是非常真实的世界为导向｡
我们将用AWS Lambda来练习｡
那么，让我们一起来了解一下安全性｡ 
  - [ ] 428 Encryption 101 [05:18]
    * 
教师：首先，我们来概述一下加密机制｡
第一个是航班加密｡
那我们为什么还要加密航班呢
我们希望在传输过程中进行加密，因为如果我发送一个非常敏感的秘密，例如，
我的信用卡到服务器，
以便进行在线支付，我希望确保在我的网络数据包将要传输的途中，没有其他人可以看到我的信用卡号｡
所以我想确保当我在网上付款时，我有绿色的锁，我有HTTPS网站，
它可以保证我，
它是一个SSL启用的网站，我会在飞行中得到加密｡
因此，当你在飞行中加密时，数据在我发送之前会被加密，
然后服务器在收到数据后会解密｡
但是，只有我自己和服务器知道如何做这些事情｡
SSL证书将帮助加密，因此另一种方法是HTTPS｡
因此，
每当我们处理一个亚马逊服务时，它都有一个HTTPS端点，这保证了它在传输过程中是加密的｡
而现在整个网络，
几乎整个网络，都需要在SSL和HTTPS上运行｡
基本上，
当您启用此功能时，您可以抵御“中间人”攻击｡
因此，
这可以保证，当您拥有绿色锁，
并且服务器证书有效时，没有人可以检索您的敏感信息｡
我们来举个简单的例子｡
这是我们，我们想与AWS上的HTTP网站交谈;可以是DynamoDB，
也可以是任何我们想要东西
然后我们要做的是，我们要添加超级机密数据，
我们要使用SSL加密对它进行加密，
并通过网络发送它，然后网站将接收数据，并知道如何解密｡
非常非常简单;但执行起来就不那么容易了，所以这就是我给予你的钱｡
好消息是，所有编程语言都知道如何进行SSL加密和解密，并且已经为您完成了这一工作，
因此您不必担心任何事情｡
这不是你必须直接处理的事情｡
第二件事将被称为服务器端静态加密｡
因此，在服务器接收到数据之后，
数据被加密｡
在此之前，服务器接收数据，解密数据，
并以解密后的形式使用数据｡
这里，
服务器将数据存储在其磁盘上，因此我们需要知道服务器以加密形式存储数据｡
因为，
万一服务器被其他人劫持，我们不希望其他人能够解密数据｡
因此，数据将在发送回客户端之前进行解密｡
因此，由于有了密钥（通常称为数据密钥），数据将以加密形式存储，
加密和解密密钥必须在某个地方进行管理，通常称为KMS或密钥管理服务，
服务器必须有权与该密钥管理服务进行通信｡
这是我们的对象，我们将把它传输到EBS｡
因此，数据将通过任何机制传输，
EBS将使用数据密钥，使用数据密钥将对该数据执行加密，现在它以加密形式存储，然后在我们出于任何原因需要检索数据的那一天，
EBS（AWS服务）将再次使用数据密钥为我们解密，
我们将获得解加密数据，并通过HTTP返回给我们，例如HTTPS｡
这就是服务器端加密的工作方式，
正如您所看到的，服务的服务器端本身管理加密和解密，并使用它有权访问的数据密钥｡
这是静态服务器端加密｡
我们已经看到，许多AWS服务在静态时确实使用了这种加密｡
现在，我们来讨论客户端加密｡
在客户端加密中，
数据将由客户端进行加密，而客户端就是我们｡
服务器将永远无法解密该数据｡
然后，数据将由接收客户端解密｡
总而言之，数据只是存储在服务器上，
但服务器并不知道数据的含义｡
而且，
作为最佳实践，服务器无论如何都不应该能够解密数据｡
为此，我们可以利用一种叫做信封加密的东西，但我稍后会有一整堂课来讲这个，因为这是非常高级的，
但这个例子问你关于信封加密的问题，所以现在，
让我们先做一个抽象的介绍｡
我们有了对象，在客户端，我们将使用一个数据密钥，
并在客户端对数据进行加密｡
所以我们用这个数据密钥进行加密｡
现在我们将数据发送到任何我们想要的数据存储;可以是FTP，
可以是S3，也可以是您真正想要任何文件
你可以把数据放在任何你想放的地方，比如亚马逊或其他地方｡
然后，当你收到它的时候，你的客户端将收到一个加密的对象，
如果它可以访问数据密钥，如果它可以设法从某个地方检索数据密钥，那么它将能够执行解密，
并得到解密的对象作为结果｡
正如您现在所看到的，加密发生在客户端｡
服务器（即数据存储）不知道如何解密或加密数据，它只接收加密数据｡
所以这也是相当安全的｡
这里有三种加密方式，除了信封加密，我们稍后会介绍｡
因此，这还没有使用任何KMS｡
这只是对加密工作原理的抽象｡
我知道这可能有点简化了，但希望这能让我们搞清楚什么是加密，在下一节课中，
我们会深入探讨KMS.
  - [ ] 429 [DVA-C02] KMS Overview [07:28]
    * 
解说员：现在我们来谈谈AWS
KMS，它是AWS的密钥管理服务｡
所以我们一直在使用它，你知道，
很多时候你不知道，但每当你听到加密时，你有一个AWS服务，
它最有可能是KMS加密｡
我们的目标是，通过这个KMS服务，
AWS将为我们管理加密密钥｡
这很好，因为这意味着我们有更少的事情要做｡
因此，KMS当然与IAM完全集成以进行授权，
如果数据使用KMS加密，它为我们提供了非常简单的方法来控制对数据的访问｡
使用AWS KMS的强大之处在于，您可以通过CloudTrail审核为使用密钥而进行的每一个API调用，
这可能是考试中要测试的内容｡
因此，在它之上，KMS可以无缝地用于大多数AWS服务｡
例如，如果您希望加密EBS卷中的静态数据，
只需启用KMS集成｡
S3､ RDS､ SSM以及几乎所有需要加密的服务都是如此｡
这个想法是，有了KMS，你也可以自己使用它｡
如果你有秘密数据，你永远不会以纯文本的形式存储它们｡
这意味着一切照旧，尤其是在代码中｡
所以如果你想使用KMS，
你也可以通过API调用来使用KMS｡
您可以使用AWS CLI或SDK｡
这意味着你可以用KMS密钥加密任何对你来说是秘密的东西｡
然后，这些加密的秘密可以存储在代码或环境变量中｡
这是一个更好的模式｡
现在我们来讨论一下您可以使用的不同类型的KMS密钥｡
顺便说一下，现在它被称为KMS密钥｡
它过去被称为KMS客户主密钥，但这很容易混淆，
因为还有客户管理密钥，
我们稍后将看到｡
现在我们只讨论KMS密钥｡
因此，我们有两种类型的KMS密钥｡
我们有对称的KMS密钥，这意味着只有一个加密密钥用于加密和解密数据｡
因此，AWS的任何与KMS集成的服务都将使用对称密钥｡
其思想是，当我们创建或使用KMS对称密钥时，我们永远无法访问密钥本身，
对吗？
我们所做的就是使用KMS API调用来利用和使用该密钥｡
KMS上可用的第二种密钥称为非对称密钥｡
这意味着你有两把钥匙｡
您有一个用于加密数据的公钥和一个用于解密数据的私钥｡
因此，当您执行加密/解密或签名/验证类型的操作时，
会使用此函数｡
在这种情况下，您可以从KMS下载公钥，
但无法访问私钥｡
您只能使用API调用来访问私钥｡
非对称类型密钥的用例是当您希望无法或没有权限访问KMS
API密钥的用户在AWS云之外进行加密时，
在这种情况下，他们将使用公钥加密数据，然后将其发送给您，
而您将在您的帐户中使用AWS的私钥解密该数据｡
因此，在KMS密钥的世界中，
您有不同类型的KMS密钥｡
第一个是AWS拥有的密钥｡
它们是免费的，这是你在使用SSE-S3类型的加密或SSE-DynamoDB时会使用的密钥，
你可以选择，例如，你选择DynamoDB拥有的密钥｡
这些并不是真正的KMS，
因为您看不到它们，
但它们是AWS中的加密密钥类型｡
然后您有了AWS管理的密钥，它们是免费的，
您可以认出它们，因为它们以AWS､
斜杠和服务名开头｡
例如aws/rds或aws/ebs，或者在本例中为aws/dynamodb｡
它们是免费的，你可以随心所欲地使用它们，
但只能在分配给它的服务中使用｡
然后你就有了自己的客户管理密钥，
它们是自定义密钥，每月要花1美元｡
如果你也想进口它们，
你可以进口它们，它们每月花费你1美元｡
KMS也有一个定价，您将为每个对KMS服务的API调用付费，
大约是每10，000个API调用3美分｡
您还可以使用自动密钥轮换｡
因此，如果它是一个AWS管理的KMS密钥，
那么它是自动的，每1年｡
如果它是您在KMS中创建的客户管理密钥，
则必须启用自动轮换，并且每1年轮换一次｡
如果它是导入的KMS密钥，
那么你只能手动旋转它｡
为此你需要利用一个化名｡
因此，KMS密钥的作用域是按区域划分的｡
这意味着，如果我们在一个地区（例如eu-west-2）中有一个使用KMS密钥加密的EBS卷，
那么如果您要将其拷贝到其他地区，我们必须执行几个步骤｡
首先，我们必须拍摄此EBS卷的快照｡
如果我们从加密的快照中获取快照，
则此快照本身也将使用相同的KMS密钥进行加密｡
然后，要将快照复制到另一个区域，我们需要使用不同的KMS密钥重新加密快照｡
这是AWS将为您做的事情｡
但是同一个KMS密钥不能存在于两个区域中｡
现在我们有了EBS快照｡
它是用KMS用不同的密钥加密的，
它位于另一个区域｡
现在，我们使用KMS将快照恢复到它自己的EBS卷中，
KMS密钥B位于区域ap-东南-2中｡
现在，我们需要了解的另一件事是KMS的关键政策｡
这是为了控制对KMS密钥的访问｡
它类似于ASWS S3存储桶策略，区别在于如果您的KMS密钥上没有KMS密钥策略，
则任何人都无法访问它｡
因此，在这方面，我们有两种类型的KMS关键策略｡
我们有默认的KMS密钥策略，如果您不提供特定的自定义KMS密钥策略，
则会创建该策略｡
这个想法是默认的允许你账户中的每个人都可以访问这个密钥｡
这意味着，如果您有一个IAM策略允许用户或角色访问这个密钥策略，
那么就可以了｡
但是，如果您希望对其进行更具体的控制，则可以使用自定义的KMS密钥策略，
在该策略中，您可以为用户定义可以访问您的KMS密钥的角色｡
并且您定义谁可以管理密钥｡
如果您希望跨帐户访问您的KMS密钥，
这将特别有用，因为我们可以授权另一个帐户使用我们的KMS密钥｡
我们什么时候用这个？
例如，如果我们要跨帐户复制加密快照｡
因此，我们创建了一个使用我们自己的KMS密钥加密的快照，
这是一个客户管理的密钥｡
一定是这样，因为我们需要附加一个自定义密钥策略｡
然后我们附加一个KMS密钥策略来授权跨帐户访问｡
它看起来像这样｡
然后我们与目标帐户共享加密的快照｡
然后，在目标帐户中，我们创建快照的拷贝，
并在该目标帐户中使用另一个客户管理的密钥对其进行加密｡
然后，我们可以从目标帐户中的快照创建卷，
这样就完成了｡
以上是KMS提供的大量信息，
但让我们开始实际操作，希望能了解更多信息｡
  - [ ] 430 KMS Hands On w/ CLI [09:13]
    * 
讲师：让我们来看看KMS服务｡
首先，在左侧，
我将查看AWS托管密钥｡
您可以看到，
如果我在本课程中一直使用KMS加密，则这些密钥将显示在此处｡
例如，我们可以看看AWS EBS｡
这是一个S管理密钥，
因为它属于EBS服务｡
所以我们可以看看它是如何被使用的｡
所以有一个密钥策略，
这个策略定义了什么可以访问这个密钥.
当然，因为这是EBS AWS键，所以您将看到所有操作｡
所以它可以从任何地方来，做某种动作｡
但条件是有色人种的账户必须是我的｡
并且VS服务必须是在EBS服务之上的服务的EC二服务｡
好吗？
例如，如果我查看另一个AWS托管密钥（例如SQS密钥），
并查看此处的密钥策略，则作为KMS密钥策略条件的via服务是SQS服务｡
因此，只允许从SQS访问KMS，
从SQS访问此密钥，我们还可以查看加密配置，
该配置显示此密钥与原始KMS对称，
并用于加密N个解密数据｡
好吧，我会的
这是AWS管理的KMS密钥，但我们还有其他客户｡
我们有客户托管密钥和客户密钥库｡
因此，客户密钥存储区是我们希望使用CloudHSM的时候，
但这超出了本测试的范围｡
所以我们不要再讨论这个了｡
我们要复习一下客户管理密钥｡
因此，这是我们希望在KMS中创建自己的密钥，
而不使用AWS管理的密钥的时候｡
所以让我们创建一个密钥，但如果我们这样做，
记住这将花费你每月1美元｡
所以如果你不想付任何钱，那就别这样做｡
所以这里对于密钥类型，有多个选项有对称或非对称类型的密钥｡
如果我使用非对称，这可以用于加密和解密，
或者签名和验证类型的操作，但这超出了本课的范围｡
我将使用对称类型的KMS密钥，
并使用加密和解密选项｡
好吧，这是最基本的一个｡
我想给你们看，
高级选项｡
密钥源将是KMS，因为我们希望KMS为我们创建此密钥｡
如果我们想导入一个密钥，这将是密钥来源的外部类型或自定义密钥故事｡
如果您想拥有CloudHSM｡
但同样，这超出了范围｡
因此，我们将使用KMS，对于区域性，
我们有单区域密钥和多区域密钥，我们现在只考虑单区域密钥，
因为这是最古老的选项类型，
也是KMS最常用的｡
我们将使用单区域密钥，单击“下一步”，
接下来我们有一个密钥别名，
因此我将它作为教程，单击“下一步”｡
在这里，我们可以开始定义密钥管理员｡
因此，如果我不定义一个密钥策略，那么我们将使用默认的KMS密钥策略，
这也是我想要的｡
但是如果你想非常具体地确定谁可以使用这个密钥，
谁可以管理它，这就是它发生的地方｡
现在，我不准备选择任何内容，
然后单击“下一步”｡
那你可以说，谁能用这把钥匙？
同样，这也是为了让您的KMS关键策略更加具体｡
我想允许每个人使用它，
如果他们有正确的IAM权限｡
但是如果你还想有一些额外的安全性，你可以说，
嘿，只有斯蒂芬可以使用这个密钥｡
这将创建一个自定义KMS密钥策略｡
但在这种情况下，我不想这样｡
正如您在底部看到的，
我可以选择其他AWS帐户来访问我的密钥｡
例如，如果您有共享加密快照EBS快照的使用情形，
您可以添加另一个帐户以允许访问您的密钥｡
所以我们总结一下｡
我们有一个对称密钥，这是密钥策略，
我称之为默认密钥策略｡
这只是为了启用IAM用户权限｡
因此，它允许任何东西对KMS上的任何资源执行操作，
当然，只要它们具有IAM权限即可｡
所以让我们结束这一切｡
现在我的密钥已创建，我们可以单击“view
key”（查看密钥）｡
现在我的密钥已经创建好了，
我可以查看一下密钥策略｡
所以关键的政策是这样的｡
这是您的密钥的IAM策略，但您可以切换到默认视图，
并可以看到更好的摘要，如谁是密钥管理员？
是否允许删除密钥？谁是密钥用户？其他帐户是否可以访问？
所以我不会碰这个｡
然后，您可以查看加密配置｡
我不会碰这个，不需要标签｡
密钥轮换非常重要｡
因此，如果我们确实要启用密钥轮换，
则必须勾选此框，
这将每年轮换此KMS密钥｡
好吧，你不能将它配置得更大或更小｡
每年都得这样｡
这是唯一可能的，因为我确实从KMS中创建了这个密钥｡
最后看看，最后，我的密钥的别名是什么？
它被命名为教程｡
所以我可以用一个别名来引用它，
这样对我们来说会简单一点｡
最后，对于密钥操作，
您可以禁用它或计划密钥删除｡
我们有钥匙了｡
这很好，但现在让我们使用CLI来加密和解密一些数据｡
在KMS下，我有KMS演示CLI. SH，它将通过一个示例向我们展示如何使用KMS的加密和密码｡
首先，我们要创建一个文件，我将其命名为example，
secret file. TXT.
我会告诉你有一个超级秘密的密码
这就是你想在这个文本文件中看到的内容，
我输入了一个名为超级密码的密码，我们将使用KMS对它进行加密和解密｡
因此，对于KMS加密，
您要做的第一件事就是使用encrypt命令｡
所以我们必须为我指定一个密钥ID它的别名斜杠教程｡
这与我在控制台中创建的键相对应｡
你可以用化名｡
您可以在此处使用此密钥ID，也可以使用完整的ARN｡
没关系，你想用什么都行｡
然后您需要以纯文本的形式传递文件的地址｡
因此，对我来说，它是示例秘密文件.
txt，查询的输出｡
因此，您要查询一个表示加密内容的密文博客｡
你想要的是文本，最后是区域，
你的键在里面｡
所以对我来说，我最近的地区是欧盟西部2区｡
这将为我们提供一个包含加密内容的base
64文件｡
所以我们把这个命令复制到这里，然后粘贴，运行它｡
现在我有了一个名为example secret file的文件，
以base 64加密｡
这是我的加密文件｡
好吗？
在64号基地｡
现在我们可以识别字母和数字，我们将进行一次64进制解码，
得到二进制加密值｡
因此，如果您使用的是Windows，则命令会有所不同｡
对于Linux，我只运行这个，但是对于Windows，
你可以运行另一个｡
我们要创建一个名为示例秘密文件的文件，
加密时不使用base 64.
让我复制并粘贴它｡
现在我有一个新的文件称为示例秘密文件加密｡
如果我尝试用文本编辑器打开它，
它将无法工作，因为它使用二进制或不支持的文本编码｡
所以这确实是一个二进制文件｡
所以这是一种你会和别人分享的秘密文件｡
所以现在我想去解密它｡
所以这完全是胡言乱语，我们无法得到任何信息｡
即使是这个，我们也无法得到任何信息｡
我们怎么知道这是超级机密密码？
这是一个加密的文件，但是现在我们要把这个加密的二进制文件解密｡
为此，我们将运行KMS解密命令｡
所以这次我们传入blog，
这个文件是加密的｡
所以这就是我们传递文件的地方｡
然后查询纯文本值｡
解密后的值，我们将其写入另一个将使用base
64加密的文件，并指定区域｡
那我们继续吧｡
KMS自动知道哪个密钥用于描述，
因为它包含在加密值的blob中｡
让我输入这个｡
所以这是成功的｡
现在我看一下我的示例文件解密base
64，它就在这里｡
这是一个短得多的东西｡
现在我们要用basic64来解码，
得到我的文本值｡
如果你使用的是Windows或者Max，
我使用的是Mac，我们会使用不同的命令｡
所以我复制这个命令，粘贴它｡
现在我们已经对文件进行了64进制解码｡
所以如果我们回到例子，文件解密点TXT我们找到了我们的超级秘密密码｡
因此，我们已经展示了加密及其反向操作｡
解密｡
显然这些都是低级命令｡
SDK将为我们抽象其中的一些内容，
但这向您展示了如何使用KMS的加密和解密命令以及您自己的客户主密钥的完整示例｡
所以这就是它超级简单｡
我希望这对你有帮助｡
我们下节课再见｡
  - [ ] 431 KMS Encryption Patterns and Envelope Encryption [07:28]
    * 
教师：现在，让我们深入了解一下KMS如何真正用于加密和解密API以及信封加密｡
所以我们做的是，
我们有一个秘密，例如，一个密码，它小于4千字节，
因为这是KMS的一个限制，我们把它发送到KMS服务｡
因此，
我们使用SDK或CLI来使用加密API，然后指定要在KMS中使用的CMK｡
然后，KMS与IAM一起检查我们是否具有正确的权限｡
如果我们有，那么它会为我们执行加密｡
KMS将发送给我们的将是完全加密的秘密｡
这就是加密数据｡
那我们就得解密｡
因此，我们使用CLI或SDK来执行解密API｡
然后，
我们会，KMS会自动了解哪个CMK用于加密，并查看它来执行解密｡
它将首先检查IAM，以确保我们具有执行解密的正确权限｡
如果我们这样做，那么它会发送我们通过解密的秘密在纯文本｡
这是加密和解密API，非常简单｡
因此，
正如我们所看到的，尽管存在问题，但我们将秘密的大小限制为4千字节｡
因此，我们有一个循环加密｡
如果你想加密超过四千字节的数据，
那么有一种技术，你可以用信封来加密｡
你要记住的主要API是为我们加密大量的数据，大量的数据是使用GenerateDataKey
API｡
从考试的角度来看，
如果你想在这堂课上到此为止，任何超过4 KB的数据都必须使用信封加密技术进行加密，
这与KMS GeneratDataKey API相对应｡
现在我要你复习考试｡
我想向大家解释一下这个API是如何工作的，我认为这可能很有价值，但请放心，
这有点困难｡
所以如果你不跟，也不要太担心｡
我们来看看信封加密｡
我们有KMS服务，这次我们要加密一个非常大的文件｡
也许它最多是10兆字节，
但它可以像你想要的那样大，真的｡
因此，我们将使用SDK，并调用GenerateDataKey
API，然后指定CMK, KMS将再次检查IAM权限，
以确保我们可以生成数据密钥｡
如果我们可以，那么KMS将为我们生成这个数据密钥，
并将它的纯文本版本发送给我们｡
我们有一个纯文本数据密钥加密，即数据加密密钥DEK｡
现在我们有了这个数据加密密钥，但为什么要有它呢？
因为现在我们可以做一些客户端的事情｡
我们可以使用我们自己的CPU和这个DEK对大文件客户端进行加密｡
这就给了我们一个加密文件｡
然后，
实际上，我们要在它周围建立一个信封，这是最终的文件｡
所以我们要做一个信封，我们在信封里放什么呢？
然后我们会放一个加密版本的DEK，
实际上KMS也会把这个发给我们｡
因此，当我们调用GenerateDataKey API时，
它会向我们发送纯文本DEK和加密的DEK｡
所以我们把这两个东西存储到一个最终的文件中｡
这就是它被称为信封加密的原因｡
因为有一个包装器围绕您的加密文件与加密的DEK｡
因此，正如我们在本例中所看到的，我们从KMS获得的唯一内容是加密密钥､
数据密钥和加密的数据密钥｡
所有的文件加密工作都发生在客户端｡
那么现在我们要怎么解密这个信封呢？
因此，
我们从这个信封文件返回，它包含加密的DEK和加密的文件｡
显然，我们将再次利用KMS｡
所以这次我们要调用解密API｡
因此，使用解密API，
我们最多只能传递4千字节的数据｡
在本例中，
我们要解密的是数据加密密钥，即DEK｡
因此，我将通过KMS，检查IAM权限｡
如果KMS一切正常我们就能解密DEK
现在我们得到了纯文本DEK｡
有了这个纯文本DEK，我们可以查看加密文件和纯文本DEK，
并在客户端一起解密｡
现在，我们有一个解密的大文件｡
因此，
这种信封加密技术的整个目的是使用KMS的优势，即生成密钥，然后在客户端进行整个加密和解密｡
因此，
这是复杂的实现，因此，AWS为我们实现了信封加密｡
为此，我们可以利用AWS加密SDK｡
因此，这也是一个CLI工具，我们可以安装它｡
此外，还有针对Java､ Python､
C和JavaScript的SDK实现｡
除了实现我刚才展示的加密模式之外，这个加密SDK还有一个叫做数据密钥缓存的特性｡
所以在这个例子中，我们可以重用它们，
而不是每次加密对象时都重新创建一个新的数据密钥｡
因此，重用数据键的想法是，
您对KMS的调用更少｡
因此，您执行的API调用更少，成本也更低｡
但这需要在安全性上做出权衡，因为现在您使用的是同一个数据密钥加密，
而数据加密密钥用于许多不同的文件｡
因此，这是安全性和API调用之间的权衡｡
但在实践中，这仍然被使用｡
所以如果你使用数据键缓存，
那么你可以使用一个名为LocalCryptoMaterialsCache的东西，它有一个很长的名字，来指示这个数据键该高速缓存应该有多大｡
您可以定义密钥的最长使用期限､ 密钥应加密的最大字节数，或者在移动到下一个DEK之前，
此DEK应加密的最大消息数｡
因此，这个加密SDK非常有用｡
现在从考试的角度来看，我们需要记住什么？
我们需要记住对称API的名称｡
第一个是加密，
通过KMS加密最多4 KB的数据｡
第二个是GenerateDataKey，它将生成一个唯一的对称数据密钥（DEK），
该API将执行两项操作，它将向我们返回数据密钥的纯文本副本，
并将向我们返回数据密钥的加密版本（使用我们指定的CMK）｡
这是我们在信封加密过程中使用的｡
还有另一个API，叫做GenerateDataKeyWithoutPlaintext，
这次它将再次生成GEK，
但不是现在使用，而是在未来的某个时候使用｡
因此，
这个DEK是一样的，它也是用我们指定的CMK加密的，
但是如果你使用它，我们必须在之后解密，这是一个额外的步骤｡
所以考试会试图欺骗你现在就执行信封加密，
你需要使用GenerateDataKey API而不是GenerateDataKeyWithoutPlaintext｡
然后要解密任何内容，您需要使用解密API｡
所以要解密最多四千字节的数据，包括一个信封加密解密的数据密钥，即数据加密密钥｡
最后，
如果你想让它生成一个随机数，那么你有一个名为GenerateRandom的API，它将返回一个随机字节字符串｡
这节课就讲到这里｡
我希望这对你们有帮助，下节课再见.
  - [ ] 432 Encryption SDK CLI [05:54] Hands On
    * 
  - [ ] 433 KMS Limits [02:49]
    * 
师：所以KMS是一个内部服务，所以有一些请求配额｡
但是KMS是极其重要的｡
因此，
如果您将超过KMS的加密或解密请求配额，例如，您将获得ThrottlingException｡
看起来像这样｡
它将显示“状态代码：400;错误代码：节流异常;“您已超出可以呼叫KMS的权限｡
为了应对这种异常，我们已经知道了，
我们可以使用指数回退，这意味着你可以回退并重试，每次调用之间的时间是指数级的｡
但是KMS有一些非常特别的东西｡
每一个加密操作，所有的解密和加密等等，
它们都共享一个配额｡
这意味着代表我们发出请求的任何服务，
例如，使用SSE-KMS数据加密的AWS S3｡
每次AWS将为我们使用该密钥，那么它将是该配额的一部分｡
因此，我们在所有加密操作中为每个地区的客户共享配额｡
这就意味着如果我们过多地使用我们的密钥，就会得到ThrottlingException.
那么我们能做些什么来解决这个问题呢？
第一，如果我们使用GenerateDataKey API，
那么我们可以使用DEK缓存｡
因此，在本地缓存数据加密密钥，以便减少在AWS上执行的API调用数量，
这是加密ID套件本身的一个功能｡
我们可以做的另一件事是生成一个请求配额增加，以防我们确实多次超过该限制｡
因此，我们可以通过API调用或通过AWS支持打开票证来请求增加配额｡
因此，
您需要记住的是，有两种方法来实现配额｡
正如我所说的，所有这些操作将共享相同的配额，
因此您应该解密､ 加密､ 生成DataKey､
生成随机等｡ 等等｡
所有这些操作都称为加密操作，它们共享相同的配额｡
因此，
要知道配额值是多少，取决于您所在的地区｡
但对于对称CMK配额，
您有5，500个共享配额，但在某些地区，您有多达10，
000个共享配额，因此在称为的所有API中共享｡
而在其他地区，
所有这些API调用的吞吐量为每秒30，000次｡
因此，
如果您以某种方式达到了该限制，则需要增加服务限制，以增加所有加密操作的共享配额｡
原来如此｡
因此，处理KMS节流的三种方法是第一种，
指数回退，也就是说，如果它是瞬态的｡
第二，要减少对KMS的API调用，
可以在数据加密密钥缓存功能的基础上使用信封加密SDK｡
最后，第三点，就是简单地向AWS申请提高限额｡
原来如此｡
我们下节课再见｡ 
  - [ ] 434 KMS and AWS Lambda Practice [05:45]
    * 
  - [ ] 435 S3 Bucket Key [02:53]
    * 
现在让我们来谈谈S3
Buckets的一个很酷的新设置，它将与SSE-KMS加密一起使用｡
这是一个新的设置，它将允许你减少和等待它｡
当您使用SSE-KMS类型的加密时，
从Amazon S3对KMS进行的API调用数减少99%｡
这将减少您的整体KMS加密的成本由亚马逊S3使用也99%｡
这是怎么做到的？
这利用了数据密钥，更重要的是，
这个叫做S3桶密钥的东西.
那这是怎么做到的呢？
客户主密钥和KMS将用于偶尔为Amazon S3 Bucket生成数据密钥，
此密钥将循环使用｡
但是，偶尔这个键被称为亚马逊S3桶键｡
该密钥将用于使用KMS加密对Amazon S3
Buckets中的对象进行加密｡
因此，这个额外的桶密钥将使用信封加密生成大量数据密钥，
这些密钥将用于加密S3桶｡
但是，通过添加S3
Bucket键，而不是直接使用KMS来生成这些数据键，我们减少了对KMS进行API调用的次数｡
因此，我们大幅降低了成本｡
因此，这是使用SSE-KMS的优化，以减少KMS
API调用的数量，例如，不需要支付高额费用或不超过Amazon
S3 Buckets中的加密限制，
但不会影响安全性｡
这样做的结果是，您在CloudTrail中看到的有关KMS的CloudTrail事件会更少｡
而且，
正如我在KMS中所说的，你将有一个降低成本的方法｡
这节课就讲到这里｡
一个非常好的设置，特别是如果你使用SSE-KMS在规模是非常高的两个｡
现在，让我向您展示在S3控制台中可以找到该设置的位置｡
现在，
我们进入S3控制台，创建一个新的存储桶｡
我将创建一个buckets并将其命名为 演示S3存储桶密钥｡
好吗？
然后我们将阻止公共设置｡
我们将禁用版本控制｡
我们将启用加密｡
它将是SSE-KMS，并且将是托管密钥｡
（鼠标点击）我们将启用桶键｡
因此，默认情况下，
它现在是启用的，但如果我们想让每一个上传与KMS对话，我们可以禁用它｡
但是，
如果您想启用它，我们只需单击“启用”｡
并且这将使用桶密钥来减少对KMS的调用的成本和次数，而不损失任何安全性｡
非常简单，然后我们创建存储桶，就可以开始了｡
我们现在使用桶密钥对S3桶进行加密｡
就这样，我们下节课再见｡ 
  - [ ] 436 [DVA-C02] KMS Key Policies & IAM Principals [02:19]
    * 
讲师：现在我们来谈谈KMS关键政策，
我想给大家举几个例子｡
因此，我们知道密钥策略用于定义谁可以访问您的KMS密钥｡
您通过AWS控制台创建的默认KMS密钥策略允许您帐户内的任何人访问您的KMS密钥，
只要他们具有适当的IAM权限｡
所以这是一个特别的｡
如果您想显式授权某个特定用户，它可以是任何用户，
可以是用户､ IAM角色，
也可以是联合用户，例如，您可以在右侧的示例中看到｡
例如，您可以允许您想要的KMS操作，
如加密､ 解密等｡
然后你明确地概述了这个原则｡
在这种情况下，本例中的联合用户不需要额外的IAM策略来使用您的KMS密钥，
因为KMS密钥策略中明确允许使用IAM策略｡
那么，在KMS关键策略中以及在任何IAM中，我们可以明确地允许什么样的原则呢？
我们有账号和根用户｡
所以当你定义这样的东西，
比如原则AWS和新帐号，或者帐号，
然后路由，你允许帐户中的每一个原则，
好吗？
然后IAM策略发挥作用｡
接下来，您可以通过直接在原则声明中概述角色arn来授权特定的IAM角色｡
您有IAM角色会话，
因此这是当您有一个假定的角色时，或者当您通过联合有一个假定的身份时｡
例如，Cognito身份或SAML｡
当您在您的帐户（当然还有其他帐户）中列出特定用户时，
也会有AIM用户｡
您拥有联合用户会话｡
这是我们以前见过的｡
因此，当您在AWS中拥有用户联合时，
您可以指定特定的联合用户，然后还可以允许特定的服务｡
因此，您可以看到该原则现在有一个服务，
允许特定服务使用您的KMS密钥｡
或者，如果你想允许一切和每个人，
你可以只使用一个星或AWS星｡
好的，让我们看看这节课｡
我希望你们喜欢，我们下节课再见｡ 
  - [ ] 437 [DVA-C02] CloudHSM Overview [05:04]
    * 
我们已经了解了用于加密的KMS，
现在我们来看一下CloudHSM｡
因此，通过KMS, AWS将管理加密软件并控制加密密钥｡
但是有了CloudHSM，
AWS将提供一些加密硬件｡
它被称为HSM设备，是一种专用硬件，
属于硬件安全模块｡
然后，我们将完全管理我们自己的加密密钥，
而不是AWS｡
所以我们完全控制了加密密钥｡
HSM设备将在AWS云中设置，
但它具有FIPS 104-2三级合规性，
这意味着如果有人试图手动访问您的HSM设备，他们将被阻止和阻止｡
CloudHSM设备支持对称和非对称加密密钥｡
因此，这意味着您可以在其上使用SSL和TLS密钥｡
没有边界，
要使用CloudHSM设备，您需要使用客户端软件，这是相当复杂的，
目前超出了范围｡
如果您想利用CloudHSM进行数据库加密和密钥管理，
Redshift和CloudHSM之间有一个集成｡
如果您希望在S3之上实施SSE-C类型的加密，
CloudHSM是一个非常非常好的候选者，
例如，因为您要管理自己的加密密钥，并将它们存储在此CloudHSM中｡
因此，通过Edge CloudHSM, AWS将管理硬件，
而服务本身可以自己使用｡
您必须使用CloudHSM客户端来建立到CloudHSM服务的连接，
然后您将管理所有密钥｡
因此，IAM权限将用于执行创建读取更新｡
在高级别删除HSM群集，但之后您将使用CloudHSM软件来管理密钥，
并管理用户及其访问密钥的权限，
这与KMS不同，因为在KMS中，一切都使用IAM来管理｡
现在，CloudHSM群集可以具有高可用性，
并且它们分布在多个AZ中，
因此它们是HA，理解这一点非常重要｡
所以，你会有两个阿兹｡
一个将从另一个复制，您的HSM客户机可以连接到其中任何一个｡
那么，我们如何在AWS服务加密中透明地利用CloudHSM呢？
嗯，CloudHSM和KMS之间有一个集成｡
这是怎么回事？
在KMS中，我们将定义一个KMS自定义密钥存储库，
并且将有CloudHSM｡
这意味着我们可以获得适用于EBS､
S3､ RDS等的CloudHSM加密｡
那么这是怎么回事呢？
我们创建了一个CloudHSM群集，
并定义了一个KMS自定义密钥存储库，该存储库将连接到CloudHSM群集｡
从那里，如果我们创建一个RDS数据库实例，
该实例具有使用KMS加密的加密EBS卷，那么在内部，
此KMS加密将利用CloudHSM群集内的加密密钥｡
这样做的好处是：第一，
我们实际上使用的是CloudHSM群集;第二，
通过KMS发出的到达CloudHSM群集的任何API调用都将记录在CloudTrail中｡
因此，如果我们比较CloudHSM和KMS，
KMS的租赁是多租户，而CloudHSM的租赁是单租户，
它们都具有相同的标准｡
KMS上的主密钥有三种，分别是AWS拥有的､
AWS管理的和客户管理的CMK｡
而对于CloudHSM，它只是客户管理的CMK，
因为AWS无法访问您的HSM设备｡
在密钥类型方面，KMS有非常相似的对称､
非对称和数字签名｡ 以及适用于CloudHSM的对称､
非对称和数字发送和散列｡
您需要注意的唯一一件事是，现在如果您想导入非对称密钥，
只能在CloudHSM中进行｡
因此，如果您有一个使用非对称密钥的内部部署密钥管理系统，
并且您希望将其导入AWS，则唯一的选择将是使用AWS
CloudHSM｡
就关键可访问性而言，
KMS可以在多个地区访问，但由于CloudHSM部署在VPC中，因此您可以使用VPC共享跨VPC共享它｡
这就意味着如果你想的话，
它可以跨多个地区访问｡
对于加密加速，您可以在KMS上不设置任何加速，
但使用CloudHSM，您可以在负载级别使用SSL和TLS加速，
也可以使用Oracle，还可以为基于Oracle的数据库使用TDE加速｡
对于身份验证中的访问，
您有IAM for
KMS，而CloudHSM有自己的安全机制来管理用户及其权限和密钥｡
最后，对于高可用性，
KMS是一种托管服务，始终可用｡
CloudHSM将在不同的可用性区域上拥有多个HSM设备｡
其他功能是适用于KMS的CloudTrail和CloudWatch，
而我们也有适用于CloudHSM的MFA支持｡
最后，KMS是AWS中免费层的一部分，
而CloudHSM不是｡
以上就是CloudHSM，
希望大家喜欢，
我们下节课再见｡
  - [ ] 438 SSM Parameter Store Overview [04:16]
    * 
教师：现在我们来讨论SSM参数存储｡
它是您的配置和机密的安全存储｡
此外，您还可以选择使用KMS服务加密这些配置，
从而使其成为机密｡
SSM参数存储是无服务器的，
它是可扩展的，它是持久的，
并且SDK非常容易使用｡
最重要的是，如果您更新了参数，那么您可以对它们进行版本跟踪｡
安全性是通过IAM提供的，在一定数量的情况下，
您可以通过Amazon EventBridge获得通知｡
您可以与CloudFormation完全集成｡
这意味着CloudFormation可以利用参数存储中的参数作为堆栈的输入参数｡
让我们举个例子｡
我们有一个应用程序，
然后我们有SSM参数存储｡
所以我们可以用这种方式存储纯文本配置｡
然后，将检查应用程序的IAM权限｡
例如，您的EC2实例角色，
或者您可以具有加密的配置｡
在这种情况下，
SSM参数存储将使用KMS对其进行加密｡
因此，KMS服务将用于加密和解密｡
当然，您需要确保您的应用程序能够访问底层KMS密钥，
以执行加密和解密｡
因此，您可以使用层次结构将参数存储在参数存储区中｡
例如，您可以将我的部门定义为一个路径，
然后在My-app和Dev下定义，然后在该文件夹中定义Dev
DB-URL和DB-password｡
这就意味着你的参数会一直向下到层次结构中｡
我们可以向上一级，存储Prod
DB-URL的参数以及Prod DB密码，
然后转到另一个应用程序或另一个部门｡
这真的允许您以结构化的方式组织您想要的参数｡
这将简化IAM策略，使应用程序能够访问整个部门､
整个应用程序或仅访问应用程序部门环境特定的路径｡
您也有机会通过参数存储区访问Secrets
of Secrets Manager，方法是使用此处的引用｡
所以这是一个没多少人知道的小把戏｡
AWS发布了一些公共参数，
您可以使用它们｡
例如，如果您要查找特定区域中Amazon
Index 2的最新AMI｡
这是在参数存储中作为API调用提供的内容｡
因此，如果您以一个应用程序为例，
我们的Dev Lambda函数将有一个IAM卷，
允许它访问我的应用程序的Dev中的DB-URL和DB-password｡
如果你有一个Prod Lambda函数，
再次感谢不同的IAM策略和一些环境变量，
你可以访问另一个路径的Prod DB-URL和Prod
DB-密码｡
（单击鼠标）现在，
在Systems Manager中，
您有两种参数层｡
您有标准层和高级层｡
因此，最大的区别将是大约4KB的大小，
也就是8KB，以及参数策略的可用性｡
对于标准的，我们没有，但对于高级的，
我们有一些｡
参数的高级类型将为$0｡
05美元｡
而第一个是免费的｡
那么，这些参数策略是什么呢？
而且这只适用于高级参数｡
（鼠标点击）好吧，
这允许你给一个参数分配一个生存时间，这意味着一个到期日期｡
这样就可以强制用户更新或删除密码等敏感数据｡
而且您可以一次分配多个策略｡
这是一个策略示例｡
这是一个删除参数的过期策略，您可以说，
“嘿，在这个时间戳上，
您必须删除这些参数｡ 然后，通过EventBridge集成，
EventBridge将获得它的通知｡
因此，在本例中，在参数到期前15天，
我们将在EventBridge中收到通知，这给了我们足够的时间来实际更新它，
并确保参数不会因为TTL而被删除｡
或者有时候你想确保参数偶尔改变一下｡
因此，您可以在EventBridge中获得无更改通知，
这样，如果某个参数在20天内未更新，您也会收到通知｡
所以你可以非常有创意地使用参数存储｡
但现在你明白它背后的意思了｡
我希望你们喜欢这节课，
  - [ ] 439 SSM Parameter Store [07:11] Hands On (CLI)
    * 
  - [ ] 440 SSM Parameter Store [10:02] Hands On (AWS Lambda)
    * 
  - [ ] 441 Secrets Manager - Overview [02:10]
    * 
讲师：现在让我们来谈谈一个非常简单的服务，
称为AWS Secrets Manager｡
因此，它是一个较新的服务，用于存储秘密，
它将与SSM参数存储不同，因为在Secrets
Manager上，您可以强制每X天轮换一次秘密，因此您有一个更好的秘密管理计划｡
最重要的是，从Secrets
Manager中，您可以强制和自动生成旋转的秘密｡
为此，您必须定义一个Lambda函数来生成新的秘密｡
此外，Secrets Manager与AWS上的不同服务集成得非常好｡
我刚刚向你们展示了Amazon RDS，
例如，MySQL, PostgreSQL, SQL或Aurora｡
但是还有其他服务以及AWS，其他数据库，
与Secrets Manager集成在一起｡
这意味着进入数据库的用户名和密码直接存储在Secrets
Manager中，并且可以旋转等等｡
现在，可以使用KMS服务加密Secret｡
因此，在考试中，任何时候你看到Secrets，
或RDS的集成，或Aurora of
Secrets，都可以想到Secrets Manager｡
还有一个特点，我们需要知道这是多地区的秘密的概念｡
因此，您可以在多个AWS区域复制您的Secret，
Secrets Manager Service将使读者与主要Secret保持同步｡
这里有两个区域｡
我们在主区域中创建一个Secret，
然后将其作为同一个Secret复制到辅助区域中｡
我们为什么要这么做
嗯，很多东西｡
第一，如果美国东部1有问题，您可以将副本Secret提升为独立的Secret｡
由于Secret可以跨区域复制，
因此您可以构建多个区域的应用程序｡
您还可以有灾难恢复策略，或者如果您有一个RDS数据库，
也正在从一个区域复制到下一个区域，那么您可以使用相同的Secret访问相应区域中的相同RDS数据库｡
这节课就到这里｡
我希望你们喜欢，我们下次课再见｡ 
  - [ ] 442 Secrets Manager [05:48] Hands On
    * 
  - [ ] 443 [DVA-C02] Secrets Manager - CloudFormation Integration [02:11]
    * 
Stephane：那么，让我们来谈谈Secrets
Manager及其与CloudFormation的集成｡
对于RDS和Aurora，
如果我们指定一个如下所示的CloudFormation模板，
并在其中将Manage Master用户密码bullion指定为true，则RDS将自动创建一个密码｡
这是怎么回事？
当然，在CloudFormation模板中，
我们定义了RDS或数据库，因此将创建它，然后RDS将在Secrets
Manager中创建一个密码，并为您的管理员生成密码｡
这样做的好处是，
秘密将完全由RDS管理，
包括轮换机制｡
所以这是一个简写，让你更简单｡
在这种情况下，如果你想引用这个秘密，
你可以做的是，
你可以从我的集群上的获取属性函数中获取秘密ARN，
就像你在右下角看到的那样｡
这是第一种方法｡
第二种方法是在CloudFormation中的Secrets
Manager中实际定义秘密，然后使用动态引用｡
因此，如果我们想再次创建一个RDS数据库，
但这次我们想自己管理秘密，我们该怎么做？
首先要做的是生成一个密码作为资源的一部分，
然后定义密码的内容和密码长度等｡
然后在RDS数据库实例中引用主用户名和主用户密码的秘密，
这是使用动态引用｡
如您所见，这里的解析类型语法使用的是动态引用，
然后我们通过执行“秘密RDS数据库实例附件”将秘密链接到RDS数据库实例，
以便我们知道并告诉AWS此秘密与我们的RDS数据库紧密关联｡
好了，这节课就到这里，
希望你们喜欢，下节课再见｡
  - [ ] 444 SSM Parameter Store vs Secrets Manager [02:21]
    * 
那么，我们来讨论一下SSM参数存储和Secrets Manager之间的区别｡
秘密管理器的成本更高，你将使用Lambda函数自动旋转秘密｡
这些Lambda函数中的一些将被提供，
例如，用于RDS､
Redshift或DocumentDB，它们与Secrets Manager有很强的集成｡
所以，它为您节省了一点时间｡
KMS加密将是强制性的为您的秘密，你可以将它们与CloudFormation集成.
参数存储区具有更多､
更广泛的用例类型，并且成本更低｡
它有一个简单的API｡
旋转没有秘密可言，不过，我将在下一张幻灯片中向您展示如何使用由CloudWatch事件触发的Lambda函数自行启用旋转，
但这不是一个自然特性｡
KMS加密将是可选的，因为您可以在参数存储区中存储机密或仅存储参数｡
它还集成了CloudFormation，您可以使用SSM参数存储API（CW事件）从机密管理器中提取机密管理器｡
但是，如果您看一下参数存储和机密管理器之间的机密轮换，
首先对于机密管理器，
假设我们要轮换Amazon RDS数据库的密码｡
因此，
我们将设置Secrets Manager，使其每隔30天自动调用Lambda函数｡
现在，还有另一个功能，例如，RDS，
由AWS提供，
并由AWS部署在您的帐户中，您只需使用Secrets Manager即可｡
它将做的是，它将更改您的亚马逊RDS数据库的密码｡
这是一个自然功能｡
如果它只是一个没有与Secrets Manager深度集成的随机秘密，
那么您需要为它编写自己的Lambda函数｡
但同样，文档由AWS提供｡
现在，对于SSM参数存储区，
循环没有自然特性，但假设您将RDS数据库密码存储到SSM参数存储区中，那么我将创建一个CloudWatch事件规则，该规则将每30天调用一次，
并将调用您必须自己编写的Lambda函数来更改Amazon RDS数据库的密码｡ 并且还可以更改其中的值，该值存储在SSM参数存储中｡
因此，
希望这能解释Secrets Manager和SSM参数存储之间的区别｡
我希望你喜欢这节课，我们下节课再见｡
  - [ ] 445 CloudWatch Logs Encryption [04:17]
    * 
那么，我们来听一个关于CloudWatch日志加密的简短讲座｡
因此，您可以使用KMS密钥加密您的CloudWatch日志｡
并且加密在日志组级别进行｡
因此，不是使用日志流，而是使用日志组级别｡
您可以将CMK与现有的日志组关联，也可以使用CMK创建新的日志组｡
但是您不能使用CloudWatch控制台将CMK与日志组关联;您必须将CloudWatch
Logs API用于CLI和SDK，因此我们将在本课中使用CLI｡
我们有两点意见需要注意｡
第一个称为关联KMS密钥｡
将KMS密钥与现有日志组关联，或创建日志组以创建尚不存在的日志组，
并将其直接与KMS密钥关联｡
那么，让我们来看看它是如何工作的｡
现在我在CloudWatch日志中｡
我将转到我的日志组，现在我有23个日志组｡
因此，如果我们选择其中的任何一个，例如aws/lambda/hello-world日志组，
我们可以看到还没有与该日志组关联的KMS密钥ID｡
我们无法通过UI执行这些操作，因此UI不允许我们将KMS密钥ID与此日志组关联｡
我们要做的就是把之前加密过的密钥，教程密钥，
和这个日志组关联起来.
为此，我们必须使用CLI｡
所以让我们继续来玩吧｡
我将进入CloudWatch Logs代码目录并打开此命令｡
因此，第一个命令是将KMS密钥与现有日志组关联｡
简单来说，
我复制这个命令，然后粘贴到这里，这样就得到了我的KMS密钥｡
我粘贴了日志组名称作为参数，以及我的KMS密钥ID｡
最后，我粘贴在该区域｡
我按下Enter键，得到一个访问被拒绝异常，
说明这个关联的KNM键操作不起作用｡
要么该键不存在，
但我知道它确实存在，要么它不允许与此日志组一起使用，这是正确的第二个选项｡
因此，实际上，
该密钥未被授权用于此日志组｡
因此，我们需要应用某个关键政策｡
如果我们转到这里，这里有一份杰森提交的重要保单.
我们需要把它应用到我的特定键上｡
所以，
我来看看第二部分，这才是有趣的地方｡
我将得到第二部分和逗号，然后进入我的KMS密钥领事，在这里我有一个密钥策略｡
我将切换到策略视图，编辑此密钥策略｡
因此，此密钥策略现在是默认密钥策略，它允许我的帐户中的任何用户或角色使用我的KMS密钥，
但不允许任何服务｡
因此，
我们需要允许CloudWatch Logs的服务访问此密钥｡
我把它贴在这里，在这句话里加了一个逗号.
这里我们允许使用logs
dot，我们需要在区域中粘贴，因此EU-west-2｡
那么，原木｡ 欧盟—西-2 亚马逊人｡
com进行加密､
解密､ 再加密､ 生成数据密钥以及对该密钥进行描述｡
因此，我保存这些更改｡
而且，现在我已经应用了一个关键的策略，应该允许更多的东西访问，
包括CloudWatch日志｡
所以，我们应该再次尝试我们的命令，并且，希望，
这一次它将工作｡
因此，我将再次运行此命令，
这一次它已经工作｡
所以，我们得到了结束，它是应用｡
我是怎么知道的？
我们可以刷新此UI，现在可以看到，此处的KNS密钥ID与CloudWatch日志相关联，
因此这意味着此日志组将使用此KMS密钥ID进行完全加密｡
我可以尝试第二个命令，
即使用我所调用的示例创建一个新的日志组，示例加密，直接传递KMS密钥ID｡
我把这个粘贴进去，按回车键，
它就显示结束了｡
因此，
如果我返回日志组并刷新，我可以在最底部找到我的示例加密日志组｡
而且这个也与我们的KMS密钥ID相关联｡
因此，这是创建与CloudWatch日志中的日志组相关联的KMS密钥ID的两种方法｡
所以，这件事不能通过执政官来做｡
我真的很喜欢这样一个事实，即我们必须修改一个密钥策略，以允许CloudWatch日志访问KMS密钥，
我认为这是安全性方面的一个很好的例子｡
这节课就讲到这里｡
我希望你们喜欢，下节课再见｡
  - [ ] 446 CodeBuild Security [02:42]
    * 
让我们来做一个关于CodeBuild安全性的简短演讲｡
首先，
我们知道CodeBuild不在VPC中，但您可以在VPC中启动CodeBuild以访问VPC资源｡
我们还没有讨论CodeBuild中的秘密，所以显然不要将它们作为明文存储在CodeBuild环境变量中｡
这是没有道理的｡
相反，您有两个选择｡
您可以使用引用参数存储区参数环境变量，也可以使用引用机密管理器机密环境变量
我们马上会看到如何配置它｡
现在我们进入CodeBuild，我将创建一个新的生成项目｡
现在，我不需要填写任何细节，
我只想告诉你设置在哪里｡
因此，如果我向下滚动并转到“其他配置”，
我将看到一些关于安全性的良好配置｡
第一个是关于VPC的，因此我们可以在VPC中启动CodeBuild，
就像子网和安全组一样｡
如果你向下滚动，环境变量非常重要｡
例如，假设我们需要访问VPC中的RDS数据库，
并且需要RDS数据库密码｡
我们可以说DB_PASSWORD和“supersecret”，但这会非常糟糕｡
在您的环境中，这是一个明文秘密，因此可能会被看到和泄露，
所以不太好｡
但您也可以有一个参数或一个secrets管理器secret｡
因此，如果是参数，
您可以进入参数存储区｡
现在，让我进入SSM参数存储区向您展示｡
因此，在我的参数存储区中，我可以创建一个参数｡
我将它命名为/CodeBuild/DBPassword｡
然后我会给它设置一个标准参数｡
它将是一个安全字符串，我可以说我想将它与这个KMS密钥ID关联｡
AWS CMK的值是“SuperSecret”，我们开始吧｡
然后创建这个参数，现在可以在值中引用这个参数名｡
所以这里我说DB_PASSWORD使用这个值，它来自参数存储区，在运行时，
我的CodeBuild会自动获取这个参数的值，也就是“SuperSecret”值，也就是这里的“SuperSecret值”，
并将它注入到我的容器中｡
但我还可以再加一个｡
它可以是DB_PASSWORD_ALT，或者｡
你也可以通过在秘密管理器中引用你要找的秘密的名字，对秘密管理器做完全相同的过程｡
当然，如果您执行这些操作，
请确保与CodeBuild项目相关联的IM卷确实可以访问系统管理器参数存储和机密管理器｡
就是这样｡
超级简单，但一些好东西要看考试前｡
我们下节课再见｡ 
  - [ ] 447 [DVA-C02] AWS Nitro Enclaves [02:40]
    * 
教练：现在我们来谈谈硝基飞地｡
因此，我们的想法是，有时您希望在云中处理高度敏感的数据，
并且希望在隔离的计算环境中处理这些数据｡
例如，敏感数据可能是PII数据，
也就是个人身份信息，或者医疗保健数据､
财务数据､ 信用卡数据等｡
从历史上看，如果您想创建这种非常隔离的计算环境，
您需要创建一个新的VPC，
限制对它的访问，限制联网，等等，这将是非常麻烦的｡
所以，你可以用硝基飞地｡
Nitro Enclaves是超级隔离的虚拟机｡
它们很坚硬，而且高度受限｡
所以它不是一个容器，它没有持久存储，它没有交互式访问，
你不能SSH到它｡
没有外部网络｡
所以它真的，真的被控制住了｡
我们的想法是，这是你想要做数据处理的地方｡
因此，通过创建Nitro
Enclave，您将减少非常敏感的数据处理应用程序的攻击面｡
最重要的是，您可以确保，由于加密认证，
只有授权的代码可以在您的Enclave中运行，
您将签署代码，然后只有签署代码可以在您的Enclave中运行｡
最重要的是，您可以保证，
由于KMS加密，
只有飞地可以访问您的敏感数据｡
Nitro Enclaves的使用案例是，
无论何时，只要您想进行私钥处理､ 处理信用卡或安全多方计算，
等等｡
因此，这为EC2提供了最高级别的安全性｡
那么这是怎么回事呢？
您将启动一个兼容的Nitro-based
EC2实例，并将“EnclaveOptions”设置为“true”，这将允许您从EC2实例（NitroEnclave）中启动｡
然后使用Nitro CLI将应用程序转换为Enclave映像文件EIF｡
然后，您可以使用Nitro CLI将其作为输入，
在EC2实例上创建Enclave，
它将与主机共享VP､ 内存､ CPU和内核，但在内部将非常非常隔离｡
因此，如果您考虑AWS上运行在Nitro虚拟机管理程序上的EC2主机｡
这就是它之所以称为Nitro
Enclave的原因，因为它利用了Nitro虚拟机管理程序｡
然后EC2实例与您的Enclave分离｡
他们只能通过安全的本地信道进行通信，但仅此而已｡
然后当然会与运行在同一主机上的任何其他实例分离，
但您可以保证Enclave将像我之前告诉您的那样安全，尽管它有很多限制｡
就是这样｡
你只需要在一个高层次上了解这个概念｡
但我希望你们喜欢，
我们下节课再见｡
  - [ ]  AWS Security & Encryption [16 问题] Quiz
    * 
 ## Section 31 - AWS Other Services [10 个讲座 • 32 分钟]
  - [ ] 448 AWS Other Services - Section Introduction [00:36]
    * 
欢迎来到本课程的最后一节，这一节有一点特别，
因为我会提到其他一些技术，在考试中可能会出现一两个问题，但会有一些非常基本的问题｡
因此，本讲座将不会深入探讨所有这些主题，而只是对几项服务进行概述｡
总的来说，随着考试的发展和变化，我会确保在这一部分添加适当的讲座｡ 但你今天需要知道的一切都已经在这里了｡
我向你保证｡
现在，让我们开始了解其他几项服务｡ 
  - [ ] 449 AWS SES [00:46]
    * 
教师：SES是AWS中最简单的服务，
它只适合一张幻灯片，我会觉得很糟糕，它太短了｡
但基本上与SES你可以发送电子邮件，太好了｡
您可以使用SMTP接口或AWS
SDK，还可以接收电子邮件，以便与S3､
SNS或AWS Lambda集成｡
因此，
如果您想发送或接收电子邮件，您将拥有IAM权限，并且该权限将与SES完全集成｡
所以这是最简单的服务，
就是这样，这就是你需要知道的全部，但我对你说这些的原因是，
有时候问题会试图欺骗你使用SES，不管是什么原因｡
只要记住SES代表电子邮件，
所以如果问题是关于电子邮件的，也许SES是一个很好的候选人，否则就不是｡
这节课就讲到这里，我们下节课再见｡
  - [ ] 450 [DVA-C02] Amazon OpenSearch Service - Overview [03:41]
    * 
讲师：现在我们来谈谈Amazon
OpenSearch服务｡
亚马逊开放搜索是你可能听说过的亚马逊弹性搜索的继承者｡
所以改名是因为一些许可问题｡
因此，在DynamoDB中，为了进行比较，
您只能通过主键查询数据，或者如果您的数据库上有索引的话｡
但是使用OpenSearch，您实际上可以如名称所示，
搜索任何字段，甚至部分匹配｡
因此，使用OpenSearch为应用程序提供搜索是非常常见的｡
因此，您可以使用OpenSearch作为对另一个数据库的赞美｡
因此，OpenSearch可以用于搜索，
但正如其名称所示，您还可以在开放搜索之上进行分析查询｡
因此，要创建开放搜索并使用它，
您需要创建一个实例集群｡
因此，它不是一个无服务器服务，
并将开放搜索作为自己的查询语言｡
它本身不支持SQL，
但您可以通过插件启用SQL兼容性｡
因此，您可以从不同的地方摄取数据，例如Kinesis
Data Firehose, IoT, CloudWatch Logs或任何自定义构建的应用程序｡
通过与Cognito
IAM集成，您可以获得地址加密和动态加密｡
正如我所说的，你可以在OpenSearch服务的基础上进行分析｡
因此，您可以使用称为OpenSearch仪表板的东西在OpenSearch数据之上创建可视化｡
下面是使用OpenSearch的一些常见模式｡
因此，您将拥有DynamoDB，它将包含您的数据｡
这是您的用户将插入､ 删除和更新数据的位置｡
然后，您在DynamoDB流中发送所有流，然后由Lambda函数拾取｡
Lambda函数将实时将数据插入Amazon
OpenSearch｡
通过这个过程，您的应用程序现在能够搜索特定的项目，
例如，使用项目名称进行部分搜索，
然后从中找到项目ID｡
一旦获得了项ID，它将调用DynamoDB从DynamoDB表中实际检索整个项｡
这是OpenSearch提供搜索功能的常见模式，
而您的主要数据源仍然是DynamoDB表｡
还有其他的方法｡
因此，您可以将CloudWatch日志摄取到OpenSearch中｡
因此，第一个是使用所谓的CloudWatch日志订阅过滤器，
将数据实时发送到由AWS管理的贷方功能｡
然后，Lender函数将所有数据实时发送到Amazon
OpenSearch｡
或者您也可以使用CloudWatch Logs，
然后使用订阅过滤器｡
但是这一次Kinesis Data Firehose可以从订阅过滤器中读取，
然后接近实时，因为它说Data Firehose，数据将插入Amazon
OpenSearch中｡
Kinesis周围的其他模式｡
因此，要将Kinesis数据流发送到Amazon OpenSearch，
您有两种策略｡
第一个是使用Kinesis数据消防软管｡
这是一种近乎实时的服务｡
您可以选择使用另一个函数进行一些数据转换，
然后将数据发送到Amazon
OpenSearch，或者您可以再次使用Kinesis
Data Streams，但这次您将创建一个Lambda函数，该函数将实时读取数据流，
然后您将编写自定义代码，以便将Lambda函数实时发送到Amazon OpenSearch｡
所以这些模式都是有效的｡
现在您已经知道了使用Amazon OpenSearch的所有可能的架构｡
这堂课就到这里｡
我希望你们喜欢，我们下节课再见｡
  - [ ] 451 [DVA-C02] Amazon Athena - Overview [05:27]
    * 
演讲者：那么现在，让我们来谈谈亚马逊雅典娜｡
Athena是一个无服务器查询服务，
可以帮助您分析存储在AmazonS3存储桶中的数据｡
为了分析这些数据，
您将使用标准SQL语言来查询文件｡
在幕后，Athena是基于Presto引擎构建的，
该引擎使用SQL语言｡
因此，我们的想法是，用户将数据加载到您的S3存储桶中，
或者您将数据加载到您的S3存储桶中，然后您将使用Athena服务在Amazon
S3中查询和分析此数据，而无需移动它｡
因此，Athena是无服务器的，
它直接分析您S3存储桶中的数据｡
因此，它支持不同的格式，
如CSV, JSON, ORC, Avro和Parquet，
以及其他格式｡
而且定价非常简单｡
您只需为每TB扫描的数据支付固定金额｡
您不需要再次提供任何数据库，
因为整个服务是无服务器的｡
因此，Athena通常与另一个名为Amazon
QuickSight的工具一起使用，以创建报告和仪表板｡
稍后我们将深入了解Quicksight，但Amazon
Quicksight连接到Athena，后者连接到您的S3存储桶｡
现在，Amazon Athena的用例是执行即席查询､
商业智能､ 分析､ 报告，以及分析和查询来自AWS服务的任何类型的日志｡
因此，它可能是您的VPC流日志､
负载均衡器日志､ CloudTrail踪迹等｡
因此，作为一个考试提示，
任何时候您需要使用无服务器SQL引擎分析AmazonS3中的数据，
您都可以考虑使用Athena｡
现在，我已经谈到了性能改进，你实际上可以提高Athena的性能，
在这次考试中，我们也会在这方面对你进行测试｡
首先，因为您要为每TB扫描的数据量付费，
所以您需要使用一种您将扫描较少数据的数据类型｡
为此，您可以使用柱状数据类型来节省成本，
因为您只扫描需要的列｡
因此，Amazon Athena的推荐格式将是Apache
Parquet和ORC，它将为您带来巨大的性能提升｡
要将文件转换为Apache Parquet或ORC格式，
必须使用本节中介绍的服务，例如Glue｡
Glue对于将数据转换为ETL作业非常有用，
例如在CSV和Parquet之间转换｡
现在，也因为我们想要扫描更少的数据，我们需要压缩数据以进行更小的检索｡
因此，有不同的压缩机制，你可以使用，
已经列出了它的权利在这里｡
接下来，如果你知道你将一直查询一些特定的列，
你可以划分你的数据集，
划分数据集意味着在你的S3桶中，你将拥有带斜线的完整路径，
每个斜线将是一个不同的列名，
有一个特定的值｡
因此，您在Amazon
S3中对数据进行组织和分区，以便在查询数据时，您可以确切地知道在Amazon
S3的哪个路径的哪个文件夹中需要扫描数据｡
这是一个数据分区的例子｡
所以我们有Parquet格式的飞行数据，
然后我们做/年=1991｡
所以我们按年划分，
每年有一个文件夹｡
然后在每一年里我们有月，所以月等于1，
在每一个月里我们有天，
这等于1.
因此，当我在Athena上执行查询时，
我会筛选特定的年份､ 特定的月份和特定的日期，
然后我们会确切地知道从Amazon S3中的哪个文件夹获取数据，因此我们只会恢复数据的一个子集｡
因此，我们会有非常非常好的分区｡
最后，你需要做的最后一个性能改进是使用更大的文件，
这是为了最小化你的开销｡
因此，如果您在Amazon S3中有很多很多小文件，
Athena的性能就不会像您有更大的文件（例如128
MB及以上）一样好，因为更大的文件更容易扫描，也更容易检索｡
Amazon Athena的另一个功能是Federated Query｡
所以你知道Athena可以在S3中查询数据，
但实际上你可以在任何地方查询数据，
例如，在关系或非关系数据库中，你可以查询对象和自定义数据源，无论是在AWS上还是在本地｡
怎么做？ 您使用的是所谓的数据源连接器｡
这是一个Lambda函数，
该Lambda函数将在其他服务中运行联邦查询｡
例如，这可能是CloudWatch Logs､ DynamoDB､
RDS等｡
所以它非常强大｡
例如，我们这里有Athena，
我们有一个Lambda函数，
每个数据源连接器都有一个Lambda函数｡
然后通过Amazon Athena，
您可以在EMR服务上的ElastiCache､
Document DB､ DynamoDB､ Redshift､
Aurora､ SQL Server､ MySQL､ HBase或任何本地数据库上运行查询｡
它们来自Athena，
当然还有Amazon S3，
你可以画画，你可以比赛，
等等｡
这就是它被称为联合查询的原因｡
然后，可以将此查询的结果存储到Amazon
S3存储桶中，以供以后分析｡
这就是亚马逊雅典娜｡
如你所见，这是一个非常强大的服务｡
我希望你们喜欢，
我们下节课再见｡
  - [ ] 452 [DVA-C02] Amazon Athena [05:16] Hands On
    * 
  - [ ] 453 [DVA-C02] Amazon MSK - Overview [03:50]
    * 
解说员：您将看到的另一个分析服务是Amazon
Managed Streaming for Apache Kafka，
也称为Amazon MSK｡
卡夫卡是什么？
卡夫卡是亚马逊运动的替代品｡
Kafka和Kinesis都允许您流式传输数据｡
因此，MSK是在AWS上获得完全管理的Kafka集群的能力｡
它还允许您动态创建､
更新和删除群集｡
MSK将为您创建和管理群集中的Kafka代理节点和Zookeeper代理节点，
您可以跨多个AZ（最多三个）在VPC中部署群集，以实现高可用性｡
您还可以从常见的卡夫卡故障中自动恢复，并且数据可以存储在EBS卷上，
只要您愿意｡
所以，从我个人的经验来看，
我知道设置Apache Kafka是非常困难的，
事实上，你只需点击一下，然后在AWS上部署Kafka是很棒的，这就是Amazon
MSK服务｡
因此，除此之外，您还可以选择使用MSK无服务器｡
这就是你在MSK上运行Apache
Kafka，但这次你不配置服务器，
不管理容量，MSK会自动为你配置资源和扩展､
计算和存储｡
那么阿帕奇·卡夫卡是什么呢？
Apache Kafka是一种流数据的方式，
Kafka集群由多个代理组成，然后你会有生产者来生产数据，所以他们必须从Kinesis､ IoT
RDS等地方接收数据，然后他们会直接将数据发送到Kafka主题中，
然后完全复制到其他代理中｡
现在，卡夫卡的这个主题是实时数据流，
消费者将从这个主题中提取数据来消费数据本身，然后您的消费者可以做任何他想做的事情，
处理它或将它发送到各种目的地，如EMR､
S3､ SageMaker､ Kinesis和RDS｡
所以卡夫卡的想法是，他和动势论很相似，
但也有不同之处要注意｡
那么Kinesis数据流和Amazon
MSK有什么区别呢？
在Kinesis数据流中，
您有一兆字节的消息限制，这是Amazon
MSK的默认值，但您可以将其配置为更高的消息保留｡
例如，10兆字节｡
你可以在Kinesis数据流或MSK中使用带碎片的数据流，
这叫做带分区的卡夫卡主题，
但概念有点相似｡
要缩放Kinesis数据流，
您需要执行碎片分割并缩小合并｡
但在Amazon MSK中要缩放一个主题，
只能添加分区｡
不能删除分区｡
您可以对Kinesis数据流进行动态加密，
然后对MSK进行纯文本或TLS动态加密｡
这两个群集的加密都存在风险，
在考试级别中，这就足够了｡
你要知道，有一些不同｡
对于Amazon MSK，您可以根据需要保留数据，
可以保留一年以上，只要您支付底层EBS存储的费用，
就可以使用｡
因此，要生产到MSK你需要创建一个卡夫卡生产者，
然后消费从MSK，你有多种选择｡
第一个是使用Apache Flink的Kinesis数据分析｡
因此，您需要一个Flink应用程序，
并让它直接从MSK集群读取｡
你也可以使用Glue来做流ETL工作，它们是由Apache
Spark Streaming提供支持的｡
您可以使用Lambda函数直接将Amazon
MSK作为事件源，或者您可以编写自己的Kafka使用者，
并使其在您想要的任何平台上运行，
例如Amazon EC2实例､ ECS集群或EKS集群｡
一旦你知道了这一点，
你就知道了亚马逊MSK考试中需要知道的几乎所有东西｡
希望你们喜欢，
下次课再见.
  - [ ] 454 Amazon Certificate Manager (ACM) [01:29]
    * 
讲师：现在我们来谈谈AWS证书管理器或ACM，
它是一种可轻松配置､ 管理和部署SSL或TLS证书的服务｡
您使用证书做什么？
嗯，它是通过提供HTTPS端点为您的网站提供战斗加密｡
让我们举个例子｡
我们有应用负载平衡器，它在后端通过HTTP连接到包含EC2实例的自动扩展组｡
但我们希望最终用户在我们的答案应用程序上公开HTTPS｡
因此，我们将使用ACM｡
ACM一旦连接到我们的域，将允许我们提供和维护这些TLS证书｡
它们将被加载到我们的应用负载平衡器上，
然后负载平衡器将能够自动提供HTTPS作为我们客户端的端点，这使我们能够通过公共web获得动态加密｡
所以ACM支持公共和私有TLS证书，并且对于公共TLS证书是免费的｡
还有一个非常好的功能是自动TLS证书更新，这是非常有用的，
我一直在使用它｡
它具有集成性，这意味着它在不同的服务上加载TLS证书｡
例如，它可以是您的弹性负载平衡器､ CloudFront分发或API网关上的API，
好吗？
因此，
只要您看到有什么服务可以帮助我们进行飞行中加密并生成这些证书，那么请考虑ACM，就是这样｡
我们下节课再见｡ 
  - [ ] 455 Amazon Certificate Manager (ACM) [06:27] Hands On
    * 
  - [ ] 456 [DVA-C02] ACM Private CA - Overview [01:42]
    * 
Stephane：我们已经看到AWS证书管理器可以颁发公共证书，
但实际上您也可以颁发私有证书｡
为此，您必须创建AWS私有证书颁发机构｡
因此，它是一个托管服务，
您可以创建一个根证书颁发机构或任何从属证书颁发机构，它们是依赖于根的证书颁发机构｡
然后，您可以从那里发出并部署终端实体X｡
509个证书，
这意味着有您的应用程序可以使用的证书｡
这些证书不能用于创建新证书｡
因此，只要这些证书信任私有证书颁发机构，
它们将仅受组织内所有应用程序的信任｡
但是您不能在公共Internet上部署这些证书｡
这是行不通的，因为它是一个私人证书颁发机构｡
最重要的是，如果您使用与ACM集成的AWS服务，
例如您的应用程序负载平衡器，
您完全可以在其上加载证书，这将是一个私有证书｡
正如您在本例中所看到的，我向您展示了CloudFront､
API Gateway､ 负载平衡器､ Kubernetes服务等｡
这些证书可以出于任何原因颁发给用户，
包括计算机､ API或HTTP端点以及物联网设备｡
因此，使用私有证书颁发机构的用例是在内部进行加密TLS通信，
或通过向用户､ 计算机､ API端点和IOT设备提供证书来对代码进行加密签名以进行身份验证，或在企业内创建公钥基础设施｡
原来如此｡
希望你喜欢｡
我们下节课再见｡ 
  - [ ] 457 [DVA-C02] AWS AppConfig - Overview [02:44]
    * 
Stephane：现在我们来谈谈AWS AppConfig｡
因此，当您配置应用程序时，
通常会将配置与应用程序一起交付，
有时您可以使用环境变量模块化配置｡
但是，如果您希望它在应用程序之外进行配置，
该怎么办？
为此，您可以使用AppConfig，
它允许您配置､ 验证动态配置并将其部署到应用程序中｡
因此，您可以更改此配置，并且应用程序的更改与您向应用程序部署任何新代码无关｡
因此，您不需要重新启动应用程序，
一切都是动态运行的｡
它的美妙之处在于，例如，您可以使用功能标志｡
什么是功能标志？
假设您的应用程序附带了一个新特性，但现在您想禁用它，
所以您只需部署应用程序，然后在AppConfig中您说该特性是off或false｡
然后，当您的应用程序部署完毕并准备好测试时，
您只需更改AppConfig中的特性标志即可｡
您的应用程序将拾取它，
并自动启用此新功能｡
除此之外，您几乎可以动态地更改任何类型的配置，
因此您可以微调应用程序性能等等｡
例如，如果您有IP阻止列表或允许列表，
您可以再次在AppConfig中实时修改它们，而无需更改应用程序代码｡
因此，它对于在EC2实例､
Lambda､ ECS､ EKS等上运行的应用非常有用｡
最重要的是，如果您有一个配置更改，
例如，让我们回到我们的特性标记，
您不希望一次将特性发布到所有实例｡
您可能希望逐步部署此更改，以查看是否有任何问题，
如果有，则进行回滚｡
因此，AppConfig也可以做到这一点｡
因此AppConfig有一些配置源｡
它可以是参数存储，可以是SSM文档，
也可以是您的SRO存储桶或其他地方｡
然后您的EC2实例，当然，
在它们上运行的应用程序将定期拉取配置更改，
然后拉取它们｡
例如，当我们切换更改配置时，我们将自动使用CloudWatch监控是否出现任何问题｡
如果是这样，让我们触发一个警报，
这个警报将触发配置回滚｡
最重要的是，确保您实际上没有分发错误的配置｡
您可以使用JSON Schema或Lambda函数来验证它，
JSON Schema将检查配置是否符合某些特定类型等｡
这是当你需要代码的时候，
这段代码将以一种更复杂的方式来检查参数｡
这就是AppConfig｡
我希望你们喜欢，我们下节课再见｡ 
  - [ ]  Other Services [4 问题] Quiz
    * 
 ## Section 32 - AWS Final Cleanup [2 个讲座 • 3 分钟]
  - [ ] 458 AWS Final Cleanup [02:59]
    * 
  - [ ] 459 Cleanup Checklist [00:20]
    * 
 ## Section 33 - Preparing for the Exam - AWS Certified Developer Associate [6 个讲座 • 22 分钟]
  - [ ] 460 Exam Preparation - Section Introduction [00:31]
    * 
  - [ ] 461 State of Learning Checkpoint [06:26]
    * 
欢迎来到本课程的最后，我们已经学到了所有需要学习的技术知识｡
我希望到目前为止，您已经了解了很多AWS服务，并且对它们非常有信心｡
这一部分将致力于帮助您通过考试｡
我要给予你一些实用的建议｡
向您介绍考试的工作原理｡
在这一节的最后，你会有一个完整的练习考试来评估你的水平｡
祝你考试顺利｡
我们开始吧
  - [ ] 462 Exam Tips - AWS Certified Developer Associate [08:10]
    * 
教师：好的，
我们差不多完成了，但是我们要复习考试，
我会给予你们一些提示，然后会有一个练习考试｡
总的来说，祝贺你走到这一步｡
让我们看看今天的情况｡
所以我想做一个检查点｡
我想看看我们在学习之旅上走了多远，
我想检查一下开发人员考试的要求，因为了解我们确实涵盖了一切是很重要的｡
所以我们现在就开始吧｡
在AWS认证开发人员的URL上，目前有两个考试要参加，但我们正在准备更新的考试，
即2018年6月发布的认证开发人员考试｡
这一个，
另一个可以到11月19日，但我们还没有准备｡
我们一直在准备新的考试｡
所以你可以看看这一页｡
里面有很多好的信息｡
正如你所看到的，
有一个练习考试，你可以使用，但没有符号问题，只是还没有为这个考试｡
有一堆白皮书｡
我将讨论这些问题，但你应该读一点｡
浏览一下｡
我们已经涵盖了这些白皮书中的所有内容｡
现在我们可以看看考试费等等｡
但我想看的，更重要的是，考试的要求，
以及我们目前已经获得了什么｡
因此，本次考试将评估您对AWS架构最佳实践的核心服务､
使用和基础知识的理解能力｡
我认为在本课程中，我们已经探讨了许多不同的体系结构｡
然后，
我们研究了使用EC2的传统架构，以及使用无服务器的非传统架构｡
所以我们没事｡
我们还在AWS中开发､ 部署和调试了一系列基于云的应用程序｡
我们已经学习了EC2､
Elastic Beanstalk等函数，并建立了一些CICD管道｡
因此，
总的来说，您现在应该能够验证这两个核心点｡
现在有一些推荐的AWS知识，所有这些都很大，但我相信我们也涵盖了它｡
有一点我不能保证，您是否有一年或多年开发和维护基于AWS的应用程序的实际经验｡
所以这是你需要获得的东西｡
显然，如果你是AWS的新手，你没有一年的经验，
这门课程可能会让你有一个巨大的飞跃，
以了解AWS，但你需要做的是去一点点动手做之前，做考试｡
你不会学到什么新东西，但你会把所有这些知识都巩固到你的头脑中，它会开始对你更有意义，
希望你已经开始在工作中使用AWS应用这些知识｡
所以这是你可能想等待的东西｡
如果你对AWS还不太有信心，那就试着多积累一些经验｡
再复习一遍本课程，您就可以通过考试了｡
这是一种高级编程语言，你需要知道，为此，
我们一直在使用Python 3｡ 这门课有6个，
但没有JS, Go Java，所有这些都能用｡
通常当你懂一门编程语言的时候，你就能理解我在这门课上做的所有事情，
所以你很好｡
请记住，考试不会问你编程问题，但了解编程是如何工作的真的很重要，
因为这是一个开发人员证书｡
现在，让我们看一下AWS的具体内容｡
我们对核心服务有一定的了解，并且我们知道基本的AWS架构最佳实践，例如负载平衡器或扩展组｡
我们非常清楚如何使用CICD进行开发､ 部署和调试，
我们可以使用CloudWatch，我们可以使用X-Ray，我们可以在这里做很多事情｡
我们知道如何使用AWS服务API｡
我们已经看到了主要的功能，我们已经使用CLI做了很多事情，
并且在使用AWS Lambda时，我们已经多次使用SDK｡
现在，我们了解了我们所看到的每个AWS服务的关键特性｡
我有很多关于它们的幻灯片，所以希望你们能学到很多东西｡
我没有明确提到AWS共享责任模型，
但这意味着AWS负责其基础架构的安全性，而您负责自己的安全性｡
因此，
这意味着您的安全组是您的责任，启用加密是您的责任，等等｡
AWS不保证您的应用程序是安全的，因为这是您的应用程序，因此是您的责任｡
你所能保证的是，AWS不会被黑客入侵｡
现在，应用程序生命周期管理，我们肯定已经看到了｡
我们已经了解了如何进行开发测试和产品测试｡
我们已经有了CD管道，
我们已经看到了如何使用Lambda别名来指向不同的版本以及API网关阶段，因此我们可以肯定地看到应用程序生命周期管理｡
我们已经使用CICD管道从CodeCommit､ CodeBuild､
CodePipeline一路构建和部署应用程序，我们已经看到了CodeDeploy的概述，我们已经看到了作为部署平台的Elastic
Beanstalk｡
我们知道如何使用CLI和控制台与AWS服务交互，这是肯定的｡
我们知道编写云原生应用程序的基本知识，所以这很容易，但这意味着它要么是Lambda函数，
要么是ECS和Docker之类的函数｡
我们知道如何使用最佳实践编写代码，请看这个｡
不要在代码中使用秘密和访问密钥｡
这一点我们可以肯定｡
AMI角色我一直都在告诉您永远不要使用键，而要始终使用AMI角色｡
我已经在EC2滚动实例､
CodeBuild滚动实例､ Lambda滚动实例中演示了这一点｡
我们已经有了大量的策略分配角色和修改策略以解决权限问题的实践｡
我们知道如何在AWS上编写和维护模块｡
这与使用SDK非常相似，我们知道如何为服务应用程序编写代码｡
我们有Lambda函数来做很多事情，我们实际上也知道如何使用SAM框架，因此无服务器应用程序模型来编写代码并将其部署在AWS网络上，
这很棒｡
最后，了解容器在开发过程中的使用｡
这是围绕ECS，所以它不要求你知道如何做｡
这只是为了让大家了解容器的使用，所以我向大家介绍了ECS｡
只要知道ECS等于Docker､
等于应用程序负载平衡器､ 等于可扩展模型类型的东西就足够了｡
原来如此｡
大家知道，我们几乎涵盖了AWS的所有知识｡
这显然是高级别的｡
我们一直在深入研究涵盖这些领域的所有服务｡
你可以去准备考试｡
如您所见，
您可以将其作为培训，您可以查看一些白色，但总体而言，
如果您相信我，我希望您已经做好了充分的准备｡
原来如此｡
你知道我们已经学会了所有我们需要学会的东西｡
下节课我会给予你们一些考试的小窍门.
  - [ ] 463 Exam Walkthrough and Signup [03:35]
    * 
旁白：所以，这是我的提示和我的两分钱通过考试，所以这只是一般的建议｡
也许有些是显而易见的，有些你只需要听一次｡
对我来说，第一条建议是熟能生巧｡
因此，
如果您是AWS的新手，需要进行大量练习才能了解如何在日常工作中使用AWS｡
如果您是AWS的新手，本课程可能会让您在使用AWS方面领先一步｡
如果你觉得有信心，那就去做考试，
如果没有信心，不要着急，你有时间｡
只要在AWS上工作，要有信心｡
使用IAM卷，
部署应用程序，然后当您准备好时，就可以参加考试了｡
考试建议你们每个人都要有一年或一年以上的实践经验｡
所以，
有些事情你是不能伪造的，所以你要看你是否准备好了通过考试｡
所以，我说的是熟能生巧!
而且，你现在可能会有一种感觉，那就是被我刚刚教给你的大量知识所淹没，
你刚刚学到的知识｡
所以，掌握知识需要时间，
这不是你三天就能完成的课程｡
这是一门需要几周时间的课程｡
所以，如果你有很多已经获得的知识，
但你认为在你的头脑中还不完美，
那么就开始练习，再做一次课程｡
很明显，
这是几个小时的时间，但这真的会帮助你在考试后不浪费考试费用｡
所以，真的只是练习｡
这是我的建议｡
所以，如果你想练习，你可能会想，
我该怎么做？
好吧，如果你在一家公司，那么好，
只是与你的公司工作｡
如果没有，那么就从现有的应用程序中选择一种您想要的语言｡
尝试在EC2中手动部署｡
这是个不错的开始｡
然后，
尝试将其部署在Elastic Beanstalk上，并使用一个小的下行服务器和一个扩展组进行扩展｡
也许可以为它创建一个CICD管道｡
因此，
从代码到工件再到部署，您一路走下去｡
也许您可以尝试将应用程序分解为几个组件，并使用SQS和SNS来分离整个应用程序｡
如果可能的话，如果你使用java, go python, node，
这些语言，那么你可以用AWS
Lambda和它的朋友来运行它｡
这是DynamoDB的朋友，API网关｡
因此，可能会涉及到一些重构，
但它可能会很有趣｡
而且，如果您想练习使用CLI和SDK，
我强烈建议您有这样的想法｡
因此，例如，创建一个脚本或创建CLI或SDK脚本，
以便在晚上关闭EC2实例并在早上启动它们｡
这其实是一个有趣的项目做自己｡
或者，您也可以在夜间自动创建EBS卷的快照，
这样您就知道它们每天都会备份一次｡
第三个想法可能是列出一个区域中未充分利用的EC2实例｡
而且可能在CPU利用率低于10%时未充分利用它们，这样您就不会在利用率不足的EC2实例上浪费资金｡
同样，只是一堆想法，你可能有自己的想法，
基于你的用例，或你在日常基础上做什么｡
但是，我想做的只是给予你们一些练习的指导｡
现在，在考试中，
你们会有问题，
你们会有多个答案，有时一个答案，有时不止一个答案｡
这些问题中的大多数都是基于情景的｡
而且，
对于所有的问题，我建议从排除那些你知道肯定是错误的答案开始｡
所以，这是一个很好的开始，
因为如果你知道什么是错误的，
然后你消除它，这是一个少一个问题，
你必须思考，回答你必须思考｡
所以，对于剩下的答案，
你需要认真思考哪一个最有意义｡
而且，老实说，我会非常诚实地告诉你，
有很少的陷阱问题，所以不要想太多你的整个过程｡
如果一个答案很有意义，那就去做吧｡
如果一个答案看起来可行，但非常复杂，需要大量的工程，
它可能是错误的｡
有时候有两个答案是正确的，
但一个确实比另一个更容易，或者更有意义，所以要真正运用你的判断力｡
试着想想你要付出多大的努力来实现问题要求你做的任何事情，并在此基础上做出决定｡
但通常情况下，通过排除法进行，然后使用你的判断和你的知识，
真的会让你通过大部分的问题｡
记住，只有非常非常少的陷阱问题｡
而且，这些问题将有关键词，
这些关键词通常会表明答案中决定性的东西｡
例如，
无服务器可能意味着AWS､ Lambda､ DynamoDB和API网关｡
这一类的东西｡
现在，AWS白皮书建议您阅读｡
老实说，
这是10个白皮书的40页，你可能不想读他们所有，但你应该略读｡
有很多白色，都是关于安全最佳实践的，我们已经看到了使用IAM卷､
加密之类的东西｡
然后是架构良好的框架｡
因此，
围绕如何构建应用程序､ 使用RDS､ ElastiCache等进行职责分离｡
云架构，这是一回事｡
CICD白皮书将围绕CodeBuild､ CodeDeploy､
CodePipeline和CodeCommit展开｡
我们已经看到了这一点｡
AWS上的微服务将围绕AWS Lambda，
还有ECS，
以及所有这些东西来解耦你的微服务，并让它们彼此创新｡
使用AWS Lambda的无服务器架构，
我想我们已经看到了很多，我们还看到了SAM框架，我们将在这里讨论它｡
“使用无服务器架构优化企业经济性”基本上向您解释了，
如果您选择无服务器，那么您就不必花钱请人来管理和维护您的数据，因此您可以保存大量资金｡
最重要的是，
无服务器意味着您只需为您使用的内容付费，因此您应该在定价上达到最佳｡
现在，AWS上的容器化微服务｡
这是一个高级主题，但这是围绕ECS的｡
基本上，它是说好的，
使用ECS中的Docker在AWS上部署微服务｡
请记住，
考试只是询问您ECS的高水平，而不是深入了解｡
蓝/绿色部署，我已经尝试将其放在课程的任何地方，
在Beanstalk上会有蓝/绿部署，在Lambda或API
Gateway上可能会有一些蓝/绿部署｡
我们看到的所有这些东西，
蓝/绿色基本上是在测试新版本，绿色版本，而蓝色版本仍在运行｡
当我们准备好的时候，从蓝色版本切换到绿色版本｡
总的来说，我觉得我们已经解释了，探讨了本课程中最重要的概念，
但是如果你对其中的一篇论文有强烈的感觉，并且你想读它，
那就去读吧｡
我觉得这些论文都很有趣｡
你可能想读的一篇文章是AWS上的蓝/绿色部署，你只是快速浏览一下，
但不要想太多｡
大部分的问题，
可能所有的问题，都将在本课程中讨论｡
现在每个服务都有一个常见问题，所以常见问题｡
例如，对于Lambda，它的/lambda/常见问题解答｡
我认为它们非常重要，
因为FAQ涵盖了他们在考试中会问你的很多问题，它们可能会帮助你确认你对某项服务的理解，或者可能会帮助你澄清一些疑问｡
因此，
一定要查看服务常见问题解答，尤其是您不太了解的问题｡
最后一点是社区，
所以你需要进入AWS社区，你需要和其他亚马逊工程师交谈｡
你知道，与人交谈真的能开启知识，
至少对我来说是这样｡
因此，请在课程问答中与其他人讨论｡
一定要帮助其他人回答他们的问题｡
通过回答他们的问题，
这就是你学习的方式，你通过教学来学习｡
然后你回顾别人问的问题｡
一定要看看别人的顾虑是什么｡
也许他们会帮助你｡
也许答案会再次教会你一些东西｡
然后，做本部分的练习测试，
看看你的情况｡
你应该阅读在线论坛｡
如果你非常好奇，可以阅读在线博客，
也有当地的聚会可以与其他亚马逊工程师讨论｡
最后，
如果你是一个YouTube的人，有很多重新发明的视频是相当不错的｡
重新发明是一个AWS会议，他们有很多好的内容｡
基本上是一个介绍他们的服务，有时是一个小演示｡
所以，这是它，真正的提示你需要做什么｡
我相信你已经准备好了，但你要看自己还想练习多少｡
但是，希望这些提示能有所帮助，
我们下节课再见｡
  - [ ] 464 Save 50% on your AWS Exam Cost! [01:41]
    * 
  - [ ] 465 Get an Extra 30 Minutes on your AWS Exam - Non Native English Speakers only [01:09]
    * 
  - [ ]  AWS Certified Developer Associate [65 问题] Practice Test
    * 
 ## Section 34 - Congratulations - AWS Certified Developer Associate [3 个讲座 • 4 分钟]
  - [ ] 466 Congratulations - AWS Certified Developer Associate [01:07]
    * 
  - [ ] 467 THANK YOU! [01:32]
    * 
  - [ ] 468 Bonus Lecture [00:58]
    * 



#
|                                                                                    |                                                                             |       |
| ---------------------------------------------------------------------------------- | --------------------------------------------------------------------------- | ----- |
| **Course Introduction - AWS Certified Developer Associate**                        | 6 个讲座 • 11 分钟                                                          |
|                                                                                    | Course Introduction - AWS Certified Developer Associate                     | 02:18 |
|                                                                                    | PLEASE READ: Lectures you can skip if you took a course from me before      | 01:03 |
|                                                                                    | Create your AWS Account                                                     | 01:48 |
|                                                                                    | AWS Account Activation Troubleshooting                                      | 02:05 |
|                                                                                    | Important Message                                                           | 00:40 |
|                                                                                    | About your instructor                                                       | 02:45 |
| **Code & Slides Download**                                                         | 1 个讲座 • 1 分钟                                                           |
|                                                                                    | Code & Slides Download                                                      | 00:15 |
| **Getting started with AWS**                                                       | 3 个讲座 • 14 分钟                                                          |
|                                                                                    | AWS Cloud Overview - Regions & AZ                                           | 08:08 |
|                                                                                    | Tour of the AWS Console & Services in AWS                                   | 03:52 |
|                                                                                    | About the UI changes in the course                                          | 01:50 |
| **IAM & AWS CLI**                                                                  | 18 个讲座 • 53 分钟                                                         |
|                                                                                    | IAM Introduction: Users, Groups, Policies                                   | 03:22 |
|                                                                                    | IAM Users & Groups Hands On                                                 | 06:55 |
|                                                                                    | IAM Policies                                                                | 02:50 |
|                                                                                    | IAM Policies Hands On                                                       | 06:09 |
|                                                                                    | IAM MFA Overview                                                            | 04:18 |
|                                                                                    | IAM MFA Hands On                                                            | 03:17 |
|                                                                                    | AWS Access Keys, CLI and SDK                                                | 04:03 |
|                                                                                    | AWS CLI Setup on Windows                                                    | 01:45 |
|                                                                                    | AWS CLI Setup on Mac OS X                                                   | 01:28 |
|                                                                                    | AWS CLI Setup on Linux                                                      | 01:30 |
|                                                                                    | AWS CLI Hands On                                                            | 03:50 |
|                                                                                    | AWS CloudShell                                                              | 03:53 |
|                                                                                    | IAM Roles for AWS Services                                                  | 01:39 |
|                                                                                    | IAM Roles Hands On                                                          | 02:04 |
|                                                                                    | IAM Security Tools                                                          | 00:54 |
|                                                                                    | IAM Security Tools Hands On                                                 | 02:25 |
|                                                                                    | IAM Best Practices                                                          | 01:29 |
|                                                                                    | IAM Summary                                                                 | 01:05 |
|                                                                                    | IAM & AWS CLI Quiz • 10 问题                                                |
| **EC2 Fundamentals**                                                               | 14 个讲座 • 1 小时 22 分钟                                                  |
|                                                                                    | AWS Budget Setup                                                            | 05:11 |
|                                                                                    | EC2 Basics                                                                  | 05:08 |
|                                                                                    | Create an EC2 Instance with EC2 User Data to have a Website Hands On        | 13:48 |
|                                                                                    | EC2 Instance Types Basics                                                   | 05:51 |
|                                                                                    | Security Groups & Classic Ports Overview                                    | 07:26 |
|                                                                                    | Security Groups Hands On                                                    | 04:45 |
|                                                                                    | SSH Overview                                                                | 02:47 |
|                                                                                    | How to SSH using Linux or Mac                                               | 07:05 |
|                                                                                    | How to SSH using Windows                                                    | 06:08 |
|                                                                                    | How to SSH using Windows 10                                                 | 05:01 |
|                                                                                    | SSH Troubleshooting                                                         | 01:23 |
|                                                                                    | EC2 Instance Connect                                                        | 03:15 |
|                                                                                    | EC2 Instance Roles Demo                                                     | 04:19 |
|                                                                                    | EC2 Instance Purchasing Options                                             | 09:48 |
|                                                                                    | EC2 Fundamentals Quiz • 11 问题                                             |
| **EC2 Instance Storage**                                                           | 13 个讲座 • 54 分钟                                                         |
|                                                                                    | EBS Overview                                                                | 04:57 |
|                                                                                    | EBS Hands On                                                                | 05:34 |
|                                                                                    | EBS Snapshots                                                               | 02:08 |
|                                                                                    | EBS Snapshots - Hands On                                                    | 03:41 |
|                                                                                    | AMI Overview                                                                | 02:45 |
|                                                                                    | AMI Hands On                                                                | 04:59 |
|                                                                                    | EC2 Instance Store                                                          | 02:47 |
|                                                                                    | EBS Volume Types                                                            | 05:32 |
|                                                                                    | EBS Multi-Attach                                                            | 01:45 |
|                                                                                    | Amazon EFS                                                                  | 05:12 |
|                                                                                    | Amazon EFS - Hands On                                                       | 11:15 |
|                                                                                    | EFS vs EBS                                                                  | 02:05 |
|                                                                                    | EBS & EFS - Section Cleanup                                                 | 01:31 |
|                                                                                    | EC2 Data Management Quiz • 9 问题                                           |
| **AWS Fundamentals: ELB + ASG**                                                    | 19 个讲座 • 1 小时 34 分钟                                                  |
|                                                                                    | High Availability and Scalability                                           | 05:05 |
|                                                                                    | Elastic Load Balancing (ELB) Overview                                       | 06:15 |
|                                                                                    | Note: About the Classic Load Balancer (CLB)                                 | 00:12 |
|                                                                                    | Application Load Balancer (ALB)                                             | 05:49 |
|                                                                                    | Application Load Balancer (ALB) - Hands On - Part 1                         | 08:34 |
|                                                                                    | Application Load Balancer (ALB) - Hands On - Part 2                         | 04:28 |
|                                                                                    | Network Load Balancer (NLB)                                                 | 03:35 |
|                                                                                    | Network Load Balancer (NLB) - Hands On                                      | 04:36 |
|                                                                                    | Gateway Load Balancer (GWLB)                                                | 03:47 |
|                                                                                    | Elastic Load Balancer - Sticky Sessions                                     | 05:41 |
|                                                                                    | Elastic Load Balancer - Cross Zone Load Balancing                           | 05:53 |
|                                                                                    | Elastic Load Balancer - SSL Certificates                                    | 06:04 |
|                                                                                    | Elastic Load Balancer - SSL Certificates - Hands On                         | 01:59 |
|                                                                                    | Elastic Load Balancer - Connection Draining                                 | 02:22 |
|                                                                                    | Auto Scaling Groups (ASG) Overview                                          | 04:42 |
|                                                                                    | Auto Scaling Groups Hands On                                                | 09:10 |
|                                                                                    | Auto Scaling Groups - Scaling Policies                                      | 05:00 |
|                                                                                    | Auto Scaling Groups - Scaling Policies Hands On                             | 09:15 |
|                                                                                    | [DVA-C02] Auto Scaling Groups - Instance Refresh                            | 01:36 |
|                                                                                    | High Availability & Scalability Quiz • 20 问题                              |
| **AWS Fundamentals: RDS + Aurora + ElastiCache**                                   | 11 个讲座 • 1 小时 4 分钟                                                   |
|                                                                                    | Amazon RDS Overview                                                         | 03:46 |
|                                                                                    | RDS Read Replicas vs Multi AZ                                               | 07:22 |
|                                                                                    | Amazon RDS Hands On                                                         | 10:30 |
|                                                                                    | Amazon Aurora                                                               | 06:29 |
|                                                                                    | Amazon Aurora - Hands On                                                    | 06:42 |
|                                                                                    | RDS & Aurora Security                                                       | 02:32 |
|                                                                                    | [DVA-C02] RDS Proxy                                                         | 04:32 |
|                                                                                    | [DVA-C02] ElastiCache Overview                                              | 04:21 |
|                                                                                    | ElastiCache Hands On                                                        | 04:34 |
|                                                                                    | ElastiCache Strategies                                                      | 11:37 |
|                                                                                    | [DVA-C02] Amazon MemoryDB for Redis - Overview                              | 01:18 |
|                                                                                    | RDS, Aurora，& ElastiCache Quiz • 23 问题                                   |
| **Route 53**                                                                       | 20 个讲座 • 1 小时 30 分钟                                                  |
|                                                                                    | What is a DNS?                                                              | 06:24 |
|                                                                                    | Route 53 Overview                                                           | 06:18 |
|                                                                                    | Route 53 - Registering a domain                                             | 02:59 |
|                                                                                    | Route 53 - Creating our first records                                       | 03:56 |
|                                                                                    | Route 53 - EC2 Setup                                                        | 05:40 |
|                                                                                    | Route 53 - TTL                                                              | 05:28 |
|                                                                                    | Route 53 CNAME vs Alias                                                     | 07:00 |
|                                                                                    | Routing Policy - Simple                                                     | 04:05 |
|                                                                                    | Routing Policy - Weighted                                                   | 05:02 |
|                                                                                    | Routing Policy - Latency                                                    | 04:39 |
|                                                                                    | Route 53 Health Checks                                                      | 04:54 |
|                                                                                    | Route 53 - Health Checks Hands On                                           | 04:39 |
|                                                                                    | Routing Policy - Failover                                                   | 04:12 |
|                                                                                    | Routing Policy - Geolocation                                                | 04:15 |
|                                                                                    | Routing Policy - Geoproximity                                               | 03:21 |
|                                                                                    | Routing Policy - Traffic Flow & Geoproximity Hands On                       | 07:32 |
|                                                                                    | Routing Policy - IP-based                                                   | 01:45 |
|                                                                                    | Routing Policy - Multi Value                                                | 03:42 |
|                                                                                    | 3rd Party Domains & Route 53                                                | 02:24 |
|                                                                                    | Route 53 - Section Cleanup                                                  | 01:21 |
|                                                                                    | Route 53 Quiz • 7 问题                                                      |
| **VPC Fundamentals**                                                               | 6 个讲座 • 25 分钟                                                          |
|                                                                                    | VPC Fundamentals - Section Introduction                                     | 01:23 |
|                                                                                    | VPC, Subnets, IGW and NAT                                                   | 05:23 |
|                                                                                    | NACL, SG, VPC Flow Logs                                                     | 04:39 |
|                                                                                    | VPC Peering, Endpoints, VPN, DX                                             | 05:50 |
|                                                                                    | VPC Cheat Sheet & Closing Comments                                          | 02:34 |
|                                                                                    | Three Tier Architecture                                                     | 05:16 |
|                                                                                    | VPC Quiz • 8 问题                                                           |
| **Amazon S3 Introduction**                                                         | 13 个讲座 • 47 分钟                                                         |
|                                                                                    | S3 Overview                                                                 | 05:06 |
|                                                                                    | S3 Hands On                                                                 | 05:55 |
|                                                                                    | S3 Security: Bucket Policy                                                  | 05:03 |
|                                                                                    | S3 Security: Bucket Policy Hands On                                         | 03:32 |
|                                                                                    | S3 Website Overview                                                         | 01:07 |
|                                                                                    | S3 Website Hands On                                                         | 01:58 |
|                                                                                    | S3 Versioning                                                               | 01:13 |
|                                                                                    | S3 Versioning - Hands On                                                    | 04:17 |
|                                                                                    | S3 Replication                                                              | 01:25 |
|                                                                                    | S3 Replication Notes                                                        | 00:57 |
|                                                                                    | S3 Replication - Hands On                                                   | 06:29 |
|                                                                                    | S3 Storage Classes Overview                                                 | 06:12 |
|                                                                                    | S3 Storage Classes Hands On                                                 | 03:37 |
|                                                                                    | Amazon S3 Quiz • 8 问题                                                     |
| **AWS CLI, SDK, IAM Roles & Policies**                                             | 9 个讲座 • 36 分钟                                                          |
|                                                                                    | AWS CLI Dry Run                                                             | 04:56 |
|                                                                                    | AWS CLI STS Decode                                                          | 04:34 |
|                                                                                    | AWS EC2 Instance Metadata                                                   | 04:53 |
|                                                                                    | AWS CLI Profiles                                                            | 03:07 |
|                                                                                    | AWS CLI with MFA                                                            | 05:14 |
|                                                                                    | AWS SDK Overview                                                            | 01:40 |
|                                                                                    | Exponential Backoff & Service Limit Increase                                | 03:48 |
|                                                                                    | AWS Credentials Provider & Chain                                            | 04:39 |
|                                                                                    | [DVA-C02] AWS Signature v4 Signing (Sigv4)                                  | 03:23 |
|                                                                                    | AWS IAM, CLI，& SDK Quiz • 13 问题                                          |
| **Advanced Amazon S3**                                                             | 7 个讲座 • 24 分钟                                                          |
|                                                                                    | S3 Lifecycle Rules (with S3 Analytics)                                      | 04:20 |
|                                                                                    | S3 Lifecycle Rules - Hands On                                               | 02:24 |
|                                                                                    | S3 Event Notifications                                                      | 02:28 |
|                                                                                    | S3 Event Notifications - Hands On                                           | 05:42 |
|                                                                                    | S3 Performance                                                              | 04:54 |
|                                                                                    | S3 Select & Glacier Select                                                  | 01:17 |
|                                                                                    | [DVA-C02] S3 Object Tags & Metadata                                         | 02:33 |
|                                                                                    | Amazon S3 Advanced Quiz • 7 问题                                            |
| **Amazon S3 Security**                                                             | 13 个讲座 • 48 分钟                                                         |
|                                                                                    | S3 Encryption                                                               | 07:31 |
|                                                                                    | S3 Encryption - Hands On                                                    | 04:39 |
|                                                                                    | S3 Default Encryption                                                       | 01:23 |
|                                                                                    | S3 CORS                                                                     | 04:19 |
|                                                                                    | S3 CORS Hands On                                                            | 07:23 |
|                                                                                    | S3 MFA Delete                                                               | 01:24 |
|                                                                                    | S3 MFA Delete Hands On                                                      | 06:25 |
|                                                                                    | S3 Access Logs                                                              | 01:16 |
|                                                                                    | S3 Access Logs - Hands On                                                   | 02:49 |
|                                                                                    | S3 Pre-signed URLs                                                          | 01:50 |
|                                                                                    | S3 Pre-signed URLs - Hands On                                               | 01:48 |
|                                                                                    | S3 Access Points                                                            | 03:34 |
|                                                                                    | S3 Object Lambda                                                            | 03:10 |
|                                                                                    | Amazon S3 Security Quiz • 9 问题                                            |
| **CloudFront**                                                                     | 12 个讲座 • 47 分钟                                                         |
|                                                                                    | CloudFront - Overview                                                       | 05:11 |
|                                                                                    | CloudFront Hands On                                                         | 05:06 |
|                                                                                    | [DVA-C02] CloudFront - Caching & Caching Policies                           | 06:46 |
|                                                                                    | [DVA-C02] CloudFront - Cache Invalidations                                  | 02:40 |
|                                                                                    | [DVA-C02] CloudFront - Cache Behaviors                                      | 02:52 |
|                                                                                    | [DVA-C02] CloudFront - Caching & Caching Invalidations - Hands On           | 04:37 |
|                                                                                    | CloudFront - ALB as an Origin                                               | 01:35 |
|                                                                                    | CloudFront - Geo Restriction                                                | 00:58 |
|                                                                                    | CloudFront Signed URL / Cookies                                             | 03:39 |
|                                                                                    | CloudFront Signed URL - Key Groups + Hands On                               | 04:44 |
|                                                                                    | CloudFront Advanced Concepts                                                | 07:07 |
|                                                                                    | [DVA-C02] CloudFront - Real Time Logs                                       | 01:29 |
|                                                                                    | CloudFront Quiz • 9 问题                                                    |
| **ECS, ECR & Fargate - Docker in AWS**                                             | 16 个讲座 • 1 小时 19 分钟                                                  |
|                                                                                    | Docker Introduction                                                         | 05:10 |
|                                                                                    | Amazon ECS                                                                  | 06:43 |
|                                                                                    | IMPORTANT: ECS UI CHANGES                                                   | 00:10 |
|                                                                                    | Creating ECS Cluster - Hands On                                             | 04:45 |
|                                                                                    | Creating ECS Service - Hands On                                             | 10:06 |
|                                                                                    | Amazon ECS - Auto Scaling                                                   | 03:21 |
|                                                                                    | Amazon ECS - Rolling Updates                                                | 02:33 |
|                                                                                    | Amazon ECS - Solutions Architectures                                        | 02:31 |
|                                                                                    | Amazon ECS Task Definitions - Deep Dive                                     | 09:02 |
|                                                                                    | Amazon ECS Task Definitions - Hands On                                      | 03:36 |
|                                                                                    | Amazon ECS - Task Placements                                                | 05:55 |
|                                                                                    | Amazon ECR                                                                  | 01:38 |
|                                                                                    | Amazon ECR - Hands On                                                       | 05:43 |
|                                                                                    | [DVA-C02] AWS CoPilot - Overview                                            | 01:23 |
|                                                                                    | [DVA-C02] AWS CoPilot - Hands On                                            | 12:29 |
|                                                                                    | Amazon EKS                                                                  | 03:58 |
|                                                                                    | Containers on AWS Quiz • 15 问题                                            |
| **AWS Elastic Beanstalk**                                                          | 15 个讲座 • 1 小时 11 分钟                                                  |
|                                                                                    | AWS Elastic Beanstalk - Section Introduction                                | 00:39 |
|                                                                                    | Elastic Beanstalk Overview (High level)                                     | 05:15 |
|                                                                                    | Beanstalk First Environment                                                 | 05:35 |
|                                                                                    | Beanstalk Second Environment                                                | 09:15 |
|                                                                                    | Beanstalk Deployment Modes                                                  | 11:39 |
|                                                                                    | Beanstalk Deployment Modes Hands On                                         | 09:06 |
|                                                                                    | Beanstalk CLI and Deployment Process                                        | 02:14 |
|                                                                                    | Beanstalk Lifecycle Policy Overview + Hands On                              | 02:45 |
|                                                                                    | Beanstalk Extensions                                                        | 03:51 |
|                                                                                    | Beanstalk & CloudFormation                                                  | 02:57 |
|                                                                                    | Beanstalk Cloning                                                           | 01:35 |
|                                                                                    | Beanstalk Migrations                                                        | 03:19 |
|                                                                                    | Beanstalk with Docker                                                       | 06:35 |
|                                                                                    | Beanstalk Advanced Concepts                                                 | 03:40 |
|                                                                                    | Beanstalk Cleanup                                                           | 02:11 |
|                                                                                    | Elastic Beanstalk Quiz • 17 问题                                            |
| **AWS CICD: CodeCommit, CodePipeline, CodeBuild, CodeDeploy**                      | 25 个讲座 • 2 小时 6 分钟                                                   |
|                                                                                    | AWS CICD - Section Introduction                                             | 00:37 |
|                                                                                    | Introduction to CICD in AWS                                                 | 05:39 |
|                                                                                    | CodeCommit Overview                                                         | 04:12 |
|                                                                                    | CodeCommit Hands On Part I                                                  | 06:25 |
|                                                                                    | CodeCommit Hands On Part 2                                                  | 05:55 |
|                                                                                    | CodePipeline Overview                                                       | 03:52 |
|                                                                                    | CodePipeline - Hands On                                                     | 09:59 |
|                                                                                    | [DVA-C02] CodePipeline - Extras                                             | 04:34 |
|                                                                                    | CodeBuild Overview                                                          | 05:41 |
|                                                                                    | CodeBuild Hands On Part I                                                   | 04:49 |
|                                                                                    | CodeBuild Hands On Part 2                                                   | 09:15 |
|                                                                                    | [DVA-C02] CodePipeline - CloudFormation Integration                         | 02:40 |
|                                                                                    | CodeDeploy Overview                                                         | 08:30 |
|                                                                                    | CodeDeploy Hands On                                                         | 12:15 |
|                                                                                    | CodeDeploy for EC2 and ASG                                                  | 02:46 |
|                                                                                    | [DVA-C02] CodeDeploy - Extras                                               | 01:16 |
|                                                                                    | CodeStar - Overview                                                         | 01:44 |
|                                                                                    | CodeStar - Hands On                                                         | 06:52 |
|                                                                                    | [DVA-C02] CodeArtifact - Overview                                           | 06:01 |
|                                                                                    | [DVA-C02] CodeArtifact - Upstream Repositories & Domains                    | 05:54 |
|                                                                                    | [DVA-C02] CodeArtifact - Hands On                                           | 06:24 |
|                                                                                    | CodeGuru - Overview                                                         | 03:22 |
|                                                                                    | [DVA-C02] CodeGuru - Agent Configuration                                    | 01:38 |
|                                                                                    | [DVA-C02] AWS Cloud9 - Overview                                             | 01:23 |
|                                                                                    | [DVA-C02] AWS Cloud9 - Hands On                                             | 04:09 |
|                                                                                    | AWS CICD Quiz • 22 问题                                                     |
| **AWS CloudFormation**                                                             | 16 个讲座 • 1 小时 6 分钟                                                   |
|                                                                                    | AWS CloudFormation - Section Introduction                                   | 00:40 |
|                                                                                    | CloudFormation Overview                                                     | 07:06 |
|                                                                                    | CloudFormation Create Stack Hands On                                        | 06:08 |
|                                                                                    | CloudFormation Update and Delete Stack Hands On                             | 07:30 |
|                                                                                    | YAML Crash Course                                                           | 03:36 |
|                                                                                    | CloudFormation Resources                                                    | 06:27 |
|                                                                                    | CloudFormation Parameters                                                   | 04:59 |
|                                                                                    | CloudFormation Mappings                                                     | 02:53 |
|                                                                                    | CloudFormation Outputs                                                      | 03:08 |
|                                                                                    | CloudFormation Conditions                                                   | 02:06 |
|                                                                                    | CloudFormation Intrinsic Functions                                          | 05:30 |
|                                                                                    | CloudFormation Rollbacks                                                    | 05:13 |
|                                                                                    | [DVA-C02] CloudFormation Stack Notifications                                | 01:12 |
|                                                                                    | CloudFormation ChangeSets, Nested Stacks & StackSet                         | 03:26 |
|                                                                                    | CloudFormation Drift                                                        | 04:20 |
|                                                                                    | [DVA-C02] CloudFormation Stack Policies                                     | 01:24 |
|                                                                                    | CloudFormation Quiz • 17 问题                                               |
| **AWS Monitoring & Audit: CloudWatch, X-Ray and CloudTrail**                       | 26 个讲座 • 1 小时 40 分钟                                                  |
|                                                                                    | AWS Monitoring - Section Introduction                                       | 00:38 |
|                                                                                    | Monitoring Overview in AWS                                                  | 02:45 |
|                                                                                    | CloudWatch Metrics                                                          | 02:54 |
|                                                                                    | CloudWatch Custom Metrics                                                   | 04:03 |
|                                                                                    | CloudWatch Logs                                                             | 03:31 |
|                                                                                    | CloudWatch Logs Hands On                                                    | 05:09 |
|                                                                                    | CloudWatch Agent & CloudWatch Logs Agent                                    | 03:16 |
|                                                                                    | CloudWatch Logs Metric Filters                                              | 05:36 |
|                                                                                    | CloudWatch Alarms                                                           | 04:01 |
|                                                                                    | CloudWatch Alarms Hands On                                                  | 04:38 |
|                                                                                    | [DVA-C02] CloudWatch Synthetics                                             | 02:54 |
|                                                                                    | Amazon EventBridge                                                          | 06:59 |
|                                                                                    | Amazon EventBridge - Hands On                                               | 07:11 |
|                                                                                    | [DVA-C02] Amazon EventBridge - Multi-Account Aggregation                    | 01:23 |
|                                                                                    | [DVA-C02] X-Ray Overview                                                    | 07:07 |
|                                                                                    | X-Ray Hands On                                                              | 08:13 |
|                                                                                    | X-Ray: Instrumentation and Concepts                                         | 04:43 |
|                                                                                    | X-Ray: Sampling Rules                                                       | 02:05 |
|                                                                                    | X-Ray APIs                                                                  | 02:55 |
|                                                                                    | X-Ray with Beanstalk                                                        | 03:11 |
|                                                                                    | X-Ray & ECS                                                                 | 04:10 |
|                                                                                    | AWS Distro for OpenTelemetry                                                | 02:40 |
|                                                                                    | CloudTrail                                                                  | 06:32 |
|                                                                                    | CloudTrail Hands On                                                         | 01:30 |
|                                                                                    | CloudTrail vs CloudWatch vs X-Ray                                           | 01:18 |
|                                                                                    | AWS Quick Clean-Up                                                          | 00:46 |
|                                                                                    | Monitoring & Audit Quiz • 24 问题                                           |
| **AWS Integration & Messaging: SQS, SNS & Kinesis**                                | 27 个讲座 • 2 小时 11 分钟                                                  |
|                                                                                    | AWS Integration & Messaging - Section Introduction                          | 00:44 |
|                                                                                    | Introduction to Messaging                                                   | 02:45 |
|                                                                                    | Amazon SQS - Standard Queues Overview                                       | 10:35 |
|                                                                                    | SQS - Standard Queue Hands On                                               | 06:27 |
|                                                                                    | SQS Queue Access Policy                                                     | 07:08 |
|                                                                                    | SQS - Message Visibility Timeout                                            | 05:18 |
|                                                                                    | SQS - Dead Letter Queues                                                    | 02:46 |
|                                                                                    | SQS - Dead Letter Queues - Hands On                                         | 03:46 |
|                                                                                    | SQS - Delay Queues                                                          | 02:27 |
|                                                                                    | SQS - Certified Developer concepts                                          | 06:19 |
|                                                                                    | SQS - FIFO Queues                                                           | 03:35 |
|                                                                                    | SQS - FIFO Queues Advanced                                                  | 05:28 |
|                                                                                    | Amazon SNS                                                                  | 04:18 |
|                                                                                    | Amazon SNS and SQS - Fan Out Pattern                                        | 06:01 |
|                                                                                    | SNS Hands On                                                                | 04:36 |
|                                                                                    | Kinesis Overview                                                            | 01:16 |
|                                                                                    | Kinesis Data Streams Overview                                               | 05:56 |
|                                                                                    | Kinesis Producers                                                           | 04:42 |
|                                                                                    | Kinesis Consumers                                                           | 05:15 |
|                                                                                    | Kinesis Data Streams Hands On                                               | 09:38 |
|                                                                                    | Kinesis Client Library                                                      | 03:13 |
|                                                                                    | Kinesis Operations                                                          | 02:17 |
|                                                                                    | Kinesis Data Firehose Overview                                              | 04:56 |
|                                                                                    | Kinesis Data Firehose Hands On                                              | 07:52 |
|                                                                                    | Kinesis Data Analytics                                                      | 03:33 |
|                                                                                    | Data Ordering for Kinesis vs SQS FIFO                                       | 07:14 |
|                                                                                    | SQS vs SNS vs Kinesis                                                       | 03:00 |
|                                                                                    | Messaging & Integration Quiz • 25 问题                                      |
| **AWS Serverless: Lambda**                                                         | 48 个讲座 • 3 小时 7 分钟                                                   |
|                                                                                    | AWS Lambda - Section Introduction                                           | 00:46 |
|                                                                                    | Serverless Introduction                                                     | 02:19 |
|                                                                                    | AWS Lambda Overview                                                         | 07:19 |
|                                                                                    | AWS Lambda - First Hands On                                                 | 09:49 |
|                                                                                    | Lambda Synchronous Invocations                                              | 02:01 |
|                                                                                    | Lambda Synchronous Invocations Hands On                                     | 02:17 |
|                                                                                    | Lambda & Application Load Balancer                                          | 03:23 |
|                                                                                    | Lambda & Application Load Balancer Hands On                                 | 08:09 |
|                                                                                    | Lambda Asynchronous Invocations & DLQ                                       | 03:13 |
|                                                                                    | Lambda Asynchronous Invocations Hands On                                    | 05:59 |
|                                                                                    | Lambda & CloudWatch Events / EventBridge                                    | 00:28 |
|                                                                                    | Lambda & CloudWatch Events / EventBridge Hands On                           | 05:04 |
|                                                                                    | Lambda & S3 Event Notifications                                             | 01:34 |
|                                                                                    | Lambda & S3 Event Notifications - Hands On                                  | 04:19 |
|                                                                                    | Lambda Event Source Mapping                                                 | 07:17 |
|                                                                                    | Lambda Event Source Mapping Hands On (SQS)                                  | 07:02 |
|                                                                                    | [DVA-C02] Lambda Event & Context Objects                                    | 02:31 |
|                                                                                    | Lambda Destinations                                                         | 02:30 |
|                                                                                    | Lambda Destinations Hands On                                                | 06:49 |
|                                                                                    | Lambda Permissions - IAM Roles & Resource Policies                          | 02:35 |
|                                                                                    | Lambda Permissions - IAM Roles & Resource Policies - Hands On               | 03:03 |
|                                                                                    | Lambda Environment Variables                                                | 00:47 |
|                                                                                    | Lambda Environment Variables - Hands On                                     | 02:42 |
|                                                                                    | Lambda Monitoring & X-Ray Tracing                                           | 01:53 |
|                                                                                    | Lambda Monitoring & X-Ray Tracing - Hands On                                | 04:14 |
|                                                                                    | [DVA-C02] Lambda@Edge & CloudFront Functions                                | 05:38 |
|                                                                                    | Lambda in VPC                                                               | 04:21 |
|                                                                                    | Lambda in VPC - Hands On                                                    | 04:39 |
|                                                                                    | Lambda Function Performance                                                 | 05:29 |
|                                                                                    | Lambda Function Performance - Hands On                                      | 06:00 |
|                                                                                    | Lambda Layers                                                               | 01:51 |
|                                                                                    | Lambda Layers - Hands On                                                    | 03:14 |
|                                                                                    | [DVA-C02] Lambda File Systems Mounting                                      | 03:36 |
|                                                                                    | Lambda Concurrency                                                          | 06:01 |
|                                                                                    | Lambda Concurrency Hands On                                                 | 02:39 |
|                                                                                    | Lambda External Dependencies                                                | 01:12 |
|                                                                                    | Lambda External Dependencies - Hands On                                     | 08:44 |
|                                                                                    | Lambda and CloudFormation                                                   | 02:56 |
|                                                                                    | Lambda and CloudFormation - Hands On                                        | 06:05 |
|                                                                                    | [DVA-C02] Lambda Container Images                                           | 04:40 |
|                                                                                    | Lambda Versions and Aliases                                                 | 03:04 |
|                                                                                    | Lambda Versions and Aliases - Hands On                                      | 05:47 |
|                                                                                    | [DVA-C02] Lambda and CodeDeploy                                             | 02:51 |
|                                                                                    | [DVA-C02] Lambda Function URL                                               | 03:55 |
|                                                                                    | [DVA-C02] Lambda Function URL - Hands On                                    | 02:49 |
|                                                                                    | [DVA-C02] Lambda - CodeGuru Integration                                     | 00:57 |
|                                                                                    | Lambda Limits                                                               | 01:44 |
|                                                                                    | Lambda Best Practices                                                       | 01:12 |
|                                                                                    | Lambda Quiz • 26 问题                                                       |
| **AWS Serverless: DynamoDB**                                                       | 25 个讲座 • 1 小时 47 分钟                                                  |
|                                                                                    | DynamoDB - Section Introduction                                             | 00:43 |
|                                                                                    | DynamoDB Overview                                                           | 07:47 |
|                                                                                    | DynamoDB Basics - Hands On                                                  | 08:42 |
|                                                                                    | DynamoDB WCU & RCU - Throughput                                             | 11:05 |
|                                                                                    | DynamoDB WCU & RCU - Hands On                                               | 04:06 |
|                                                                                    | [DVA-C02] DynamoDB - Basic Operations                                       | 07:54 |
|                                                                                    | DynamoDB Basic APIs - Hands On                                              | 03:10 |
|                                                                                    | [DVA-C02] DynamoDB - Conditional Writes                                     | 05:36 |
|                                                                                    | DynamoDB Indexes (GSI + LSI)                                                | 04:09 |
|                                                                                    | DynamoDB Indexes (GSI + LSI) - Hands On                                     | 03:51 |
|                                                                                    | DynamoDB PartiQL                                                            | 03:11 |
|                                                                                    | DynamoDB Optimistic Locking                                                 | 01:46 |
|                                                                                    | DynamoDB DAX                                                                | 02:45 |
|                                                                                    | DynamoDB DAX - Hands On                                                     | 04:08 |
|                                                                                    | DynamoDB Streams                                                            | 04:26 |
|                                                                                    | DynamoDB Streams - Hands On                                                 | 05:38 |
|                                                                                    | DynamoDB TTL                                                                | 05:20 |
|                                                                                    | DynamoDB CLI                                                                | 05:15 |
|                                                                                    | DynamoDB Transactions                                                       | 03:37 |
|                                                                                    | DynamoDB Session State                                                      | 02:20 |
|                                                                                    | DynamoDB Partitioning Strategies                                            | 01:20 |
|                                                                                    | DynamoDB Conditional Writes, Concurrent Writes & Atomic Writes              | 01:55 |
|                                                                                    | DynamoDB Patterns with S3                                                   | 02:46 |
|                                                                                    | DynamoDB Operations                                                         | 01:50 |
|                                                                                    | DynamoDB Security & Other                                                   | 03:29 |
|                                                                                    | DynamoDB Quiz • 27 问题                                                     |
| **AWS Serverless: API Gateway**                                                    | 21 个讲座 • 1 小时 42 分钟                                                  |
|                                                                                    | API Gateway - Section Introduction                                          | 00:43 |
|                                                                                    | API Gateway Overview                                                        | 06:37 |
|                                                                                    | API Gateway Basics Hands On                                                 | 09:32 |
|                                                                                    | [DVA-C02] API Gateway Stages and Deployment                                 | 04:01 |
|                                                                                    | API Gateway Stages and Deployment Hands On                                  | 07:51 |
|                                                                                    | API Gateway Stages Configurations Hands On                                  | 01:24 |
|                                                                                    | API Gateway Canary Deployments                                              | 01:17 |
|                                                                                    | API Gateway Canary Deployments Hands On                                     | 03:42 |
|                                                                                    | [DVA-C02] API Gateway Integration Types & Mappings                          | 05:53 |
|                                                                                    | API Gateway Mapping Templates Hands On                                      | 03:56 |
|                                                                                    | [DVA-C02] API Gateway Open API                                              | 02:51 |
|                                                                                    | [DVA-C02] API Gateway Open API - Hands On                                   | 01:49 |
|                                                                                    | API Gateway Caching                                                         | 04:07 |
|                                                                                    | API Gateway Usage Plans & API Keys                                          | 08:17 |
|                                                                                    | [DVA-C02] API Gateway Monitoring, Logging and Tracing                       | 05:03 |
|                                                                                    | API Gateway CORS & Hands On                                                 | 08:33 |
|                                                                                    | API Gateway Authentication and Authorization                                | 08:31 |
|                                                                                    | API Gateway REST API vs HTTP API                                            | 01:23 |
|                                                                                    | API Gateway Websocket API                                                   | 06:44 |
|                                                                                    | API Gateway Websocket API Hands On                                          | 08:00 |
|                                                                                    | API Gateway - Architecture                                                  | 01:44 |
|                                                                                    | API Gateway Quiz • 17 问题                                                  |
| **AWS Serverless: SAM - Serverless Application Model**                             | 14 个讲座 • 1 小时 4 分钟                                                   |
|                                                                                    | AWS SAM - Section Introduction                                              | 00:50 |
|                                                                                    | SAM Overview                                                                | 04:06 |
|                                                                                    | Installing the SAM CLI                                                      | 01:54 |
|                                                                                    | Creating first SAM Project                                                  | 04:12 |
|                                                                                    | Deploying SAM Project                                                       | 06:05 |
|                                                                                    | SAM API Gateway                                                             | 06:24 |
|                                                                                    | SAM DynamoDB                                                                | 08:34 |
|                                                                                    | SAM - CloudFormation Designer and Application Repository                    | 02:36 |
|                                                                                    | SAM Policy Templates                                                        | 02:10 |
|                                                                                    | SAM with CodeDeploy                                                         | 08:57 |
|                                                                                    | [DVA-C02] SAM - Local Capabilities                                          | 02:00 |
|                                                                                    | SAM Section Summary                                                         | 00:53 |
|                                                                                    | Serverless Application Repository (SAR)                                     | 01:21 |
|                                                                                    | Serverless Application Repository (SAR) - Hands On                          | 13:33 |
|                                                                                    | SAM Quiz • 6 问题                                                           |
| **Cloud Development Kit (CDK)**                                                    | 5 个讲座 • 26 分钟                                                          |
|                                                                                    | CDK Overview                                                                | 04:51 |
|                                                                                    | CDK - Hands On                                                              | 11:33 |
|                                                                                    | [DVA-C02] CDK - Constructs                                                  | 03:58 |
|                                                                                    | [DVA-C02] CDK - Commands & Bootstraping                                     | 02:42 |
|                                                                                    | [DVA-C02] CDK - Unit Testing                                                | 02:27 |
|                                                                                    | CDK Quiz • 1 问题                                                           |
| **Cognito: Cognito User Pools, Cognito Identity Pools & Cognito Sync**             | 8 个讲座 • 43 分钟                                                          |
|                                                                                    | [DVA-C02] Cognito Overview                                                  | 01:20 |
|                                                                                    | Cognito User Pools                                                          | 03:25 |
|                                                                                    | [DVA-C02] Cognito User Pools Hands On                                       | 10:23 |
|                                                                                    | [DVA-C02] Cognito User Pools - Others                                       | 06:09 |
|                                                                                    | [DVA-C02] Application Load Balancer - User Authentication                   | 05:10 |
|                                                                                    | Cognito Identity Pools                                                      | 07:16 |
|                                                                                    | Cognito Identity Pools Hands On                                             | 05:15 |
|                                                                                    | [DVA-C02] Cognito User Pools vs Cognito Identity Pools                      | 03:36 |
|                                                                                    | Cognito Quiz • 7 问题                                                       |
| **Other Serverless: Step Functions & AppSync**                                     | 11 个讲座 • 56 分钟                                                         |
|                                                                                    | Step Functions Overview                                                     | 04:59 |
|                                                                                    | Step Functions - Hands On                                                   | 07:51 |
|                                                                                    | Step Functions - Error Handling                                             | 06:25 |
|                                                                                    | Step Functions - Error Handling Hands On                                    | 05:49 |
|                                                                                    | [DVA-C02] Step Functions - Wait For Task Token                              | 02:38 |
|                                                                                    | [DVA-C02] Step Functions - Activity Tasks                                   | 03:22 |
|                                                                                    | [DVA-C02] Step Functions - Standard vs Express                              | 03:32 |
|                                                                                    | [DVA-C02] AppSync Overview                                                  | 04:30 |
|                                                                                    | AppSync Hands On                                                            | 05:27 |
|                                                                                    | [DVA-C02] AWS Amplify                                                       | 04:59 |
|                                                                                    | AWS Amplify - Hands On                                                      | 06:56 |
|                                                                                    | Other Serverless Quiz • 6 问题                                              |
| **Advanced Identity**                                                              | 4 个讲座 • 23 分钟                                                          |
|                                                                                    | STS Overview                                                                | 03:43 |
|                                                                                    | Advanced IAM                                                                | 10:17 |
|                                                                                    | Granting a User Permissions to Pass a Role to an AWS Service                | 03:39 |
|                                                                                    | AWS Directory Services                                                      | 05:33 |
|                                                                                    | Advanced IAM Quiz • 5 问题                                                  |
| **AWS Security & Encryption: KMS, Encryption SDK, SSM Parameter Store, IAM & STS** | 21 个讲座 • 1 小时 39 分钟                                                  |
|                                                                                    | AWS Security - Section Introduction                                         | 00:44 |
|                                                                                    | Encryption 101                                                              | 05:18 |
|                                                                                    | [DVA-C02] KMS Overview                                                      | 07:28 |
|                                                                                    | KMS Hands On w/ CLI                                                         | 09:13 |
|                                                                                    | KMS Encryption Patterns and Envelope Encryption                             | 07:28 |
|                                                                                    | Encryption SDK CLI Hands On                                                 | 05:54 |
|                                                                                    | KMS Limits                                                                  | 02:49 |
|                                                                                    | KMS and AWS Lambda Practice                                                 | 05:45 |
|                                                                                    | S3 Bucket Key                                                               | 02:53 |
|                                                                                    | [DVA-C02] KMS Key Policies & IAM Principals                                 | 02:19 |
|                                                                                    | [DVA-C02] CloudHSM Overview                                                 | 05:04 |
|                                                                                    | SSM Parameter Store Overview                                                | 04:16 |
|                                                                                    | SSM Parameter Store Hands On (CLI)                                          | 07:11 |
|                                                                                    | SSM Parameter Store Hands On (AWS Lambda)                                   | 10:02 |
|                                                                                    | Secrets Manager - Overview                                                  | 02:10 |
|                                                                                    | Secrets Manager - Hands On                                                  | 05:48 |
|                                                                                    | [DVA-C02] Secrets Manager - CloudFormation Integration                      | 02:11 |
|                                                                                    | SSM Parameter Store vs Secrets Manager                                      | 02:21 |
|                                                                                    | CloudWatch Logs Encryption                                                  | 04:17 |
|                                                                                    | CodeBuild Security                                                          | 02:42 |
|                                                                                    | [DVA-C02] AWS Nitro Enclaves                                                | 02:40 |
|                                                                                    | AWS Security & Encryption Quiz • 16 问题                                    |
| **AWS Other Services**                                                             | 10 个讲座 • 32 分钟                                                         |
|                                                                                    | AWS Other Services - Section Introduction                                   | 00:36 |
|                                                                                    | AWS SES                                                                     | 00:46 |
|                                                                                    | [DVA-C02] Amazon OpenSearch Service - Overview                              | 03:41 |
|                                                                                    | [DVA-C02] Amazon Athena - Overview                                          | 05:27 |
|                                                                                    | [DVA-C02] Amazon Athena - Hands On                                          | 05:16 |
|                                                                                    | [DVA-C02] Amazon MSK - Overview                                             | 03:50 |
|                                                                                    | Amazon Certificate Manager (ACM)                                            | 01:29 |
|                                                                                    | Amazon Certificate Manager (ACM) Hands On                                   | 06:27 |
|                                                                                    | [DVA-C02] ACM Private CA - Overview                                         | 01:42 |
|                                                                                    | [DVA-C02] AWS AppConfig - Overview                                          | 02:44 |
|                                                                                    | Other Services Quiz • 4 问题                                                |
| **AWS Final Cleanup**                                                              | 2 个讲座 • 3 分钟                                                           |
|                                                                                    | AWS Final Cleanup                                                           | 02:59 |
|                                                                                    | Cleanup Checklist                                                           | 00:20 |
| **Preparing for the Exam - AWS Certified Developer Associate**                     | 6 个讲座 • 22 分钟                                                          |
|                                                                                    | Exam Preparation - Section Introduction                                     | 00:31 |
|                                                                                    | State of Learning Checkpoint                                                | 06:26 |
|                                                                                    | Exam Tips - AWS Certified Developer Associate                               | 08:10 |
|                                                                                    | Exam Walkthrough and Signup                                                 | 03:35 |
|                                                                                    | Save 50% on your AWS Exam Cost!                                             | 01:41 |
|                                                                                    | Get an Extra 30 Minutes on your AWS Exam - Non Native English Speakers only | 01:09 |
|                                                                                    | Practice Test - AWS Certified Developer Associate • 65 问题                 |
| **Congratulations - AWS Certified Developer Associate**                            | 3 个讲座 • 4 分钟                                                           |
|                                                                                    | Congratulations - AWS Certified Developer Associate                         | 01:07 |
|                                                                                    | THANK YOU!                                                                  | 01:32 |
|                                                                                    | Bonus Lecture                                                               | 00:58 |
